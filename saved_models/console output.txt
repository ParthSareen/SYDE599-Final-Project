4 Training loss: 0.353165
Epoch: 2 2400/3904 Training loss: 0.732257
Epoch: 2 3200/3904 Training loss: 0.492125
Training loss: 0.611743
Test loss: 1.022778; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 3 0/3904 Training loss: 0.556295
Epoch: 3 800/3904 Training loss: 0.577427
Epoch: 3 1600/3904 Training loss: 0.291339
Epoch: 3 2400/3904 Training loss: 0.968765
Epoch: 3 3200/3904 Training loss: 0.420623
Training loss: 0.536358
Test loss: 1.216761; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 4 0/3904 Training loss: 0.500588
Epoch: 4 800/3904 Training loss: 0.508950
Epoch: 4 1600/3904 Training loss: 0.235736
Epoch: 4 2400/3904 Training loss: 0.812022
Epoch: 4 3200/3904 Training loss: 0.456401
Training loss: 0.486790
Test loss: 1.474394; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 5 0/3904 Training loss: 0.513696
Epoch: 5 800/3904 Training loss: 0.500729
Epoch: 5 1600/3904 Training loss: 0.168562
Epoch: 5 2400/3904 Training loss: 0.883152
Epoch: 5 3200/3904 Training loss: 0.350036
Training loss: 0.450395
Test loss: 0.747481; True positive: 497; True negative: 178, False Positive: 87, False negative: 406, accuracy: 0.5779109589041096, precision: 0.851027397260274, recall: 0.5503875968992248
Epoch: 6 0/3904 Training loss: 0.399480
Epoch: 6 800/3904 Training loss: 0.427732
Epoch: 6 1600/3904 Training loss: 0.133383
Epoch: 6 2400/3904 Training loss: 1.113602
Epoch: 6 3200/3904 Training loss: 0.386674
Training loss: 0.418630
Test loss: 0.480855; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 7 0/3904 Training loss: 0.504517
Epoch: 7 800/3904 Training loss: 0.453733
Epoch: 7 1600/3904 Training loss: 0.159101
Epoch: 7 2400/3904 Training loss: 0.840474
Epoch: 7 3200/3904 Training loss: 0.519216
Training loss: 0.394738
Test loss: 0.479255; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 8 0/3904 Training loss: 0.408377
Epoch: 8 800/3904 Training loss: 0.346797
Epoch: 8 1600/3904 Training loss: 0.124312
Epoch: 8 2400/3904 Training loss: 0.838988
Epoch: 8 3200/3904 Training loss: 0.419565
Training loss: 0.377782
Test loss: 0.479790; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 9 0/3904 Training loss: 0.611083
Epoch: 9 800/3904 Training loss: 0.369087
Epoch: 9 1600/3904 Training loss: 0.096822
Epoch: 9 2400/3904 Training loss: 0.811049
Epoch: 9 3200/3904 Training loss: 0.324190
Training loss: 0.363277
Test loss: 0.481747; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 10 0/3904 Training loss: 0.277972
Epoch: 10 800/3904 Training loss: 0.370497
Epoch: 10 1600/3904 Training loss: 0.248093
Epoch: 10 2400/3904 Training loss: 0.741570
Epoch: 10 3200/3904 Training loss: 0.545165
Training loss: 0.359366
Test loss: 0.488041; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 11 0/3904 Training loss: 0.437296
Epoch: 11 800/3904 Training loss: 0.393996
Epoch: 11 1600/3904 Training loss: 0.194386
Epoch: 11 2400/3904 Training loss: 0.603508
Epoch: 11 3200/3904 Training loss: 0.417873
Training loss: 0.340040
Test loss: 0.496839; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 12 0/3904 Training loss: 0.389872
Epoch: 12 800/3904 Training loss: 0.392678
Epoch: 12 1600/3904 Training loss: 0.123343
Epoch: 12 2400/3904 Training loss: 0.378499
Epoch: 12 3200/3904 Training loss: 0.508231
Training loss: 0.332893
Test loss: 0.500055; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 13 0/3904 Training loss: 0.255692
Epoch: 13 800/3904 Training loss: 0.251802
Epoch: 13 1600/3904 Training loss: 0.096944
Epoch: 13 2400/3904 Training loss: 0.317167
Epoch: 13 3200/3904 Training loss: 0.407004
Training loss: 0.322961
Test loss: 0.504742; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 14 0/3904 Training loss: 0.368942
Epoch: 14 800/3904 Training loss: 0.384871
Epoch: 14 1600/3904 Training loss: 0.086546
Epoch: 14 2400/3904 Training loss: 0.452431
Epoch: 14 3200/3904 Training loss: 0.460880
Training loss: 0.329986
Test loss: 0.507332; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 15 0/3904 Training loss: 0.264387
Epoch: 15 800/3904 Training loss: 0.258238
Epoch: 15 1600/3904 Training loss: 0.102029
Epoch: 15 2400/3904 Training loss: 0.543539
Epoch: 15 3200/3904 Training loss: 0.388289
Training loss: 0.315329
Test loss: 0.515279; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 16 0/3904 Training loss: 0.205679
Epoch: 16 800/3904 Training loss: 0.225347
Epoch: 16 1600/3904 Training loss: 0.108014
Epoch: 16 2400/3904 Training loss: 0.383425
Epoch: 16 3200/3904 Training loss: 0.309435
Training loss: 0.305265
Test loss: 0.522041; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 17 0/3904 Training loss: 0.237337
Epoch: 17 800/3904 Training loss: 0.311870
Epoch: 17 1600/3904 Training loss: 0.133292
Epoch: 17 2400/3904 Training loss: 0.325451
Epoch: 17 3200/3904 Training loss: 0.425265
Training loss: 0.305029
Test loss: 0.523543; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
starting trial 157
[I 2022-12-05 04:03:12,050] Trial 156 finished with value: 0.8176369863013698 and parameters: {'d_model': 16, 'nhead': 8, 'n_encoders': 3, 'learning_rate': 0.0001461462493390673, 'weight_decay': 2.801880481998442e-06, 'dropout': 0.17100475376543775, 'max_pool_conv': 32, 'kernel_size': 10, 'd_mlp': 62, 'num_conv_layers': 2, 'encoder_dropout': 0.08455615293755214, 'd_feed_forward': 128, 'max_pool_dim': 16, 'n_mlp_layers': 3}. Best is trial 62 with value: 0.860445205479452.
Epoch: 0 0/3904 Training loss: 0.698297
Epoch: 0 800/3904 Training loss: 0.719940
Epoch: 0 1600/3904 Training loss: 0.493680
Epoch: 0 2400/3904 Training loss: 0.818881
Epoch: 0 3200/3904 Training loss: 0.558408
Training loss: 0.667741
Test loss: 0.866623; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 1 0/3904 Training loss: 0.725765
Epoch: 1 800/3904 Training loss: 0.754996
Epoch: 1 1600/3904 Training loss: 0.473914
Epoch: 1 2400/3904 Training loss: 0.822498
Epoch: 1 3200/3904 Training loss: 0.546316
Training loss: 0.656913
Test loss: 0.934876; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 2 0/3904 Training loss: 0.741322
Epoch: 2 800/3904 Training loss: 0.748533
Epoch: 2 1600/3904 Training loss: 0.382906
Epoch: 2 2400/3904 Training loss: 0.745634
Epoch: 2 3200/3904 Training loss: 0.509803
Training loss: 0.637236
Test loss: 0.955077; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 3 0/3904 Training loss: 0.680587
Epoch: 3 800/3904 Training loss: 0.685520
Epoch: 3 1600/3904 Training loss: 0.314317
Epoch: 3 2400/3904 Training loss: 0.595036
Epoch: 3 3200/3904 Training loss: 0.435526
Training loss: 0.580392
Test loss: 1.742314; True positive: 65; True negative: 148, False Positive: 117, False negative: 838, accuracy: 0.18236301369863014, precision: 0.35714285714285715, recall: 0.07198228128460686
Epoch: 4 0/3904 Training loss: 0.567661
Epoch: 4 800/3904 Training loss: 0.691003
Epoch: 4 1600/3904 Training loss: 0.247046
Epoch: 4 2400/3904 Training loss: 0.663673
Epoch: 4 3200/3904 Training loss: 0.350635
Training loss: 0.514354
Test loss: 1.966385; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 5 0/3904 Training loss: 0.475558
Epoch: 5 800/3904 Training loss: 0.489546
Epoch: 5 1600/3904 Training loss: 0.285708
Epoch: 5 2400/3904 Training loss: 0.554134
Epoch: 5 3200/3904 Training loss: 0.402802
Training loss: 0.468106
Test loss: 2.098516; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 6 0/3904 Training loss: 0.367501
Epoch: 6 800/3904 Training loss: 0.363189
Epoch: 6 1600/3904 Training loss: 0.305163
Epoch: 6 2400/3904 Training loss: 0.420699
Epoch: 6 3200/3904 Training loss: 0.477988
Training loss: 0.436105
Test loss: 2.149506; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 7 0/3904 Training loss: 0.376083
Epoch: 7 800/3904 Training loss: 0.435307
Epoch: 7 1600/3904 Training loss: 0.183358
Epoch: 7 2400/3904 Training loss: 0.450707
Epoch: 7 3200/3904 Training loss: 0.418396
Training loss: 0.421467
Test loss: 2.122369; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 8 0/3904 Training loss: 0.358514
Epoch: 8 800/3904 Training loss: 0.394802
Epoch: 8 1600/3904 Training loss: 0.250808
Epoch: 8 2400/3904 Training loss: 0.347490
Epoch: 8 3200/3904 Training loss: 0.378189
Training loss: 0.410728
Test loss: 2.071140; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 9 0/3904 Training loss: 0.339427
Epoch: 9 800/3904 Training loss: 0.432953
Epoch: 9 1600/3904 Training loss: 0.302331
Epoch: 9 2400/3904 Training loss: 0.442259
Epoch: 9 3200/3904 Training loss: 0.387983
Training loss: 0.384953
Test loss: 2.192170; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 10 0/3904 Training loss: 0.388360
Epoch: 10 800/3904 Training loss: 0.435651
Epoch: 10 1600/3904 Training loss: 0.274290
Epoch: 10 2400/3904 Training loss: 0.428618
Epoch: 10 3200/3904 Training loss: 0.368208
Training loss: 0.375101
Test loss: 2.214378; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
starting trial 158
[I 2022-12-05 04:04:00,779] Trial 157 finished with value: 0.2268835616438356 and parameters: {'d_model': 64, 'nhead': 8, 'n_encoders': 1, 'learning_rate': 8.865785157088794e-05, 'weight_decay': 1.5678582151175188e-05, 'dropout': 0.4554646925087032, 'max_pool_conv': 64, 'kernel_size': 9, 'd_mlp': 32, 'num_conv_layers': 3, 'encoder_dropout': 0.0640688261918483, 'd_feed_forward': 128, 'max_pool_dim': 8, 'n_mlp_layers': 3}. Best is trial 62 with value: 0.860445205479452.
Epoch: 0 0/3904 Training loss: 0.689628
Epoch: 0 800/3904 Training loss: 0.710936
Epoch: 0 1600/3904 Training loss: 0.618968
Epoch: 0 2400/3904 Training loss: 0.774908
Epoch: 0 3200/3904 Training loss: 0.562094
Training loss: 0.672423
Test loss: 0.666855; True positive: 630; True negative: 187, False Positive: 78, False negative: 273, accuracy: 0.699486301369863, precision: 0.8898305084745762, recall: 0.6976744186046512
Epoch: 1 0/3904 Training loss: 0.705263
Epoch: 1 800/3904 Training loss: 0.705231
Epoch: 1 1600/3904 Training loss: 0.530218
Epoch: 1 2400/3904 Training loss: 0.862495
Epoch: 1 3200/3904 Training loss: 0.607377
Training loss: 0.660883
Test loss: 0.704271; True positive: 317; True negative: 238, False Positive: 27, False negative: 586, accuracy: 0.4751712328767123, precision: 0.9215116279069767, recall: 0.35105204872646734
Epoch: 2 0/3904 Training loss: 0.735418
Epoch: 2 800/3904 Training loss: 0.708334
Epoch: 2 1600/3904 Training loss: 0.490663
Epoch: 2 2400/3904 Training loss: 0.788171
Epoch: 2 3200/3904 Training loss: 0.570024
Training loss: 0.662527
Test loss: 0.734563; True positive: 121; True negative: 256, False Positive: 9, False negative: 782, accuracy: 0.3227739726027397, precision: 0.9307692307692308, recall: 0.13399778516057587
Epoch: 3 0/3904 Training loss: 0.692863
Epoch: 3 800/3904 Training loss: 0.710835
Epoch: 3 1600/3904 Training loss: 0.520317
Epoch: 3 2400/3904 Training loss: 0.824158
Epoch: 3 3200/3904 Training loss: 0.533592
Training loss: 0.660102
Test loss: 0.751661; True positive: 39; True negative: 259, False Positive: 6, False negative: 864, accuracy: 0.2551369863013699, precision: 0.8666666666666667, recall: 0.04318936877076412
Epoch: 4 0/3904 Training loss: 0.689966
Epoch: 4 800/3904 Training loss: 0.775959
Epoch: 4 1600/3904 Training loss: 0.487773
Epoch: 4 2400/3904 Training loss: 0.837126
Epoch: 4 3200/3904 Training loss: 0.526892
Training loss: 0.659449
Test loss: 0.785482; True positive: 3; True negative: 265, False Positive: 0, False negative: 900, accuracy: 0.22945205479452055, precision: 1.0, recall: 0.0033222591362126247
Epoch: 5 0/3904 Training loss: 0.733648
Epoch: 5 800/3904 Training loss: 0.735035
Epoch: 5 1600/3904 Training loss: 0.519949
Epoch: 5 2400/3904 Training loss: 0.801369
Epoch: 5 3200/3904 Training loss: 0.539317
Training loss: 0.655348
Test loss: 0.808466; True positive: 2; True negative: 265, False Positive: 0, False negative: 901, accuracy: 0.2285958904109589, precision: 1.0, recall: 0.0022148394241417496
Epoch: 6 0/3904 Training loss: 0.683088
Epoch: 6 800/3904 Training loss: 0.692761
Epoch: 6 1600/3904 Training loss: 0.529267
Epoch: 6 2400/3904 Training loss: 0.802746
Epoch: 6 3200/3904 Training loss: 0.541590
Training loss: 0.649273
Test loss: 0.863501; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 7 0/3904 Training loss: 0.677409
Epoch: 7 800/3904 Training loss: 0.687771
Epoch: 7 1600/3904 Training loss: 0.501955
Epoch: 7 2400/3904 Training loss: 0.796220
Epoch: 7 3200/3904 Training loss: 0.565505
Training loss: 0.640184
Test loss: 0.935302; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 8 0/3904 Training loss: 0.676301
Epoch: 8 800/3904 Training loss: 0.707443
Epoch: 8 1600/3904 Training loss: 0.515978
Epoch: 8 2400/3904 Training loss: 0.852964
Epoch: 8 3200/3904 Training loss: 0.566132
Training loss: 0.632411
Test loss: 1.016099; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 9 0/3904 Training loss: 0.630636
Epoch: 9 800/3904 Training loss: 0.660584
Epoch: 9 1600/3904 Training loss: 0.396789
Epoch: 9 2400/3904 Training loss: 0.803688
Epoch: 9 3200/3904 Training loss: 0.482595
Training loss: 0.618081
Test loss: 1.118669; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 10 0/3904 Training loss: 0.677740
Epoch: 10 800/3904 Training loss: 0.615939
Epoch: 10 1600/3904 Training loss: 0.435171
Epoch: 10 2400/3904 Training loss: 0.774397
Epoch: 10 3200/3904 Training loss: 0.567538
Training loss: 0.608977
Test loss: 1.193101; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
starting trial 159
[I 2022-12-05 04:04:42,466] Trial 158 finished with value: 0.699486301369863 and parameters: {'d_model': 16, 'nhead': 4, 'n_encoders': 3, 'learning_rate': 3.540092573280951e-05, 'weight_decay': 3.8206782417810405e-06, 'dropout': 0.21637286641724857, 'max_pool_conv': 128, 'kernel_size': 7, 'd_mlp': 16, 'num_conv_layers': 2, 'encoder_dropout': 0.1112541231489824, 'd_feed_forward': 256, 'max_pool_dim': 16, 'n_mlp_layers': 2}. Best is trial 62 with value: 0.860445205479452.
Epoch: 0 0/3904 Training loss: 0.691319
Epoch: 0 800/3904 Training loss: 0.705954
Epoch: 0 1600/3904 Training loss: 0.621670
Epoch: 0 2400/3904 Training loss: 0.734682
Epoch: 0 3200/3904 Training loss: 0.633576
Training loss: 0.674300
Test loss: 0.768836; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 1 0/3904 Training loss: 0.699518
Epoch: 1 800/3904 Training loss: 0.716233
Epoch: 1 1600/3904 Training loss: 0.587768
Epoch: 1 2400/3904 Training loss: 0.752780
Epoch: 1 3200/3904 Training loss: 0.609813
Training loss: 0.666992
Test loss: 0.782952; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 2 0/3904 Training loss: 0.708121
Epoch: 2 800/3904 Training loss: 0.720176
Epoch: 2 1600/3904 Training loss: 0.555748
Epoch: 2 2400/3904 Training loss: 0.768201
Epoch: 2 3200/3904 Training loss: 0.593485
Training loss: 0.661707
Test loss: 0.812252; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 3 0/3904 Training loss: 0.709132
Epoch: 3 800/3904 Training loss: 0.734298
Epoch: 3 1600/3904 Training loss: 0.527586
Epoch: 3 2400/3904 Training loss: 0.784591
Epoch: 3 3200/3904 Training loss: 0.575564
Training loss: 0.656945
Test loss: 0.859604; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 4 0/3904 Training loss: 0.708216
Epoch: 4 800/3904 Training loss: 0.726519
Epoch: 4 1600/3904 Training loss: 0.493921
Epoch: 4 2400/3904 Training loss: 0.752112
Epoch: 4 3200/3904 Training loss: 0.533210
Training loss: 0.643523
Test loss: 0.890555; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 5 0/3904 Training loss: 0.684113
Epoch: 5 800/3904 Training loss: 0.678464
Epoch: 5 1600/3904 Training loss: 0.440347
Epoch: 5 2400/3904 Training loss: 0.735082
Epoch: 5 3200/3904 Training loss: 0.466106
Training loss: 0.602882
Test loss: 0.979302; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 6 0/3904 Training loss: 0.630670
Epoch: 6 800/3904 Training loss: 0.639382
Epoch: 6 1600/3904 Training loss: 0.355730
Epoch: 6 2400/3904 Training loss: 0.781613
Epoch: 6 3200/3904 Training loss: 0.433562
Training loss: 0.550795
Test loss: 1.104733; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 7 0/3904 Training loss: 0.638058
Epoch: 7 800/3904 Training loss: 0.554367
Epoch: 7 1600/3904 Training loss: 0.316995
Epoch: 7 2400/3904 Training loss: 0.675491
Epoch: 7 3200/3904 Training loss: 0.420154
Training loss: 0.517053
Test loss: 1.216008; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 8 0/3904 Training loss: 0.561244
Epoch: 8 800/3904 Training loss: 0.503944
Epoch: 8 1600/3904 Training loss: 0.279845
Epoch: 8 2400/3904 Training loss: 0.556079
Epoch: 8 3200/3904 Training loss: 0.418339
Training loss: 0.482883
Test loss: 1.314525; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 9 0/3904 Training loss: 0.586440
Epoch: 9 800/3904 Training loss: 0.443165
Epoch: 9 1600/3904 Training loss: 0.269168
Epoch: 9 2400/3904 Training loss: 0.462995
Epoch: 9 3200/3904 Training loss: 0.454861
Training loss: 0.456417
Test loss: 1.389951; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 10 0/3904 Training loss: 0.526011
Epoch: 10 800/3904 Training loss: 0.475546
Epoch: 10 1600/3904 Training loss: 0.255107
Epoch: 10 2400/3904 Training loss: 0.463172
Epoch: 10 3200/3904 Training loss: 0.439432
Training loss: 0.436364
Test loss: 1.455400; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
starting trial 160
[I 2022-12-05 04:06:18,532] Trial 159 finished with value: 0.2268835616438356 and parameters: {'d_model': 64, 'nhead': 8, 'n_encoders': 2, 'learning_rate': 2.3466339432018607e-05, 'weight_decay': 5.852154627269784e-06, 'dropout': 0.28890248500323723, 'max_pool_conv': 64, 'kernel_size': 16, 'd_mlp': 16, 'num_conv_layers': 4, 'encoder_dropout': 0.012713712468840017, 'd_feed_forward': 128, 'max_pool_dim': 8, 'n_mlp_layers': 4}. Best is trial 62 with value: 0.860445205479452.
Epoch: 0 0/3904 Training loss: 0.709492
Epoch: 0 800/3904 Training loss: 0.680812
Epoch: 0 1600/3904 Training loss: 0.684761
Epoch: 0 2400/3904 Training loss: 0.719188
Epoch: 0 3200/3904 Training loss: 0.687849
Training loss: 0.687567
Test loss: 0.726753; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 1 0/3904 Training loss: 0.679891
Epoch: 1 800/3904 Training loss: 0.688915
Epoch: 1 1600/3904 Training loss: 0.644709
Epoch: 1 2400/3904 Training loss: 0.720852
Epoch: 1 3200/3904 Training loss: 0.608538
Training loss: 0.675950
Test loss: 0.759222; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 2 0/3904 Training loss: 0.715772
Epoch: 2 800/3904 Training loss: 0.732500
Epoch: 2 1600/3904 Training loss: 0.606522
Epoch: 2 2400/3904 Training loss: 0.760770
Epoch: 2 3200/3904 Training loss: 0.610026
Training loss: 0.669093
Test loss: 0.787971; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 3 0/3904 Training loss: 0.730316
Epoch: 3 800/3904 Training loss: 0.729980
Epoch: 3 1600/3904 Training loss: 0.559720
Epoch: 3 2400/3904 Training loss: 0.770465
Epoch: 3 3200/3904 Training loss: 0.608222
Training loss: 0.663722
Test loss: 0.811707; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 4 0/3904 Training loss: 0.735036
Epoch: 4 800/3904 Training loss: 0.734258
Epoch: 4 1600/3904 Training loss: 0.523226
Epoch: 4 2400/3904 Training loss: 0.769160
Epoch: 4 3200/3904 Training loss: 0.594958
Training loss: 0.662246
Test loss: 0.829218; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 5 0/3904 Training loss: 0.707682
Epoch: 5 800/3904 Training loss: 0.745220
Epoch: 5 1600/3904 Training loss: 0.531702
Epoch: 5 2400/3904 Training loss: 0.807311
Epoch: 5 3200/3904 Training loss: 0.580171
Training loss: 0.660418
Test loss: 0.841429; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 6 0/3904 Training loss: 0.725458
Epoch: 6 800/3904 Training loss: 0.770425
Epoch: 6 1600/3904 Training loss: 0.507513
Epoch: 6 2400/3904 Training loss: 0.798061
Epoch: 6 3200/3904 Training loss: 0.588075
Training loss: 0.660143
Test loss: 0.850549; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 7 0/3904 Training loss: 0.718361
Epoch: 7 800/3904 Training loss: 0.755893
Epoch: 7 1600/3904 Training loss: 0.504098
Epoch: 7 2400/3904 Training loss: 0.805075
Epoch: 7 3200/3904 Training loss: 0.586587
Training loss: 0.660398
Test loss: 0.856266; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 8 0/3904 Training loss: 0.748834
Epoch: 8 800/3904 Training loss: 0.733167
Epoch: 8 1600/3904 Training loss: 0.540445
Epoch: 8 2400/3904 Training loss: 0.828869
Epoch: 8 3200/3904 Training loss: 0.563586
Training loss: 0.659172
Test loss: 0.860530; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 9 0/3904 Training loss: 0.733920
Epoch: 9 800/3904 Training loss: 0.764633
Epoch: 9 1600/3904 Training loss: 0.530831
Epoch: 9 2400/3904 Training loss: 0.805584
Epoch: 9 3200/3904 Training loss: 0.580477
Training loss: 0.660530
Test loss: 0.863512; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 10 0/3904 Training loss: 0.702017
Epoch: 10 800/3904 Training loss: 0.779174
Epoch: 10 1600/3904 Training loss: 0.517926
Epoch: 10 2400/3904 Training loss: 0.798758
Epoch: 10 3200/3904 Training loss: 0.555753
Training loss: 0.660477
Test loss: 0.865230; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
starting trial 161
[I 2022-12-05 04:07:05,466] Trial 160 finished with value: 0.2268835616438356 and parameters: {'d_model': 16, 'nhead': 8, 'n_encoders': 1, 'learning_rate': 1.1627700810025745e-05, 'weight_decay': 4.294702588288622e-06, 'dropout': 0.4991731323905575, 'max_pool_conv': 64, 'kernel_size': 15, 'd_mlp': 32, 'num_conv_layers': 8, 'encoder_dropout': 0.036356054995961465, 'd_feed_forward': 128, 'max_pool_dim': 8, 'n_mlp_layers': 3}. Best is trial 62 with value: 0.860445205479452.
Epoch: 0 0/3904 Training loss: 0.687443
Epoch: 0 800/3904 Training loss: 0.744760
Epoch: 0 1600/3904 Training loss: 0.448607
Epoch: 0 2400/3904 Training loss: 0.801629
Epoch: 0 3200/3904 Training loss: 0.555226
Training loss: 0.663716
Test loss: 0.833236; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 1 0/3904 Training loss: 0.716283
Epoch: 1 800/3904 Training loss: 0.720831
Epoch: 1 1600/3904 Training loss: 0.453571
Epoch: 1 2400/3904 Training loss: 0.775209
Epoch: 1 3200/3904 Training loss: 0.547616
Training loss: 0.658407
Test loss: 0.845620; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 2 0/3904 Training loss: 0.699697
Epoch: 2 800/3904 Training loss: 0.727405
Epoch: 2 1600/3904 Training loss: 0.369082
Epoch: 2 2400/3904 Training loss: 0.574290
Epoch: 2 3200/3904 Training loss: 0.514853
Training loss: 0.630615
Test loss: 0.611049; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 3 0/3904 Training loss: 0.657529
Epoch: 3 800/3904 Training loss: 0.503349
Epoch: 3 1600/3904 Training loss: 0.268491
Epoch: 3 2400/3904 Training loss: 0.461601
Epoch: 3 3200/3904 Training loss: 0.456483
Training loss: 0.556231
Test loss: 0.525078; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 4 0/3904 Training loss: 0.580576
Epoch: 4 800/3904 Training loss: 0.497896
Epoch: 4 1600/3904 Training loss: 0.283909
Epoch: 4 2400/3904 Training loss: 0.494342
Epoch: 4 3200/3904 Training loss: 0.571768
Training loss: 0.505501
Test loss: 0.513680; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 5 0/3904 Training loss: 0.478095
Epoch: 5 800/3904 Training loss: 0.485692
Epoch: 5 1600/3904 Training loss: 0.226465
Epoch: 5 2400/3904 Training loss: 0.499077
Epoch: 5 3200/3904 Training loss: 0.515776
Training loss: 0.470147
Test loss: 0.501441; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 6 0/3904 Training loss: 0.466769
Epoch: 6 800/3904 Training loss: 0.531257
Epoch: 6 1600/3904 Training loss: 0.268607
Epoch: 6 2400/3904 Training loss: 0.411036
Epoch: 6 3200/3904 Training loss: 0.477597
Training loss: 0.451139
Test loss: 0.502894; True positive: 830; True negative: 118, False Positive: 147, False negative: 73, accuracy: 0.8116438356164384, precision: 0.849539406345957, recall: 0.9191583610188261
Epoch: 7 0/3904 Training loss: 0.408412
Epoch: 7 800/3904 Training loss: 0.282180
Epoch: 7 1600/3904 Training loss: 0.244298
Epoch: 7 2400/3904 Training loss: 0.393325
Epoch: 7 3200/3904 Training loss: 0.560662
Training loss: 0.448560
Test loss: 0.495914; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 8 0/3904 Training loss: 0.520236
Epoch: 8 800/3904 Training loss: 0.435844
Epoch: 8 1600/3904 Training loss: 0.220284
Epoch: 8 2400/3904 Training loss: 0.385845
Epoch: 8 3200/3904 Training loss: 0.493813
Training loss: 0.438180
Test loss: 0.493958; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 9 0/3904 Training loss: 0.523872
Epoch: 9 800/3904 Training loss: 0.428978
Epoch: 9 1600/3904 Training loss: 0.233374
Epoch: 9 2400/3904 Training loss: 0.371970
Epoch: 9 3200/3904 Training loss: 0.420871
Training loss: 0.434810
Test loss: 0.516062; True positive: 819; True negative: 122, False Positive: 143, False negative: 84, accuracy: 0.8056506849315068, precision: 0.8513513513513513, recall: 0.9069767441860465
Epoch: 10 0/3904 Training loss: 0.416289
Epoch: 10 800/3904 Training loss: 0.447813
Epoch: 10 1600/3904 Training loss: 0.258295
Epoch: 10 2400/3904 Training loss: 0.353663
Epoch: 10 3200/3904 Training loss: 0.519475
Training loss: 0.427364
Test loss: 1.570733; True positive: 267; True negative: 212, False Positive: 53, False negative: 636, accuracy: 0.4101027397260274, precision: 0.834375, recall: 0.2956810631229236
Epoch: 11 0/3904 Training loss: 0.602194
Epoch: 11 800/3904 Training loss: 0.348411
Epoch: 11 1600/3904 Training loss: 0.255234
Epoch: 11 2400/3904 Training loss: 0.329318
Epoch: 11 3200/3904 Training loss: 0.381674
Training loss: 0.413056
Test loss: 2.625679; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 12 0/3904 Training loss: 0.596553
Epoch: 12 800/3904 Training loss: 0.358356
Epoch: 12 1600/3904 Training loss: 0.218978
Epoch: 12 2400/3904 Training loss: 0.312732
Epoch: 12 3200/3904 Training loss: 0.484059
Training loss: 0.413831
Test loss: 2.313391; True positive: 60; True negative: 250, False Positive: 15, False negative: 843, accuracy: 0.2654109589041096, precision: 0.8, recall: 0.0664451827242525
Epoch: 13 0/3904 Training loss: 0.492964
Epoch: 13 800/3904 Training loss: 0.289190
Epoch: 13 1600/3904 Training loss: 0.221406
Epoch: 13 2400/3904 Training loss: 0.284185
Epoch: 13 3200/3904 Training loss: 0.489136
Training loss: 0.405591
Test loss: 2.620692; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 14 0/3904 Training loss: 0.641940
Epoch: 14 800/3904 Training loss: 0.376505
Epoch: 14 1600/3904 Training loss: 0.222473
Epoch: 14 2400/3904 Training loss: 0.304561
Epoch: 14 3200/3904 Training loss: 0.472527
Training loss: 0.392546
Test loss: 2.669661; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 15 0/3904 Training loss: 0.532407
Epoch: 15 800/3904 Training loss: 0.331493
Epoch: 15 1600/3904 Training loss: 0.223793
Epoch: 15 2400/3904 Training loss: 0.342371
Epoch: 15 3200/3904 Training loss: 0.424793
Training loss: 0.385354
Test loss: 2.605641; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 16 0/3904 Training loss: 0.534569
Epoch: 16 800/3904 Training loss: 0.257042
Epoch: 16 1600/3904 Training loss: 0.232417
Epoch: 16 2400/3904 Training loss: 0.292801
Epoch: 16 3200/3904 Training loss: 0.467465
Training loss: 0.390171
Test loss: 2.508230; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 17 0/3904 Training loss: 0.600075
Epoch: 17 800/3904 Training loss: 0.293218
Epoch: 17 1600/3904 Training loss: 0.184298
Epoch: 17 2400/3904 Training loss: 0.262405
Epoch: 17 3200/3904 Training loss: 0.407912
Training loss: 0.384878
Test loss: 2.597755; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 18 0/3904 Training loss: 0.557296
Epoch: 18 800/3904 Training loss: 0.261950
Epoch: 18 1600/3904 Training loss: 0.222577
Epoch: 18 2400/3904 Training loss: 0.246989
Epoch: 18 3200/3904 Training loss: 0.467035
Training loss: 0.373782
Test loss: 2.488751; True positive: 29; True negative: 243, False Positive: 22, False negative: 874, accuracy: 0.2328767123287671, precision: 0.5686274509803921, recall: 0.03211517165005537
starting trial 162
[I 2022-12-05 04:08:04,451] Trial 161 finished with value: 0.8176369863013698 and parameters: {'d_model': 16, 'nhead': 2, 'n_encoders': 1, 'learning_rate': 0.00023400394155298368, 'weight_decay': 9.535576859172644e-06, 'dropout': 0.12532871196922102, 'max_pool_conv': 128, 'kernel_size': 6, 'd_mlp': 128, 'num_conv_layers': 6, 'encoder_dropout': 0.03461024705256481, 'd_feed_forward': 256, 'max_pool_dim': 16, 'n_mlp_layers': 3}. Best is trial 62 with value: 0.860445205479452.
Epoch: 0 0/3904 Training loss: 0.695815
Epoch: 0 800/3904 Training loss: 0.732810
Epoch: 0 1600/3904 Training loss: 0.458052
Epoch: 0 2400/3904 Training loss: 0.807199
Epoch: 0 3200/3904 Training loss: 0.561276
Training loss: 0.662442
Test loss: 0.866487; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 1 0/3904 Training loss: 0.722702
Epoch: 1 800/3904 Training loss: 0.731744
Epoch: 1 1600/3904 Training loss: 0.394427
Epoch: 1 2400/3904 Training loss: 0.781090
Epoch: 1 3200/3904 Training loss: 0.540474
Training loss: 0.655081
Test loss: 1.041554; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 2 0/3904 Training loss: 0.690509
Epoch: 2 800/3904 Training loss: 0.700621
Epoch: 2 1600/3904 Training loss: 0.335366
Epoch: 2 2400/3904 Training loss: 0.687847
Epoch: 2 3200/3904 Training loss: 0.520376
Training loss: 0.620254
Test loss: 1.507065; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 3 0/3904 Training loss: 0.668050
Epoch: 3 800/3904 Training loss: 0.616470
Epoch: 3 1600/3904 Training loss: 0.302411
Epoch: 3 2400/3904 Training loss: 0.675747
Epoch: 3 3200/3904 Training loss: 0.366653
Training loss: 0.571180
Test loss: 1.846734; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 4 0/3904 Training loss: 0.616104
Epoch: 4 800/3904 Training loss: 0.581037
Epoch: 4 1600/3904 Training loss: 0.247549
Epoch: 4 2400/3904 Training loss: 0.947165
Epoch: 4 3200/3904 Training loss: 0.301030
Training loss: 0.533823
Test loss: 1.934030; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 5 0/3904 Training loss: 0.610685
Epoch: 5 800/3904 Training loss: 0.669223
Epoch: 5 1600/3904 Training loss: 0.223417
Epoch: 5 2400/3904 Training loss: 0.774625
Epoch: 5 3200/3904 Training loss: 0.384968
Training loss: 0.498245
Test loss: 2.092751; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 6 0/3904 Training loss: 0.605980
Epoch: 6 800/3904 Training loss: 0.536840
Epoch: 6 1600/3904 Training loss: 0.224183
Epoch: 6 2400/3904 Training loss: 0.884322
Epoch: 6 3200/3904 Training loss: 0.381554
Training loss: 0.481910
Test loss: 2.190735; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 7 0/3904 Training loss: 0.640272
Epoch: 7 800/3904 Training loss: 0.678180
Epoch: 7 1600/3904 Training loss: 0.205211
Epoch: 7 2400/3904 Training loss: 0.928135
Epoch: 7 3200/3904 Training loss: 0.413546
Training loss: 0.463046
Test loss: 2.227924; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 8 0/3904 Training loss: 0.682449
Epoch: 8 800/3904 Training loss: 0.603851
Epoch: 8 1600/3904 Training loss: 0.183598
Epoch: 8 2400/3904 Training loss: 0.882762
Epoch: 8 3200/3904 Training loss: 0.355264
Training loss: 0.450481
Test loss: 2.272386; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 9 0/3904 Training loss: 0.634957
Epoch: 9 800/3904 Training loss: 0.716946
Epoch: 9 1600/3904 Training loss: 0.136657
Epoch: 9 2400/3904 Training loss: 0.719653
Epoch: 9 3200/3904 Training loss: 0.405095
Training loss: 0.440209
Test loss: 2.365028; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 10 0/3904 Training loss: 0.607689
Epoch: 10 800/3904 Training loss: 0.639700
Epoch: 10 1600/3904 Training loss: 0.230288
Epoch: 10 2400/3904 Training loss: 0.688456
Epoch: 10 3200/3904 Training loss: 0.234185
Training loss: 0.433336
Test loss: 2.442319; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
starting trial 163
[I 2022-12-05 04:08:35,989] Trial 162 finished with value: 0.2268835616438356 and parameters: {'d_model': 16, 'nhead': 2, 'n_encoders': 1, 'learning_rate': 0.0001932976903308003, 'weight_decay': 6.899452089958647e-06, 'dropout': 0.11999473915947488, 'max_pool_conv': 128, 'kernel_size': 5, 'd_mlp': 128, 'num_conv_layers': 5, 'encoder_dropout': 0.027161728957781434, 'd_feed_forward': 256, 'max_pool_dim': 16, 'n_mlp_layers': 3}. Best is trial 62 with value: 0.860445205479452.
Epoch: 0 0/3904 Training loss: 0.701774
Epoch: 0 800/3904 Training loss: 0.689481
Epoch: 0 1600/3904 Training loss: 0.606578
Epoch: 0 2400/3904 Training loss: 0.765279
Epoch: 0 3200/3904 Training loss: 0.582396
Training loss: 0.677906
Test loss: 0.822961; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 1 0/3904 Training loss: 0.727303
Epoch: 1 800/3904 Training loss: 0.732646
Epoch: 1 1600/3904 Training loss: 0.496173
Epoch: 1 2400/3904 Training loss: 0.828983
Epoch: 1 3200/3904 Training loss: 0.543982
Training loss: 0.657966
Test loss: 0.874938; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 2 0/3904 Training loss: 0.732511
Epoch: 2 800/3904 Training loss: 0.736883
Epoch: 2 1600/3904 Training loss: 0.461402
Epoch: 2 2400/3904 Training loss: 0.811471
Epoch: 2 3200/3904 Training loss: 0.535759
Training loss: 0.651238
Test loss: 0.932159; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 3 0/3904 Training loss: 0.701254
Epoch: 3 800/3904 Training loss: 0.709037
Epoch: 3 1600/3904 Training loss: 0.394071
Epoch: 3 2400/3904 Training loss: 0.757278
Epoch: 3 3200/3904 Training loss: 0.443259
Training loss: 0.603764
Test loss: 1.218307; True positive: 4; True negative: 265, False Positive: 0, False negative: 899, accuracy: 0.2303082191780822, precision: 1.0, recall: 0.004429678848283499
Epoch: 4 0/3904 Training loss: 0.564184
Epoch: 4 800/3904 Training loss: 0.521553
Epoch: 4 1600/3904 Training loss: 0.315319
Epoch: 4 2400/3904 Training loss: 1.034727
Epoch: 4 3200/3904 Training loss: 0.452016
Training loss: 0.529825
Test loss: 1.534988; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 5 0/3904 Training loss: 0.620089
Epoch: 5 800/3904 Training loss: 0.583442
Epoch: 5 1600/3904 Training loss: 0.242724
Epoch: 5 2400/3904 Training loss: 1.058590
Epoch: 5 3200/3904 Training loss: 0.354713
Training loss: 0.467917
Test loss: 1.754493; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 6 0/3904 Training loss: 0.439501
Epoch: 6 800/3904 Training loss: 0.311624
Epoch: 6 1600/3904 Training loss: 0.260583
Epoch: 6 2400/3904 Training loss: 0.877960
Epoch: 6 3200/3904 Training loss: 0.537192
Training loss: 0.437518
Test loss: 1.956559; True positive: 4; True negative: 265, False Positive: 0, False negative: 899, accuracy: 0.2303082191780822, precision: 1.0, recall: 0.004429678848283499
Epoch: 7 0/3904 Training loss: 0.560782
Epoch: 7 800/3904 Training loss: 0.456413
Epoch: 7 1600/3904 Training loss: 0.166278
Epoch: 7 2400/3904 Training loss: 0.803271
Epoch: 7 3200/3904 Training loss: 0.328150
Training loss: 0.414526
Test loss: 2.098797; True positive: 5; True negative: 265, False Positive: 0, False negative: 898, accuracy: 0.23116438356164384, precision: 1.0, recall: 0.005537098560354375
Epoch: 8 0/3904 Training loss: 0.503049
Epoch: 8 800/3904 Training loss: 0.497315
Epoch: 8 1600/3904 Training loss: 0.278132
Epoch: 8 2400/3904 Training loss: 0.828050
Epoch: 8 3200/3904 Training loss: 0.300549
Training loss: 0.396413
Test loss: 2.414791; True positive: 5; True negative: 265, False Positive: 0, False negative: 898, accuracy: 0.23116438356164384, precision: 1.0, recall: 0.005537098560354375
Epoch: 9 0/3904 Training loss: 0.300392
Epoch: 9 800/3904 Training loss: 0.293979
Epoch: 9 1600/3904 Training loss: 0.252141
Epoch: 9 2400/3904 Training loss: 0.669372
Epoch: 9 3200/3904 Training loss: 0.304709
Training loss: 0.371378
Test loss: 0.510404; True positive: 834; True negative: 117, False Positive: 148, False negative: 69, accuracy: 0.8142123287671232, precision: 0.8492871690427699, recall: 0.9235880398671097
Epoch: 10 0/3904 Training loss: 0.423153
Epoch: 10 800/3904 Training loss: 0.507025
Epoch: 10 1600/3904 Training loss: 0.145248
Epoch: 10 2400/3904 Training loss: 0.806602
Epoch: 10 3200/3904 Training loss: 0.353322
Training loss: 0.369014
Test loss: 0.518927; True positive: 836; True negative: 117, False Positive: 148, False negative: 67, accuracy: 0.8159246575342466, precision: 0.8495934959349594, recall: 0.9258028792912514
Epoch: 11 0/3904 Training loss: 0.467444
Epoch: 11 800/3904 Training loss: 0.257974
Epoch: 11 1600/3904 Training loss: 0.181589
Epoch: 11 2400/3904 Training loss: 0.884495
Epoch: 11 3200/3904 Training loss: 0.250367
Training loss: 0.360211
Test loss: 0.516273; True positive: 827; True negative: 122, False Positive: 143, False negative: 76, accuracy: 0.8125, precision: 0.8525773195876288, recall: 0.9158361018826136
Epoch: 12 0/3904 Training loss: 0.406559
Epoch: 12 800/3904 Training loss: 0.337154
Epoch: 12 1600/3904 Training loss: 0.175786
Epoch: 12 2400/3904 Training loss: 0.593359
Epoch: 12 3200/3904 Training loss: 0.256071
Training loss: 0.346271
Test loss: 0.523380; True positive: 827; True negative: 119, False Positive: 146, False negative: 76, accuracy: 0.809931506849315, precision: 0.8499486125385406, recall: 0.9158361018826136
Epoch: 13 0/3904 Training loss: 0.376218
Epoch: 13 800/3904 Training loss: 0.293908
Epoch: 13 1600/3904 Training loss: 0.115460
Epoch: 13 2400/3904 Training loss: 0.513647
Epoch: 13 3200/3904 Training loss: 0.395626
Training loss: 0.343859
Test loss: 0.533048; True positive: 814; True negative: 127, False Positive: 138, False negative: 89, accuracy: 0.8056506849315068, precision: 0.8550420168067226, recall: 0.9014396456256921
Epoch: 14 0/3904 Training loss: 0.577150
Epoch: 14 800/3904 Training loss: 0.380470
Epoch: 14 1600/3904 Training loss: 0.234978
Epoch: 14 2400/3904 Training loss: 0.468572
Epoch: 14 3200/3904 Training loss: 0.328040
Training loss: 0.333310
Test loss: 0.524468; True positive: 827; True negative: 125, False Positive: 140, False negative: 76, accuracy: 0.815068493150685, precision: 0.8552223371251293, recall: 0.9158361018826136
Epoch: 15 0/3904 Training loss: 0.270166
Epoch: 15 800/3904 Training loss: 0.180268
Epoch: 15 1600/3904 Training loss: 0.116903
Epoch: 15 2400/3904 Training loss: 0.452255
Epoch: 15 3200/3904 Training loss: 0.314754
Training loss: 0.325377
Test loss: 0.525954; True positive: 836; True negative: 117, False Positive: 148, False negative: 67, accuracy: 0.8159246575342466, precision: 0.8495934959349594, recall: 0.9258028792912514
Epoch: 16 0/3904 Training loss: 0.467279
Epoch: 16 800/3904 Training loss: 0.245658
Epoch: 16 1600/3904 Training loss: 0.222807
Epoch: 16 2400/3904 Training loss: 0.553532
Epoch: 16 3200/3904 Training loss: 0.465864
Training loss: 0.322453
Test loss: 0.531636; True positive: 837; True negative: 117, False Positive: 148, False negative: 66, accuracy: 0.8167808219178082, precision: 0.849746192893401, recall: 0.9269102990033222
Epoch: 17 0/3904 Training loss: 0.319230
Epoch: 17 800/3904 Training loss: 0.245395
Epoch: 17 1600/3904 Training loss: 0.160613
Epoch: 17 2400/3904 Training loss: 0.688314
Epoch: 17 3200/3904 Training loss: 0.471456
Training loss: 0.315038
Test loss: 0.543479; True positive: 836; True negative: 117, False Positive: 148, False negative: 67, accuracy: 0.8159246575342466, precision: 0.8495934959349594, recall: 0.9258028792912514
Epoch: 18 0/3904 Training loss: 0.430369
Epoch: 18 800/3904 Training loss: 0.414009
Epoch: 18 1600/3904 Training loss: 0.213758
Epoch: 18 2400/3904 Training loss: 0.421321
Epoch: 18 3200/3904 Training loss: 0.293403
Training loss: 0.305990
Test loss: 0.537154; True positive: 835; True negative: 117, False Positive: 148, False negative: 68, accuracy: 0.815068493150685, precision: 0.8494404883011191, recall: 0.9246954595791805
Epoch: 19 0/3904 Training loss: 0.456713
Epoch: 19 800/3904 Training loss: 0.212002
Epoch: 19 1600/3904 Training loss: 0.212108
Epoch: 19 2400/3904 Training loss: 0.340142
Epoch: 19 3200/3904 Training loss: 0.495744
Training loss: 0.303901
Test loss: 0.543320; True positive: 837; True negative: 117, False Positive: 148, False negative: 66, accuracy: 0.8167808219178082, precision: 0.849746192893401, recall: 0.9269102990033222
starting trial 164
[I 2022-12-05 04:09:29,519] Trial 163 finished with value: 0.8167808219178082 and parameters: {'d_model': 16, 'nhead': 8, 'n_encoders': 1, 'learning_rate': 0.00013228045241354394, 'weight_decay': 4.839149350234749e-06, 'dropout': 0.1953325172020784, 'max_pool_conv': 64, 'kernel_size': 12, 'd_mlp': 32, 'num_conv_layers': 3, 'encoder_dropout': 0.09309758501949356, 'd_feed_forward': 128, 'max_pool_dim': 8, 'n_mlp_layers': 3}. Best is trial 62 with value: 0.860445205479452.
Epoch: 0 0/3904 Training loss: 0.693372
Epoch: 0 800/3904 Training loss: 0.695270
Epoch: 0 1600/3904 Training loss: 0.596230
Epoch: 0 2400/3904 Training loss: 0.759305
Epoch: 0 3200/3904 Training loss: 0.575423
Training loss: 0.673018
Test loss: 0.879793; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 1 0/3904 Training loss: 0.725857
Epoch: 1 800/3904 Training loss: 0.749178
Epoch: 1 1600/3904 Training loss: 0.465741
Epoch: 1 2400/3904 Training loss: 0.824246
Epoch: 1 3200/3904 Training loss: 0.545165
Training loss: 0.649123
Test loss: 0.826034; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 2 0/3904 Training loss: 0.726193
Epoch: 2 800/3904 Training loss: 0.725170
Epoch: 2 1600/3904 Training loss: 0.420119
Epoch: 2 2400/3904 Training loss: 0.729889
Epoch: 2 3200/3904 Training loss: 0.552714
Training loss: 0.628677
Test loss: 0.696309; True positive: 85; True negative: 244, False Positive: 21, False negative: 818, accuracy: 0.2816780821917808, precision: 0.8018867924528302, recall: 0.09413067552602436
Epoch: 3 0/3904 Training loss: 0.683459
Epoch: 3 800/3904 Training loss: 0.707397
Epoch: 3 1600/3904 Training loss: 0.319672
Epoch: 3 2400/3904 Training loss: 0.634215
Epoch: 3 3200/3904 Training loss: 0.458702
Training loss: 0.560610
Test loss: 0.600224; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 4 0/3904 Training loss: 0.479341
Epoch: 4 800/3904 Training loss: 0.479598
Epoch: 4 1600/3904 Training loss: 0.274200
Epoch: 4 2400/3904 Training loss: 0.477909
Epoch: 4 3200/3904 Training loss: 0.604188
Training loss: 0.496215
Test loss: 0.581417; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 5 0/3904 Training loss: 0.468455
Epoch: 5 800/3904 Training loss: 0.354079
Epoch: 5 1600/3904 Training loss: 0.205211
Epoch: 5 2400/3904 Training loss: 0.451131
Epoch: 5 3200/3904 Training loss: 0.489328
Training loss: 0.455284
Test loss: 0.591008; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 6 0/3904 Training loss: 0.422312
Epoch: 6 800/3904 Training loss: 0.345939
Epoch: 6 1600/3904 Training loss: 0.214291
Epoch: 6 2400/3904 Training loss: 0.422963
Epoch: 6 3200/3904 Training loss: 0.498906
Training loss: 0.426954
Test loss: 0.582175; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 7 0/3904 Training loss: 0.434028
Epoch: 7 800/3904 Training loss: 0.287111
Epoch: 7 1600/3904 Training loss: 0.182288
Epoch: 7 2400/3904 Training loss: 0.377509
Epoch: 7 3200/3904 Training loss: 0.613579
Training loss: 0.416521
Test loss: 0.542882; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 8 0/3904 Training loss: 0.397683
Epoch: 8 800/3904 Training loss: 0.268783
Epoch: 8 1600/3904 Training loss: 0.159192
Epoch: 8 2400/3904 Training loss: 0.341609
Epoch: 8 3200/3904 Training loss: 0.507482
Training loss: 0.395509
Test loss: 0.532285; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 9 0/3904 Training loss: 0.472560
Epoch: 9 800/3904 Training loss: 0.382005
Epoch: 9 1600/3904 Training loss: 0.204912
Epoch: 9 2400/3904 Training loss: 0.369141
Epoch: 9 3200/3904 Training loss: 0.484815
Training loss: 0.384162
Test loss: 0.525321; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 10 0/3904 Training loss: 0.439109
Epoch: 10 800/3904 Training loss: 0.324758
Epoch: 10 1600/3904 Training loss: 0.233731
Epoch: 10 2400/3904 Training loss: 0.379823
Epoch: 10 3200/3904 Training loss: 0.662882
Training loss: 0.383920
Test loss: 0.512845; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 11 0/3904 Training loss: 0.397643
Epoch: 11 800/3904 Training loss: 0.245852
Epoch: 11 1600/3904 Training loss: 0.241634
Epoch: 11 2400/3904 Training loss: 0.415943
Epoch: 11 3200/3904 Training loss: 0.514027
Training loss: 0.369430
Test loss: 0.516108; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 12 0/3904 Training loss: 0.383851
Epoch: 12 800/3904 Training loss: 0.252953
Epoch: 12 1600/3904 Training loss: 0.087054
Epoch: 12 2400/3904 Training loss: 0.313006
Epoch: 12 3200/3904 Training loss: 0.580508
Training loss: 0.356825
Test loss: 0.530212; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 13 0/3904 Training loss: 0.512694
Epoch: 13 800/3904 Training loss: 0.394001
Epoch: 13 1600/3904 Training loss: 0.272196
Epoch: 13 2400/3904 Training loss: 0.308890
Epoch: 13 3200/3904 Training loss: 0.521919
Training loss: 0.351667
Test loss: 0.545137; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 14 0/3904 Training loss: 0.352359
Epoch: 14 800/3904 Training loss: 0.165683
Epoch: 14 1600/3904 Training loss: 0.255730
Epoch: 14 2400/3904 Training loss: 0.285833
Epoch: 14 3200/3904 Training loss: 0.604197
Training loss: 0.338059
Test loss: 0.557989; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 15 0/3904 Training loss: 0.415952
Epoch: 15 800/3904 Training loss: 0.347473
Epoch: 15 1600/3904 Training loss: 0.156817
Epoch: 15 2400/3904 Training loss: 0.238651
Epoch: 15 3200/3904 Training loss: 0.525697
Training loss: 0.332166
Test loss: 0.560731; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 16 0/3904 Training loss: 0.494863
Epoch: 16 800/3904 Training loss: 0.305789
Epoch: 16 1600/3904 Training loss: 0.124194
Epoch: 16 2400/3904 Training loss: 0.344357
Epoch: 16 3200/3904 Training loss: 0.432110
Training loss: 0.321965
Test loss: 0.559249; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 17 0/3904 Training loss: 0.534154
Epoch: 17 800/3904 Training loss: 0.261351
Epoch: 17 1600/3904 Training loss: 0.145574
Epoch: 17 2400/3904 Training loss: 0.276315
Epoch: 17 3200/3904 Training loss: 0.490491
Training loss: 0.312503
Test loss: 0.564481; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 18 0/3904 Training loss: 0.398991
Epoch: 18 800/3904 Training loss: 0.192532
Epoch: 18 1600/3904 Training loss: 0.183213
Epoch: 18 2400/3904 Training loss: 0.303891
Epoch: 18 3200/3904 Training loss: 0.660201
Training loss: 0.306221
Test loss: 2.395702; True positive: 72; True negative: 232, False Positive: 33, False negative: 831, accuracy: 0.2602739726027397, precision: 0.6857142857142857, recall: 0.07973421926910298
Epoch: 19 0/3904 Training loss: 0.549507
Epoch: 19 800/3904 Training loss: 0.208656
Epoch: 19 1600/3904 Training loss: 0.227016
Epoch: 19 2400/3904 Training loss: 0.305703
Epoch: 19 3200/3904 Training loss: 0.503136
Training loss: 0.315434
Test loss: 0.579031; True positive: 835; True negative: 117, False Positive: 148, False negative: 68, accuracy: 0.815068493150685, precision: 0.8494404883011191, recall: 0.9246954595791805
Epoch: 20 0/3904 Training loss: 0.506737
Epoch: 20 800/3904 Training loss: 0.282146
Epoch: 20 1600/3904 Training loss: 0.151053
Epoch: 20 2400/3904 Training loss: 0.317519
Epoch: 20 3200/3904 Training loss: 0.659896
Training loss: 0.301109
Test loss: 0.569360; True positive: 835; True negative: 118, False Positive: 147, False negative: 68, accuracy: 0.8159246575342466, precision: 0.8503054989816701, recall: 0.9246954595791805
starting trial 165
[I 2022-12-05 04:10:26,666] Trial 164 finished with value: 0.8176369863013698 and parameters: {'d_model': 16, 'nhead': 8, 'n_encoders': 1, 'learning_rate': 0.00010374998385893373, 'weight_decay': 3.5011974508697685e-06, 'dropout': 0.22150126241638177, 'max_pool_conv': 64, 'kernel_size': 14, 'd_mlp': 32, 'num_conv_layers': 3, 'encoder_dropout': 0.10152282692313713, 'd_feed_forward': 128, 'max_pool_dim': 8, 'n_mlp_layers': 3}. Best is trial 62 with value: 0.860445205479452.
Epoch: 0 0/3904 Training loss: 0.696547
Epoch: 0 800/3904 Training loss: 0.736267
Epoch: 0 1600/3904 Training loss: 0.445698
Epoch: 0 2400/3904 Training loss: 0.805968
Epoch: 0 3200/3904 Training loss: 0.568012
Training loss: 0.663675
Test loss: 0.822063; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 1 0/3904 Training loss: 0.723790
Epoch: 1 800/3904 Training loss: 0.733497
Epoch: 1 1600/3904 Training loss: 0.443747
Epoch: 1 2400/3904 Training loss: 0.794472
Epoch: 1 3200/3904 Training loss: 0.538101
Training loss: 0.658265
Test loss: 0.798054; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 2 0/3904 Training loss: 0.680485
Epoch: 2 800/3904 Training loss: 0.727552
Epoch: 2 1600/3904 Training loss: 0.398704
Epoch: 2 2400/3904 Training loss: 0.667180
Epoch: 2 3200/3904 Training loss: 0.525556
Training loss: 0.634250
Test loss: 0.686852; True positive: 835; True negative: 119, False Positive: 146, False negative: 68, accuracy: 0.8167808219178082, precision: 0.8511722731906218, recall: 0.9246954595791805
Epoch: 3 0/3904 Training loss: 0.682110
Epoch: 3 800/3904 Training loss: 0.693322
Epoch: 3 1600/3904 Training loss: 0.302862
Epoch: 3 2400/3904 Training loss: 0.584247
Epoch: 3 3200/3904 Training loss: 0.481886
Training loss: 0.575674
Test loss: 0.599878; True positive: 900; True negative: 0, False Positive: 265, False negative: 3, accuracy: 0.7705479452054794, precision: 0.7725321888412017, recall: 0.9966777408637874
Epoch: 4 0/3904 Training loss: 0.531775
Epoch: 4 800/3904 Training loss: 0.527162
Epoch: 4 1600/3904 Training loss: 0.275263
Epoch: 4 2400/3904 Training loss: 0.429233
Epoch: 4 3200/3904 Training loss: 0.507911
Training loss: 0.513105
Test loss: 0.539727; True positive: 900; True negative: 0, False Positive: 265, False negative: 3, accuracy: 0.7705479452054794, precision: 0.7725321888412017, recall: 0.9966777408637874
Epoch: 5 0/3904 Training loss: 0.531519
Epoch: 5 800/3904 Training loss: 0.376345
Epoch: 5 1600/3904 Training loss: 0.261550
Epoch: 5 2400/3904 Training loss: 0.429760
Epoch: 5 3200/3904 Training loss: 0.411205
Training loss: 0.488284
Test loss: 0.529776; True positive: 903; True negative: 0, False Positive: 265, False negative: 0, accuracy: 0.7731164383561644, precision: 0.7731164383561644, recall: 1.0
Epoch: 6 0/3904 Training loss: 0.387882
Epoch: 6 800/3904 Training loss: 0.286657
Epoch: 6 1600/3904 Training loss: 0.331508
Epoch: 6 2400/3904 Training loss: 0.407197
Epoch: 6 3200/3904 Training loss: 0.481807
Training loss: 0.470147
Test loss: 0.530100; True positive: 903; True negative: 0, False Positive: 265, False negative: 0, accuracy: 0.7731164383561644, precision: 0.7731164383561644, recall: 1.0
Epoch: 7 0/3904 Training loss: 0.441372
Epoch: 7 800/3904 Training loss: 0.351344
Epoch: 7 1600/3904 Training loss: 0.296993
Epoch: 7 2400/3904 Training loss: 0.427948
Epoch: 7 3200/3904 Training loss: 0.429768
Training loss: 0.470043
Test loss: 0.533868; True positive: 903; True negative: 0, False Positive: 265, False negative: 0, accuracy: 0.7731164383561644, precision: 0.7731164383561644, recall: 1.0
Epoch: 8 0/3904 Training loss: 0.417757
Epoch: 8 800/3904 Training loss: 0.353482
Epoch: 8 1600/3904 Training loss: 0.325588
Epoch: 8 2400/3904 Training loss: 0.373622
Epoch: 8 3200/3904 Training loss: 0.426567
Training loss: 0.449740
Test loss: 0.530082; True positive: 903; True negative: 0, False Positive: 265, False negative: 0, accuracy: 0.7731164383561644, precision: 0.7731164383561644, recall: 1.0
Epoch: 9 0/3904 Training loss: 0.414392
Epoch: 9 800/3904 Training loss: 0.317947
Epoch: 9 1600/3904 Training loss: 0.218843
Epoch: 9 2400/3904 Training loss: 0.343392
Epoch: 9 3200/3904 Training loss: 0.344822
Training loss: 0.435513
Test loss: 0.527249; True positive: 903; True negative: 0, False Positive: 265, False negative: 0, accuracy: 0.7731164383561644, precision: 0.7731164383561644, recall: 1.0
Epoch: 10 0/3904 Training loss: 0.401513
Epoch: 10 800/3904 Training loss: 0.262730
Epoch: 10 1600/3904 Training loss: 0.281473
Epoch: 10 2400/3904 Training loss: 0.313896
Epoch: 10 3200/3904 Training loss: 0.390144
Training loss: 0.429757
Test loss: 0.525694; True positive: 903; True negative: 0, False Positive: 265, False negative: 0, accuracy: 0.7731164383561644, precision: 0.7731164383561644, recall: 1.0
Epoch: 11 0/3904 Training loss: 0.398822
Epoch: 11 800/3904 Training loss: 0.237724
Epoch: 11 1600/3904 Training loss: 0.125824
Epoch: 11 2400/3904 Training loss: 0.294268
Epoch: 11 3200/3904 Training loss: 0.387540
Training loss: 0.426947
Test loss: 0.527466; True positive: 903; True negative: 0, False Positive: 265, False negative: 0, accuracy: 0.7731164383561644, precision: 0.7731164383561644, recall: 1.0
Epoch: 12 0/3904 Training loss: 0.406618
Epoch: 12 800/3904 Training loss: 0.242163
Epoch: 12 1600/3904 Training loss: 0.192547
Epoch: 12 2400/3904 Training loss: 0.340370
Epoch: 12 3200/3904 Training loss: 0.388924
Training loss: 0.427050
Test loss: 0.519423; True positive: 903; True negative: 0, False Positive: 265, False negative: 0, accuracy: 0.7731164383561644, precision: 0.7731164383561644, recall: 1.0
Epoch: 13 0/3904 Training loss: 0.400245
Epoch: 13 800/3904 Training loss: 0.256500
Epoch: 13 1600/3904 Training loss: 0.154269
Epoch: 13 2400/3904 Training loss: 0.351024
Epoch: 13 3200/3904 Training loss: 0.309380
Training loss: 0.419639
Test loss: 0.524847; True positive: 902; True negative: 0, False Positive: 265, False negative: 1, accuracy: 0.7722602739726028, precision: 0.7729220222793488, recall: 0.9988925802879292
Epoch: 14 0/3904 Training loss: 0.420170
Epoch: 14 800/3904 Training loss: 0.260253
Epoch: 14 1600/3904 Training loss: 0.208981
Epoch: 14 2400/3904 Training loss: 0.367284
Epoch: 14 3200/3904 Training loss: 0.431119
Training loss: 0.407657
Test loss: 0.523034; True positive: 900; True negative: 0, False Positive: 265, False negative: 3, accuracy: 0.7705479452054794, precision: 0.7725321888412017, recall: 0.9966777408637874
Epoch: 15 0/3904 Training loss: 0.308194
Epoch: 15 800/3904 Training loss: 0.224979
Epoch: 15 1600/3904 Training loss: 0.193401
Epoch: 15 2400/3904 Training loss: 0.376949
Epoch: 15 3200/3904 Training loss: 0.615943
Training loss: 0.407704
Test loss: 0.532192; True positive: 903; True negative: 0, False Positive: 265, False negative: 0, accuracy: 0.7731164383561644, precision: 0.7731164383561644, recall: 1.0
Epoch: 16 0/3904 Training loss: 0.342067
Epoch: 16 800/3904 Training loss: 0.179126
Epoch: 16 1600/3904 Training loss: 0.212247
Epoch: 16 2400/3904 Training loss: 0.426348
Epoch: 16 3200/3904 Training loss: 0.336968
Training loss: 0.404010
Test loss: 0.531185; True positive: 899; True negative: 0, False Positive: 265, False negative: 4, accuracy: 0.7696917808219178, precision: 0.7723367697594502, recall: 0.9955703211517165
Epoch: 17 0/3904 Training loss: 0.374122
Epoch: 17 800/3904 Training loss: 0.194779
Epoch: 17 1600/3904 Training loss: 0.138666
Epoch: 17 2400/3904 Training loss: 0.362473
Epoch: 17 3200/3904 Training loss: 0.504435
Training loss: 0.400958
Test loss: 0.536604; True positive: 899; True negative: 0, False Positive: 265, False negative: 4, accuracy: 0.7696917808219178, precision: 0.7723367697594502, recall: 0.9955703211517165
Epoch: 18 0/3904 Training loss: 0.311144
Epoch: 18 800/3904 Training loss: 0.231721
Epoch: 18 1600/3904 Training loss: 0.172958
Epoch: 18 2400/3904 Training loss: 0.395498
Epoch: 18 3200/3904 Training loss: 0.432677
Training loss: 0.392315
Test loss: 0.540664; True positive: 898; True negative: 0, False Positive: 265, False negative: 5, accuracy: 0.7688356164383562, precision: 0.7721410146173688, recall: 0.9944629014396457
Epoch: 19 0/3904 Training loss: 0.360108
Epoch: 19 800/3904 Training loss: 0.193810
Epoch: 19 1600/3904 Training loss: 0.151693
Epoch: 19 2400/3904 Training loss: 0.415715
Epoch: 19 3200/3904 Training loss: 0.420197
Training loss: 0.390722
Test loss: 0.552192; True positive: 899; True negative: 0, False Positive: 265, False negative: 4, accuracy: 0.7696917808219178, precision: 0.7723367697594502, recall: 0.9955703211517165
Epoch: 20 0/3904 Training loss: 0.349358
Epoch: 20 800/3904 Training loss: 0.225723
Epoch: 20 1600/3904 Training loss: 0.118487
Epoch: 20 2400/3904 Training loss: 0.380066
Epoch: 20 3200/3904 Training loss: 0.525742
Training loss: 0.392114
Test loss: 0.539046; True positive: 898; True negative: 0, False Positive: 265, False negative: 5, accuracy: 0.7688356164383562, precision: 0.7721410146173688, recall: 0.9944629014396457
Epoch: 21 0/3904 Training loss: 0.322848
Epoch: 21 800/3904 Training loss: 0.232588
Epoch: 21 1600/3904 Training loss: 0.179267
Epoch: 21 2400/3904 Training loss: 0.356239
Epoch: 21 3200/3904 Training loss: 0.556854
Training loss: 0.380842
Test loss: 0.550043; True positive: 898; True negative: 0, False Positive: 265, False negative: 5, accuracy: 0.7688356164383562, precision: 0.7721410146173688, recall: 0.9944629014396457
Epoch: 22 0/3904 Training loss: 0.263727
Epoch: 22 800/3904 Training loss: 0.223024
Epoch: 22 1600/3904 Training loss: 0.124419
Epoch: 22 2400/3904 Training loss: 0.409016
Epoch: 22 3200/3904 Training loss: 0.382810
Training loss: 0.390847
Test loss: 0.548472; True positive: 898; True negative: 0, False Positive: 265, False negative: 5, accuracy: 0.7688356164383562, precision: 0.7721410146173688, recall: 0.9944629014396457
starting trial 166
[I 2022-12-05 04:11:38,158] Trial 165 finished with value: 0.8167808219178082 and parameters: {'d_model': 16, 'nhead': 2, 'n_encoders': 1, 'learning_rate': 0.0002058179664053435, 'weight_decay': 1.2362539039621436e-05, 'dropout': 0.10517210228753536, 'max_pool_conv': 128, 'kernel_size': 6, 'd_mlp': 128, 'num_conv_layers': 6, 'encoder_dropout': 0.048195989253648985, 'd_feed_forward': 256, 'max_pool_dim': 16, 'n_mlp_layers': 3}. Best is trial 62 with value: 0.860445205479452.
Epoch: 0 0/3904 Training loss: 0.719784
Epoch: 0 800/3904 Training loss: 0.748447
Epoch: 0 1600/3904 Training loss: 0.456568
Epoch: 0 2400/3904 Training loss: 0.755974
Epoch: 0 3200/3904 Training loss: 0.540855
Training loss: 0.654969
Test loss: 0.705078; True positive: 1; True negative: 265, False Positive: 0, False negative: 902, accuracy: 0.22773972602739725, precision: 1.0, recall: 0.0011074197120708748
Epoch: 1 0/3904 Training loss: 0.692936
Epoch: 1 800/3904 Training loss: 0.685385
Epoch: 1 1600/3904 Training loss: 0.328550
Epoch: 1 2400/3904 Training loss: 0.590575
Epoch: 1 3200/3904 Training loss: 0.379168
Training loss: 0.555506
Test loss: 0.537838; True positive: 837; True negative: 117, False Positive: 148, False negative: 66, accuracy: 0.8167808219178082, precision: 0.849746192893401, recall: 0.9269102990033222
Epoch: 2 0/3904 Training loss: 0.446091
Epoch: 2 800/3904 Training loss: 0.424982
Epoch: 2 1600/3904 Training loss: 0.215320
Epoch: 2 2400/3904 Training loss: 0.434802
Epoch: 2 3200/3904 Training loss: 0.352174
Training loss: 0.450664
Test loss: 2.129671; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 3 0/3904 Training loss: 0.380610
Epoch: 3 800/3904 Training loss: 0.378165
Epoch: 3 1600/3904 Training loss: 0.212444
Epoch: 3 2400/3904 Training loss: 0.347811
Epoch: 3 3200/3904 Training loss: 0.356452
Training loss: 0.409327
Test loss: 0.474079; True positive: 832; True negative: 134, False Positive: 131, False negative: 71, accuracy: 0.827054794520548, precision: 0.8639667705088265, recall: 0.9213732004429679
Epoch: 4 0/3904 Training loss: 0.312447
Epoch: 4 800/3904 Training loss: 0.278729
Epoch: 4 1600/3904 Training loss: 0.197713
Epoch: 4 2400/3904 Training loss: 0.315217
Epoch: 4 3200/3904 Training loss: 0.322240
Training loss: 0.377205
Test loss: 0.517865; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 5 0/3904 Training loss: 0.328828
Epoch: 5 800/3904 Training loss: 0.323113
Epoch: 5 1600/3904 Training loss: 0.142591
Epoch: 5 2400/3904 Training loss: 0.211875
Epoch: 5 3200/3904 Training loss: 0.305653
Training loss: 0.353500
Test loss: 0.535639; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 6 0/3904 Training loss: 0.279884
Epoch: 6 800/3904 Training loss: 0.270663
Epoch: 6 1600/3904 Training loss: 0.151032
Epoch: 6 2400/3904 Training loss: 0.309849
Epoch: 6 3200/3904 Training loss: 0.338430
Training loss: 0.327036
Test loss: 0.480231; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 7 0/3904 Training loss: 0.299137
Epoch: 7 800/3904 Training loss: 0.117018
Epoch: 7 1600/3904 Training loss: 0.208840
Epoch: 7 2400/3904 Training loss: 0.247281
Epoch: 7 3200/3904 Training loss: 0.303439
Training loss: 0.301087
Test loss: 0.539542; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 8 0/3904 Training loss: 0.235937
Epoch: 8 800/3904 Training loss: 0.242105
Epoch: 8 1600/3904 Training loss: 0.142969
Epoch: 8 2400/3904 Training loss: 0.217361
Epoch: 8 3200/3904 Training loss: 0.374650
Training loss: 0.285597
Test loss: 0.545806; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 9 0/3904 Training loss: 0.315703
Epoch: 9 800/3904 Training loss: 0.210714
Epoch: 9 1600/3904 Training loss: 0.136894
Epoch: 9 2400/3904 Training loss: 0.245546
Epoch: 9 3200/3904 Training loss: 0.310499
Training loss: 0.263077
Test loss: 0.566394; True positive: 836; True negative: 117, False Positive: 148, False negative: 67, accuracy: 0.8159246575342466, precision: 0.8495934959349594, recall: 0.9258028792912514
Epoch: 10 0/3904 Training loss: 0.292057
Epoch: 10 800/3904 Training loss: 0.133557
Epoch: 10 1600/3904 Training loss: 0.117260
Epoch: 10 2400/3904 Training loss: 0.184205
Epoch: 10 3200/3904 Training loss: 0.332427
Training loss: 0.244963
Test loss: 0.569204; True positive: 836; True negative: 117, False Positive: 148, False negative: 67, accuracy: 0.8159246575342466, precision: 0.8495934959349594, recall: 0.9258028792912514
Epoch: 11 0/3904 Training loss: 0.265797
Epoch: 11 800/3904 Training loss: 0.138134
Epoch: 11 1600/3904 Training loss: 0.155740
Epoch: 11 2400/3904 Training loss: 0.101474
Epoch: 11 3200/3904 Training loss: 0.198671
Training loss: 0.235472
Test loss: 0.595878; True positive: 837; True negative: 117, False Positive: 148, False negative: 66, accuracy: 0.8167808219178082, precision: 0.849746192893401, recall: 0.9269102990033222
Epoch: 12 0/3904 Training loss: 0.234562
Epoch: 12 800/3904 Training loss: 0.115548
Epoch: 12 1600/3904 Training loss: 0.101525
Epoch: 12 2400/3904 Training loss: 0.182491
Epoch: 12 3200/3904 Training loss: 0.301499
Training loss: 0.217996
Test loss: 0.579536; True positive: 837; True negative: 117, False Positive: 148, False negative: 66, accuracy: 0.8167808219178082, precision: 0.849746192893401, recall: 0.9269102990033222
Epoch: 13 0/3904 Training loss: 0.246047
Epoch: 13 800/3904 Training loss: 0.312452
Epoch: 13 1600/3904 Training loss: 0.107640
Epoch: 13 2400/3904 Training loss: 0.118969
Epoch: 13 3200/3904 Training loss: 0.280422
Training loss: 0.214689
Test loss: 0.572721; True positive: 832; True negative: 117, False Positive: 148, False negative: 71, accuracy: 0.8125, precision: 0.8489795918367347, recall: 0.9213732004429679
starting trial 167
[I 2022-12-05 04:13:01,314] Trial 166 finished with value: 0.827054794520548 and parameters: {'d_model': 64, 'nhead': 8, 'n_encoders': 1, 'learning_rate': 0.00012852661084310633, 'weight_decay': 4.008900686944715e-06, 'dropout': 0.20425409317023083, 'max_pool_conv': 64, 'kernel_size': 14, 'd_mlp': 32, 'num_conv_layers': 3, 'encoder_dropout': 0.08030905712250946, 'd_feed_forward': 128, 'max_pool_dim': 8, 'n_mlp_layers': 3}. Best is trial 62 with value: 0.860445205479452.
Epoch: 0 0/3904 Training loss: 0.695647
Epoch: 0 800/3904 Training loss: 0.719882
Epoch: 0 1600/3904 Training loss: 0.457365
Epoch: 0 2400/3904 Training loss: 0.773013
Epoch: 0 3200/3904 Training loss: 0.545670
Training loss: 0.657147
Test loss: 0.643545; True positive: 903; True negative: 0, False Positive: 265, False negative: 0, accuracy: 0.7731164383561644, precision: 0.7731164383561644, recall: 1.0
Epoch: 1 0/3904 Training loss: 0.683066
Epoch: 1 800/3904 Training loss: 0.696110
Epoch: 1 1600/3904 Training loss: 0.313711
Epoch: 1 2400/3904 Training loss: 0.562089
Epoch: 1 3200/3904 Training loss: 0.437138
Training loss: 0.563743
Test loss: 1.389890; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 2 0/3904 Training loss: 0.486671
Epoch: 2 800/3904 Training loss: 0.399218
Epoch: 2 1600/3904 Training loss: 0.194825
Epoch: 2 2400/3904 Training loss: 0.557535
Epoch: 2 3200/3904 Training loss: 0.510379
Training loss: 0.444967
Test loss: 1.844812; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 3 0/3904 Training loss: 0.417406
Epoch: 3 800/3904 Training loss: 0.413404
Epoch: 3 1600/3904 Training loss: 0.178910
Epoch: 3 2400/3904 Training loss: 0.445241
Epoch: 3 3200/3904 Training loss: 0.500457
Training loss: 0.397398
Test loss: 1.925611; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 4 0/3904 Training loss: 0.335163
Epoch: 4 800/3904 Training loss: 0.239200
Epoch: 4 1600/3904 Training loss: 0.232258
Epoch: 4 2400/3904 Training loss: 0.590996
Epoch: 4 3200/3904 Training loss: 0.387884
Training loss: 0.357822
Test loss: 0.587997; True positive: 755; True negative: 134, False Positive: 131, False negative: 148, accuracy: 0.7611301369863014, precision: 0.8521444695259593, recall: 0.8361018826135105
Epoch: 5 0/3904 Training loss: 0.295173
Epoch: 5 800/3904 Training loss: 0.138264
Epoch: 5 1600/3904 Training loss: 0.121954
Epoch: 5 2400/3904 Training loss: 0.569234
Epoch: 5 3200/3904 Training loss: 0.459432
Training loss: 0.330687
Test loss: 0.491803; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 6 0/3904 Training loss: 0.386788
Epoch: 6 800/3904 Training loss: 0.100624
Epoch: 6 1600/3904 Training loss: 0.171131
Epoch: 6 2400/3904 Training loss: 0.412440
Epoch: 6 3200/3904 Training loss: 0.343053
Training loss: 0.305350
Test loss: 0.503959; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 7 0/3904 Training loss: 0.194148
Epoch: 7 800/3904 Training loss: 0.146442
Epoch: 7 1600/3904 Training loss: 0.159878
Epoch: 7 2400/3904 Training loss: 0.322994
Epoch: 7 3200/3904 Training loss: 0.278973
Training loss: 0.285136
Test loss: 0.521518; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 8 0/3904 Training loss: 0.384994
Epoch: 8 800/3904 Training loss: 0.106581
Epoch: 8 1600/3904 Training loss: 0.166711
Epoch: 8 2400/3904 Training loss: 0.176050
Epoch: 8 3200/3904 Training loss: 0.583842
Training loss: 0.272233
Test loss: 2.163286; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 9 0/3904 Training loss: 0.373394
Epoch: 9 800/3904 Training loss: 0.099929
Epoch: 9 1600/3904 Training loss: 0.082132
Epoch: 9 2400/3904 Training loss: 0.175509
Epoch: 9 3200/3904 Training loss: 0.363023
Training loss: 0.249921
Test loss: 2.286696; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 10 0/3904 Training loss: 0.333614
Epoch: 10 800/3904 Training loss: 0.229498
Epoch: 10 1600/3904 Training loss: 0.094102
Epoch: 10 2400/3904 Training loss: 0.236042
Epoch: 10 3200/3904 Training loss: 0.350430
Training loss: 0.239954
Test loss: 2.064087; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 11 0/3904 Training loss: 0.562642
Epoch: 11 800/3904 Training loss: 0.171204
Epoch: 11 1600/3904 Training loss: 0.050595
Epoch: 11 2400/3904 Training loss: 0.121876
Epoch: 11 3200/3904 Training loss: 0.307299
Training loss: 0.220221
Test loss: 2.106392; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 12 0/3904 Training loss: 0.331056
Epoch: 12 800/3904 Training loss: 0.205296
Epoch: 12 1600/3904 Training loss: 0.055872
Epoch: 12 2400/3904 Training loss: 0.294953
Epoch: 12 3200/3904 Training loss: 0.294120
Training loss: 0.213200
Test loss: 2.091186; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 13 0/3904 Training loss: 0.220276
Epoch: 13 800/3904 Training loss: 0.072458
Epoch: 13 1600/3904 Training loss: 0.053018
Epoch: 13 2400/3904 Training loss: 0.106327
Epoch: 13 3200/3904 Training loss: 0.269258
Training loss: 0.203281
Test loss: 2.138734; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 14 0/3904 Training loss: 0.316002
Epoch: 14 800/3904 Training loss: 0.129879
Epoch: 14 1600/3904 Training loss: 0.064230
Epoch: 14 2400/3904 Training loss: 0.112836
Epoch: 14 3200/3904 Training loss: 0.347514
Training loss: 0.188980
Test loss: 2.181060; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 15 0/3904 Training loss: 0.193022
Epoch: 15 800/3904 Training loss: 0.110987
Epoch: 15 1600/3904 Training loss: 0.051577
Epoch: 15 2400/3904 Training loss: 0.065814
Epoch: 15 3200/3904 Training loss: 0.291559
Training loss: 0.180772
Test loss: 2.285242; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
starting trial 168
[I 2022-12-05 04:14:46,240] Trial 167 finished with value: 0.8176369863013698 and parameters: {'d_model': 64, 'nhead': 8, 'n_encoders': 1, 'learning_rate': 0.00011279360190341389, 'weight_decay': 3.238881707442361e-06, 'dropout': 0.18926051247156153, 'max_pool_conv': 64, 'kernel_size': 17, 'd_mlp': 32, 'num_conv_layers': 3, 'encoder_dropout': 0.07749796396775259, 'd_feed_forward': 128, 'max_pool_dim': 8, 'n_mlp_layers': 3}. Best is trial 62 with value: 0.860445205479452.
Epoch: 0 0/3904 Training loss: 0.690517
Epoch: 0 800/3904 Training loss: 0.723551
Epoch: 0 1600/3904 Training loss: 0.450570
Epoch: 0 2400/3904 Training loss: 0.792408
Epoch: 0 3200/3904 Training loss: 0.558952
Training loss: 0.664209
Test loss: 0.794665; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 1 0/3904 Training loss: 0.698677
Epoch: 1 800/3904 Training loss: 0.740130
Epoch: 1 1600/3904 Training loss: 0.468076
Epoch: 1 2400/3904 Training loss: 0.796593
Epoch: 1 3200/3904 Training loss: 0.537735
Training loss: 0.657340
Test loss: 0.774460; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 2 0/3904 Training loss: 0.691501
Epoch: 2 800/3904 Training loss: 0.703509
Epoch: 2 1600/3904 Training loss: 0.374263
Epoch: 2 2400/3904 Training loss: 0.708930
Epoch: 2 3200/3904 Training loss: 0.436545
Training loss: 0.602705
Test loss: 1.111243; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 3 0/3904 Training loss: 0.526343
Epoch: 3 800/3904 Training loss: 0.510041
Epoch: 3 1600/3904 Training loss: 0.261570
Epoch: 3 2400/3904 Training loss: 0.567145
Epoch: 3 3200/3904 Training loss: 0.331050
Training loss: 0.485521
Test loss: 0.573839; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 4 0/3904 Training loss: 0.422633
Epoch: 4 800/3904 Training loss: 0.520329
Epoch: 4 1600/3904 Training loss: 0.257696
Epoch: 4 2400/3904 Training loss: 0.495322
Epoch: 4 3200/3904 Training loss: 0.365670
Training loss: 0.440266
Test loss: 0.513635; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 5 0/3904 Training loss: 0.365197
Epoch: 5 800/3904 Training loss: 0.408903
Epoch: 5 1600/3904 Training loss: 0.300580
Epoch: 5 2400/3904 Training loss: 0.542422
Epoch: 5 3200/3904 Training loss: 0.361290
Training loss: 0.411454
Test loss: 0.535224; True positive: 903; True negative: 0, False Positive: 265, False negative: 0, accuracy: 0.7731164383561644, precision: 0.7731164383561644, recall: 1.0
Epoch: 6 0/3904 Training loss: 0.317127
Epoch: 6 800/3904 Training loss: 0.356841
Epoch: 6 1600/3904 Training loss: 0.213273
Epoch: 6 2400/3904 Training loss: 0.506783
Epoch: 6 3200/3904 Training loss: 0.353744
Training loss: 0.378782
Test loss: 0.528879; True positive: 903; True negative: 0, False Positive: 265, False negative: 0, accuracy: 0.7731164383561644, precision: 0.7731164383561644, recall: 1.0
Epoch: 7 0/3904 Training loss: 0.323951
Epoch: 7 800/3904 Training loss: 0.247935
Epoch: 7 1600/3904 Training loss: 0.288937
Epoch: 7 2400/3904 Training loss: 0.567914
Epoch: 7 3200/3904 Training loss: 0.320832
Training loss: 0.352914
Test loss: 0.531410; True positive: 903; True negative: 0, False Positive: 265, False negative: 0, accuracy: 0.7731164383561644, precision: 0.7731164383561644, recall: 1.0
Epoch: 8 0/3904 Training loss: 0.406147
Epoch: 8 800/3904 Training loss: 0.179496
Epoch: 8 1600/3904 Training loss: 0.204538
Epoch: 8 2400/3904 Training loss: 0.437867
Epoch: 8 3200/3904 Training loss: 0.339686
Training loss: 0.320294
Test loss: 0.510368; True positive: 903; True negative: 0, False Positive: 265, False negative: 0, accuracy: 0.7731164383561644, precision: 0.7731164383561644, recall: 1.0
Epoch: 9 0/3904 Training loss: 0.350945
Epoch: 9 800/3904 Training loss: 0.201997
Epoch: 9 1600/3904 Training loss: 0.211259
Epoch: 9 2400/3904 Training loss: 0.403325
Epoch: 9 3200/3904 Training loss: 0.357553
Training loss: 0.301348
Test loss: 0.491943; True positive: 903; True negative: 3, False Positive: 262, False negative: 0, accuracy: 0.7756849315068494, precision: 0.7751072961373391, recall: 1.0
Epoch: 10 0/3904 Training loss: 0.327414
Epoch: 10 800/3904 Training loss: 0.239566
Epoch: 10 1600/3904 Training loss: 0.143436
Epoch: 10 2400/3904 Training loss: 0.680307
Epoch: 10 3200/3904 Training loss: 0.391007
Training loss: 0.285438
Test loss: 0.507638; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 11 0/3904 Training loss: 0.605918
Epoch: 11 800/3904 Training loss: 0.220829
Epoch: 11 1600/3904 Training loss: 0.174061
Epoch: 11 2400/3904 Training loss: 0.549379
Epoch: 11 3200/3904 Training loss: 0.416027
Training loss: 0.276591
Test loss: 0.467558; True positive: 838; True negative: 116, False Positive: 149, False negative: 65, accuracy: 0.8167808219178082, precision: 0.8490374873353597, recall: 0.9280177187153932
Epoch: 12 0/3904 Training loss: 0.367557
Epoch: 12 800/3904 Training loss: 0.160840
Epoch: 12 1600/3904 Training loss: 0.106494
Epoch: 12 2400/3904 Training loss: 0.430577
Epoch: 12 3200/3904 Training loss: 0.262197
Training loss: 0.262618
Test loss: 0.519732; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 13 0/3904 Training loss: 0.391957
Epoch: 13 800/3904 Training loss: 0.223333
Epoch: 13 1600/3904 Training loss: 0.102249
Epoch: 13 2400/3904 Training loss: 0.365781
Epoch: 13 3200/3904 Training loss: 0.248502
Training loss: 0.255851
Test loss: 0.514859; True positive: 837; True negative: 120, False Positive: 145, False negative: 66, accuracy: 0.8193493150684932, precision: 0.8523421588594705, recall: 0.9269102990033222
Epoch: 14 0/3904 Training loss: 0.208172
Epoch: 14 800/3904 Training loss: 0.251733
Epoch: 14 1600/3904 Training loss: 0.111508
Epoch: 14 2400/3904 Training loss: 0.348431
Epoch: 14 3200/3904 Training loss: 0.422227
Training loss: 0.249924
Test loss: 0.533827; True positive: 791; True negative: 151, False Positive: 114, False negative: 112, accuracy: 0.8065068493150684, precision: 0.8740331491712707, recall: 0.875968992248062
Epoch: 15 0/3904 Training loss: 0.209177
Epoch: 15 800/3904 Training loss: 0.133538
Epoch: 15 1600/3904 Training loss: 0.097664
Epoch: 15 2400/3904 Training loss: 0.273475
Epoch: 15 3200/3904 Training loss: 0.411074
Training loss: 0.236101
Test loss: 0.532083; True positive: 821; True negative: 126, False Positive: 139, False negative: 82, accuracy: 0.8107876712328768, precision: 0.8552083333333333, recall: 0.9091915836101883
Epoch: 16 0/3904 Training loss: 0.339593
Epoch: 16 800/3904 Training loss: 0.231589
Epoch: 16 1600/3904 Training loss: 0.182892
Epoch: 16 2400/3904 Training loss: 0.297258
Epoch: 16 3200/3904 Training loss: 0.280042
Training loss: 0.221665
Test loss: 0.550024; True positive: 837; True negative: 118, False Positive: 147, False negative: 66, accuracy: 0.8176369863013698, precision: 0.850609756097561, recall: 0.9269102990033222
Epoch: 17 0/3904 Training loss: 0.161002
Epoch: 17 800/3904 Training loss: 0.146417
Epoch: 17 1600/3904 Training loss: 0.122407
Epoch: 17 2400/3904 Training loss: 0.314732
Epoch: 17 3200/3904 Training loss: 0.323408
Training loss: 0.213895
Test loss: 1.877837; True positive: 123; True negative: 243, False Positive: 22, False negative: 780, accuracy: 0.3133561643835616, precision: 0.8482758620689655, recall: 0.1362126245847176
Epoch: 18 0/3904 Training loss: 0.215761
Epoch: 18 800/3904 Training loss: 0.151139
Epoch: 18 1600/3904 Training loss: 0.047283
Epoch: 18 2400/3904 Training loss: 0.300281
Epoch: 18 3200/3904 Training loss: 0.394897
Training loss: 0.204588
Test loss: 2.202205; True positive: 39; True negative: 258, False Positive: 7, False negative: 864, accuracy: 0.2542808219178082, precision: 0.8478260869565217, recall: 0.04318936877076412
Epoch: 19 0/3904 Training loss: 0.309715
Epoch: 19 800/3904 Training loss: 0.164230
Epoch: 19 1600/3904 Training loss: 0.081853
Epoch: 19 2400/3904 Training loss: 0.289428
Epoch: 19 3200/3904 Training loss: 0.273512
Training loss: 0.198669
Test loss: 2.381903; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 20 0/3904 Training loss: 0.278631
Epoch: 20 800/3904 Training loss: 0.165836
Epoch: 20 1600/3904 Training loss: 0.039035
Epoch: 20 2400/3904 Training loss: 0.301350
Epoch: 20 3200/3904 Training loss: 0.242385
Training loss: 0.201091
Test loss: 2.253235; True positive: 62; True negative: 245, False Positive: 20, False negative: 841, accuracy: 0.2628424657534247, precision: 0.7560975609756098, recall: 0.06866002214839424
Epoch: 21 0/3904 Training loss: 0.308915
Epoch: 21 800/3904 Training loss: 0.462108
Epoch: 21 1600/3904 Training loss: 0.105395
Epoch: 21 2400/3904 Training loss: 0.153788
Epoch: 21 3200/3904 Training loss: 0.283535
Training loss: 0.187982
Test loss: 2.558035; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
starting trial 169
[I 2022-12-05 04:17:05,061] Trial 168 finished with value: 0.8193493150684932 and parameters: {'d_model': 64, 'nhead': 8, 'n_encoders': 3, 'learning_rate': 8.02030164618743e-05, 'weight_decay': 4.017475728567596e-06, 'dropout': 0.204171524090288, 'max_pool_conv': 64, 'kernel_size': 13, 'd_mlp': 32, 'num_conv_layers': 3, 'encoder_dropout': 0.289131635371236, 'd_feed_forward': 128, 'max_pool_dim': 8, 'n_mlp_layers': 3}. Best is trial 62 with value: 0.860445205479452.
Epoch: 0 0/3904 Training loss: 0.703844
Epoch: 0 800/3904 Training loss: 0.726755
Epoch: 0 1600/3904 Training loss: 0.428372
Epoch: 0 2400/3904 Training loss: 0.757072
Epoch: 0 3200/3904 Training loss: 0.504317
Training loss: 0.658169
Test loss: 0.802050; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 1 0/3904 Training loss: 0.709126
Epoch: 1 800/3904 Training loss: 0.702337
Epoch: 1 1600/3904 Training loss: 0.343298
Epoch: 1 2400/3904 Training loss: 0.621668
Epoch: 1 3200/3904 Training loss: 0.428943
Training loss: 0.598062
Test loss: 0.875264; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 2 0/3904 Training loss: 0.513660
Epoch: 2 800/3904 Training loss: 0.495725
Epoch: 2 1600/3904 Training loss: 0.233643
Epoch: 2 2400/3904 Training loss: 0.548893
Epoch: 2 3200/3904 Training loss: 0.418504
Training loss: 0.475762
Test loss: 1.538392; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 3 0/3904 Training loss: 0.371914
Epoch: 3 800/3904 Training loss: 0.260753
Epoch: 3 1600/3904 Training loss: 0.241696
Epoch: 3 2400/3904 Training loss: 0.464859
Epoch: 3 3200/3904 Training loss: 0.350420
Training loss: 0.403385
Test loss: 0.937270; True positive: 209; True negative: 207, False Positive: 58, False negative: 694, accuracy: 0.3561643835616438, precision: 0.7827715355805244, recall: 0.23145071982281284
Epoch: 4 0/3904 Training loss: 0.334776
Epoch: 4 800/3904 Training loss: 0.331776
Epoch: 4 1600/3904 Training loss: 0.148155
Epoch: 4 2400/3904 Training loss: 0.339520
Epoch: 4 3200/3904 Training loss: 0.571074
Training loss: 0.361366
Test loss: 0.495199; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 5 0/3904 Training loss: 0.270823
Epoch: 5 800/3904 Training loss: 0.293674
Epoch: 5 1600/3904 Training loss: 0.163252
Epoch: 5 2400/3904 Training loss: 0.334603
Epoch: 5 3200/3904 Training loss: 0.417748
Training loss: 0.331909
Test loss: 0.480331; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 6 0/3904 Training loss: 0.334345
Epoch: 6 800/3904 Training loss: 0.162996
Epoch: 6 1600/3904 Training loss: 0.153868
Epoch: 6 2400/3904 Training loss: 0.376744
Epoch: 6 3200/3904 Training loss: 0.407567
Training loss: 0.295812
Test loss: 0.505753; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 7 0/3904 Training loss: 0.364354
Epoch: 7 800/3904 Training loss: 0.201725
Epoch: 7 1600/3904 Training loss: 0.127669
Epoch: 7 2400/3904 Training loss: 0.323668
Epoch: 7 3200/3904 Training loss: 0.360714
Training loss: 0.284097
Test loss: 0.959526; True positive: 326; True negative: 174, False Positive: 91, False negative: 577, accuracy: 0.4280821917808219, precision: 0.7817745803357314, recall: 0.3610188261351052
Epoch: 8 0/3904 Training loss: 0.296060
Epoch: 8 800/3904 Training loss: 0.127486
Epoch: 8 1600/3904 Training loss: 0.113308
Epoch: 8 2400/3904 Training loss: 0.329514
Epoch: 8 3200/3904 Training loss: 0.424349
Training loss: 0.269825
Test loss: 0.519901; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 9 0/3904 Training loss: 0.381341
Epoch: 9 800/3904 Training loss: 0.138257
Epoch: 9 1600/3904 Training loss: 0.061774
Epoch: 9 2400/3904 Training loss: 0.215044
Epoch: 9 3200/3904 Training loss: 0.527687
Training loss: 0.247770
Test loss: 0.498694; True positive: 838; True negative: 120, False Positive: 145, False negative: 65, accuracy: 0.8202054794520548, precision: 0.8524923702950152, recall: 0.9280177187153932
Epoch: 10 0/3904 Training loss: 0.308802
Epoch: 10 800/3904 Training loss: 0.122295
Epoch: 10 1600/3904 Training loss: 0.129819
Epoch: 10 2400/3904 Training loss: 0.249943
Epoch: 10 3200/3904 Training loss: 0.436955
Training loss: 0.242452
Test loss: 0.501652; True positive: 838; True negative: 119, False Positive: 146, False negative: 65, accuracy: 0.8193493150684932, precision: 0.8516260162601627, recall: 0.9280177187153932
Epoch: 11 0/3904 Training loss: 0.518843
Epoch: 11 800/3904 Training loss: 0.170425
Epoch: 11 1600/3904 Training loss: 0.070174
Epoch: 11 2400/3904 Training loss: 0.207714
Epoch: 11 3200/3904 Training loss: 0.305935
Training loss: 0.233127
Test loss: 0.511203; True positive: 837; True negative: 121, False Positive: 144, False negative: 66, accuracy: 0.8202054794520548, precision: 0.8532110091743119, recall: 0.9269102990033222
Epoch: 12 0/3904 Training loss: 0.204633
Epoch: 12 800/3904 Training loss: 0.147936
Epoch: 12 1600/3904 Training loss: 0.112465
Epoch: 12 2400/3904 Training loss: 0.197621
Epoch: 12 3200/3904 Training loss: 0.406258
Training loss: 0.224168
Test loss: 0.517417; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 13 0/3904 Training loss: 0.255370
Epoch: 13 800/3904 Training loss: 0.234001
Epoch: 13 1600/3904 Training loss: 0.150806
Epoch: 13 2400/3904 Training loss: 0.238202
Epoch: 13 3200/3904 Training loss: 0.413491
Training loss: 0.220619
Test loss: 0.531173; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 14 0/3904 Training loss: 0.311442
Epoch: 14 800/3904 Training loss: 0.090789
Epoch: 14 1600/3904 Training loss: 0.082330
Epoch: 14 2400/3904 Training loss: 0.141113
Epoch: 14 3200/3904 Training loss: 0.263947
Training loss: 0.200540
Test loss: 0.510804; True positive: 802; True negative: 144, False Positive: 121, False negative: 101, accuracy: 0.809931506849315, precision: 0.8689057421451788, recall: 0.8881506090808416
Epoch: 15 0/3904 Training loss: 0.272163
Epoch: 15 800/3904 Training loss: 0.086792
Epoch: 15 1600/3904 Training loss: 0.094832
Epoch: 15 2400/3904 Training loss: 0.091228
Epoch: 15 3200/3904 Training loss: 0.305681
Training loss: 0.191842
Test loss: 0.515958; True positive: 837; True negative: 117, False Positive: 148, False negative: 66, accuracy: 0.8167808219178082, precision: 0.849746192893401, recall: 0.9269102990033222
starting trial 170
[I 2022-12-05 04:18:27,900] Trial 169 finished with value: 0.8202054794520548 and parameters: {'d_model': 64, 'nhead': 4, 'n_encoders': 2, 'learning_rate': 9.60716775933751e-05, 'weight_decay': 3.855303600852335e-06, 'dropout': 0.3443561697077561, 'max_pool_conv': 64, 'kernel_size': 18, 'd_mlp': 62, 'num_conv_layers': 2, 'encoder_dropout': 0.06505607794829577, 'd_feed_forward': 128, 'max_pool_dim': 8, 'n_mlp_layers': 3}. Best is trial 62 with value: 0.860445205479452.
Epoch: 0 0/3904 Training loss: 0.695110
Epoch: 0 800/3904 Training loss: 0.686096
Epoch: 0 1600/3904 Training loss: 0.752914
Epoch: 0 2400/3904 Training loss: 0.671393
Epoch: 0 3200/3904 Training loss: 0.732174
Training loss: 0.713007
Test loss: 0.666791; True positive: 903; True negative: 0, False Positive: 265, False negative: 0, accuracy: 0.7731164383561644, precision: 0.7731164383561644, recall: 1.0
Epoch: 1 0/3904 Training loss: 0.694103
Epoch: 1 800/3904 Training loss: 0.688336
Epoch: 1 1600/3904 Training loss: 0.728672
Epoch: 1 2400/3904 Training loss: 0.680355
Epoch: 1 3200/3904 Training loss: 0.704976
Training loss: 0.702832
Test loss: 0.690517; True positive: 903; True negative: 0, False Positive: 265, False negative: 0, accuracy: 0.7731164383561644, precision: 0.7731164383561644, recall: 1.0
Epoch: 2 0/3904 Training loss: 0.695314
Epoch: 2 800/3904 Training loss: 0.689046
Epoch: 2 1600/3904 Training loss: 0.683322
Epoch: 2 2400/3904 Training loss: 0.698102
Epoch: 2 3200/3904 Training loss: 0.671531
Training loss: 0.689046
Test loss: 0.709490; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 3 0/3904 Training loss: 0.695823
Epoch: 3 800/3904 Training loss: 0.699028
Epoch: 3 1600/3904 Training loss: 0.645754
Epoch: 3 2400/3904 Training loss: 0.715531
Epoch: 3 3200/3904 Training loss: 0.645882
Training loss: 0.679078
Test loss: 0.725504; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 4 0/3904 Training loss: 0.692091
Epoch: 4 800/3904 Training loss: 0.702973
Epoch: 4 1600/3904 Training loss: 0.612692
Epoch: 4 2400/3904 Training loss: 0.730825
Epoch: 4 3200/3904 Training loss: 0.623597
Training loss: 0.670555
Test loss: 0.740005; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 5 0/3904 Training loss: 0.700608
Epoch: 5 800/3904 Training loss: 0.713647
Epoch: 5 1600/3904 Training loss: 0.579074
Epoch: 5 2400/3904 Training loss: 0.747908
Epoch: 5 3200/3904 Training loss: 0.606008
Training loss: 0.664862
Test loss: 0.752576; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 6 0/3904 Training loss: 0.700300
Epoch: 6 800/3904 Training loss: 0.720157
Epoch: 6 1600/3904 Training loss: 0.552329
Epoch: 6 2400/3904 Training loss: 0.755147
Epoch: 6 3200/3904 Training loss: 0.592550
Training loss: 0.659396
Test loss: 0.762268; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 7 0/3904 Training loss: 0.704684
Epoch: 7 800/3904 Training loss: 0.719417
Epoch: 7 1600/3904 Training loss: 0.541855
Epoch: 7 2400/3904 Training loss: 0.763338
Epoch: 7 3200/3904 Training loss: 0.579009
Training loss: 0.655418
Test loss: 0.770346; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 8 0/3904 Training loss: 0.700852
Epoch: 8 800/3904 Training loss: 0.725479
Epoch: 8 1600/3904 Training loss: 0.516868
Epoch: 8 2400/3904 Training loss: 0.773521
Epoch: 8 3200/3904 Training loss: 0.567520
Training loss: 0.651635
Test loss: 0.777743; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 9 0/3904 Training loss: 0.710176
Epoch: 9 800/3904 Training loss: 0.720087
Epoch: 9 1600/3904 Training loss: 0.501038
Epoch: 9 2400/3904 Training loss: 0.777171
Epoch: 9 3200/3904 Training loss: 0.551414
Training loss: 0.647895
Test loss: 0.783415; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 10 0/3904 Training loss: 0.710086
Epoch: 10 800/3904 Training loss: 0.722932
Epoch: 10 1600/3904 Training loss: 0.492764
Epoch: 10 2400/3904 Training loss: 0.775843
Epoch: 10 3200/3904 Training loss: 0.540416
Training loss: 0.644459
Test loss: 0.781506; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
starting trial 171
[I 2022-12-05 04:19:07,578] Trial 170 finished with value: 0.7731164383561644 and parameters: {'d_model': 64, 'nhead': 8, 'n_encoders': 1, 'learning_rate': 1.71858730935504e-05, 'weight_decay': 4.499449201312709e-06, 'dropout': 0.31641344710525554, 'max_pool_conv': 64, 'kernel_size': 11, 'd_mlp': 16, 'num_conv_layers': 2, 'encoder_dropout': 0.056307677265685134, 'd_feed_forward': 128, 'max_pool_dim': 8, 'n_mlp_layers': 4}. Best is trial 62 with value: 0.860445205479452.
Epoch: 0 0/3904 Training loss: 0.695615
Epoch: 0 800/3904 Training loss: 0.728756
Epoch: 0 1600/3904 Training loss: 0.472739
Epoch: 0 2400/3904 Training loss: 0.812693
Epoch: 0 3200/3904 Training loss: 0.553807
Training loss: 0.659559
Test loss: 0.807293; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 1 0/3904 Training loss: 0.694752
Epoch: 1 800/3904 Training loss: 0.729465
Epoch: 1 1600/3904 Training loss: 0.356487
Epoch: 1 2400/3904 Training loss: 0.744844
Epoch: 1 3200/3904 Training loss: 0.437830
Training loss: 0.600067
Test loss: 1.217783; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 2 0/3904 Training loss: 0.606937
Epoch: 2 800/3904 Training loss: 0.517791
Epoch: 2 1600/3904 Training loss: 0.237406
Epoch: 2 2400/3904 Training loss: 0.422242
Epoch: 2 3200/3904 Training loss: 0.484057
Training loss: 0.477725
Test loss: 1.063269; True positive: 147; True negative: 254, False Positive: 11, False negative: 756, accuracy: 0.3433219178082192, precision: 0.930379746835443, recall: 0.16279069767441862
Epoch: 3 0/3904 Training loss: 0.392495
Epoch: 3 800/3904 Training loss: 0.524662
Epoch: 3 1600/3904 Training loss: 0.223265
Epoch: 3 2400/3904 Training loss: 0.356920
Epoch: 3 3200/3904 Training loss: 0.456462
Training loss: 0.417128
Test loss: 0.520290; True positive: 837; True negative: 125, False Positive: 140, False negative: 66, accuracy: 0.8236301369863014, precision: 0.8567041965199591, recall: 0.9269102990033222
Epoch: 4 0/3904 Training loss: 0.317652
Epoch: 4 800/3904 Training loss: 0.257855
Epoch: 4 1600/3904 Training loss: 0.227464
Epoch: 4 2400/3904 Training loss: 0.348167
Epoch: 4 3200/3904 Training loss: 0.414527
Training loss: 0.385736
Test loss: 0.506413; True positive: 838; True negative: 119, False Positive: 146, False negative: 65, accuracy: 0.8193493150684932, precision: 0.8516260162601627, recall: 0.9280177187153932
Epoch: 5 0/3904 Training loss: 0.258930
Epoch: 5 800/3904 Training loss: 0.342353
Epoch: 5 1600/3904 Training loss: 0.117868
Epoch: 5 2400/3904 Training loss: 0.374202
Epoch: 5 3200/3904 Training loss: 0.373539
Training loss: 0.364138
Test loss: 0.526803; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 6 0/3904 Training loss: 0.310246
Epoch: 6 800/3904 Training loss: 0.243248
Epoch: 6 1600/3904 Training loss: 0.129023
Epoch: 6 2400/3904 Training loss: 0.388014
Epoch: 6 3200/3904 Training loss: 0.360279
Training loss: 0.325603
Test loss: 0.522311; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 7 0/3904 Training loss: 0.252789
Epoch: 7 800/3904 Training loss: 0.153141
Epoch: 7 1600/3904 Training loss: 0.155831
Epoch: 7 2400/3904 Training loss: 0.333719
Epoch: 7 3200/3904 Training loss: 0.355966
Training loss: 0.305153
Test loss: 0.533881; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 8 0/3904 Training loss: 0.407790
Epoch: 8 800/3904 Training loss: 0.119735
Epoch: 8 1600/3904 Training loss: 0.133942
Epoch: 8 2400/3904 Training loss: 0.240530
Epoch: 8 3200/3904 Training loss: 0.328881
Training loss: 0.280861
Test loss: 0.529976; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 9 0/3904 Training loss: 0.285285
Epoch: 9 800/3904 Training loss: 0.172123
Epoch: 9 1600/3904 Training loss: 0.158359
Epoch: 9 2400/3904 Training loss: 0.272036
Epoch: 9 3200/3904 Training loss: 0.455966
Training loss: 0.271409
Test loss: 0.510489; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 10 0/3904 Training loss: 0.427415
Epoch: 10 800/3904 Training loss: 0.112745
Epoch: 10 1600/3904 Training loss: 0.114684
Epoch: 10 2400/3904 Training loss: 0.267199
Epoch: 10 3200/3904 Training loss: 0.441038
Training loss: 0.250276
Test loss: 0.538646; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 11 0/3904 Training loss: 0.299550
Epoch: 11 800/3904 Training loss: 0.170807
Epoch: 11 1600/3904 Training loss: 0.177481
Epoch: 11 2400/3904 Training loss: 0.148247
Epoch: 11 3200/3904 Training loss: 0.312719
Training loss: 0.246586
Test loss: 0.570289; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 12 0/3904 Training loss: 0.231331
Epoch: 12 800/3904 Training loss: 0.145579
Epoch: 12 1600/3904 Training loss: 0.151716
Epoch: 12 2400/3904 Training loss: 0.185819
Epoch: 12 3200/3904 Training loss: 0.357906
Training loss: 0.239469
Test loss: 0.578942; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 13 0/3904 Training loss: 0.383505
Epoch: 13 800/3904 Training loss: 0.135549
Epoch: 13 1600/3904 Training loss: 0.263322
Epoch: 13 2400/3904 Training loss: 0.202478
Epoch: 13 3200/3904 Training loss: 0.448060
Training loss: 0.225294
Test loss: 0.546147; True positive: 903; True negative: 0, False Positive: 265, False negative: 0, accuracy: 0.7731164383561644, precision: 0.7731164383561644, recall: 1.0
Epoch: 14 0/3904 Training loss: 0.272029
Epoch: 14 800/3904 Training loss: 0.105156
Epoch: 14 1600/3904 Training loss: 0.094216
Epoch: 14 2400/3904 Training loss: 0.169893
Epoch: 14 3200/3904 Training loss: 0.363451
Training loss: 0.214350
Test loss: 0.464851; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 15 0/3904 Training loss: 0.314924
Epoch: 15 800/3904 Training loss: 0.114504
Epoch: 15 1600/3904 Training loss: 0.153490
Epoch: 15 2400/3904 Training loss: 0.091624
Epoch: 15 3200/3904 Training loss: 0.254377
Training loss: 0.204202
Test loss: 0.586616; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 16 0/3904 Training loss: 0.227164
Epoch: 16 800/3904 Training loss: 0.104417
Epoch: 16 1600/3904 Training loss: 0.122728
Epoch: 16 2400/3904 Training loss: 0.096947
Epoch: 16 3200/3904 Training loss: 0.418543
Training loss: 0.188503
Test loss: 0.587002; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 17 0/3904 Training loss: 0.222480
Epoch: 17 800/3904 Training loss: 0.131775
Epoch: 17 1600/3904 Training loss: 0.145893
Epoch: 17 2400/3904 Training loss: 0.119822
Epoch: 17 3200/3904 Training loss: 0.232242
Training loss: 0.186177
Test loss: 0.538480; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 18 0/3904 Training loss: 0.388385
Epoch: 18 800/3904 Training loss: 0.089496
Epoch: 18 1600/3904 Training loss: 0.136736
Epoch: 18 2400/3904 Training loss: 0.069755
Epoch: 18 3200/3904 Training loss: 0.246677
Training loss: 0.175093
Test loss: 0.621350; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 19 0/3904 Training loss: 0.079074
Epoch: 19 800/3904 Training loss: 0.054451
Epoch: 19 1600/3904 Training loss: 0.241040
Epoch: 19 2400/3904 Training loss: 0.042838
Epoch: 19 3200/3904 Training loss: 0.315327
Training loss: 0.167992
Test loss: 0.583336; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 20 0/3904 Training loss: 0.149425
Epoch: 20 800/3904 Training loss: 0.140976
Epoch: 20 1600/3904 Training loss: 0.167338
Epoch: 20 2400/3904 Training loss: 0.103112
Epoch: 20 3200/3904 Training loss: 0.190767
Training loss: 0.151405
Test loss: 0.588190; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 21 0/3904 Training loss: 0.437224
Epoch: 21 800/3904 Training loss: 0.031843
Epoch: 21 1600/3904 Training loss: 0.124915
Epoch: 21 2400/3904 Training loss: 0.133078
Epoch: 21 3200/3904 Training loss: 0.235400
Training loss: 0.159535
Test loss: 0.589250; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 22 0/3904 Training loss: 0.155720
Epoch: 22 800/3904 Training loss: 0.138042
Epoch: 22 1600/3904 Training loss: 0.203235
Epoch: 22 2400/3904 Training loss: 0.046483
Epoch: 22 3200/3904 Training loss: 0.170902
Training loss: 0.145676
Test loss: 0.562747; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 23 0/3904 Training loss: 0.272483
Epoch: 23 800/3904 Training loss: 0.112291
Epoch: 23 1600/3904 Training loss: 0.186217
Epoch: 23 2400/3904 Training loss: 0.029106
Epoch: 23 3200/3904 Training loss: 0.198125
Training loss: 0.143504
Test loss: 0.580067; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 24 0/3904 Training loss: 0.357810
Epoch: 24 800/3904 Training loss: 0.112584
Epoch: 24 1600/3904 Training loss: 0.190548
Epoch: 24 2400/3904 Training loss: 0.026985
Epoch: 24 3200/3904 Training loss: 0.086623
Training loss: 0.142573
Test loss: 0.603431; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
starting trial 172
[I 2022-12-05 04:21:37,900] Trial 171 finished with value: 0.8236301369863014 and parameters: {'d_model': 64, 'nhead': 8, 'n_encoders': 1, 'learning_rate': 0.00012984131342529004, 'weight_decay': 5.335059923997365e-06, 'dropout': 0.2086862659987011, 'max_pool_conv': 64, 'kernel_size': 15, 'd_mlp': 32, 'num_conv_layers': 3, 'encoder_dropout': 0.11712556351128353, 'd_feed_forward': 128, 'max_pool_dim': 8, 'n_mlp_layers': 3}. Best is trial 62 with value: 0.860445205479452.
Epoch: 0 0/3904 Training loss: 0.698174
Epoch: 0 800/3904 Training loss: 0.725278
Epoch: 0 1600/3904 Training loss: 0.428777
Epoch: 0 2400/3904 Training loss: 0.773880
Epoch: 0 3200/3904 Training loss: 0.523640
Training loss: 0.655321
Test loss: 0.759150; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 1 0/3904 Training loss: 0.674888
Epoch: 1 800/3904 Training loss: 0.673162
Epoch: 1 1600/3904 Training loss: 0.311243
Epoch: 1 2400/3904 Training loss: 0.352520
Epoch: 1 3200/3904 Training loss: 0.348347
Training loss: 0.548140
Test loss: 1.931564; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 2 0/3904 Training loss: 0.443308
Epoch: 2 800/3904 Training loss: 0.421384
Epoch: 2 1600/3904 Training loss: 0.214267
Epoch: 2 2400/3904 Training loss: 0.220981
Epoch: 2 3200/3904 Training loss: 0.358312
Training loss: 0.445324
Test loss: 0.906588; True positive: 599; True negative: 129, False Positive: 136, False negative: 304, accuracy: 0.6232876712328768, precision: 0.8149659863945579, recall: 0.6633444075304541
Epoch: 3 0/3904 Training loss: 0.374583
Epoch: 3 800/3904 Training loss: 0.391525
Epoch: 3 1600/3904 Training loss: 0.176850
Epoch: 3 2400/3904 Training loss: 0.234753
Epoch: 3 3200/3904 Training loss: 0.319985
Training loss: 0.407348
Test loss: 0.573632; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 4 0/3904 Training loss: 0.333404
Epoch: 4 800/3904 Training loss: 0.363357
Epoch: 4 1600/3904 Training loss: 0.138650
Epoch: 4 2400/3904 Training loss: 0.199119
Epoch: 4 3200/3904 Training loss: 0.310385
Training loss: 0.373245
Test loss: 0.557299; True positive: 903; True negative: 0, False Positive: 265, False negative: 0, accuracy: 0.7731164383561644, precision: 0.7731164383561644, recall: 1.0
Epoch: 5 0/3904 Training loss: 0.383715
Epoch: 5 800/3904 Training loss: 0.386940
Epoch: 5 1600/3904 Training loss: 0.159224
Epoch: 5 2400/3904 Training loss: 0.197797
Epoch: 5 3200/3904 Training loss: 0.313393
Training loss: 0.348758
Test loss: 0.509896; True positive: 903; True negative: 0, False Positive: 265, False negative: 0, accuracy: 0.7731164383561644, precision: 0.7731164383561644, recall: 1.0
Epoch: 6 0/3904 Training loss: 0.240999
Epoch: 6 800/3904 Training loss: 0.298457
Epoch: 6 1600/3904 Training loss: 0.110961
Epoch: 6 2400/3904 Training loss: 0.165701
Epoch: 6 3200/3904 Training loss: 0.266139
Training loss: 0.321446
Test loss: 0.524552; True positive: 903; True negative: 0, False Positive: 265, False negative: 0, accuracy: 0.7731164383561644, precision: 0.7731164383561644, recall: 1.0
Epoch: 7 0/3904 Training loss: 0.307478
Epoch: 7 800/3904 Training loss: 0.163343
Epoch: 7 1600/3904 Training loss: 0.084152
Epoch: 7 2400/3904 Training loss: 0.150458
Epoch: 7 3200/3904 Training loss: 0.404475
Training loss: 0.304739
Test loss: 0.485929; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 8 0/3904 Training loss: 0.390799
Epoch: 8 800/3904 Training loss: 0.290124
Epoch: 8 1600/3904 Training loss: 0.077767
Epoch: 8 2400/3904 Training loss: 0.202481
Epoch: 8 3200/3904 Training loss: 0.382699
Training loss: 0.284336
Test loss: 0.506548; True positive: 903; True negative: 0, False Positive: 265, False negative: 0, accuracy: 0.7731164383561644, precision: 0.7731164383561644, recall: 1.0
Epoch: 9 0/3904 Training loss: 0.275393
Epoch: 9 800/3904 Training loss: 0.116972
Epoch: 9 1600/3904 Training loss: 0.090587
Epoch: 9 2400/3904 Training loss: 0.166888
Epoch: 9 3200/3904 Training loss: 0.248096
Training loss: 0.269407
Test loss: 0.469758; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 10 0/3904 Training loss: 0.335181
Epoch: 10 800/3904 Training loss: 0.167279
Epoch: 10 1600/3904 Training loss: 0.074931
Epoch: 10 2400/3904 Training loss: 0.151165
Epoch: 10 3200/3904 Training loss: 0.257035
Training loss: 0.253644
Test loss: 0.529546; True positive: 903; True negative: 0, False Positive: 265, False negative: 0, accuracy: 0.7731164383561644, precision: 0.7731164383561644, recall: 1.0
Epoch: 11 0/3904 Training loss: 0.417363
Epoch: 11 800/3904 Training loss: 0.269596
Epoch: 11 1600/3904 Training loss: 0.070458
Epoch: 11 2400/3904 Training loss: 0.102642
Epoch: 11 3200/3904 Training loss: 0.355749
Training loss: 0.238709
Test loss: 0.504434; True positive: 903; True negative: 0, False Positive: 265, False negative: 0, accuracy: 0.7731164383561644, precision: 0.7731164383561644, recall: 1.0
Epoch: 12 0/3904 Training loss: 0.397986
Epoch: 12 800/3904 Training loss: 0.331661
Epoch: 12 1600/3904 Training loss: 0.102826
Epoch: 12 2400/3904 Training loss: 0.109494
Epoch: 12 3200/3904 Training loss: 0.275376
Training loss: 0.221088
Test loss: 0.619967; True positive: 903; True negative: 0, False Positive: 265, False negative: 0, accuracy: 0.7731164383561644, precision: 0.7731164383561644, recall: 1.0
Epoch: 13 0/3904 Training loss: 0.486606
Epoch: 13 800/3904 Training loss: 0.173299
Epoch: 13 1600/3904 Training loss: 0.109918
Epoch: 13 2400/3904 Training loss: 0.082658
Epoch: 13 3200/3904 Training loss: 0.130609
Training loss: 0.214556
Test loss: 0.613437; True positive: 903; True negative: 0, False Positive: 265, False negative: 0, accuracy: 0.7731164383561644, precision: 0.7731164383561644, recall: 1.0
Epoch: 14 0/3904 Training loss: 0.346807
Epoch: 14 800/3904 Training loss: 0.163913
Epoch: 14 1600/3904 Training loss: 0.110232
Epoch: 14 2400/3904 Training loss: 0.151305
Epoch: 14 3200/3904 Training loss: 0.314678
Training loss: 0.207340
Test loss: 0.660848; True positive: 903; True negative: 0, False Positive: 265, False negative: 0, accuracy: 0.7731164383561644, precision: 0.7731164383561644, recall: 1.0
Epoch: 15 0/3904 Training loss: 0.439779
Epoch: 15 800/3904 Training loss: 0.228502
Epoch: 15 1600/3904 Training loss: 0.134997
Epoch: 15 2400/3904 Training loss: 0.062500
Epoch: 15 3200/3904 Training loss: 0.295291
Training loss: 0.195922
Test loss: 0.654533; True positive: 903; True negative: 0, False Positive: 265, False negative: 0, accuracy: 0.7731164383561644, precision: 0.7731164383561644, recall: 1.0
Epoch: 16 0/3904 Training loss: 0.195650
Epoch: 16 800/3904 Training loss: 0.128705
Epoch: 16 1600/3904 Training loss: 0.073481
Epoch: 16 2400/3904 Training loss: 0.060876
Epoch: 16 3200/3904 Training loss: 0.111788
Training loss: 0.182782
Test loss: 0.619363; True positive: 903; True negative: 0, False Positive: 265, False negative: 0, accuracy: 0.7731164383561644, precision: 0.7731164383561644, recall: 1.0
Epoch: 17 0/3904 Training loss: 0.252843
Epoch: 17 800/3904 Training loss: 0.117252
Epoch: 17 1600/3904 Training loss: 0.110498
Epoch: 17 2400/3904 Training loss: 0.076610
Epoch: 17 3200/3904 Training loss: 0.152926
Training loss: 0.178793
Test loss: 0.671136; True positive: 903; True negative: 0, False Positive: 265, False negative: 0, accuracy: 0.7731164383561644, precision: 0.7731164383561644, recall: 1.0
Epoch: 18 0/3904 Training loss: 0.145863
Epoch: 18 800/3904 Training loss: 0.125847
Epoch: 18 1600/3904 Training loss: 0.070863
Epoch: 18 2400/3904 Training loss: 0.073889
Epoch: 18 3200/3904 Training loss: 0.072441
Training loss: 0.164648
Test loss: 0.702894; True positive: 903; True negative: 0, False Positive: 265, False negative: 0, accuracy: 0.7731164383561644, precision: 0.7731164383561644, recall: 1.0
Epoch: 19 0/3904 Training loss: 0.159104
Epoch: 19 800/3904 Training loss: 0.266098
Epoch: 19 1600/3904 Training loss: 0.098188
Epoch: 19 2400/3904 Training loss: 0.033811
Epoch: 19 3200/3904 Training loss: 0.189496
Training loss: 0.168366
Test loss: 0.702660; True positive: 903; True negative: 0, False Positive: 265, False negative: 0, accuracy: 0.7731164383561644, precision: 0.7731164383561644, recall: 1.0
starting trial 173
[I 2022-12-05 04:23:38,194] Trial 172 finished with value: 0.8176369863013698 and parameters: {'d_model': 64, 'nhead': 8, 'n_encoders': 1, 'learning_rate': 0.00014408061475944763, 'weight_decay': 6.175518486173087e-06, 'dropout': 0.22882070691330064, 'max_pool_conv': 64, 'kernel_size': 15, 'd_mlp': 32, 'num_conv_layers': 3, 'encoder_dropout': 0.11216391971420853, 'd_feed_forward': 128, 'max_pool_dim': 8, 'n_mlp_layers': 3}. Best is trial 62 with value: 0.860445205479452.
Epoch: 0 0/3904 Training loss: 0.702264
Epoch: 0 800/3904 Training loss: 0.732504
Epoch: 0 1600/3904 Training loss: 0.409915
Epoch: 0 2400/3904 Training loss: 0.733123
Epoch: 0 3200/3904 Training loss: 0.522320
Training loss: 0.650713
Test loss: 0.741424; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 1 0/3904 Training loss: 0.676472
Epoch: 1 800/3904 Training loss: 0.677940
Epoch: 1 1600/3904 Training loss: 0.248007
Epoch: 1 2400/3904 Training loss: 0.581360
Epoch: 1 3200/3904 Training loss: 0.425165
Training loss: 0.550674
Test loss: 0.626900; True positive: 903; True negative: 1, False Positive: 264, False negative: 0, accuracy: 0.773972602739726, precision: 0.7737789203084833, recall: 1.0
Epoch: 2 0/3904 Training loss: 0.449114
Epoch: 2 800/3904 Training loss: 0.465727
Epoch: 2 1600/3904 Training loss: 0.186597
Epoch: 2 2400/3904 Training loss: 0.350602
Epoch: 2 3200/3904 Training loss: 0.494899
Training loss: 0.444980
Test loss: 0.626211; True positive: 865; True negative: 82, False Positive: 183, False negative: 38, accuracy: 0.8107876712328768, precision: 0.825381679389313, recall: 0.9579180509413068
Epoch: 3 0/3904 Training loss: 0.332193
Epoch: 3 800/3904 Training loss: 0.352130
Epoch: 3 1600/3904 Training loss: 0.218738
Epoch: 3 2400/3904 Training loss: 0.345497
Epoch: 3 3200/3904 Training loss: 0.448435
Training loss: 0.400751
Test loss: 0.718564; True positive: 149; True negative: 143, False Positive: 122, False negative: 754, accuracy: 0.25, precision: 0.5498154981549815, recall: 0.16500553709856036
Epoch: 4 0/3904 Training loss: 0.308341
Epoch: 4 800/3904 Training loss: 0.258011
Epoch: 4 1600/3904 Training loss: 0.245592
Epoch: 4 2400/3904 Training loss: 0.294646
Epoch: 4 3200/3904 Training loss: 0.413311
Training loss: 0.382273
Test loss: 0.822389; True positive: 1; True negative: 265, False Positive: 0, False negative: 902, accuracy: 0.22773972602739725, precision: 1.0, recall: 0.0011074197120708748
Epoch: 5 0/3904 Training loss: 0.334790
Epoch: 5 800/3904 Training loss: 0.267813
Epoch: 5 1600/3904 Training loss: 0.208826
Epoch: 5 2400/3904 Training loss: 0.303469
Epoch: 5 3200/3904 Training loss: 0.415008
Training loss: 0.361808
Test loss: 1.029297; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 6 0/3904 Training loss: 0.239859
Epoch: 6 800/3904 Training loss: 0.182419
Epoch: 6 1600/3904 Training loss: 0.182556
Epoch: 6 2400/3904 Training loss: 0.386749
Epoch: 6 3200/3904 Training loss: 0.290769
Training loss: 0.339581
Test loss: 0.716546; True positive: 257; True negative: 255, False Positive: 10, False negative: 646, accuracy: 0.4383561643835616, precision: 0.9625468164794008, recall: 0.28460686600221485
Epoch: 7 0/3904 Training loss: 0.315993
Epoch: 7 800/3904 Training loss: 0.187767
Epoch: 7 1600/3904 Training loss: 0.192890
Epoch: 7 2400/3904 Training loss: 0.222171
Epoch: 7 3200/3904 Training loss: 0.301971
Training loss: 0.316711
Test loss: 0.839585; True positive: 8; True negative: 262, False Positive: 3, False negative: 895, accuracy: 0.23116438356164384, precision: 0.7272727272727273, recall: 0.008859357696566999
Epoch: 8 0/3904 Training loss: 0.253535
Epoch: 8 800/3904 Training loss: 0.168952
Epoch: 8 1600/3904 Training loss: 0.213906
Epoch: 8 2400/3904 Training loss: 0.249110
Epoch: 8 3200/3904 Training loss: 0.381167
Training loss: 0.299254
Test loss: 0.466960; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 9 0/3904 Training loss: 0.163503
Epoch: 9 800/3904 Training loss: 0.098333
Epoch: 9 1600/3904 Training loss: 0.202911
Epoch: 9 2400/3904 Training loss: 0.199762
Epoch: 9 3200/3904 Training loss: 0.337441
Training loss: 0.278675
Test loss: 0.521296; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 10 0/3904 Training loss: 0.116631
Epoch: 10 800/3904 Training loss: 0.067531
Epoch: 10 1600/3904 Training loss: 0.180205
Epoch: 10 2400/3904 Training loss: 0.218421
Epoch: 10 3200/3904 Training loss: 0.368199
Training loss: 0.261899
Test loss: 0.552689; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 11 0/3904 Training loss: 0.121019
Epoch: 11 800/3904 Training loss: 0.057276
Epoch: 11 1600/3904 Training loss: 0.161726
Epoch: 11 2400/3904 Training loss: 0.179464
Epoch: 11 3200/3904 Training loss: 0.412649
Training loss: 0.240671
Test loss: 0.556827; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 12 0/3904 Training loss: 0.237939
Epoch: 12 800/3904 Training loss: 0.145407
Epoch: 12 1600/3904 Training loss: 0.071088
Epoch: 12 2400/3904 Training loss: 0.069340
Epoch: 12 3200/3904 Training loss: 0.288951
Training loss: 0.227457
Test loss: 0.570291; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 13 0/3904 Training loss: 0.152916
Epoch: 13 800/3904 Training loss: 0.047584
Epoch: 13 1600/3904 Training loss: 0.119681
Epoch: 13 2400/3904 Training loss: 0.122967
Epoch: 13 3200/3904 Training loss: 0.405254
Training loss: 0.214712
Test loss: 0.578993; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 14 0/3904 Training loss: 0.174326
Epoch: 14 800/3904 Training loss: 0.036969
Epoch: 14 1600/3904 Training loss: 0.238421
Epoch: 14 2400/3904 Training loss: 0.099379
Epoch: 14 3200/3904 Training loss: 0.448467
Training loss: 0.205222
Test loss: 0.606484; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 15 0/3904 Training loss: 0.115705
Epoch: 15 800/3904 Training loss: 0.055386
Epoch: 15 1600/3904 Training loss: 0.106609
Epoch: 15 2400/3904 Training loss: 0.107343
Epoch: 15 3200/3904 Training loss: 0.316692
Training loss: 0.191101
Test loss: 0.629294; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 16 0/3904 Training loss: 0.148534
Epoch: 16 800/3904 Training loss: 0.029106
Epoch: 16 1600/3904 Training loss: 0.128021
Epoch: 16 2400/3904 Training loss: 0.065410
Epoch: 16 3200/3904 Training loss: 0.270157
Training loss: 0.173196
Test loss: 0.658562; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 17 0/3904 Training loss: 0.206858
Epoch: 17 800/3904 Training loss: 0.042287
Epoch: 17 1600/3904 Training loss: 0.156176
Epoch: 17 2400/3904 Training loss: 0.106312
Epoch: 17 3200/3904 Training loss: 0.344186
Training loss: 0.182535
Test loss: 0.688928; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 18 0/3904 Training loss: 0.167961
Epoch: 18 800/3904 Training loss: 0.041866
Epoch: 18 1600/3904 Training loss: 0.189496
Epoch: 18 2400/3904 Training loss: 0.159545
Epoch: 18 3200/3904 Training loss: 0.164935
Training loss: 0.158412
Test loss: 0.711618; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
starting trial 174
[I 2022-12-05 04:25:30,882] Trial 173 finished with value: 0.8176369863013698 and parameters: {'d_model': 64, 'nhead': 8, 'n_encoders': 1, 'learning_rate': 0.00016732143485865742, 'weight_decay': 5.284727295193055e-06, 'dropout': 0.20986065486995256, 'max_pool_conv': 64, 'kernel_size': 14, 'd_mlp': 32, 'num_conv_layers': 3, 'encoder_dropout': 0.14567424862754202, 'd_feed_forward': 128, 'max_pool_dim': 8, 'n_mlp_layers': 3}. Best is trial 62 with value: 0.860445205479452.
Epoch: 0 0/3904 Training loss: 0.694816
Epoch: 0 800/3904 Training loss: 0.734014
Epoch: 0 1600/3904 Training loss: 0.437717
Epoch: 0 2400/3904 Training loss: 0.786268
Epoch: 0 3200/3904 Training loss: 0.520458
Training loss: 0.655061
Test loss: 0.786518; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 1 0/3904 Training loss: 0.670364
Epoch: 1 800/3904 Training loss: 0.676840
Epoch: 1 1600/3904 Training loss: 0.274793
Epoch: 1 2400/3904 Training loss: 0.462878
Epoch: 1 3200/3904 Training loss: 0.353639
Training loss: 0.558313
Test loss: 0.952273; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 2 0/3904 Training loss: 0.445207
Epoch: 2 800/3904 Training loss: 0.379047
Epoch: 2 1600/3904 Training loss: 0.226781
Epoch: 2 2400/3904 Training loss: 0.443881
Epoch: 2 3200/3904 Training loss: 0.413305
Training loss: 0.451289
Test loss: 1.251510; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 3 0/3904 Training loss: 0.378969
Epoch: 3 800/3904 Training loss: 0.342071
Epoch: 3 1600/3904 Training loss: 0.201939
Epoch: 3 2400/3904 Training loss: 0.257993
Epoch: 3 3200/3904 Training loss: 0.409483
Training loss: 0.416501
Test loss: 1.385858; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 4 0/3904 Training loss: 0.300657
Epoch: 4 800/3904 Training loss: 0.239795
Epoch: 4 1600/3904 Training loss: 0.178600
Epoch: 4 2400/3904 Training loss: 0.331359
Epoch: 4 3200/3904 Training loss: 0.304792
Training loss: 0.385019
Test loss: 1.484301; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 5 0/3904 Training loss: 0.250626
Epoch: 5 800/3904 Training loss: 0.210753
Epoch: 5 1600/3904 Training loss: 0.123083
Epoch: 5 2400/3904 Training loss: 0.269900
Epoch: 5 3200/3904 Training loss: 0.420459
Training loss: 0.362683
Test loss: 1.586384; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 6 0/3904 Training loss: 0.215922
Epoch: 6 800/3904 Training loss: 0.154606
Epoch: 6 1600/3904 Training loss: 0.149391
Epoch: 6 2400/3904 Training loss: 0.307220
Epoch: 6 3200/3904 Training loss: 0.440519
Training loss: 0.336225
Test loss: 0.625478; True positive: 585; True negative: 239, False Positive: 26, False negative: 318, accuracy: 0.7054794520547946, precision: 0.9574468085106383, recall: 0.6478405315614618
Epoch: 7 0/3904 Training loss: 0.275002
Epoch: 7 800/3904 Training loss: 0.275872
Epoch: 7 1600/3904 Training loss: 0.097721
Epoch: 7 2400/3904 Training loss: 0.399488
Epoch: 7 3200/3904 Training loss: 0.375935
Training loss: 0.306699
Test loss: 0.505583; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 8 0/3904 Training loss: 0.256856
Epoch: 8 800/3904 Training loss: 0.117359
Epoch: 8 1600/3904 Training loss: 0.128029
Epoch: 8 2400/3904 Training loss: 0.248489
Epoch: 8 3200/3904 Training loss: 0.406952
Training loss: 0.282101
Test loss: 0.505821; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 9 0/3904 Training loss: 0.196708
Epoch: 9 800/3904 Training loss: 0.169797
Epoch: 9 1600/3904 Training loss: 0.081115
Epoch: 9 2400/3904 Training loss: 0.146486
Epoch: 9 3200/3904 Training loss: 0.365942
Training loss: 0.269617
Test loss: 0.512332; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 10 0/3904 Training loss: 0.296460
Epoch: 10 800/3904 Training loss: 0.193627
Epoch: 10 1600/3904 Training loss: 0.088777
Epoch: 10 2400/3904 Training loss: 0.232025
Epoch: 10 3200/3904 Training loss: 0.268141
Training loss: 0.261047
Test loss: 0.520271; True positive: 834; True negative: 117, False Positive: 148, False negative: 69, accuracy: 0.8142123287671232, precision: 0.8492871690427699, recall: 0.9235880398671097
Epoch: 11 0/3904 Training loss: 0.260886
Epoch: 11 800/3904 Training loss: 0.160650
Epoch: 11 1600/3904 Training loss: 0.061809
Epoch: 11 2400/3904 Training loss: 0.171943
Epoch: 11 3200/3904 Training loss: 0.333270
Training loss: 0.239147
Test loss: 0.510394; True positive: 833; True negative: 117, False Positive: 148, False negative: 70, accuracy: 0.8133561643835616, precision: 0.8491335372069317, recall: 0.9224806201550387
Epoch: 12 0/3904 Training loss: 0.229020
Epoch: 12 800/3904 Training loss: 0.104725
Epoch: 12 1600/3904 Training loss: 0.115202
Epoch: 12 2400/3904 Training loss: 0.130673
Epoch: 12 3200/3904 Training loss: 0.391468
Training loss: 0.231000
Test loss: 0.496722; True positive: 833; True negative: 117, False Positive: 148, False negative: 70, accuracy: 0.8133561643835616, precision: 0.8491335372069317, recall: 0.9224806201550387
Epoch: 13 0/3904 Training loss: 0.210909
Epoch: 13 800/3904 Training loss: 0.085322
Epoch: 13 1600/3904 Training loss: 0.100804
Epoch: 13 2400/3904 Training loss: 0.161680
Epoch: 13 3200/3904 Training loss: 0.370039
Training loss: 0.218714
Test loss: 0.537210; True positive: 829; True negative: 117, False Positive: 148, False negative: 74, accuracy: 0.809931506849315, precision: 0.8485158648925282, recall: 0.9180509413067552
Epoch: 14 0/3904 Training loss: 0.197271
Epoch: 14 800/3904 Training loss: 0.093780
Epoch: 14 1600/3904 Training loss: 0.140878
Epoch: 14 2400/3904 Training loss: 0.065837
Epoch: 14 3200/3904 Training loss: 0.246394
Training loss: 0.214044
Test loss: 0.547109; True positive: 826; True negative: 117, False Positive: 148, False negative: 77, accuracy: 0.8073630136986302, precision: 0.8480492813141683, recall: 0.9147286821705426
Epoch: 15 0/3904 Training loss: 0.245146
Epoch: 15 800/3904 Training loss: 0.227146
Epoch: 15 1600/3904 Training loss: 0.073680
Epoch: 15 2400/3904 Training loss: 0.102523
Epoch: 15 3200/3904 Training loss: 0.295356
Training loss: 0.196783
Test loss: 0.515484; True positive: 865; True negative: 94, False Positive: 171, False negative: 38, accuracy: 0.8210616438356164, precision: 0.834942084942085, recall: 0.9579180509413068
Epoch: 16 0/3904 Training loss: 0.222170
Epoch: 16 800/3904 Training loss: 0.075554
Epoch: 16 1600/3904 Training loss: 0.086969
Epoch: 16 2400/3904 Training loss: 0.087489
Epoch: 16 3200/3904 Training loss: 0.370291
Training loss: 0.195176
Test loss: 0.625815; True positive: 766; True negative: 124, False Positive: 141, False negative: 137, accuracy: 0.761986301369863, precision: 0.844542447629548, recall: 0.8482834994462901
Epoch: 17 0/3904 Training loss: 0.232509
Epoch: 17 800/3904 Training loss: 0.118085
Epoch: 17 1600/3904 Training loss: 0.066419
Epoch: 17 2400/3904 Training loss: 0.061093
Epoch: 17 3200/3904 Training loss: 0.310021
Training loss: 0.178861
Test loss: 0.914627; True positive: 270; True negative: 101, False Positive: 164, False negative: 633, accuracy: 0.3176369863013699, precision: 0.6221198156682027, recall: 0.29900332225913623
Epoch: 18 0/3904 Training loss: 0.121907
Epoch: 18 800/3904 Training loss: 0.109271
Epoch: 18 1600/3904 Training loss: 0.046481
Epoch: 18 2400/3904 Training loss: 0.071701
Epoch: 18 3200/3904 Training loss: 0.224471
Training loss: 0.184912
Test loss: 1.586414; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 19 0/3904 Training loss: 0.172716
Epoch: 19 800/3904 Training loss: 0.092120
Epoch: 19 1600/3904 Training loss: 0.037710
Epoch: 19 2400/3904 Training loss: 0.112553
Epoch: 19 3200/3904 Training loss: 0.364020
Training loss: 0.173161
Test loss: 1.534043; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 20 0/3904 Training loss: 0.220283
Epoch: 20 800/3904 Training loss: 0.201325
Epoch: 20 1600/3904 Training loss: 0.142509
Epoch: 20 2400/3904 Training loss: 0.037719
Epoch: 20 3200/3904 Training loss: 0.176319
Training loss: 0.168858
Test loss: 1.867978; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 21 0/3904 Training loss: 0.118905
Epoch: 21 800/3904 Training loss: 0.084585
Epoch: 21 1600/3904 Training loss: 0.042213
Epoch: 21 2400/3904 Training loss: 0.032691
Epoch: 21 3200/3904 Training loss: 0.223194
Training loss: 0.160949
Test loss: 1.947111; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 22 0/3904 Training loss: 0.136670
Epoch: 22 800/3904 Training loss: 0.131432
Epoch: 22 1600/3904 Training loss: 0.055776
Epoch: 22 2400/3904 Training loss: 0.030375
Epoch: 22 3200/3904 Training loss: 0.493624
Training loss: 0.159997
Test loss: 1.627769; True positive: 65; True negative: 157, False Positive: 108, False negative: 838, accuracy: 0.19006849315068494, precision: 0.37572254335260113, recall: 0.07198228128460686
starting trial 175
[I 2022-12-05 04:27:47,557] Trial 174 finished with value: 0.8210616438356164 and parameters: {'d_model': 64, 'nhead': 8, 'n_encoders': 1, 'learning_rate': 0.00012035750275346318, 'weight_decay': 4.6477946436556526e-06, 'dropout': 0.23689429891616015, 'max_pool_conv': 64, 'kernel_size': 14, 'd_mlp': 32, 'num_conv_layers': 3, 'encoder_dropout': 0.12537929324868882, 'd_feed_forward': 128, 'max_pool_dim': 8, 'n_mlp_layers': 3}. Best is trial 62 with value: 0.860445205479452.
Epoch: 0 0/3904 Training loss: 0.700579
Epoch: 0 800/3904 Training loss: 0.731024
Epoch: 0 1600/3904 Training loss: 0.433395
Epoch: 0 2400/3904 Training loss: 0.747365
Epoch: 0 3200/3904 Training loss: 0.525871
Training loss: 0.653529
Test loss: 0.722497; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 1 0/3904 Training loss: 0.687965
Epoch: 1 800/3904 Training loss: 0.691540
Epoch: 1 1600/3904 Training loss: 0.339643
Epoch: 1 2400/3904 Training loss: 0.658479
Epoch: 1 3200/3904 Training loss: 0.416934
Training loss: 0.567360
Test loss: 0.589785; True positive: 834; True negative: 122, False Positive: 143, False negative: 69, accuracy: 0.8184931506849316, precision: 0.8536335721596725, recall: 0.9235880398671097
Epoch: 2 0/3904 Training loss: 0.518361
Epoch: 2 800/3904 Training loss: 0.433687
Epoch: 2 1600/3904 Training loss: 0.206658
Epoch: 2 2400/3904 Training loss: 0.472113
Epoch: 2 3200/3904 Training loss: 0.431379
Training loss: 0.463652
Test loss: 0.542200; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 3 0/3904 Training loss: 0.369898
Epoch: 3 800/3904 Training loss: 0.440371
Epoch: 3 1600/3904 Training loss: 0.187864
Epoch: 3 2400/3904 Training loss: 0.387316
Epoch: 3 3200/3904 Training loss: 0.463835
Training loss: 0.412504
Test loss: 0.548694; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 4 0/3904 Training loss: 0.336687
Epoch: 4 800/3904 Training loss: 0.358561
Epoch: 4 1600/3904 Training loss: 0.189735
Epoch: 4 2400/3904 Training loss: 0.287886
Epoch: 4 3200/3904 Training loss: 0.500915
Training loss: 0.379069
Test loss: 0.527556; True positive: 837; True negative: 128, False Positive: 137, False negative: 66, accuracy: 0.8261986301369864, precision: 0.8593429158110883, recall: 0.9269102990033222
Epoch: 5 0/3904 Training loss: 0.318308
Epoch: 5 800/3904 Training loss: 0.382674
Epoch: 5 1600/3904 Training loss: 0.198424
Epoch: 5 2400/3904 Training loss: 0.239734
Epoch: 5 3200/3904 Training loss: 0.438145
Training loss: 0.357014
Test loss: 0.545529; True positive: 836; True negative: 119, False Positive: 146, False negative: 67, accuracy: 0.8176369863013698, precision: 0.8513238289205702, recall: 0.9258028792912514
Epoch: 6 0/3904 Training loss: 0.288733
Epoch: 6 800/3904 Training loss: 0.298101
Epoch: 6 1600/3904 Training loss: 0.187221
Epoch: 6 2400/3904 Training loss: 0.247156
Epoch: 6 3200/3904 Training loss: 0.542015
Training loss: 0.331629
Test loss: 0.558658; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 7 0/3904 Training loss: 0.246119
Epoch: 7 800/3904 Training loss: 0.298336
Epoch: 7 1600/3904 Training loss: 0.132446
Epoch: 7 2400/3904 Training loss: 0.244416
Epoch: 7 3200/3904 Training loss: 0.502841
Training loss: 0.314481
Test loss: 0.577291; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 8 0/3904 Training loss: 0.309392
Epoch: 8 800/3904 Training loss: 0.321714
Epoch: 8 1600/3904 Training loss: 0.150639
Epoch: 8 2400/3904 Training loss: 0.250376
Epoch: 8 3200/3904 Training loss: 0.448702
Training loss: 0.283892
Test loss: 0.605642; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 9 0/3904 Training loss: 0.307815
Epoch: 9 800/3904 Training loss: 0.276506
Epoch: 9 1600/3904 Training loss: 0.143543
Epoch: 9 2400/3904 Training loss: 0.180755
Epoch: 9 3200/3904 Training loss: 0.518562
Training loss: 0.271648
Test loss: 0.620745; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 10 0/3904 Training loss: 0.272444
Epoch: 10 800/3904 Training loss: 0.300124
Epoch: 10 1600/3904 Training loss: 0.100387
Epoch: 10 2400/3904 Training loss: 0.150539
Epoch: 10 3200/3904 Training loss: 0.522326
Training loss: 0.256543
Test loss: 0.659645; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 11 0/3904 Training loss: 0.290928
Epoch: 11 800/3904 Training loss: 0.231303
Epoch: 11 1600/3904 Training loss: 0.128038
Epoch: 11 2400/3904 Training loss: 0.159392
Epoch: 11 3200/3904 Training loss: 0.523704
Training loss: 0.240066
Test loss: 0.673220; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 12 0/3904 Training loss: 0.232143
Epoch: 12 800/3904 Training loss: 0.173685
Epoch: 12 1600/3904 Training loss: 0.131998
Epoch: 12 2400/3904 Training loss: 0.165398
Epoch: 12 3200/3904 Training loss: 0.480406
Training loss: 0.228573
Test loss: 0.709496; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 13 0/3904 Training loss: 0.179752
Epoch: 13 800/3904 Training loss: 0.114649
Epoch: 13 1600/3904 Training loss: 0.135553
Epoch: 13 2400/3904 Training loss: 0.201678
Epoch: 13 3200/3904 Training loss: 0.381189
Training loss: 0.214393
Test loss: 0.691886; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 14 0/3904 Training loss: 0.324284
Epoch: 14 800/3904 Training loss: 0.129674
Epoch: 14 1600/3904 Training loss: 0.065722
Epoch: 14 2400/3904 Training loss: 0.081604
Epoch: 14 3200/3904 Training loss: 0.363548
Training loss: 0.206238
Test loss: 0.723269; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
starting trial 176
[I 2022-12-05 04:29:20,088] Trial 175 finished with value: 0.8261986301369864 and parameters: {'d_model': 64, 'nhead': 8, 'n_encoders': 1, 'learning_rate': 0.00013359786872347657, 'weight_decay': 3.47852360224032e-06, 'dropout': 0.15728995504233945, 'max_pool_conv': 32, 'kernel_size': 15, 'd_mlp': 32, 'num_conv_layers': 3, 'encoder_dropout': 0.100779305959219, 'd_feed_forward': 128, 'max_pool_dim': 8, 'n_mlp_layers': 3}. Best is trial 62 with value: 0.860445205479452.
Epoch: 0 0/3904 Training loss: 0.695933
Epoch: 0 800/3904 Training loss: 0.728173
Epoch: 0 1600/3904 Training loss: 0.424244
Epoch: 0 2400/3904 Training loss: 0.772150
Epoch: 0 3200/3904 Training loss: 0.525719
Training loss: 0.656014
Test loss: 0.741510; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 1 0/3904 Training loss: 0.660647
Epoch: 1 800/3904 Training loss: 0.688859
Epoch: 1 1600/3904 Training loss: 0.273406
Epoch: 1 2400/3904 Training loss: 0.773926
Epoch: 1 3200/3904 Training loss: 0.372689
Training loss: 0.551236
Test loss: 0.626990; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 2 0/3904 Training loss: 0.460130
Epoch: 2 800/3904 Training loss: 0.425960
Epoch: 2 1600/3904 Training loss: 0.216283
Epoch: 2 2400/3904 Training loss: 0.498321
Epoch: 2 3200/3904 Training loss: 0.437491
Training loss: 0.449718
Test loss: 1.021173; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 3 0/3904 Training loss: 0.371499
Epoch: 3 800/3904 Training loss: 0.315123
Epoch: 3 1600/3904 Training loss: 0.204663
Epoch: 3 2400/3904 Training loss: 0.436603
Epoch: 3 3200/3904 Training loss: 0.388615
Training loss: 0.411645
Test loss: 1.252944; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 4 0/3904 Training loss: 0.335929
Epoch: 4 800/3904 Training loss: 0.278665
Epoch: 4 1600/3904 Training loss: 0.175193
Epoch: 4 2400/3904 Training loss: 0.338770
Epoch: 4 3200/3904 Training loss: 0.383623
Training loss: 0.385397
Test loss: 1.228951; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 5 0/3904 Training loss: 0.338219
Epoch: 5 800/3904 Training loss: 0.304213
Epoch: 5 1600/3904 Training loss: 0.115698
Epoch: 5 2400/3904 Training loss: 0.301645
Epoch: 5 3200/3904 Training loss: 0.388907
Training loss: 0.365147
Test loss: 1.167170; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 6 0/3904 Training loss: 0.270159
Epoch: 6 800/3904 Training loss: 0.238527
Epoch: 6 1600/3904 Training loss: 0.085104
Epoch: 6 2400/3904 Training loss: 0.255931
Epoch: 6 3200/3904 Training loss: 0.318897
Training loss: 0.337829
Test loss: 1.250067; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 7 0/3904 Training loss: 0.285632
Epoch: 7 800/3904 Training loss: 0.237731
Epoch: 7 1600/3904 Training loss: 0.096289
Epoch: 7 2400/3904 Training loss: 0.235655
Epoch: 7 3200/3904 Training loss: 0.377715
Training loss: 0.311128
Test loss: 1.038027; True positive: 5; True negative: 265, False Positive: 0, False negative: 898, accuracy: 0.23116438356164384, precision: 1.0, recall: 0.005537098560354375
Epoch: 8 0/3904 Training loss: 0.252329
Epoch: 8 800/3904 Training loss: 0.169973
Epoch: 8 1600/3904 Training loss: 0.096235
Epoch: 8 2400/3904 Training loss: 0.280135
Epoch: 8 3200/3904 Training loss: 0.271443
Training loss: 0.281868
Test loss: 1.124116; True positive: 4; True negative: 265, False Positive: 0, False negative: 899, accuracy: 0.2303082191780822, precision: 1.0, recall: 0.004429678848283499
Epoch: 9 0/3904 Training loss: 0.296536
Epoch: 9 800/3904 Training loss: 0.102406
Epoch: 9 1600/3904 Training loss: 0.085578
Epoch: 9 2400/3904 Training loss: 0.324342
Epoch: 9 3200/3904 Training loss: 0.309008
Training loss: 0.259649
Test loss: 1.197374; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 10 0/3904 Training loss: 0.149356
Epoch: 10 800/3904 Training loss: 0.138729
Epoch: 10 1600/3904 Training loss: 0.051409
Epoch: 10 2400/3904 Training loss: 0.329258
Epoch: 10 3200/3904 Training loss: 0.253435
Training loss: 0.243151
Test loss: 1.272226; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 11 0/3904 Training loss: 0.245531
Epoch: 11 800/3904 Training loss: 0.089747
Epoch: 11 1600/3904 Training loss: 0.048266
Epoch: 11 2400/3904 Training loss: 0.277085
Epoch: 11 3200/3904 Training loss: 0.207594
Training loss: 0.228839
Test loss: 1.330341; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
starting trial 177
[I 2022-12-05 04:30:39,557] Trial 176 finished with value: 0.8176369863013698 and parameters: {'d_model': 64, 'nhead': 8, 'n_encoders': 1, 'learning_rate': 0.00013001251301815916, 'weight_decay': 3.574488243322885e-06, 'dropout': 0.15952502253292414, 'max_pool_conv': 32, 'kernel_size': 16, 'd_mlp': 32, 'num_conv_layers': 3, 'encoder_dropout': 0.08578576180963857, 'd_feed_forward': 128, 'max_pool_dim': 8, 'n_mlp_layers': 3}. Best is trial 62 with value: 0.860445205479452.
Epoch: 0 0/3904 Training loss: 0.708096
Epoch: 0 800/3904 Training loss: 0.687666
Epoch: 0 1600/3904 Training loss: 0.581369
Epoch: 0 2400/3904 Training loss: 0.759571
Epoch: 0 3200/3904 Training loss: 0.547628
Training loss: 0.679917
Test loss: 0.748914; True positive: 65; True negative: 148, False Positive: 117, False negative: 838, accuracy: 0.18236301369863014, precision: 0.35714285714285715, recall: 0.07198228128460686
Epoch: 1 0/3904 Training loss: 0.698727
Epoch: 1 800/3904 Training loss: 0.726427
Epoch: 1 1600/3904 Training loss: 0.392642
Epoch: 1 2400/3904 Training loss: 0.849456
Epoch: 1 3200/3904 Training loss: 0.404894
Training loss: 0.603308
Test loss: 0.608107; True positive: 903; True negative: 0, False Positive: 265, False negative: 0, accuracy: 0.7731164383561644, precision: 0.7731164383561644, recall: 1.0
Epoch: 2 0/3904 Training loss: 0.596922
Epoch: 2 800/3904 Training loss: 0.495969
Epoch: 2 1600/3904 Training loss: 0.270227
Epoch: 2 2400/3904 Training loss: 0.449624
Epoch: 2 3200/3904 Training loss: 0.414291
Training loss: 0.484271
Test loss: 0.557578; True positive: 903; True negative: 0, False Positive: 265, False negative: 0, accuracy: 0.7731164383561644, precision: 0.7731164383561644, recall: 1.0
Epoch: 3 0/3904 Training loss: 0.506703
Epoch: 3 800/3904 Training loss: 0.443189
Epoch: 3 1600/3904 Training loss: 0.260492
Epoch: 3 2400/3904 Training loss: 0.404667
Epoch: 3 3200/3904 Training loss: 0.422530
Training loss: 0.442098
Test loss: 0.548032; True positive: 903; True negative: 0, False Positive: 265, False negative: 0, accuracy: 0.7731164383561644, precision: 0.7731164383561644, recall: 1.0
Epoch: 4 0/3904 Training loss: 0.500633
Epoch: 4 800/3904 Training loss: 0.389030
Epoch: 4 1600/3904 Training loss: 0.200110
Epoch: 4 2400/3904 Training loss: 0.342948
Epoch: 4 3200/3904 Training loss: 0.395430
Training loss: 0.417428
Test loss: 0.546433; True positive: 903; True negative: 0, False Positive: 265, False negative: 0, accuracy: 0.7731164383561644, precision: 0.7731164383561644, recall: 1.0
Epoch: 5 0/3904 Training loss: 0.492467
Epoch: 5 800/3904 Training loss: 0.342749
Epoch: 5 1600/3904 Training loss: 0.187506
Epoch: 5 2400/3904 Training loss: 0.318664
Epoch: 5 3200/3904 Training loss: 0.346591
Training loss: 0.397450
Test loss: 0.538010; True positive: 903; True negative: 0, False Positive: 265, False negative: 0, accuracy: 0.7731164383561644, precision: 0.7731164383561644, recall: 1.0
Epoch: 6 0/3904 Training loss: 0.466584
Epoch: 6 800/3904 Training loss: 0.307379
Epoch: 6 1600/3904 Training loss: 0.189541
Epoch: 6 2400/3904 Training loss: 0.310924
Epoch: 6 3200/3904 Training loss: 0.399030
Training loss: 0.382199
Test loss: 0.516763; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 7 0/3904 Training loss: 0.520187
Epoch: 7 800/3904 Training loss: 0.396454
Epoch: 7 1600/3904 Training loss: 0.163871
Epoch: 7 2400/3904 Training loss: 0.308367
Epoch: 7 3200/3904 Training loss: 0.417450
Training loss: 0.378398
Test loss: 0.519440; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 8 0/3904 Training loss: 0.489998
Epoch: 8 800/3904 Training loss: 0.231243
Epoch: 8 1600/3904 Training loss: 0.150747
Epoch: 8 2400/3904 Training loss: 0.251146
Epoch: 8 3200/3904 Training loss: 0.387470
Training loss: 0.357263
Test loss: 0.513781; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 9 0/3904 Training loss: 0.422927
Epoch: 9 800/3904 Training loss: 0.225254
Epoch: 9 1600/3904 Training loss: 0.169744
Epoch: 9 2400/3904 Training loss: 0.216789
Epoch: 9 3200/3904 Training loss: 0.406036
Training loss: 0.349506
Test loss: 0.499113; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 10 0/3904 Training loss: 0.426374
Epoch: 10 800/3904 Training loss: 0.251187
Epoch: 10 1600/3904 Training loss: 0.130205
Epoch: 10 2400/3904 Training loss: 0.246973
Epoch: 10 3200/3904 Training loss: 0.391124
Training loss: 0.344330
Test loss: 0.481371; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 11 0/3904 Training loss: 0.384042
Epoch: 11 800/3904 Training loss: 0.414847
Epoch: 11 1600/3904 Training loss: 0.129977
Epoch: 11 2400/3904 Training loss: 0.198662
Epoch: 11 3200/3904 Training loss: 0.356781
Training loss: 0.329112
Test loss: 0.548417; True positive: 834; True negative: 118, False Positive: 147, False negative: 69, accuracy: 0.815068493150685, precision: 0.8501529051987767, recall: 0.9235880398671097
Epoch: 12 0/3904 Training loss: 0.453962
Epoch: 12 800/3904 Training loss: 0.234318
Epoch: 12 1600/3904 Training loss: 0.164365
Epoch: 12 2400/3904 Training loss: 0.201114
Epoch: 12 3200/3904 Training loss: 0.288719
Training loss: 0.315468
Test loss: 0.535984; True positive: 820; True negative: 123, False Positive: 142, False negative: 83, accuracy: 0.8073630136986302, precision: 0.8523908523908524, recall: 0.9080841638981174
Epoch: 13 0/3904 Training loss: 0.373297
Epoch: 13 800/3904 Training loss: 0.218584
Epoch: 13 1600/3904 Training loss: 0.145717
Epoch: 13 2400/3904 Training loss: 0.204993
Epoch: 13 3200/3904 Training loss: 0.434666
Training loss: 0.298169
Test loss: 0.552412; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 14 0/3904 Training loss: 0.358315
Epoch: 14 800/3904 Training loss: 0.183563
Epoch: 14 1600/3904 Training loss: 0.113034
Epoch: 14 2400/3904 Training loss: 0.160139
Epoch: 14 3200/3904 Training loss: 0.400981
Training loss: 0.277503
Test loss: 0.550995; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 15 0/3904 Training loss: 0.418377
Epoch: 15 800/3904 Training loss: 0.146758
Epoch: 15 1600/3904 Training loss: 0.137273
Epoch: 15 2400/3904 Training loss: 0.145297
Epoch: 15 3200/3904 Training loss: 0.416506
Training loss: 0.264149
Test loss: 0.561435; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 16 0/3904 Training loss: 0.342373
Epoch: 16 800/3904 Training loss: 0.189934
Epoch: 16 1600/3904 Training loss: 0.120244
Epoch: 16 2400/3904 Training loss: 0.220391
Epoch: 16 3200/3904 Training loss: 0.468068
Training loss: 0.257867
Test loss: 0.562130; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 17 0/3904 Training loss: 0.424648
Epoch: 17 800/3904 Training loss: 0.106308
Epoch: 17 1600/3904 Training loss: 0.097574
Epoch: 17 2400/3904 Training loss: 0.111631
Epoch: 17 3200/3904 Training loss: 0.350053
Training loss: 0.253530
Test loss: 0.567377; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 18 0/3904 Training loss: 0.367803
Epoch: 18 800/3904 Training loss: 0.207493
Epoch: 18 1600/3904 Training loss: 0.090653
Epoch: 18 2400/3904 Training loss: 0.068048
Epoch: 18 3200/3904 Training loss: 0.353998
Training loss: 0.235866
Test loss: 0.570895; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 19 0/3904 Training loss: 0.389582
Epoch: 19 800/3904 Training loss: 0.146654
Epoch: 19 1600/3904 Training loss: 0.095542
Epoch: 19 2400/3904 Training loss: 0.061141
Epoch: 19 3200/3904 Training loss: 0.459933
Training loss: 0.231622
Test loss: 0.588312; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 20 0/3904 Training loss: 0.271971
Epoch: 20 800/3904 Training loss: 0.236963
Epoch: 20 1600/3904 Training loss: 0.097371
Epoch: 20 2400/3904 Training loss: 0.133171
Epoch: 20 3200/3904 Training loss: 0.421891
Training loss: 0.218941
Test loss: 0.595583; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
starting trial 178
[I 2022-12-05 04:33:27,614] Trial 177 finished with value: 0.8176369863013698 and parameters: {'d_model': 64, 'nhead': 8, 'n_encoders': 1, 'learning_rate': 0.00011492925775502988, 'weight_decay': 3.0603181607724157e-06, 'dropout': 0.14641092038207748, 'max_pool_conv': 32, 'kernel_size': 15, 'd_mlp': 16, 'num_conv_layers': 4, 'encoder_dropout': 0.010177319277079554, 'd_feed_forward': 128, 'max_pool_dim': 8, 'n_mlp_layers': 3}. Best is trial 62 with value: 0.860445205479452.
Epoch: 0 0/3904 Training loss: 0.682177
Epoch: 0 800/3904 Training loss: 0.744758
Epoch: 0 1600/3904 Training loss: 0.425840
Epoch: 0 2400/3904 Training loss: 0.727160
Epoch: 0 3200/3904 Training loss: 0.508915
Training loss: 0.655000
Test loss: 0.901606; True positive: 65; True negative: 148, False Positive: 117, False negative: 838, accuracy: 0.18236301369863014, precision: 0.35714285714285715, recall: 0.07198228128460686
Epoch: 1 0/3904 Training loss: 0.683893
Epoch: 1 800/3904 Training loss: 0.657321
Epoch: 1 1600/3904 Training loss: 0.291549
Epoch: 1 2400/3904 Training loss: 0.745559
Epoch: 1 3200/3904 Training loss: 0.391080
Training loss: 0.574721
Test loss: 1.160745; True positive: 1; True negative: 265, False Positive: 0, False negative: 902, accuracy: 0.22773972602739725, precision: 1.0, recall: 0.0011074197120708748
Epoch: 2 0/3904 Training loss: 0.591444
Epoch: 2 800/3904 Training loss: 0.473165
Epoch: 2 1600/3904 Training loss: 0.205013
Epoch: 2 2400/3904 Training loss: 0.561792
Epoch: 2 3200/3904 Training loss: 0.444366
Training loss: 0.459688
Test loss: 0.897003; True positive: 20; True negative: 264, False Positive: 1, False negative: 883, accuracy: 0.24315068493150685, precision: 0.9523809523809523, recall: 0.0221483942414175
Epoch: 3 0/3904 Training loss: 0.421131
Epoch: 3 800/3904 Training loss: 0.281037
Epoch: 3 1600/3904 Training loss: 0.193432
Epoch: 3 2400/3904 Training loss: 0.560134
Epoch: 3 3200/3904 Training loss: 0.479439
Training loss: 0.380124
Test loss: 0.456202; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 4 0/3904 Training loss: 0.366797
Epoch: 4 800/3904 Training loss: 0.177327
Epoch: 4 1600/3904 Training loss: 0.167050
Epoch: 4 2400/3904 Training loss: 0.437813
Epoch: 4 3200/3904 Training loss: 0.554611
Training loss: 0.324846
Test loss: 0.516684; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 5 0/3904 Training loss: 0.219495
Epoch: 5 800/3904 Training loss: 0.228787
Epoch: 5 1600/3904 Training loss: 0.129207
Epoch: 5 2400/3904 Training loss: 0.409218
Epoch: 5 3200/3904 Training loss: 0.419015
Training loss: 0.290430
Test loss: 0.525629; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 6 0/3904 Training loss: 0.261654
Epoch: 6 800/3904 Training loss: 0.110644
Epoch: 6 1600/3904 Training loss: 0.119345
Epoch: 6 2400/3904 Training loss: 0.273210
Epoch: 6 3200/3904 Training loss: 0.543186
Training loss: 0.267764
Test loss: 0.542310; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 7 0/3904 Training loss: 0.235567
Epoch: 7 800/3904 Training loss: 0.178162
Epoch: 7 1600/3904 Training loss: 0.099094
Epoch: 7 2400/3904 Training loss: 0.201158
Epoch: 7 3200/3904 Training loss: 0.433751
Training loss: 0.245465
Test loss: 0.541911; True positive: 837; True negative: 117, False Positive: 148, False negative: 66, accuracy: 0.8167808219178082, precision: 0.849746192893401, recall: 0.9269102990033222
Epoch: 8 0/3904 Training loss: 0.235143
Epoch: 8 800/3904 Training loss: 0.084761
Epoch: 8 1600/3904 Training loss: 0.075702
Epoch: 8 2400/3904 Training loss: 0.220022
Epoch: 8 3200/3904 Training loss: 0.474573
Training loss: 0.232458
Test loss: 0.607920; True positive: 833; True negative: 117, False Positive: 148, False negative: 70, accuracy: 0.8133561643835616, precision: 0.8491335372069317, recall: 0.9224806201550387
Epoch: 9 0/3904 Training loss: 0.204374
Epoch: 9 800/3904 Training loss: 0.108458
Epoch: 9 1600/3904 Training loss: 0.054107
Epoch: 9 2400/3904 Training loss: 0.145189
Epoch: 9 3200/3904 Training loss: 0.497935
Training loss: 0.211883
Test loss: 0.585743; True positive: 834; True negative: 117, False Positive: 148, False negative: 69, accuracy: 0.8142123287671232, precision: 0.8492871690427699, recall: 0.9235880398671097
Epoch: 10 0/3904 Training loss: 0.297944
Epoch: 10 800/3904 Training loss: 0.080272
Epoch: 10 1600/3904 Training loss: 0.124587
Epoch: 10 2400/3904 Training loss: 0.151701
Epoch: 10 3200/3904 Training loss: 0.370731
Training loss: 0.208743
Test loss: 0.616672; True positive: 832; True negative: 117, False Positive: 148, False negative: 71, accuracy: 0.8125, precision: 0.8489795918367347, recall: 0.9213732004429679
Epoch: 11 0/3904 Training loss: 0.320329
Epoch: 11 800/3904 Training loss: 0.067475
Epoch: 11 1600/3904 Training loss: 0.083142
Epoch: 11 2400/3904 Training loss: 0.153599
Epoch: 11 3200/3904 Training loss: 0.402105
Training loss: 0.191987
Test loss: 0.617677; True positive: 829; True negative: 117, False Positive: 148, False negative: 74, accuracy: 0.809931506849315, precision: 0.8485158648925282, recall: 0.9180509413067552
Epoch: 12 0/3904 Training loss: 0.096049
Epoch: 12 800/3904 Training loss: 0.081336
Epoch: 12 1600/3904 Training loss: 0.084505
Epoch: 12 2400/3904 Training loss: 0.098000
Epoch: 12 3200/3904 Training loss: 0.285226
Training loss: 0.171326
Test loss: 0.629669; True positive: 826; True negative: 117, False Positive: 148, False negative: 77, accuracy: 0.8073630136986302, precision: 0.8480492813141683, recall: 0.9147286821705426
Epoch: 13 0/3904 Training loss: 0.320442
Epoch: 13 800/3904 Training loss: 0.091876
Epoch: 13 1600/3904 Training loss: 0.052728
Epoch: 13 2400/3904 Training loss: 0.107542
Epoch: 13 3200/3904 Training loss: 0.182376
Training loss: 0.161469
Test loss: 0.591030; True positive: 837; True negative: 117, False Positive: 148, False negative: 66, accuracy: 0.8167808219178082, precision: 0.849746192893401, recall: 0.9269102990033222
starting trial 179
[I 2022-12-05 04:34:32,634] Trial 178 finished with value: 0.8176369863013698 and parameters: {'d_model': 64, 'nhead': 8, 'n_encoders': 1, 'learning_rate': 0.00015031643050082577, 'weight_decay': 2.413590845277025e-06, 'dropout': 0.18147356814764065, 'max_pool_conv': 32, 'kernel_size': 17, 'd_mlp': 32, 'num_conv_layers': 2, 'encoder_dropout': 0.016824136281162236, 'd_feed_forward': 128, 'max_pool_dim': 8, 'n_mlp_layers': 3}. Best is trial 62 with value: 0.860445205479452.
Epoch: 0 0/3904 Training loss: 0.696866
Epoch: 0 800/3904 Training loss: 0.729006
Epoch: 0 1600/3904 Training loss: 0.424827
Epoch: 0 2400/3904 Training loss: 0.748710
Epoch: 0 3200/3904 Training loss: 0.528074
Training loss: 0.658867
Test loss: 0.912812; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 1 0/3904 Training loss: 0.696542
Epoch: 1 800/3904 Training loss: 0.676351
Epoch: 1 1600/3904 Training loss: 0.228028
Epoch: 1 2400/3904 Training loss: 0.518544
Epoch: 1 3200/3904 Training loss: 0.440004
Training loss: 0.574987
Test loss: 2.179379; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 2 0/3904 Training loss: 0.433077
Epoch: 2 800/3904 Training loss: 0.428146
Epoch: 2 1600/3904 Training loss: 0.190027
Epoch: 2 2400/3904 Training loss: 0.447788
Epoch: 2 3200/3904 Training loss: 0.340083
Training loss: 0.468365
Test loss: 2.515988; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 3 0/3904 Training loss: 0.372964
Epoch: 3 800/3904 Training loss: 0.410291
Epoch: 3 1600/3904 Training loss: 0.177744
Epoch: 3 2400/3904 Training loss: 0.312567
Epoch: 3 3200/3904 Training loss: 0.392197
Training loss: 0.427144
Test loss: 2.720086; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 4 0/3904 Training loss: 0.381212
Epoch: 4 800/3904 Training loss: 0.472582
Epoch: 4 1600/3904 Training loss: 0.160344
Epoch: 4 2400/3904 Training loss: 0.307446
Epoch: 4 3200/3904 Training loss: 0.424601
Training loss: 0.409784
Test loss: 3.320531; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 5 0/3904 Training loss: 0.288908
Epoch: 5 800/3904 Training loss: 0.431965
Epoch: 5 1600/3904 Training loss: 0.221079
Epoch: 5 2400/3904 Training loss: 0.452128
Epoch: 5 3200/3904 Training loss: 0.347985
Training loss: 0.381576
Test loss: 3.547418; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 6 0/3904 Training loss: 0.533115
Epoch: 6 800/3904 Training loss: 0.421974
Epoch: 6 1600/3904 Training loss: 0.146149
Epoch: 6 2400/3904 Training loss: 0.353660
Epoch: 6 3200/3904 Training loss: 0.314629
Training loss: 0.354347
Test loss: 3.605447; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 7 0/3904 Training loss: 0.339742
Epoch: 7 800/3904 Training loss: 0.419818
Epoch: 7 1600/3904 Training loss: 0.139547
Epoch: 7 2400/3904 Training loss: 0.402154
Epoch: 7 3200/3904 Training loss: 0.349809
Training loss: 0.335214
Test loss: 1.337042; True positive: 146; True negative: 252, False Positive: 13, False negative: 757, accuracy: 0.3407534246575342, precision: 0.9182389937106918, recall: 0.16168327796234774
Epoch: 8 0/3904 Training loss: 0.326473
Epoch: 8 800/3904 Training loss: 0.384318
Epoch: 8 1600/3904 Training loss: 0.126416
Epoch: 8 2400/3904 Training loss: 0.367898
Epoch: 8 3200/3904 Training loss: 0.230414
Training loss: 0.312740
Test loss: 0.601735; True positive: 779; True negative: 205, False Positive: 60, False negative: 124, accuracy: 0.8424657534246576, precision: 0.9284862932061978, recall: 0.8626799557032115
Epoch: 9 0/3904 Training loss: 0.365395
Epoch: 9 800/3904 Training loss: 0.164658
Epoch: 9 1600/3904 Training loss: 0.237963
Epoch: 9 2400/3904 Training loss: 0.284426
Epoch: 9 3200/3904 Training loss: 0.223768
Training loss: 0.295377
Test loss: 2.996000; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 10 0/3904 Training loss: 0.417330
Epoch: 10 800/3904 Training loss: 0.192884
Epoch: 10 1600/3904 Training loss: 0.120753
Epoch: 10 2400/3904 Training loss: 0.191148
Epoch: 10 3200/3904 Training loss: 0.384393
Training loss: 0.308469
Test loss: 2.185267; True positive: 29; True negative: 260, False Positive: 5, False negative: 874, accuracy: 0.24743150684931506, precision: 0.8529411764705882, recall: 0.03211517165005537
Epoch: 11 0/3904 Training loss: 0.268091
Epoch: 11 800/3904 Training loss: 0.323535
Epoch: 11 1600/3904 Training loss: 0.142483
Epoch: 11 2400/3904 Training loss: 0.153272
Epoch: 11 3200/3904 Training loss: 0.381044
Training loss: 0.283604
Test loss: 4.275306; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 12 0/3904 Training loss: 0.333041
Epoch: 12 800/3904 Training loss: 0.125400
Epoch: 12 1600/3904 Training loss: 0.085037
Epoch: 12 2400/3904 Training loss: 0.382934
Epoch: 12 3200/3904 Training loss: 0.293818
Training loss: 0.282399
Test loss: 4.663004; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 13 0/3904 Training loss: 0.486523
Epoch: 13 800/3904 Training loss: 0.402572
Epoch: 13 1600/3904 Training loss: 0.154459
Epoch: 13 2400/3904 Training loss: 0.142841
Epoch: 13 3200/3904 Training loss: 0.398842
Training loss: 0.281484
Test loss: 4.867229; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 14 0/3904 Training loss: 0.402569
Epoch: 14 800/3904 Training loss: 0.235792
Epoch: 14 1600/3904 Training loss: 0.110543
Epoch: 14 2400/3904 Training loss: 0.300064
Epoch: 14 3200/3904 Training loss: 0.281935
Training loss: 0.261002
Test loss: 4.483154; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 15 0/3904 Training loss: 0.298724
Epoch: 15 800/3904 Training loss: 0.148337
Epoch: 15 1600/3904 Training loss: 0.166752
Epoch: 15 2400/3904 Training loss: 0.114709
Epoch: 15 3200/3904 Training loss: 0.385164
Training loss: 0.244129
Test loss: 5.276968; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 16 0/3904 Training loss: 0.277986
Epoch: 16 800/3904 Training loss: 0.441354
Epoch: 16 1600/3904 Training loss: 0.270306
Epoch: 16 2400/3904 Training loss: 0.049383
Epoch: 16 3200/3904 Training loss: 0.300522
Training loss: 0.237247
Test loss: 5.750736; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 17 0/3904 Training loss: 0.391411
Epoch: 17 800/3904 Training loss: 0.219908
Epoch: 17 1600/3904 Training loss: 0.064284
Epoch: 17 2400/3904 Training loss: 0.057288
Epoch: 17 3200/3904 Training loss: 0.488263
Training loss: 0.231832
Test loss: 5.691658; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 18 0/3904 Training loss: 0.369973
Epoch: 18 800/3904 Training loss: 0.049655
Epoch: 18 1600/3904 Training loss: 0.074811
Epoch: 18 2400/3904 Training loss: 0.231248
Epoch: 18 3200/3904 Training loss: 0.281869
Training loss: 0.252759
Test loss: 5.732776; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
starting trial 180
[I 2022-12-05 04:36:18,181] Trial 179 finished with value: 0.8424657534246576 and parameters: {'d_model': 64, 'nhead': 8, 'n_encoders': 1, 'learning_rate': 0.000518689602005456, 'weight_decay': 4.165753548428544e-06, 'dropout': 0.25221955939213314, 'max_pool_conv': 32, 'kernel_size': 13, 'd_mlp': 32, 'num_conv_layers': 3, 'encoder_dropout': 0.10143993798791706, 'd_feed_forward': 128, 'max_pool_dim': 8, 'n_mlp_layers': 3}. Best is trial 62 with value: 0.860445205479452.
Epoch: 0 0/3904 Training loss: 0.703306
Epoch: 0 800/3904 Training loss: 0.698507
Epoch: 0 1600/3904 Training loss: 0.282319
Epoch: 0 2400/3904 Training loss: 0.714245
Epoch: 0 3200/3904 Training loss: 0.421764
Training loss: 0.617027
Test loss: 0.704814; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 1 0/3904 Training loss: 0.587233
Epoch: 1 800/3904 Training loss: 0.603800
Epoch: 1 1600/3904 Training loss: 0.295100
Epoch: 1 2400/3904 Training loss: 0.537831
Epoch: 1 3200/3904 Training loss: 0.466711
Training loss: 0.499650
Test loss: 0.685089; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 2 0/3904 Training loss: 0.480238
Epoch: 2 800/3904 Training loss: 0.328174
Epoch: 2 1600/3904 Training loss: 0.225922
Epoch: 2 2400/3904 Training loss: 0.361196
Epoch: 2 3200/3904 Training loss: 0.455861
Training loss: 0.448435
Test loss: 0.607259; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 3 0/3904 Training loss: 0.501226
Epoch: 3 800/3904 Training loss: 0.264874
Epoch: 3 1600/3904 Training loss: 0.143862
Epoch: 3 2400/3904 Training loss: 0.384856
Epoch: 3 3200/3904 Training loss: 0.491348
Training loss: 0.432148
Test loss: 0.575242; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 4 0/3904 Training loss: 0.400754
Epoch: 4 800/3904 Training loss: 0.370722
Epoch: 4 1600/3904 Training loss: 0.170799
Epoch: 4 2400/3904 Training loss: 0.545656
Epoch: 4 3200/3904 Training loss: 0.454578
Training loss: 0.405837
Test loss: 0.562717; True positive: 834; True negative: 117, False Positive: 148, False negative: 69, accuracy: 0.8142123287671232, precision: 0.8492871690427699, recall: 0.9235880398671097
Epoch: 5 0/3904 Training loss: 0.385831
Epoch: 5 800/3904 Training loss: 0.240589
Epoch: 5 1600/3904 Training loss: 0.163258
Epoch: 5 2400/3904 Training loss: 0.395531
Epoch: 5 3200/3904 Training loss: 0.285131
Training loss: 0.386667
Test loss: 0.585788; True positive: 903; True negative: 0, False Positive: 265, False negative: 0, accuracy: 0.7731164383561644, precision: 0.7731164383561644, recall: 1.0
Epoch: 6 0/3904 Training loss: 0.406471
Epoch: 6 800/3904 Training loss: 0.272858
Epoch: 6 1600/3904 Training loss: 0.149106
Epoch: 6 2400/3904 Training loss: 0.441999
Epoch: 6 3200/3904 Training loss: 0.494959
Training loss: 0.366115
Test loss: 0.698567; True positive: 903; True negative: 0, False Positive: 265, False negative: 0, accuracy: 0.7731164383561644, precision: 0.7731164383561644, recall: 1.0
Epoch: 7 0/3904 Training loss: 0.290094
Epoch: 7 800/3904 Training loss: 0.348188
Epoch: 7 1600/3904 Training loss: 0.129298
Epoch: 7 2400/3904 Training loss: 0.302156
Epoch: 7 3200/3904 Training loss: 0.391380
Training loss: 0.352742
Test loss: 0.732309; True positive: 903; True negative: 0, False Positive: 265, False negative: 0, accuracy: 0.7731164383561644, precision: 0.7731164383561644, recall: 1.0
Epoch: 8 0/3904 Training loss: 0.181687
Epoch: 8 800/3904 Training loss: 0.193477
Epoch: 8 1600/3904 Training loss: 0.112541
Epoch: 8 2400/3904 Training loss: 0.391589
Epoch: 8 3200/3904 Training loss: 0.401564
Training loss: 0.341828
Test loss: 0.518044; True positive: 883; True negative: 91, False Positive: 174, False negative: 20, accuracy: 0.833904109589041, precision: 0.8353831598864712, recall: 0.9778516057585825
Epoch: 9 0/3904 Training loss: 0.138469
Epoch: 9 800/3904 Training loss: 0.274100
Epoch: 9 1600/3904 Training loss: 0.109884
Epoch: 9 2400/3904 Training loss: 0.379169
Epoch: 9 3200/3904 Training loss: 0.497127
Training loss: 0.322617
Test loss: 0.638490; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 10 0/3904 Training loss: 0.229340
Epoch: 10 800/3904 Training loss: 0.216635
Epoch: 10 1600/3904 Training loss: 0.104372
Epoch: 10 2400/3904 Training loss: 0.278245
Epoch: 10 3200/3904 Training loss: 0.361496
Training loss: 0.314690
Test loss: 0.635434; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 11 0/3904 Training loss: 0.203893
Epoch: 11 800/3904 Training loss: 0.186819
Epoch: 11 1600/3904 Training loss: 0.159577
Epoch: 11 2400/3904 Training loss: 0.308111
Epoch: 11 3200/3904 Training loss: 0.302534
Training loss: 0.298974
Test loss: 0.656677; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 12 0/3904 Training loss: 0.306775
Epoch: 12 800/3904 Training loss: 0.298773
Epoch: 12 1600/3904 Training loss: 0.094864
Epoch: 12 2400/3904 Training loss: 0.409623
Epoch: 12 3200/3904 Training loss: 0.238365
Training loss: 0.295586
Test loss: 0.697229; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 13 0/3904 Training loss: 0.152670
Epoch: 13 800/3904 Training loss: 0.308845
Epoch: 13 1600/3904 Training loss: 0.097695
Epoch: 13 2400/3904 Training loss: 0.192554
Epoch: 13 3200/3904 Training loss: 0.444353
Training loss: 0.277442
Test loss: 0.659935; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 14 0/3904 Training loss: 0.164987
Epoch: 14 800/3904 Training loss: 0.251694
Epoch: 14 1600/3904 Training loss: 0.095166
Epoch: 14 2400/3904 Training loss: 0.265211
Epoch: 14 3200/3904 Training loss: 0.424444
Training loss: 0.264312
Test loss: 0.680870; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 15 0/3904 Training loss: 0.185627
Epoch: 15 800/3904 Training loss: 0.250104
Epoch: 15 1600/3904 Training loss: 0.121302
Epoch: 15 2400/3904 Training loss: 0.322259
Epoch: 15 3200/3904 Training loss: 0.326248
Training loss: 0.260132
Test loss: 0.674353; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 16 0/3904 Training loss: 0.218285
Epoch: 16 800/3904 Training loss: 0.148907
Epoch: 16 1600/3904 Training loss: 0.112526
Epoch: 16 2400/3904 Training loss: 0.410031
Epoch: 16 3200/3904 Training loss: 0.360701
Training loss: 0.242236
Test loss: 0.696405; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 17 0/3904 Training loss: 0.124883
Epoch: 17 800/3904 Training loss: 0.246620
Epoch: 17 1600/3904 Training loss: 0.156972
Epoch: 17 2400/3904 Training loss: 0.137276
Epoch: 17 3200/3904 Training loss: 0.447501
Training loss: 0.248052
Test loss: 0.718926; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 18 0/3904 Training loss: 0.091285
Epoch: 18 800/3904 Training loss: 0.412651
Epoch: 18 1600/3904 Training loss: 0.140046
Epoch: 18 2400/3904 Training loss: 0.240960
Epoch: 18 3200/3904 Training loss: 0.348916
Training loss: 0.249921
Test loss: 0.713960; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
starting trial 181
[I 2022-12-05 04:38:03,555] Trial 180 finished with value: 0.833904109589041 and parameters: {'d_model': 64, 'nhead': 8, 'n_encoders': 1, 'learning_rate': 0.0005674887234199361, 'weight_decay': 4.233910940625396e-06, 'dropout': 0.16583623227064986, 'max_pool_conv': 32, 'kernel_size': 13, 'd_mlp': 32, 'num_conv_layers': 3, 'encoder_dropout': 0.12284196092153106, 'd_feed_forward': 128, 'max_pool_dim': 8, 'n_mlp_layers': 3}. Best is trial 62 with value: 0.860445205479452.
Epoch: 0 0/3904 Training loss: 0.698051
Epoch: 0 800/3904 Training loss: 0.698815
Epoch: 0 1600/3904 Training loss: 0.372801
Epoch: 0 2400/3904 Training loss: 0.768639
Epoch: 0 3200/3904 Training loss: 0.469515
Training loss: 0.647691
Test loss: 0.673036; True positive: 903; True negative: 0, False Positive: 265, False negative: 0, accuracy: 0.7731164383561644, precision: 0.7731164383561644, recall: 1.0
Epoch: 1 0/3904 Training loss: 0.576826
Epoch: 1 800/3904 Training loss: 0.637738
Epoch: 1 1600/3904 Training loss: 0.184328
Epoch: 1 2400/3904 Training loss: 0.572048
Epoch: 1 3200/3904 Training loss: 0.370766
Training loss: 0.528522
Test loss: 0.542547; True positive: 903; True negative: 0, False Positive: 265, False negative: 0, accuracy: 0.7731164383561644, precision: 0.7731164383561644, recall: 1.0
Epoch: 2 0/3904 Training loss: 0.496153
Epoch: 2 800/3904 Training loss: 0.338731
Epoch: 2 1600/3904 Training loss: 0.214713
Epoch: 2 2400/3904 Training loss: 1.340969
Epoch: 2 3200/3904 Training loss: 0.475413
Training loss: 0.492775
Test loss: 1.090304; True positive: 70; True negative: 148, False Positive: 117, False negative: 833, accuracy: 0.18664383561643835, precision: 0.37433155080213903, recall: 0.07751937984496124
Epoch: 3 0/3904 Training loss: 0.371058
Epoch: 3 800/3904 Training loss: 0.593553
Epoch: 3 1600/3904 Training loss: 0.220145
Epoch: 3 2400/3904 Training loss: 0.559619
Epoch: 3 3200/3904 Training loss: 0.578297
Training loss: 0.483323
Test loss: 1.876005; True positive: 65; True negative: 148, False Positive: 117, False negative: 838, accuracy: 0.18236301369863014, precision: 0.35714285714285715, recall: 0.07198228128460686
Epoch: 4 0/3904 Training loss: 0.526934
Epoch: 4 800/3904 Training loss: 0.306676
Epoch: 4 1600/3904 Training loss: 0.190635
Epoch: 4 2400/3904 Training loss: 0.290892
Epoch: 4 3200/3904 Training loss: 0.311678
Training loss: 0.483937
Test loss: 0.607684; True positive: 903; True negative: 7, False Positive: 258, False negative: 0, accuracy: 0.7791095890410958, precision: 0.7777777777777778, recall: 1.0
Epoch: 5 0/3904 Training loss: 0.411691
Epoch: 5 800/3904 Training loss: 0.597123
Epoch: 5 1600/3904 Training loss: 0.213181
Epoch: 5 2400/3904 Training loss: 0.358914
Epoch: 5 3200/3904 Training loss: 0.409375
Training loss: 0.493319
Test loss: 0.709633; True positive: 867; True negative: 14, False Positive: 251, False negative: 36, accuracy: 0.7542808219178082, precision: 0.7754919499105546, recall: 0.9601328903654485
Epoch: 6 0/3904 Training loss: 0.471280
Epoch: 6 800/3904 Training loss: 0.316859
Epoch: 6 1600/3904 Training loss: 0.196201
Epoch: 6 2400/3904 Training loss: 0.543723
Epoch: 6 3200/3904 Training loss: 0.471990
Training loss: 0.482374
Test loss: 0.619359; True positive: 903; True negative: 0, False Positive: 265, False negative: 0, accuracy: 0.7731164383561644, precision: 0.7731164383561644, recall: 1.0
Epoch: 7 0/3904 Training loss: 0.393609
Epoch: 7 800/3904 Training loss: 0.459411
Epoch: 7 1600/3904 Training loss: 0.175433
Epoch: 7 2400/3904 Training loss: 0.457580
Epoch: 7 3200/3904 Training loss: 0.293324
Training loss: 0.464163
Test loss: 1.330471; True positive: 65; True negative: 148, False Positive: 117, False negative: 838, accuracy: 0.18236301369863014, precision: 0.35714285714285715, recall: 0.07198228128460686
Epoch: 8 0/3904 Training loss: 0.422201
Epoch: 8 800/3904 Training loss: 0.326952
Epoch: 8 1600/3904 Training loss: 0.161346
Epoch: 8 2400/3904 Training loss: 0.464807
Epoch: 8 3200/3904 Training loss: 0.444573
Training loss: 0.442596
Test loss: 1.717286; True positive: 65; True negative: 148, False Positive: 117, False negative: 838, accuracy: 0.18236301369863014, precision: 0.35714285714285715, recall: 0.07198228128460686
Epoch: 9 0/3904 Training loss: 0.406065
Epoch: 9 800/3904 Training loss: 0.310952
Epoch: 9 1600/3904 Training loss: 0.207395
Epoch: 9 2400/3904 Training loss: 0.315504
Epoch: 9 3200/3904 Training loss: 0.400514
Training loss: 0.453801
Test loss: 1.581130; True positive: 70; True negative: 148, False Positive: 117, False negative: 833, accuracy: 0.18664383561643835, precision: 0.37433155080213903, recall: 0.07751937984496124
Epoch: 10 0/3904 Training loss: 0.442384
Epoch: 10 800/3904 Training loss: 0.279226
Epoch: 10 1600/3904 Training loss: 0.191548
Epoch: 10 2400/3904 Training loss: 0.476833
Epoch: 10 3200/3904 Training loss: 0.436517
Training loss: 0.513807
Test loss: 0.577974; True positive: 903; True negative: 0, False Positive: 265, False negative: 0, accuracy: 0.7731164383561644, precision: 0.7731164383561644, recall: 1.0
Epoch: 11 0/3904 Training loss: 0.446382
Epoch: 11 800/3904 Training loss: 0.359596
Epoch: 11 1600/3904 Training loss: 0.143440
Epoch: 11 2400/3904 Training loss: 0.457860
Epoch: 11 3200/3904 Training loss: 0.352776
Training loss: 0.457034
Test loss: 0.604859; True positive: 903; True negative: 0, False Positive: 265, False negative: 0, accuracy: 0.7731164383561644, precision: 0.7731164383561644, recall: 1.0
starting trial 182
[I 2022-12-05 04:39:10,692] Trial 181 finished with value: 0.7791095890410958 and parameters: {'d_model': 64, 'nhead': 8, 'n_encoders': 1, 'learning_rate': 0.0005145290058660273, 'weight_decay': 4.0322073998319375e-06, 'dropout': 0.1677165810275564, 'max_pool_conv': 32, 'kernel_size': 13, 'd_mlp': 32, 'num_conv_layers': 3, 'encoder_dropout': 0.11913327170884318, 'd_feed_forward': 128, 'max_pool_dim': 8, 'n_mlp_layers': 3}. Best is trial 62 with value: 0.860445205479452.
Epoch: 0 0/3904 Training loss: 0.699527
Epoch: 0 800/3904 Training loss: 0.710362
Epoch: 0 1600/3904 Training loss: 0.384619
Epoch: 0 2400/3904 Training loss: 0.730056
Epoch: 0 3200/3904 Training loss: 0.470429
Training loss: 0.643848
Test loss: 0.690718; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 1 0/3904 Training loss: 0.595646
Epoch: 1 800/3904 Training loss: 0.674283
Epoch: 1 1600/3904 Training loss: 0.151035
Epoch: 1 2400/3904 Training loss: 0.425745
Epoch: 1 3200/3904 Training loss: 0.422958
Training loss: 0.525151
Test loss: 0.601818; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 2 0/3904 Training loss: 0.354257
Epoch: 2 800/3904 Training loss: 0.393736
Epoch: 2 1600/3904 Training loss: 0.241839
Epoch: 2 2400/3904 Training loss: 0.431922
Epoch: 2 3200/3904 Training loss: 0.374850
Training loss: 0.463314
Test loss: 0.622458; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 3 0/3904 Training loss: 0.300001
Epoch: 3 800/3904 Training loss: 0.415820
Epoch: 3 1600/3904 Training loss: 0.257304
Epoch: 3 2400/3904 Training loss: 0.662518
Epoch: 3 3200/3904 Training loss: 0.472417
Training loss: 0.456123
Test loss: 0.610512; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 4 0/3904 Training loss: 0.357812
Epoch: 4 800/3904 Training loss: 0.279017
Epoch: 4 1600/3904 Training loss: 0.188601
Epoch: 4 2400/3904 Training loss: 0.748760
Epoch: 4 3200/3904 Training loss: 0.355925
Training loss: 0.425635
Test loss: 0.693717; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 5 0/3904 Training loss: 0.334047
Epoch: 5 800/3904 Training loss: 0.349681
Epoch: 5 1600/3904 Training loss: 0.228124
Epoch: 5 2400/3904 Training loss: 0.448820
Epoch: 5 3200/3904 Training loss: 0.415073
Training loss: 0.434222
Test loss: 0.706855; True positive: 5; True negative: 265, False Positive: 0, False negative: 898, accuracy: 0.23116438356164384, precision: 1.0, recall: 0.005537098560354375
Epoch: 6 0/3904 Training loss: 0.397465
Epoch: 6 800/3904 Training loss: 0.378523
Epoch: 6 1600/3904 Training loss: 0.179933
Epoch: 6 2400/3904 Training loss: 0.682765
Epoch: 6 3200/3904 Training loss: 0.388800
Training loss: 0.416182
Test loss: 1.573786; True positive: 4; True negative: 265, False Positive: 0, False negative: 899, accuracy: 0.2303082191780822, precision: 1.0, recall: 0.004429678848283499
Epoch: 7 0/3904 Training loss: 0.333069
Epoch: 7 800/3904 Training loss: 0.360260
Epoch: 7 1600/3904 Training loss: 0.171091
Epoch: 7 2400/3904 Training loss: 0.291449
Epoch: 7 3200/3904 Training loss: 0.410427
Training loss: 0.385388
Test loss: 3.266126; True positive: 4; True negative: 265, False Positive: 0, False negative: 899, accuracy: 0.2303082191780822, precision: 1.0, recall: 0.004429678848283499
Epoch: 8 0/3904 Training loss: 0.261638
Epoch: 8 800/3904 Training loss: 0.422966
Epoch: 8 1600/3904 Training loss: 0.157747
Epoch: 8 2400/3904 Training loss: 0.401594
Epoch: 8 3200/3904 Training loss: 0.416695
Training loss: 0.379777
Test loss: 3.792297; True positive: 4; True negative: 265, False Positive: 0, False negative: 899, accuracy: 0.2303082191780822, precision: 1.0, recall: 0.004429678848283499
Epoch: 9 0/3904 Training loss: 0.338934
Epoch: 9 800/3904 Training loss: 0.658827
Epoch: 9 1600/3904 Training loss: 0.144499
Epoch: 9 2400/3904 Training loss: 0.473616
Epoch: 9 3200/3904 Training loss: 0.475361
Training loss: 0.399787
Test loss: 3.178355; True positive: 4; True negative: 265, False Positive: 0, False negative: 899, accuracy: 0.2303082191780822, precision: 1.0, recall: 0.004429678848283499
Epoch: 10 0/3904 Training loss: 0.351991
Epoch: 10 800/3904 Training loss: 0.386972
Epoch: 10 1600/3904 Training loss: 0.187816
Epoch: 10 2400/3904 Training loss: 0.331813
Epoch: 10 3200/3904 Training loss: 0.442985
Training loss: 0.375708
Test loss: 3.924581; True positive: 4; True negative: 265, False Positive: 0, False negative: 899, accuracy: 0.2303082191780822, precision: 1.0, recall: 0.004429678848283499
Epoch: 11 0/3904 Training loss: 0.318084
Epoch: 11 800/3904 Training loss: 0.363338
Epoch: 11 1600/3904 Training loss: 0.192703
Epoch: 11 2400/3904 Training loss: 0.366479
Epoch: 11 3200/3904 Training loss: 0.436748
Training loss: 0.363296
Test loss: 3.488995; True positive: 4; True negative: 265, False Positive: 0, False negative: 899, accuracy: 0.2303082191780822, precision: 1.0, recall: 0.004429678848283499
starting trial 183
[I 2022-12-05 04:40:17,610] Trial 182 finished with value: 0.8176369863013698 and parameters: {'d_model': 64, 'nhead': 8, 'n_encoders': 1, 'learning_rate': 0.0006448348938507636, 'weight_decay': 4.2895633968578286e-06, 'dropout': 0.1986365050190516, 'max_pool_conv': 32, 'kernel_size': 13, 'd_mlp': 32, 'num_conv_layers': 3, 'encoder_dropout': 0.10522156714926759, 'd_feed_forward': 128, 'max_pool_dim': 8, 'n_mlp_layers': 3}. Best is trial 62 with value: 0.860445205479452.
Epoch: 0 0/3904 Training loss: 0.711555
Epoch: 0 800/3904 Training loss: 0.692781
Epoch: 0 1600/3904 Training loss: 0.381122
Epoch: 0 2400/3904 Training loss: 0.740503
Epoch: 0 3200/3904 Training loss: 0.483583
Training loss: 0.650249
Test loss: 0.651507; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 1 0/3904 Training loss: 0.611922
Epoch: 1 800/3904 Training loss: 0.613681
Epoch: 1 1600/3904 Training loss: 0.235648
Epoch: 1 2400/3904 Training loss: 0.719528
Epoch: 1 3200/3904 Training loss: 0.366127
Training loss: 0.520053
Test loss: 0.578654; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 2 0/3904 Training loss: 0.478885
Epoch: 2 800/3904 Training loss: 0.408188
Epoch: 2 1600/3904 Training loss: 0.221445
Epoch: 2 2400/3904 Training loss: 0.425379
Epoch: 2 3200/3904 Training loss: 0.414637
Training loss: 0.442996
Test loss: 0.558313; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 3 0/3904 Training loss: 0.429857
Epoch: 3 800/3904 Training loss: 0.480346
Epoch: 3 1600/3904 Training loss: 0.135664
Epoch: 3 2400/3904 Training loss: 0.463638
Epoch: 3 3200/3904 Training loss: 0.460317
Training loss: 0.422209
Test loss: 0.574604; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 4 0/3904 Training loss: 0.316947
Epoch: 4 800/3904 Training loss: 0.405542
Epoch: 4 1600/3904 Training loss: 0.131934
Epoch: 4 2400/3904 Training loss: 0.420356
Epoch: 4 3200/3904 Training loss: 0.385582
Training loss: 0.386840
Test loss: 0.622365; True positive: 829; True negative: 117, False Positive: 148, False negative: 74, accuracy: 0.809931506849315, precision: 0.8485158648925282, recall: 0.9180509413067552
Epoch: 5 0/3904 Training loss: 0.368912
Epoch: 5 800/3904 Training loss: 0.288631
Epoch: 5 1600/3904 Training loss: 0.150294
Epoch: 5 2400/3904 Training loss: 0.241762
Epoch: 5 3200/3904 Training loss: 0.524181
Training loss: 0.376574
Test loss: 1.163214; True positive: 383; True negative: 173, False Positive: 92, False negative: 520, accuracy: 0.476027397260274, precision: 0.8063157894736842, recall: 0.42414174972314506
Epoch: 6 0/3904 Training loss: 0.362846
Epoch: 6 800/3904 Training loss: 0.452201
Epoch: 6 1600/3904 Training loss: 0.118196
Epoch: 6 2400/3904 Training loss: 0.274175
Epoch: 6 3200/3904 Training loss: 0.528724
Training loss: 0.363047
Test loss: 1.887595; True positive: 129; True negative: 210, False Positive: 55, False negative: 774, accuracy: 0.2902397260273973, precision: 0.7010869565217391, recall: 0.14285714285714285
Epoch: 7 0/3904 Training loss: 0.529939
Epoch: 7 800/3904 Training loss: 0.364376
Epoch: 7 1600/3904 Training loss: 0.116141
Epoch: 7 2400/3904 Training loss: 0.469645
Epoch: 7 3200/3904 Training loss: 0.458163
Training loss: 0.376729
Test loss: 1.588365; True positive: 46; True negative: 250, False Positive: 15, False negative: 857, accuracy: 0.2534246575342466, precision: 0.7540983606557377, recall: 0.05094130675526024
Epoch: 8 0/3904 Training loss: 0.342126
Epoch: 8 800/3904 Training loss: 0.527377
Epoch: 8 1600/3904 Training loss: 0.142587
Epoch: 8 2400/3904 Training loss: 0.164737
Epoch: 8 3200/3904 Training loss: 0.477953
Training loss: 0.344258
Test loss: 0.559703; True positive: 793; True negative: 127, False Positive: 138, False negative: 110, accuracy: 0.7876712328767124, precision: 0.8517722878625135, recall: 0.8781838316722038
Epoch: 9 0/3904 Training loss: 0.430996
Epoch: 9 800/3904 Training loss: 0.462898
Epoch: 9 1600/3904 Training loss: 0.116500
Epoch: 9 2400/3904 Training loss: 0.254543
Epoch: 9 3200/3904 Training loss: 0.508225
Training loss: 0.334885
Test loss: 2.259224; True positive: 93; True negative: 243, False Positive: 22, False negative: 810, accuracy: 0.2876712328767123, precision: 0.808695652173913, recall: 0.10299003322259136
Epoch: 10 0/3904 Training loss: 0.332768
Epoch: 10 800/3904 Training loss: 0.440894
Epoch: 10 1600/3904 Training loss: 0.145347
Epoch: 10 2400/3904 Training loss: 0.361379
Epoch: 10 3200/3904 Training loss: 0.442912
Training loss: 0.324851
Test loss: 1.415512; True positive: 368; True negative: 163, False Positive: 102, False negative: 535, accuracy: 0.4546232876712329, precision: 0.7829787234042553, recall: 0.40753045404208194
Epoch: 11 0/3904 Training loss: 0.478482
Epoch: 11 800/3904 Training loss: 0.303775
Epoch: 11 1600/3904 Training loss: 0.166995
Epoch: 11 2400/3904 Training loss: 0.220695
Epoch: 11 3200/3904 Training loss: 0.402821
Training loss: 0.316818
Test loss: 0.539425; True positive: 836; True negative: 117, False Positive: 148, False negative: 67, accuracy: 0.8159246575342466, precision: 0.8495934959349594, recall: 0.9258028792912514
Epoch: 12 0/3904 Training loss: 0.512997
Epoch: 12 800/3904 Training loss: 0.312227
Epoch: 12 1600/3904 Training loss: 0.100793
Epoch: 12 2400/3904 Training loss: 0.281421
Epoch: 12 3200/3904 Training loss: 0.304563
Training loss: 0.325584
Test loss: 4.932629; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 13 0/3904 Training loss: 0.537645
Epoch: 13 800/3904 Training loss: 0.323990
Epoch: 13 1600/3904 Training loss: 0.077366
Epoch: 13 2400/3904 Training loss: 0.632420
Epoch: 13 3200/3904 Training loss: 0.327516
Training loss: 0.328887
Test loss: 0.929985; True positive: 296; True negative: 208, False Positive: 57, False negative: 607, accuracy: 0.4315068493150685, precision: 0.8385269121813032, recall: 0.327796234772979
Epoch: 14 0/3904 Training loss: 0.475392
Epoch: 14 800/3904 Training loss: 0.172199
Epoch: 14 1600/3904 Training loss: 0.123180
Epoch: 14 2400/3904 Training loss: 0.300255
Epoch: 14 3200/3904 Training loss: 0.391003
Training loss: 0.299602
Test loss: 1.379861; True positive: 10; True negative: 260, False Positive: 5, False negative: 893, accuracy: 0.23116438356164384, precision: 0.6666666666666666, recall: 0.01107419712070875
Epoch: 15 0/3904 Training loss: 0.195431
Epoch: 15 800/3904 Training loss: 0.321578
Epoch: 15 1600/3904 Training loss: 0.147238
Epoch: 15 2400/3904 Training loss: 0.230563
Epoch: 15 3200/3904 Training loss: 0.316073
Training loss: 0.290969
Test loss: 1.548312; True positive: 52; True negative: 231, False Positive: 34, False negative: 851, accuracy: 0.2422945205479452, precision: 0.6046511627906976, recall: 0.05758582502768549
Epoch: 16 0/3904 Training loss: 0.376280
Epoch: 16 800/3904 Training loss: 0.275594
Epoch: 16 1600/3904 Training loss: 0.122290
Epoch: 16 2400/3904 Training loss: 0.177750
Epoch: 16 3200/3904 Training loss: 0.310546
Training loss: 0.279516
Test loss: 0.925947; True positive: 654; True negative: 132, False Positive: 133, False negative: 249, accuracy: 0.672945205479452, precision: 0.8310038119440915, recall: 0.7242524916943521
Epoch: 17 0/3904 Training loss: 0.321165
Epoch: 17 800/3904 Training loss: 0.217633
Epoch: 17 1600/3904 Training loss: 0.152196
Epoch: 17 2400/3904 Training loss: 0.260050
Epoch: 17 3200/3904 Training loss: 0.473407
Training loss: 0.276620
Test loss: 1.073401; True positive: 552; True negative: 147, False Positive: 118, False negative: 351, accuracy: 0.598458904109589, precision: 0.8238805970149253, recall: 0.6112956810631229
Epoch: 18 0/3904 Training loss: 0.353561
Epoch: 18 800/3904 Training loss: 0.362769
Epoch: 18 1600/3904 Training loss: 0.090547
Epoch: 18 2400/3904 Training loss: 0.154889
Epoch: 18 3200/3904 Training loss: 0.341743
Training loss: 0.285119
Test loss: 2.857378; True positive: 87; True negative: 216, False Positive: 49, False negative: 816, accuracy: 0.2594178082191781, precision: 0.6397058823529411, recall: 0.09634551495016612
Epoch: 19 0/3904 Training loss: 0.244928
Epoch: 19 800/3904 Training loss: 0.253567
Epoch: 19 1600/3904 Training loss: 0.120123
Epoch: 19 2400/3904 Training loss: 0.186070
Epoch: 19 3200/3904 Training loss: 0.331651
Training loss: 0.276764
Test loss: 0.822611; True positive: 833; True negative: 117, False Positive: 148, False negative: 70, accuracy: 0.8133561643835616, precision: 0.8491335372069317, recall: 0.9224806201550387
Epoch: 20 0/3904 Training loss: 0.355797
Epoch: 20 800/3904 Training loss: 0.193389
Epoch: 20 1600/3904 Training loss: 0.077676
Epoch: 20 2400/3904 Training loss: 0.210075
Epoch: 20 3200/3904 Training loss: 0.425307
Training loss: 0.259658
Test loss: 1.286770; True positive: 515; True negative: 143, False Positive: 122, False negative: 388, accuracy: 0.5633561643835616, precision: 0.8084772370486656, recall: 0.5703211517165006
Epoch: 21 0/3904 Training loss: 0.449563
Epoch: 21 800/3904 Training loss: 0.169833
Epoch: 21 1600/3904 Training loss: 0.085003
Epoch: 21 2400/3904 Training loss: 0.212539
Epoch: 21 3200/3904 Training loss: 0.370089
Training loss: 0.251224
Test loss: 2.544244; True positive: 60; True negative: 236, False Positive: 29, False negative: 843, accuracy: 0.2534246575342466, precision: 0.6741573033707865, recall: 0.0664451827242525
starting trial 184
[I 2022-12-05 04:42:18,731] Trial 183 finished with value: 0.8176369863013698 and parameters: {'d_model': 64, 'nhead': 8, 'n_encoders': 1, 'learning_rate': 0.0005546643888863112, 'weight_decay': 3.362171139940685e-06, 'dropout': 0.17766925869347844, 'max_pool_conv': 32, 'kernel_size': 12, 'd_mlp': 32, 'num_conv_layers': 3, 'encoder_dropout': 0.130835089306852, 'd_feed_forward': 128, 'max_pool_dim': 8, 'n_mlp_layers': 3}. Best is trial 62 with value: 0.860445205479452.
Epoch: 0 0/3904 Training loss: 0.690126
Epoch: 0 800/3904 Training loss: 0.704417
Epoch: 0 1600/3904 Training loss: 0.330044
Epoch: 0 2400/3904 Training loss: 0.694598
Epoch: 0 3200/3904 Training loss: 0.445086
Training loss: 0.631715
Test loss: 0.691162; True positive: 888; True negative: 36, False Positive: 229, False negative: 15, accuracy: 0.791095890410959, precision: 0.7949865711727843, recall: 0.9833887043189369
Epoch: 1 0/3904 Training loss: 0.625573
Epoch: 1 800/3904 Training loss: 0.504405
Epoch: 1 1600/3904 Training loss: 0.248874
Epoch: 1 2400/3904 Training loss: 0.517136
Epoch: 1 3200/3904 Training loss: 0.410953
Training loss: 0.501080
Test loss: 0.514374; True positive: 903; True negative: 12, False Positive: 253, False negative: 0, accuracy: 0.7833904109589042, precision: 0.7811418685121108, recall: 1.0
Epoch: 2 0/3904 Training loss: 0.382831
Epoch: 2 800/3904 Training loss: 0.423223
Epoch: 2 1600/3904 Training loss: 0.196660
Epoch: 2 2400/3904 Training loss: 0.302137
Epoch: 2 3200/3904 Training loss: 0.493812
Training loss: 0.460863
Test loss: 0.601170; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 3 0/3904 Training loss: 0.431617
Epoch: 3 800/3904 Training loss: 0.397392
Epoch: 3 1600/3904 Training loss: 0.154166
Epoch: 3 2400/3904 Training loss: 0.534935
Epoch: 3 3200/3904 Training loss: 0.521376
Training loss: 0.436336
Test loss: 0.648697; True positive: 791; True negative: 29, False Positive: 236, False negative: 112, accuracy: 0.702054794520548, precision: 0.7702044790652386, recall: 0.875968992248062
Epoch: 4 0/3904 Training loss: 0.332332
Epoch: 4 800/3904 Training loss: 0.365335
Epoch: 4 1600/3904 Training loss: 0.126570
Epoch: 4 2400/3904 Training loss: 0.817871
Epoch: 4 3200/3904 Training loss: 0.427593
Training loss: 0.416677
Test loss: 2.124092; True positive: 15; True negative: 235, False Positive: 30, False negative: 888, accuracy: 0.21404109589041095, precision: 0.3333333333333333, recall: 0.016611295681063124
Epoch: 5 0/3904 Training loss: 0.528184
Epoch: 5 800/3904 Training loss: 0.467616
Epoch: 5 1600/3904 Training loss: 0.154080
Epoch: 5 2400/3904 Training loss: 0.382836
Epoch: 5 3200/3904 Training loss: 0.311390
Training loss: 0.410668
Test loss: 3.056468; True positive: 4; True negative: 265, False Positive: 0, False negative: 899, accuracy: 0.2303082191780822, precision: 1.0, recall: 0.004429678848283499
Epoch: 6 0/3904 Training loss: 0.541907
Epoch: 6 800/3904 Training loss: 0.340350
Epoch: 6 1600/3904 Training loss: 0.163184
Epoch: 6 2400/3904 Training loss: 0.278708
Epoch: 6 3200/3904 Training loss: 0.393583
Training loss: 0.436587
Test loss: 4.034470; True positive: 4; True negative: 265, False Positive: 0, False negative: 899, accuracy: 0.2303082191780822, precision: 1.0, recall: 0.004429678848283499
Epoch: 7 0/3904 Training loss: 0.470791
Epoch: 7 800/3904 Training loss: 0.284558
Epoch: 7 1600/3904 Training loss: 0.233945
Epoch: 7 2400/3904 Training loss: 0.223715
Epoch: 7 3200/3904 Training loss: 0.376338
Training loss: 0.401466
Test loss: 4.734196; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 8 0/3904 Training loss: 0.470073
Epoch: 8 800/3904 Training loss: 0.288484
Epoch: 8 1600/3904 Training loss: 0.120205
Epoch: 8 2400/3904 Training loss: 0.220509
Epoch: 8 3200/3904 Training loss: 0.375777
Training loss: 0.382532
Test loss: 3.853846; True positive: 4; True negative: 265, False Positive: 0, False negative: 899, accuracy: 0.2303082191780822, precision: 1.0, recall: 0.004429678848283499
Epoch: 9 0/3904 Training loss: 0.458965
Epoch: 9 800/3904 Training loss: 0.476455
Epoch: 9 1600/3904 Training loss: 0.128791
Epoch: 9 2400/3904 Training loss: 0.631956
Epoch: 9 3200/3904 Training loss: 0.321859
Training loss: 0.375411
Test loss: 4.921972; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 10 0/3904 Training loss: 0.533857
Epoch: 10 800/3904 Training loss: 0.507728
Epoch: 10 1600/3904 Training loss: 0.122907
Epoch: 10 2400/3904 Training loss: 0.464875
Epoch: 10 3200/3904 Training loss: 0.420284
Training loss: 0.382625
Test loss: 5.399793; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 11 0/3904 Training loss: 0.483497
Epoch: 11 800/3904 Training loss: 0.237253
Epoch: 11 1600/3904 Training loss: 0.179045
Epoch: 11 2400/3904 Training loss: 0.207706
Epoch: 11 3200/3904 Training loss: 0.337153
Training loss: 0.403388
Test loss: 4.800374; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
starting trial 185
[I 2022-12-05 04:43:32,298] Trial 184 finished with value: 0.8176369863013698 and parameters: {'d_model': 64, 'nhead': 8, 'n_encoders': 1, 'learning_rate': 0.0007592815125799332, 'weight_decay': 4.9381387520659535e-06, 'dropout': 0.1560641835502783, 'max_pool_conv': 32, 'kernel_size': 15, 'd_mlp': 32, 'num_conv_layers': 3, 'encoder_dropout': 0.12176934697899508, 'd_feed_forward': 128, 'max_pool_dim': 8, 'n_mlp_layers': 3}. Best is trial 62 with value: 0.860445205479452.
Epoch: 0 0/3904 Training loss: 0.699610
Epoch: 0 800/3904 Training loss: 0.712934
Epoch: 0 1600/3904 Training loss: 0.389342
Epoch: 0 2400/3904 Training loss: 0.732254
Epoch: 0 3200/3904 Training loss: 0.494196
Training loss: 0.657352
Test loss: 0.680682; True positive: 903; True negative: 0, False Positive: 265, False negative: 0, accuracy: 0.7731164383561644, precision: 0.7731164383561644, recall: 1.0
Epoch: 1 0/3904 Training loss: 0.666282
Epoch: 1 800/3904 Training loss: 0.670692
Epoch: 1 1600/3904 Training loss: 0.218850
Epoch: 1 2400/3904 Training loss: 0.566394
Epoch: 1 3200/3904 Training loss: 0.431986
Training loss: 0.544243
Test loss: 0.636115; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 2 0/3904 Training loss: 0.459775
Epoch: 2 800/3904 Training loss: 0.423069
Epoch: 2 1600/3904 Training loss: 0.254530
Epoch: 2 2400/3904 Training loss: 0.398984
Epoch: 2 3200/3904 Training loss: 0.388878
Training loss: 0.456255
Test loss: 0.611940; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 3 0/3904 Training loss: 0.363245
Epoch: 3 800/3904 Training loss: 0.480642
Epoch: 3 1600/3904 Training loss: 0.180158
Epoch: 3 2400/3904 Training loss: 0.284332
Epoch: 3 3200/3904 Training loss: 0.393781
Training loss: 0.419281
Test loss: 0.624631; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 4 0/3904 Training loss: 0.357207
Epoch: 4 800/3904 Training loss: 0.438727
Epoch: 4 1600/3904 Training loss: 0.207903
Epoch: 4 2400/3904 Training loss: 0.367702
Epoch: 4 3200/3904 Training loss: 0.541787
Training loss: 0.397526
Test loss: 0.591521; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 5 0/3904 Training loss: 0.321854
Epoch: 5 800/3904 Training loss: 0.356504
Epoch: 5 1600/3904 Training loss: 0.128681
Epoch: 5 2400/3904 Training loss: 0.327888
Epoch: 5 3200/3904 Training loss: 0.322975
Training loss: 0.371451
Test loss: 0.610831; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 6 0/3904 Training loss: 0.348206
Epoch: 6 800/3904 Training loss: 0.229025
Epoch: 6 1600/3904 Training loss: 0.148496
Epoch: 6 2400/3904 Training loss: 0.227444
Epoch: 6 3200/3904 Training loss: 0.327539
Training loss: 0.354664
Test loss: 0.680124; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 7 0/3904 Training loss: 0.399020
Epoch: 7 800/3904 Training loss: 0.383219
Epoch: 7 1600/3904 Training loss: 0.169395
Epoch: 7 2400/3904 Training loss: 0.249690
Epoch: 7 3200/3904 Training loss: 0.454943
Training loss: 0.338525
Test loss: 0.664971; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 8 0/3904 Training loss: 0.198622
Epoch: 8 800/3904 Training loss: 0.354946
Epoch: 8 1600/3904 Training loss: 0.155000
Epoch: 8 2400/3904 Training loss: 0.269162
Epoch: 8 3200/3904 Training loss: 0.269110
Training loss: 0.330252
Test loss: 0.715456; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 9 0/3904 Training loss: 0.357240
Epoch: 9 800/3904 Training loss: 0.297986
Epoch: 9 1600/3904 Training loss: 0.124370
Epoch: 9 2400/3904 Training loss: 0.302679
Epoch: 9 3200/3904 Training loss: 0.276644
Training loss: 0.308444
Test loss: 0.734115; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 10 0/3904 Training loss: 0.324360
Epoch: 10 800/3904 Training loss: 0.285241
Epoch: 10 1600/3904 Training loss: 0.160876
Epoch: 10 2400/3904 Training loss: 0.327465
Epoch: 10 3200/3904 Training loss: 0.332004
Training loss: 0.294885
Test loss: 0.762622; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 11 0/3904 Training loss: 0.296450
Epoch: 11 800/3904 Training loss: 0.212097
Epoch: 11 1600/3904 Training loss: 0.225360
Epoch: 11 2400/3904 Training loss: 0.240958
Epoch: 11 3200/3904 Training loss: 0.367649
Training loss: 0.275604
Test loss: 0.759959; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 12 0/3904 Training loss: 0.298086
Epoch: 12 800/3904 Training loss: 0.187745
Epoch: 12 1600/3904 Training loss: 0.115467
Epoch: 12 2400/3904 Training loss: 0.270473
Epoch: 12 3200/3904 Training loss: 0.470944
Training loss: 0.270201
Test loss: 0.814352; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 13 0/3904 Training loss: 0.226902
Epoch: 13 800/3904 Training loss: 0.116987
Epoch: 13 1600/3904 Training loss: 0.120813
Epoch: 13 2400/3904 Training loss: 0.404713
Epoch: 13 3200/3904 Training loss: 0.442481
Training loss: 0.272049
Test loss: 0.823830; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 14 0/3904 Training loss: 0.173286
Epoch: 14 800/3904 Training loss: 0.418862
Epoch: 14 1600/3904 Training loss: 0.195693
Epoch: 14 2400/3904 Training loss: 0.206863
Epoch: 14 3200/3904 Training loss: 0.537586
Training loss: 0.271037
Test loss: 0.794277; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
starting trial 186
[I 2022-12-05 04:44:47,847] Trial 185 finished with value: 0.8176369863013698 and parameters: {'d_model': 64, 'nhead': 8, 'n_encoders': 1, 'learning_rate': 0.00043568220465356504, 'weight_decay': 3.8696917452345e-06, 'dropout': 0.22094736272307752, 'max_pool_conv': 32, 'kernel_size': 11, 'd_mlp': 32, 'num_conv_layers': 3, 'encoder_dropout': 0.15356693571983884, 'd_feed_forward': 128, 'max_pool_dim': 8, 'n_mlp_layers': 3}. Best is trial 62 with value: 0.860445205479452.
Epoch: 0 0/3904 Training loss: 0.690898
Epoch: 0 800/3904 Training loss: 0.693758
Epoch: 0 1600/3904 Training loss: 0.322531
Epoch: 0 2400/3904 Training loss: 0.655420
Epoch: 0 3200/3904 Training loss: 0.428254
Training loss: 0.633304
Test loss: 0.641118; True positive: 903; True negative: 0, False Positive: 265, False negative: 0, accuracy: 0.7731164383561644, precision: 0.7731164383561644, recall: 1.0
Epoch: 1 0/3904 Training loss: 0.526484
Epoch: 1 800/3904 Training loss: 0.499461
Epoch: 1 1600/3904 Training loss: 0.245469
Epoch: 1 2400/3904 Training loss: 0.600500
Epoch: 1 3200/3904 Training loss: 0.467691
Training loss: 0.492218
Test loss: 0.625277; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 2 0/3904 Training loss: 0.449034
Epoch: 2 800/3904 Training loss: 0.369548
Epoch: 2 1600/3904 Training loss: 0.190568
Epoch: 2 2400/3904 Training loss: 0.475764
Epoch: 2 3200/3904 Training loss: 0.382967
Training loss: 0.446957
Test loss: 0.553059; True positive: 903; True negative: 0, False Positive: 265, False negative: 0, accuracy: 0.7731164383561644, precision: 0.7731164383561644, recall: 1.0
Epoch: 3 0/3904 Training loss: 0.451055
Epoch: 3 800/3904 Training loss: 0.472899
Epoch: 3 1600/3904 Training loss: 0.191895
Epoch: 3 2400/3904 Training loss: 0.396205
Epoch: 3 3200/3904 Training loss: 0.367565
Training loss: 0.444417
Test loss: 0.608943; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 4 0/3904 Training loss: 0.343895
Epoch: 4 800/3904 Training loss: 0.322717
Epoch: 4 1600/3904 Training loss: 0.165489
Epoch: 4 2400/3904 Training loss: 0.417794
Epoch: 4 3200/3904 Training loss: 0.407562
Training loss: 0.422228
Test loss: 0.503662; True positive: 901; True negative: 42, False Positive: 223, False negative: 2, accuracy: 0.8073630136986302, precision: 0.8016014234875445, recall: 0.9977851605758582
Epoch: 5 0/3904 Training loss: 0.316410
Epoch: 5 800/3904 Training loss: 0.367159
Epoch: 5 1600/3904 Training loss: 0.186550
Epoch: 5 2400/3904 Training loss: 0.375969
Epoch: 5 3200/3904 Training loss: 0.441847
Training loss: 0.419717
Test loss: 0.503290; True positive: 903; True negative: 0, False Positive: 265, False negative: 0, accuracy: 0.7731164383561644, precision: 0.7731164383561644, recall: 1.0
Epoch: 6 0/3904 Training loss: 0.402750
Epoch: 6 800/3904 Training loss: 0.373837
Epoch: 6 1600/3904 Training loss: 0.115015
Epoch: 6 2400/3904 Training loss: 0.418039
Epoch: 6 3200/3904 Training loss: 0.376193
Training loss: 0.396375
Test loss: 0.543366; True positive: 903; True negative: 0, False Positive: 265, False negative: 0, accuracy: 0.7731164383561644, precision: 0.7731164383561644, recall: 1.0
Epoch: 7 0/3904 Training loss: 0.349324
Epoch: 7 800/3904 Training loss: 0.311186
Epoch: 7 1600/3904 Training loss: 0.145582
Epoch: 7 2400/3904 Training loss: 0.487489
Epoch: 7 3200/3904 Training loss: 0.310457
Training loss: 0.404812
Test loss: 0.708984; True positive: 767; True negative: 4, False Positive: 261, False negative: 136, accuracy: 0.6601027397260274, precision: 0.7461089494163424, recall: 0.8493909191583611
Epoch: 8 0/3904 Training loss: 0.447751
Epoch: 8 800/3904 Training loss: 0.298892
Epoch: 8 1600/3904 Training loss: 0.163998
Epoch: 8 2400/3904 Training loss: 0.433863
Epoch: 8 3200/3904 Training loss: 0.381792
Training loss: 0.389630
Test loss: 1.338614; True positive: 273; True negative: 193, False Positive: 72, False negative: 630, accuracy: 0.398972602739726, precision: 0.7913043478260869, recall: 0.3023255813953488
Epoch: 9 0/3904 Training loss: 0.368319
Epoch: 9 800/3904 Training loss: 0.487505
Epoch: 9 1600/3904 Training loss: 0.159934
Epoch: 9 2400/3904 Training loss: 0.610855
Epoch: 9 3200/3904 Training loss: 0.488517
Training loss: 0.389844
Test loss: 1.583103; True positive: 247; True negative: 123, False Positive: 142, False negative: 656, accuracy: 0.3167808219178082, precision: 0.6349614395886889, recall: 0.27353266888150607
Epoch: 10 0/3904 Training loss: 0.395898
Epoch: 10 800/3904 Training loss: 0.475965
Epoch: 10 1600/3904 Training loss: 0.142400
Epoch: 10 2400/3904 Training loss: 0.483259
Epoch: 10 3200/3904 Training loss: 0.325728
Training loss: 0.393318
Test loss: 2.316790; True positive: 113; True negative: 143, False Positive: 122, False negative: 790, accuracy: 0.2191780821917808, precision: 0.4808510638297872, recall: 0.12513842746400886
Epoch: 11 0/3904 Training loss: 0.442814
Epoch: 11 800/3904 Training loss: 0.399690
Epoch: 11 1600/3904 Training loss: 0.206461
Epoch: 11 2400/3904 Training loss: 0.454066
Epoch: 11 3200/3904 Training loss: 0.503472
Training loss: 0.373835
Test loss: 1.575801; True positive: 352; True negative: 233, False Positive: 32, False negative: 551, accuracy: 0.5008561643835616, precision: 0.9166666666666666, recall: 0.38981173864894797
Epoch: 12 0/3904 Training loss: 0.418909
Epoch: 12 800/3904 Training loss: 0.339886
Epoch: 12 1600/3904 Training loss: 0.140287
Epoch: 12 2400/3904 Training loss: 0.376297
Epoch: 12 3200/3904 Training loss: 0.306754
Training loss: 0.362615
Test loss: 0.587743; True positive: 601; True negative: 150, False Positive: 115, False negative: 302, accuracy: 0.6429794520547946, precision: 0.8393854748603352, recall: 0.6655592469545958
Epoch: 13 0/3904 Training loss: 0.395177
Epoch: 13 800/3904 Training loss: 0.609097
Epoch: 13 1600/3904 Training loss: 0.122641
Epoch: 13 2400/3904 Training loss: 0.431155
Epoch: 13 3200/3904 Training loss: 0.310875
Training loss: 0.360644
Test loss: 0.540090; True positive: 704; True negative: 150, False Positive: 115, False negative: 199, accuracy: 0.7311643835616438, precision: 0.8595848595848596, recall: 0.7796234772978959
Epoch: 14 0/3904 Training loss: 0.357255
Epoch: 14 800/3904 Training loss: 0.338508
Epoch: 14 1600/3904 Training loss: 0.123698
Epoch: 14 2400/3904 Training loss: 0.284530
Epoch: 14 3200/3904 Training loss: 0.386530
Training loss: 0.368739
Test loss: 0.733609; True positive: 233; True negative: 149, False Positive: 116, False negative: 670, accuracy: 0.3270547945205479, precision: 0.667621776504298, recall: 0.25802879291251385
Epoch: 15 0/3904 Training loss: 0.488235
Epoch: 15 800/3904 Training loss: 0.327836
Epoch: 15 1600/3904 Training loss: 0.128373
Epoch: 15 2400/3904 Training loss: 0.330856
Epoch: 15 3200/3904 Training loss: 0.333886
Training loss: 0.363862
Test loss: 0.829154; True positive: 36; True negative: 228, False Positive: 37, False negative: 867, accuracy: 0.22602739726027396, precision: 0.4931506849315068, recall: 0.03986710963455149
starting trial 187
[I 2022-12-05 04:46:16,920] Trial 186 finished with value: 0.8176369863013698 and parameters: {'d_model': 64, 'nhead': 8, 'n_encoders': 1, 'learning_rate': 0.0007087843252332882, 'weight_decay': 2.9044388788228754e-06, 'dropout': 0.25503549506063056, 'max_pool_conv': 32, 'kernel_size': 13, 'd_mlp': 32, 'num_conv_layers': 3, 'encoder_dropout': 0.09778077155851393, 'd_feed_forward': 128, 'max_pool_dim': 8, 'n_mlp_layers': 3}. Best is trial 62 with value: 0.860445205479452.
Epoch: 0 0/3904 Training loss: 0.685311
Epoch: 0 800/3904 Training loss: 0.724885
Epoch: 0 1600/3904 Training loss: 0.347601
Epoch: 0 2400/3904 Training loss: 0.669395
Epoch: 0 3200/3904 Training loss: 0.541435
Training loss: 0.647390
Test loss: 0.649203; True positive: 903; True negative: 0, False Positive: 265, False negative: 0, accuracy: 0.7731164383561644, precision: 0.7731164383561644, recall: 1.0
Epoch: 1 0/3904 Training loss: 0.522583
Epoch: 1 800/3904 Training loss: 0.721296
Epoch: 1 1600/3904 Training loss: 0.248299
Epoch: 1 2400/3904 Training loss: 0.438666
Epoch: 1 3200/3904 Training loss: 0.416938
Training loss: 0.492757
Test loss: 0.547057; True positive: 900; True negative: 0, False Positive: 265, False negative: 3, accuracy: 0.7705479452054794, precision: 0.7725321888412017, recall: 0.9966777408637874
Epoch: 2 0/3904 Training loss: 0.440389
Epoch: 2 800/3904 Training loss: 0.331552
Epoch: 2 1600/3904 Training loss: 0.147989
Epoch: 2 2400/3904 Training loss: 0.401741
Epoch: 2 3200/3904 Training loss: 0.480113
Training loss: 0.424070
Test loss: 2.257948; True positive: 0; True negative: 264, False Positive: 1, False negative: 903, accuracy: 0.22602739726027396, precision: 0.0, recall: 0.0
Epoch: 3 0/3904 Training loss: 0.371338
Epoch: 3 800/3904 Training loss: 0.298895
Epoch: 3 1600/3904 Training loss: 0.179568
Epoch: 3 2400/3904 Training loss: 0.406935
Epoch: 3 3200/3904 Training loss: 0.466483
Training loss: 0.403372
Test loss: 1.159350; True positive: 239; True negative: 214, False Positive: 51, False negative: 664, accuracy: 0.3878424657534247, precision: 0.8241379310344827, recall: 0.2646733111849391
Epoch: 4 0/3904 Training loss: 0.319544
Epoch: 4 800/3904 Training loss: 0.313118
Epoch: 4 1600/3904 Training loss: 0.138391
Epoch: 4 2400/3904 Training loss: 0.412779
Epoch: 4 3200/3904 Training loss: 0.405433
Training loss: 0.383804
Test loss: 0.775341; True positive: 541; True negative: 66, False Positive: 199, False negative: 362, accuracy: 0.5196917808219178, precision: 0.731081081081081, recall: 0.5991140642303433
Epoch: 5 0/3904 Training loss: 0.404945
Epoch: 5 800/3904 Training loss: 0.231443
Epoch: 5 1600/3904 Training loss: 0.137453
Epoch: 5 2400/3904 Training loss: 0.310561
Epoch: 5 3200/3904 Training loss: 0.531900
Training loss: 0.370385
Test loss: 0.572336; True positive: 869; True negative: 5, False Positive: 260, False negative: 34, accuracy: 0.7482876712328768, precision: 0.7697077059344553, recall: 0.9623477297895903
Epoch: 6 0/3904 Training loss: 0.354414
Epoch: 6 800/3904 Training loss: 0.207387
Epoch: 6 1600/3904 Training loss: 0.184122
Epoch: 6 2400/3904 Training loss: 0.257266
Epoch: 6 3200/3904 Training loss: 0.543335
Training loss: 0.344170
Test loss: 0.574136; True positive: 893; True negative: 1, False Positive: 264, False negative: 10, accuracy: 0.7654109589041096, precision: 0.7718236819360415, recall: 0.9889258028792912
Epoch: 7 0/3904 Training loss: 0.314283
Epoch: 7 800/3904 Training loss: 0.199060
Epoch: 7 1600/3904 Training loss: 0.169612
Epoch: 7 2400/3904 Training loss: 0.344824
Epoch: 7 3200/3904 Training loss: 0.497551
Training loss: 0.340244
Test loss: 0.858518; True positive: 61; True negative: 240, False Positive: 25, False negative: 842, accuracy: 0.2577054794520548, precision: 0.7093023255813954, recall: 0.06755260243632337
Epoch: 8 0/3904 Training loss: 0.339623
Epoch: 8 800/3904 Training loss: 0.283254
Epoch: 8 1600/3904 Training loss: 0.158611
Epoch: 8 2400/3904 Training loss: 0.245111
Epoch: 8 3200/3904 Training loss: 0.412672
Training loss: 0.325105
Test loss: 1.176443; True positive: 12; True negative: 250, False Positive: 15, False negative: 891, accuracy: 0.2243150684931507, precision: 0.4444444444444444, recall: 0.013289036544850499
Epoch: 9 0/3904 Training loss: 0.298111
Epoch: 9 800/3904 Training loss: 0.262727
Epoch: 9 1600/3904 Training loss: 0.130130
Epoch: 9 2400/3904 Training loss: 0.370269
Epoch: 9 3200/3904 Training loss: 0.494078
Training loss: 0.312848
Test loss: 1.100322; True positive: 187; True negative: 165, False Positive: 100, False negative: 716, accuracy: 0.3013698630136986, precision: 0.6515679442508711, recall: 0.2070874861572536
Epoch: 10 0/3904 Training loss: 0.237254
Epoch: 10 800/3904 Training loss: 0.223414
Epoch: 10 1600/3904 Training loss: 0.120184
Epoch: 10 2400/3904 Training loss: 0.226934
Epoch: 10 3200/3904 Training loss: 0.430696
Training loss: 0.289522
Test loss: 1.166634; True positive: 106; True negative: 174, False Positive: 91, False negative: 797, accuracy: 0.23972602739726026, precision: 0.5380710659898477, recall: 0.11738648947951273
Epoch: 11 0/3904 Training loss: 0.203387
Epoch: 11 800/3904 Training loss: 0.126361
Epoch: 11 1600/3904 Training loss: 0.163981
Epoch: 11 2400/3904 Training loss: 0.163098
Epoch: 11 3200/3904 Training loss: 0.401031
Training loss: 0.289201
Test loss: 2.400637; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
starting trial 188
[I 2022-12-05 04:47:29,507] Trial 187 finished with value: 0.7731164383561644 and parameters: {'d_model': 64, 'nhead': 8, 'n_encoders': 1, 'learning_rate': 0.0005405146699320137, 'weight_decay': 4.430891619894945e-06, 'dropout': 0.14340156470355897, 'max_pool_conv': 32, 'kernel_size': 14, 'd_mlp': 32, 'num_conv_layers': 3, 'encoder_dropout': 0.08775497776515923, 'd_feed_forward': 64, 'max_pool_dim': 8, 'n_mlp_layers': 3}. Best is trial 62 with value: 0.860445205479452.
Epoch: 0 0/3904 Training loss: 0.694776
Epoch: 0 800/3904 Training loss: 0.708448
Epoch: 0 1600/3904 Training loss: 0.357861
Epoch: 0 2400/3904 Training loss: 0.735721
Epoch: 0 3200/3904 Training loss: 0.611749
Training loss: 0.655557
Test loss: 0.750154; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 1 0/3904 Training loss: 0.694686
Epoch: 1 800/3904 Training loss: 0.730969
Epoch: 1 1600/3904 Training loss: 0.211228
Epoch: 1 2400/3904 Training loss: 0.660295
Epoch: 1 3200/3904 Training loss: 0.547043
Training loss: 0.604445
Test loss: 0.654268; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 2 0/3904 Training loss: 0.452480
Epoch: 2 800/3904 Training loss: 0.624307
Epoch: 2 1600/3904 Training loss: 0.241620
Epoch: 2 2400/3904 Training loss: 0.485932
Epoch: 2 3200/3904 Training loss: 0.524336
Training loss: 0.480293
Test loss: 0.520839; True positive: 903; True negative: 0, False Positive: 265, False negative: 0, accuracy: 0.7731164383561644, precision: 0.7731164383561644, recall: 1.0
Epoch: 3 0/3904 Training loss: 0.432257
Epoch: 3 800/3904 Training loss: 0.437491
Epoch: 3 1600/3904 Training loss: 0.132159
Epoch: 3 2400/3904 Training loss: 0.278891
Epoch: 3 3200/3904 Training loss: 0.502745
Training loss: 0.437938
Test loss: 0.552620; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 4 0/3904 Training loss: 0.393003
Epoch: 4 800/3904 Training loss: 0.389673
Epoch: 4 1600/3904 Training loss: 0.148147
Epoch: 4 2400/3904 Training loss: 0.372044
Epoch: 4 3200/3904 Training loss: 0.495873
Training loss: 0.405959
Test loss: 0.841566; True positive: 211; True negative: 236, False Positive: 29, False negative: 692, accuracy: 0.3827054794520548, precision: 0.8791666666666667, recall: 0.2336655592469546
Epoch: 5 0/3904 Training loss: 0.308068
Epoch: 5 800/3904 Training loss: 0.338421
Epoch: 5 1600/3904 Training loss: 0.103518
Epoch: 5 2400/3904 Training loss: 0.352691
Epoch: 5 3200/3904 Training loss: 0.666638
Training loss: 0.370287
Test loss: 1.103158; True positive: 13; True negative: 262, False Positive: 3, False negative: 890, accuracy: 0.23544520547945205, precision: 0.8125, recall: 0.014396456256921373
Epoch: 6 0/3904 Training loss: 0.330048
Epoch: 6 800/3904 Training loss: 0.315784
Epoch: 6 1600/3904 Training loss: 0.095917
Epoch: 6 2400/3904 Training loss: 0.240438
Epoch: 6 3200/3904 Training loss: 0.557323
Training loss: 0.351787
Test loss: 1.427790; True positive: 5; True negative: 265, False Positive: 0, False negative: 898, accuracy: 0.23116438356164384, precision: 1.0, recall: 0.005537098560354375
Epoch: 7 0/3904 Training loss: 0.387954
Epoch: 7 800/3904 Training loss: 0.250284
Epoch: 7 1600/3904 Training loss: 0.150013
Epoch: 7 2400/3904 Training loss: 0.225804
Epoch: 7 3200/3904 Training loss: 0.399199
Training loss: 0.330519
Test loss: 1.596611; True positive: 5; True negative: 265, False Positive: 0, False negative: 898, accuracy: 0.23116438356164384, precision: 1.0, recall: 0.005537098560354375
Epoch: 8 0/3904 Training loss: 0.443114
Epoch: 8 800/3904 Training loss: 0.325726
Epoch: 8 1600/3904 Training loss: 0.162307
Epoch: 8 2400/3904 Training loss: 0.245537
Epoch: 8 3200/3904 Training loss: 0.571819
Training loss: 0.314184
Test loss: 1.207202; True positive: 65; True negative: 251, False Positive: 14, False negative: 838, accuracy: 0.2705479452054795, precision: 0.8227848101265823, recall: 0.07198228128460686
Epoch: 9 0/3904 Training loss: 0.399687
Epoch: 9 800/3904 Training loss: 0.239732
Epoch: 9 1600/3904 Training loss: 0.128240
Epoch: 9 2400/3904 Training loss: 0.161097
Epoch: 9 3200/3904 Training loss: 0.630930
Training loss: 0.294192
Test loss: 1.390400; True positive: 28; True negative: 255, False Positive: 10, False negative: 875, accuracy: 0.2422945205479452, precision: 0.7368421052631579, recall: 0.031007751937984496
Epoch: 10 0/3904 Training loss: 0.500119
Epoch: 10 800/3904 Training loss: 0.187020
Epoch: 10 1600/3904 Training loss: 0.135949
Epoch: 10 2400/3904 Training loss: 0.177111
Epoch: 10 3200/3904 Training loss: 0.640286
Training loss: 0.276761
Test loss: 2.334479; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 11 0/3904 Training loss: 0.390455
Epoch: 11 800/3904 Training loss: 0.159207
Epoch: 11 1600/3904 Training loss: 0.109727
Epoch: 11 2400/3904 Training loss: 0.295950
Epoch: 11 3200/3904 Training loss: 0.700113
Training loss: 0.270147
Test loss: 2.162005; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 12 0/3904 Training loss: 0.235966
Epoch: 12 800/3904 Training loss: 0.228508
Epoch: 12 1600/3904 Training loss: 0.166111
Epoch: 12 2400/3904 Training loss: 0.351434
Epoch: 12 3200/3904 Training loss: 0.755699
Training loss: 0.254615
Test loss: 2.374380; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
starting trial 189
[I 2022-12-05 04:48:29,127] Trial 188 finished with value: 0.8176369863013698 and parameters: {'d_model': 64, 'nhead': 8, 'n_encoders': 1, 'learning_rate': 0.0006363619463835488, 'weight_decay': 3.7091690196165184e-06, 'dropout': 0.20778364478197864, 'max_pool_conv': 32, 'kernel_size': 16, 'd_mlp': 32, 'num_conv_layers': 2, 'encoder_dropout': 0.11506131858035999, 'd_feed_forward': 128, 'max_pool_dim': 8, 'n_mlp_layers': 4}. Best is trial 62 with value: 0.860445205479452.
Epoch: 0 0/3904 Training loss: 0.690729
Epoch: 0 800/3904 Training loss: 0.725880
Epoch: 0 1600/3904 Training loss: 0.439319
Epoch: 0 2400/3904 Training loss: 0.846658
Epoch: 0 3200/3904 Training loss: 0.551591
Training loss: 0.663074
Test loss: 0.722858; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 1 0/3904 Training loss: 0.693580
Epoch: 1 800/3904 Training loss: 0.696749
Epoch: 1 1600/3904 Training loss: 0.341260
Epoch: 1 2400/3904 Training loss: 0.659325
Epoch: 1 3200/3904 Training loss: 0.425742
Training loss: 0.617126
Test loss: 0.550327; True positive: 903; True negative: 0, False Positive: 265, False negative: 0, accuracy: 0.7731164383561644, precision: 0.7731164383561644, recall: 1.0
Epoch: 2 0/3904 Training loss: 0.575892
Epoch: 2 800/3904 Training loss: 0.626207
Epoch: 2 1600/3904 Training loss: 0.224111
Epoch: 2 2400/3904 Training loss: 0.429709
Epoch: 2 3200/3904 Training loss: 0.387021
Training loss: 0.474145
Test loss: 0.534281; True positive: 832; True negative: 96, False Positive: 169, False negative: 71, accuracy: 0.7945205479452054, precision: 0.8311688311688312, recall: 0.9213732004429679
Epoch: 3 0/3904 Training loss: 0.449610
Epoch: 3 800/3904 Training loss: 0.321055
Epoch: 3 1600/3904 Training loss: 0.174995
Epoch: 3 2400/3904 Training loss: 0.353527
Epoch: 3 3200/3904 Training loss: 0.356513
Training loss: 0.413646
Test loss: 0.984704; True positive: 4; True negative: 265, False Positive: 0, False negative: 899, accuracy: 0.2303082191780822, precision: 1.0, recall: 0.004429678848283499
Epoch: 4 0/3904 Training loss: 0.339171
Epoch: 4 800/3904 Training loss: 0.371013
Epoch: 4 1600/3904 Training loss: 0.124079
Epoch: 4 2400/3904 Training loss: 0.552589
Epoch: 4 3200/3904 Training loss: 0.441030
Training loss: 0.394750
Test loss: 1.230796; True positive: 7; True negative: 261, False Positive: 4, False negative: 896, accuracy: 0.22945205479452055, precision: 0.6363636363636364, recall: 0.007751937984496124
Epoch: 5 0/3904 Training loss: 0.288002
Epoch: 5 800/3904 Training loss: 0.355238
Epoch: 5 1600/3904 Training loss: 0.162613
Epoch: 5 2400/3904 Training loss: 0.372648
Epoch: 5 3200/3904 Training loss: 0.405966
Training loss: 0.374471
Test loss: 1.700789; True positive: 1; True negative: 265, False Positive: 0, False negative: 902, accuracy: 0.22773972602739725, precision: 1.0, recall: 0.0011074197120708748
Epoch: 6 0/3904 Training loss: 0.321980
Epoch: 6 800/3904 Training loss: 0.256303
Epoch: 6 1600/3904 Training loss: 0.152521
Epoch: 6 2400/3904 Training loss: 0.366030
Epoch: 6 3200/3904 Training loss: 0.336586
Training loss: 0.349132
Test loss: 2.190875; True positive: 4; True negative: 265, False Positive: 0, False negative: 899, accuracy: 0.2303082191780822, precision: 1.0, recall: 0.004429678848283499
Epoch: 7 0/3904 Training loss: 0.412317
Epoch: 7 800/3904 Training loss: 0.363856
Epoch: 7 1600/3904 Training loss: 0.180997
Epoch: 7 2400/3904 Training loss: 0.371790
Epoch: 7 3200/3904 Training loss: 0.360528
Training loss: 0.355048
Test loss: 2.360704; True positive: 5; True negative: 257, False Positive: 8, False negative: 898, accuracy: 0.2243150684931507, precision: 0.38461538461538464, recall: 0.005537098560354375
Epoch: 8 0/3904 Training loss: 0.419164
Epoch: 8 800/3904 Training loss: 0.395752
Epoch: 8 1600/3904 Training loss: 0.129547
Epoch: 8 2400/3904 Training loss: 0.248683
Epoch: 8 3200/3904 Training loss: 0.359971
Training loss: 0.363242
Test loss: 1.805526; True positive: 45; True negative: 195, False Positive: 70, False negative: 858, accuracy: 0.2054794520547945, precision: 0.391304347826087, recall: 0.04983388704318937
Epoch: 9 0/3904 Training loss: 0.519191
Epoch: 9 800/3904 Training loss: 0.334770
Epoch: 9 1600/3904 Training loss: 0.144585
Epoch: 9 2400/3904 Training loss: 0.466096
Epoch: 9 3200/3904 Training loss: 0.414632
Training loss: 0.340225
Test loss: 3.133167; True positive: 3; True negative: 265, False Positive: 0, False negative: 900, accuracy: 0.22945205479452055, precision: 1.0, recall: 0.0033222591362126247
Epoch: 10 0/3904 Training loss: 0.316401
Epoch: 10 800/3904 Training loss: 0.475635
Epoch: 10 1600/3904 Training loss: 0.127829
Epoch: 10 2400/3904 Training loss: 0.330061
Epoch: 10 3200/3904 Training loss: 0.436759
Training loss: 0.317384
Test loss: 4.023629; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 11 0/3904 Training loss: 0.404869
Epoch: 11 800/3904 Training loss: 0.225971
Epoch: 11 1600/3904 Training loss: 0.132953
Epoch: 11 2400/3904 Training loss: 0.276891
Epoch: 11 3200/3904 Training loss: 0.431186
Training loss: 0.325610
Test loss: 4.104085; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 12 0/3904 Training loss: 0.481487
Epoch: 12 800/3904 Training loss: 0.444334
Epoch: 12 1600/3904 Training loss: 0.127722
Epoch: 12 2400/3904 Training loss: 0.295657
Epoch: 12 3200/3904 Training loss: 0.438993
Training loss: 0.306745
Test loss: 4.520241; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
starting trial 190
[I 2022-12-05 04:49:41,725] Trial 189 finished with value: 0.7945205479452054 and parameters: {'d_model': 64, 'nhead': 8, 'n_encoders': 1, 'learning_rate': 0.0005875407389196816, 'weight_decay': 5.576728046491164e-06, 'dropout': 0.1885205423632291, 'max_pool_conv': 32, 'kernel_size': 13, 'd_mlp': 16, 'num_conv_layers': 3, 'encoder_dropout': 0.07462759538649258, 'd_feed_forward': 128, 'max_pool_dim': 8, 'n_mlp_layers': 3}. Best is trial 62 with value: 0.860445205479452.
Epoch: 0 0/3904 Training loss: 0.702298
Epoch: 0 800/3904 Training loss: 0.710652
Epoch: 0 1600/3904 Training loss: 0.273496
Epoch: 0 2400/3904 Training loss: 0.656441
Epoch: 0 3200/3904 Training loss: 0.485614
Training loss: 0.615858
Test loss: 0.608686; True positive: 843; True negative: 117, False Positive: 148, False negative: 60, accuracy: 0.821917808219178, precision: 0.8506559031281534, recall: 0.9335548172757475
Epoch: 1 0/3904 Training loss: 0.452022
Epoch: 1 800/3904 Training loss: 0.441913
Epoch: 1 1600/3904 Training loss: 0.256086
Epoch: 1 2400/3904 Training loss: 0.395615
Epoch: 1 3200/3904 Training loss: 0.396924
Training loss: 0.463025
Test loss: 0.604370; True positive: 838; True negative: 120, False Positive: 145, False negative: 65, accuracy: 0.8202054794520548, precision: 0.8524923702950152, recall: 0.9280177187153932
Epoch: 2 0/3904 Training loss: 0.348373
Epoch: 2 800/3904 Training loss: 0.378951
Epoch: 2 1600/3904 Training loss: 0.121913
Epoch: 2 2400/3904 Training loss: 0.474352
Epoch: 2 3200/3904 Training loss: 0.398152
Training loss: 0.411616
Test loss: 0.619946; True positive: 838; True negative: 120, False Positive: 145, False negative: 65, accuracy: 0.8202054794520548, precision: 0.8524923702950152, recall: 0.9280177187153932
Epoch: 3 0/3904 Training loss: 0.347356
Epoch: 3 800/3904 Training loss: 0.240505
Epoch: 3 1600/3904 Training loss: 0.155319
Epoch: 3 2400/3904 Training loss: 0.314327
Epoch: 3 3200/3904 Training loss: 0.294893
Training loss: 0.381722
Test loss: 0.547253; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 4 0/3904 Training loss: 0.346124
Epoch: 4 800/3904 Training loss: 0.211115
Epoch: 4 1600/3904 Training loss: 0.156133
Epoch: 4 2400/3904 Training loss: 0.430789
Epoch: 4 3200/3904 Training loss: 0.226893
Training loss: 0.339847
Test loss: 0.642286; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 5 0/3904 Training loss: 0.383713
Epoch: 5 800/3904 Training loss: 0.208272
Epoch: 5 1600/3904 Training loss: 0.159533
Epoch: 5 2400/3904 Training loss: 0.269617
Epoch: 5 3200/3904 Training loss: 0.328837
Training loss: 0.313479
Test loss: 0.715914; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 6 0/3904 Training loss: 0.283231
Epoch: 6 800/3904 Training loss: 0.170301
Epoch: 6 1600/3904 Training loss: 0.149460
Epoch: 6 2400/3904 Training loss: 0.162922
Epoch: 6 3200/3904 Training loss: 0.366697
Training loss: 0.288447
Test loss: 0.762539; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 7 0/3904 Training loss: 0.225977
Epoch: 7 800/3904 Training loss: 0.132286
Epoch: 7 1600/3904 Training loss: 0.268962
Epoch: 7 2400/3904 Training loss: 0.218705
Epoch: 7 3200/3904 Training loss: 0.356177
Training loss: 0.256518
Test loss: 0.687599; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 8 0/3904 Training loss: 0.231452
Epoch: 8 800/3904 Training loss: 0.227444
Epoch: 8 1600/3904 Training loss: 0.174217
Epoch: 8 2400/3904 Training loss: 0.120169
Epoch: 8 3200/3904 Training loss: 0.229612
Training loss: 0.253254
Test loss: 0.749090; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 9 0/3904 Training loss: 0.298011
Epoch: 9 800/3904 Training loss: 0.214574
Epoch: 9 1600/3904 Training loss: 0.197990
Epoch: 9 2400/3904 Training loss: 0.276936
Epoch: 9 3200/3904 Training loss: 0.305079
Training loss: 0.236863
Test loss: 0.760436; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 10 0/3904 Training loss: 0.264378
Epoch: 10 800/3904 Training loss: 0.134244
Epoch: 10 1600/3904 Training loss: 0.199187
Epoch: 10 2400/3904 Training loss: 0.424100
Epoch: 10 3200/3904 Training loss: 0.271858
Training loss: 0.209341
Test loss: 0.984487; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 11 0/3904 Training loss: 0.247302
Epoch: 11 800/3904 Training loss: 0.229530
Epoch: 11 1600/3904 Training loss: 0.148035
Epoch: 11 2400/3904 Training loss: 0.117254
Epoch: 11 3200/3904 Training loss: 0.321069
Training loss: 0.208533
Test loss: 0.995233; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 12 0/3904 Training loss: 0.141706
Epoch: 12 800/3904 Training loss: 0.115652
Epoch: 12 1600/3904 Training loss: 0.092179
Epoch: 12 2400/3904 Training loss: 0.061351
Epoch: 12 3200/3904 Training loss: 0.219979
Training loss: 0.182095
Test loss: 1.134563; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 13 0/3904 Training loss: 0.179257
Epoch: 13 800/3904 Training loss: 0.161214
Epoch: 13 1600/3904 Training loss: 0.141928
Epoch: 13 2400/3904 Training loss: 0.150551
Epoch: 13 3200/3904 Training loss: 0.231520
Training loss: 0.190256
Test loss: 1.307348; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
starting trial 191
[I 2022-12-05 04:50:40,506] Trial 190 finished with value: 0.821917808219178 and parameters: {'d_model': 64, 'nhead': 8, 'n_encoders': 1, 'learning_rate': 0.0004877246628260422, 'weight_decay': 3.455156301722549e-06, 'dropout': 0.1611006716583398, 'max_pool_conv': 64, 'kernel_size': 15, 'd_mlp': 62, 'num_conv_layers': 2, 'encoder_dropout': 0.3224525972393036, 'd_feed_forward': 512, 'max_pool_dim': 8, 'n_mlp_layers': 3}. Best is trial 62 with value: 0.860445205479452.
Epoch: 0 0/3904 Training loss: 0.699489
Epoch: 0 800/3904 Training loss: 0.735830
Epoch: 0 1600/3904 Training loss: 0.448253
Epoch: 0 2400/3904 Training loss: 0.777341
Epoch: 0 3200/3904 Training loss: 0.556107
Training loss: 0.660073
Test loss: 0.908878; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 1 0/3904 Training loss: 0.707686
Epoch: 1 800/3904 Training loss: 0.722132
Epoch: 1 1600/3904 Training loss: 0.398753
Epoch: 1 2400/3904 Training loss: 0.716721
Epoch: 1 3200/3904 Training loss: 0.502596
Training loss: 0.638526
Test loss: 0.868138; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 2 0/3904 Training loss: 0.653352
Epoch: 2 800/3904 Training loss: 0.681584
Epoch: 2 1600/3904 Training loss: 0.323676
Epoch: 2 2400/3904 Training loss: 0.780630
Epoch: 2 3200/3904 Training loss: 0.470805
Training loss: 0.572012
Test loss: 0.679267; True positive: 753; True negative: 128, False Positive: 137, False negative: 150, accuracy: 0.7542808219178082, precision: 0.8460674157303371, recall: 0.8338870431893688
Epoch: 3 0/3904 Training loss: 0.560322
Epoch: 3 800/3904 Training loss: 0.602621
Epoch: 3 1600/3904 Training loss: 0.240118
Epoch: 3 2400/3904 Training loss: 0.795633
Epoch: 3 3200/3904 Training loss: 0.432908
Training loss: 0.495770
Test loss: 1.979769; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 4 0/3904 Training loss: 0.507236
Epoch: 4 800/3904 Training loss: 0.563524
Epoch: 4 1600/3904 Training loss: 0.229984
Epoch: 4 2400/3904 Training loss: 0.590073
Epoch: 4 3200/3904 Training loss: 0.467046
Training loss: 0.450399
Test loss: 2.058450; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 5 0/3904 Training loss: 0.450444
Epoch: 5 800/3904 Training loss: 0.469287
Epoch: 5 1600/3904 Training loss: 0.241186
Epoch: 5 2400/3904 Training loss: 0.605273
Epoch: 5 3200/3904 Training loss: 0.364238
Training loss: 0.418072
Test loss: 2.166017; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 6 0/3904 Training loss: 0.372411
Epoch: 6 800/3904 Training loss: 0.467878
Epoch: 6 1600/3904 Training loss: 0.227318
Epoch: 6 2400/3904 Training loss: 0.525700
Epoch: 6 3200/3904 Training loss: 0.360796
Training loss: 0.393037
Test loss: 2.243389; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 7 0/3904 Training loss: 0.344336
Epoch: 7 800/3904 Training loss: 0.392535
Epoch: 7 1600/3904 Training loss: 0.288192
Epoch: 7 2400/3904 Training loss: 0.605856
Epoch: 7 3200/3904 Training loss: 0.401278
Training loss: 0.371246
Test loss: 2.428153; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 8 0/3904 Training loss: 0.355668
Epoch: 8 800/3904 Training loss: 0.278950
Epoch: 8 1600/3904 Training loss: 0.207397
Epoch: 8 2400/3904 Training loss: 0.571999
Epoch: 8 3200/3904 Training loss: 0.402102
Training loss: 0.345895
Test loss: 0.601797; True positive: 799; True negative: 120, False Positive: 145, False negative: 104, accuracy: 0.7868150684931506, precision: 0.8463983050847458, recall: 0.884828349944629
Epoch: 9 0/3904 Training loss: 0.376344
Epoch: 9 800/3904 Training loss: 0.222809
Epoch: 9 1600/3904 Training loss: 0.245364
Epoch: 9 2400/3904 Training loss: 0.612737
Epoch: 9 3200/3904 Training loss: 0.368561
Training loss: 0.328783
Test loss: 0.545499; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 10 0/3904 Training loss: 0.310434
Epoch: 10 800/3904 Training loss: 0.318720
Epoch: 10 1600/3904 Training loss: 0.207532
Epoch: 10 2400/3904 Training loss: 0.546903
Epoch: 10 3200/3904 Training loss: 0.368106
Training loss: 0.311859
Test loss: 0.551484; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 11 0/3904 Training loss: 0.323319
Epoch: 11 800/3904 Training loss: 0.265560
Epoch: 11 1600/3904 Training loss: 0.177345
Epoch: 11 2400/3904 Training loss: 0.495146
Epoch: 11 3200/3904 Training loss: 0.342052
Training loss: 0.292398
Test loss: 0.568910; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 12 0/3904 Training loss: 0.334580
Epoch: 12 800/3904 Training loss: 0.239360
Epoch: 12 1600/3904 Training loss: 0.222348
Epoch: 12 2400/3904 Training loss: 0.505051
Epoch: 12 3200/3904 Training loss: 0.399576
Training loss: 0.282285
Test loss: 0.571251; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 13 0/3904 Training loss: 0.398644
Epoch: 13 800/3904 Training loss: 0.292214
Epoch: 13 1600/3904 Training loss: 0.179705
Epoch: 13 2400/3904 Training loss: 0.461938
Epoch: 13 3200/3904 Training loss: 0.406662
Training loss: 0.265538
Test loss: 0.601421; True positive: 834; True negative: 117, False Positive: 148, False negative: 69, accuracy: 0.8142123287671232, precision: 0.8492871690427699, recall: 0.9235880398671097
Epoch: 14 0/3904 Training loss: 0.573108
Epoch: 14 800/3904 Training loss: 0.299119
Epoch: 14 1600/3904 Training loss: 0.130139
Epoch: 14 2400/3904 Training loss: 0.384091
Epoch: 14 3200/3904 Training loss: 0.441246
Training loss: 0.259768
Test loss: 0.613959; True positive: 833; True negative: 117, False Positive: 148, False negative: 70, accuracy: 0.8133561643835616, precision: 0.8491335372069317, recall: 0.9224806201550387
Epoch: 15 0/3904 Training loss: 0.300943
Epoch: 15 800/3904 Training loss: 0.259718
Epoch: 15 1600/3904 Training loss: 0.125921
Epoch: 15 2400/3904 Training loss: 0.391625
Epoch: 15 3200/3904 Training loss: 0.318612
Training loss: 0.241849
Test loss: 0.599873; True positive: 832; True negative: 118, False Positive: 147, False negative: 71, accuracy: 0.8133561643835616, precision: 0.849846782431052, recall: 0.9213732004429679
Epoch: 16 0/3904 Training loss: 0.388886
Epoch: 16 800/3904 Training loss: 0.157769
Epoch: 16 1600/3904 Training loss: 0.188544
Epoch: 16 2400/3904 Training loss: 0.291226
Epoch: 16 3200/3904 Training loss: 0.433881
Training loss: 0.228384
Test loss: 0.601053; True positive: 831; True negative: 119, False Positive: 146, False negative: 72, accuracy: 0.8133561643835616, precision: 0.8505629477993859, recall: 0.920265780730897
Epoch: 17 0/3904 Training loss: 0.324529
Epoch: 17 800/3904 Training loss: 0.112888
Epoch: 17 1600/3904 Training loss: 0.157386
Epoch: 17 2400/3904 Training loss: 0.374334
Epoch: 17 3200/3904 Training loss: 0.368455
Training loss: 0.221493
Test loss: 0.749722; True positive: 578; True negative: 199, False Positive: 66, False negative: 325, accuracy: 0.6652397260273972, precision: 0.8975155279503105, recall: 0.6400885935769657
Epoch: 18 0/3904 Training loss: 0.231277
Epoch: 18 800/3904 Training loss: 0.140633
Epoch: 18 1600/3904 Training loss: 0.120462
Epoch: 18 2400/3904 Training loss: 0.373582
Epoch: 18 3200/3904 Training loss: 0.352827
Training loss: 0.211145
Test loss: 0.667392; True positive: 759; True negative: 135, False Positive: 130, False negative: 144, accuracy: 0.7654109589041096, precision: 0.8537682789651294, recall: 0.840531561461794
Epoch: 19 0/3904 Training loss: 0.286168
Epoch: 19 800/3904 Training loss: 0.126775
Epoch: 19 1600/3904 Training loss: 0.128527
Epoch: 19 2400/3904 Training loss: 0.310438
Epoch: 19 3200/3904 Training loss: 0.571018
Training loss: 0.203158
Test loss: 0.643475; True positive: 759; True negative: 142, False Positive: 123, False negative: 144, accuracy: 0.771404109589041, precision: 0.8605442176870748, recall: 0.840531561461794
starting trial 192
[I 2022-12-05 04:51:57,995] Trial 191 finished with value: 0.8176369863013698 and parameters: {'d_model': 64, 'nhead': 8, 'n_encoders': 1, 'learning_rate': 0.00010667575566441943, 'weight_decay': 4.164895021576526e-06, 'dropout': 0.1318574084308667, 'max_pool_conv': 64, 'kernel_size': 7, 'd_mlp': 16, 'num_conv_layers': 3, 'encoder_dropout': 0.10600750811549399, 'd_feed_forward': 128, 'max_pool_dim': 8, 'n_mlp_layers': 3}. Best is trial 62 with value: 0.860445205479452.
Epoch: 0 0/3904 Training loss: 0.690344
Epoch: 0 800/3904 Training loss: 0.732009
Epoch: 0 1600/3904 Training loss: 0.428219
Epoch: 0 2400/3904 Training loss: 0.759048
Epoch: 0 3200/3904 Training loss: 0.549177
Training loss: 0.664339
Test loss: 0.827177; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 1 0/3904 Training loss: 0.694276
Epoch: 1 800/3904 Training loss: 0.723615
Epoch: 1 1600/3904 Training loss: 0.348444
Epoch: 1 2400/3904 Training loss: 0.858897
Epoch: 1 3200/3904 Training loss: 0.429749
Training loss: 0.617524
Test loss: 0.680371; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 2 0/3904 Training loss: 0.573790
Epoch: 2 800/3904 Training loss: 0.549038
Epoch: 2 1600/3904 Training loss: 0.203506
Epoch: 2 2400/3904 Training loss: 0.789038
Epoch: 2 3200/3904 Training loss: 0.435716
Training loss: 0.506104
Test loss: 0.610289; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 3 0/3904 Training loss: 0.401231
Epoch: 3 800/3904 Training loss: 0.384865
Epoch: 3 1600/3904 Training loss: 0.213702
Epoch: 3 2400/3904 Training loss: 0.558612
Epoch: 3 3200/3904 Training loss: 0.429660
Training loss: 0.436290
Test loss: 0.557998; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 4 0/3904 Training loss: 0.322791
Epoch: 4 800/3904 Training loss: 0.314514
Epoch: 4 1600/3904 Training loss: 0.166132
Epoch: 4 2400/3904 Training loss: 0.515892
Epoch: 4 3200/3904 Training loss: 0.393838
Training loss: 0.395811
Test loss: 0.540070; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 5 0/3904 Training loss: 0.392174
Epoch: 5 800/3904 Training loss: 0.259803
Epoch: 5 1600/3904 Training loss: 0.156705
Epoch: 5 2400/3904 Training loss: 0.474958
Epoch: 5 3200/3904 Training loss: 0.555241
Training loss: 0.377295
Test loss: 0.517135; True positive: 903; True negative: 0, False Positive: 265, False negative: 0, accuracy: 0.7731164383561644, precision: 0.7731164383561644, recall: 1.0
Epoch: 6 0/3904 Training loss: 0.318418
Epoch: 6 800/3904 Training loss: 0.257249
Epoch: 6 1600/3904 Training loss: 0.225807
Epoch: 6 2400/3904 Training loss: 0.427782
Epoch: 6 3200/3904 Training loss: 0.429219
Training loss: 0.346218
Test loss: 0.493298; True positive: 903; True negative: 0, False Positive: 265, False negative: 0, accuracy: 0.7731164383561644, precision: 0.7731164383561644, recall: 1.0
Epoch: 7 0/3904 Training loss: 0.389135
Epoch: 7 800/3904 Training loss: 0.267426
Epoch: 7 1600/3904 Training loss: 0.079295
Epoch: 7 2400/3904 Training loss: 0.368193
Epoch: 7 3200/3904 Training loss: 0.413661
Training loss: 0.316087
Test loss: 0.522053; True positive: 903; True negative: 0, False Positive: 265, False negative: 0, accuracy: 0.7731164383561644, precision: 0.7731164383561644, recall: 1.0
Epoch: 8 0/3904 Training loss: 0.518013
Epoch: 8 800/3904 Training loss: 0.174632
Epoch: 8 1600/3904 Training loss: 0.124001
Epoch: 8 2400/3904 Training loss: 0.375106
Epoch: 8 3200/3904 Training loss: 0.647516
Training loss: 0.291804
Test loss: 0.465640; True positive: 903; True negative: 0, False Positive: 265, False negative: 0, accuracy: 0.7731164383561644, precision: 0.7731164383561644, recall: 1.0
Epoch: 9 0/3904 Training loss: 0.356882
Epoch: 9 800/3904 Training loss: 0.221997
Epoch: 9 1600/3904 Training loss: 0.075510
Epoch: 9 2400/3904 Training loss: 0.410351
Epoch: 9 3200/3904 Training loss: 0.325205
Training loss: 0.278824
Test loss: 0.479212; True positive: 842; True negative: 47, False Positive: 218, False negative: 61, accuracy: 0.7611301369863014, precision: 0.7943396226415095, recall: 0.9324473975636767
Epoch: 10 0/3904 Training loss: 0.462664
Epoch: 10 800/3904 Training loss: 0.103800
Epoch: 10 1600/3904 Training loss: 0.068130
Epoch: 10 2400/3904 Training loss: 0.362867
Epoch: 10 3200/3904 Training loss: 0.312047
Training loss: 0.252760
Test loss: 0.477170; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 11 0/3904 Training loss: 0.310286
Epoch: 11 800/3904 Training loss: 0.189279
Epoch: 11 1600/3904 Training loss: 0.070312
Epoch: 11 2400/3904 Training loss: 0.365530
Epoch: 11 3200/3904 Training loss: 0.271180
Training loss: 0.251811
Test loss: 0.468732; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 12 0/3904 Training loss: 0.362520
Epoch: 12 800/3904 Training loss: 0.252101
Epoch: 12 1600/3904 Training loss: 0.052513
Epoch: 12 2400/3904 Training loss: 0.358136
Epoch: 12 3200/3904 Training loss: 0.280780
Training loss: 0.231342
Test loss: 0.479194; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 13 0/3904 Training loss: 0.368250
Epoch: 13 800/3904 Training loss: 0.151124
Epoch: 13 1600/3904 Training loss: 0.053526
Epoch: 13 2400/3904 Training loss: 0.306485
Epoch: 13 3200/3904 Training loss: 0.262612
Training loss: 0.215312
Test loss: 0.477223; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 14 0/3904 Training loss: 0.393090
Epoch: 14 800/3904 Training loss: 0.108206
Epoch: 14 1600/3904 Training loss: 0.074961
Epoch: 14 2400/3904 Training loss: 0.316690
Epoch: 14 3200/3904 Training loss: 0.184388
Training loss: 0.211440
Test loss: 0.482498; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 15 0/3904 Training loss: 0.304914
Epoch: 15 800/3904 Training loss: 0.091296
Epoch: 15 1600/3904 Training loss: 0.043736
Epoch: 15 2400/3904 Training loss: 0.308610
Epoch: 15 3200/3904 Training loss: 0.267630
Training loss: 0.196134
Test loss: 0.478847; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 16 0/3904 Training loss: 0.320875
Epoch: 16 800/3904 Training loss: 0.147197
Epoch: 16 1600/3904 Training loss: 0.068130
Epoch: 16 2400/3904 Training loss: 0.292509
Epoch: 16 3200/3904 Training loss: 0.199400
Training loss: 0.178985
Test loss: 0.476347; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 17 0/3904 Training loss: 0.207283
Epoch: 17 800/3904 Training loss: 0.063134
Epoch: 17 1600/3904 Training loss: 0.057895
Epoch: 17 2400/3904 Training loss: 0.232925
Epoch: 17 3200/3904 Training loss: 0.159154
Training loss: 0.179897
Test loss: 0.486717; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 18 0/3904 Training loss: 0.540381
Epoch: 18 800/3904 Training loss: 0.129104
Epoch: 18 1600/3904 Training loss: 0.066054
Epoch: 18 2400/3904 Training loss: 0.186299
Epoch: 18 3200/3904 Training loss: 0.164828
Training loss: 0.171713
Test loss: 0.511832; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
starting trial 193
[I 2022-12-05 04:53:53,544] Trial 192 finished with value: 0.8176369863013698 and parameters: {'d_model': 64, 'nhead': 4, 'n_encoders': 1, 'learning_rate': 0.00013113110737605668, 'weight_decay': 5.024443031903714e-06, 'dropout': 0.2464427110605498, 'max_pool_conv': 32, 'kernel_size': 14, 'd_mlp': 32, 'num_conv_layers': 3, 'encoder_dropout': 0.09451448462832825, 'd_feed_forward': 128, 'max_pool_dim': 4, 'n_mlp_layers': 3}. Best is trial 62 with value: 0.860445205479452.
Epoch: 0 0/3904 Training loss: 0.700764
Epoch: 0 800/3904 Training loss: 0.726918
Epoch: 0 1600/3904 Training loss: 0.322162
Epoch: 0 2400/3904 Training loss: 0.617233
Epoch: 0 3200/3904 Training loss: 0.439572
Training loss: 0.620312
Test loss: 1.061505; True positive: 36; True negative: 235, False Positive: 30, False negative: 867, accuracy: 0.2320205479452055, precision: 0.5454545454545454, recall: 0.03986710963455149
Epoch: 1 0/3904 Training loss: 0.617774
Epoch: 1 800/3904 Training loss: 0.479315
Epoch: 1 1600/3904 Training loss: 0.193923
Epoch: 1 2400/3904 Training loss: 0.388730
Epoch: 1 3200/3904 Training loss: 0.460194
Training loss: 0.466035
Test loss: 2.416635; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 2 0/3904 Training loss: 0.309700
Epoch: 2 800/3904 Training loss: 0.351621
Epoch: 2 1600/3904 Training loss: 0.167463
Epoch: 2 2400/3904 Training loss: 0.468470
Epoch: 2 3200/3904 Training loss: 0.451831
Training loss: 0.408484
Test loss: 2.947416; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 3 0/3904 Training loss: 0.289734
Epoch: 3 800/3904 Training loss: 0.335055
Epoch: 3 1600/3904 Training loss: 0.161362
Epoch: 3 2400/3904 Training loss: 0.291075
Epoch: 3 3200/3904 Training loss: 0.390601
Training loss: 0.382068
Test loss: 0.518011; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 4 0/3904 Training loss: 0.312238
Epoch: 4 800/3904 Training loss: 0.271418
Epoch: 4 1600/3904 Training loss: 0.161804
Epoch: 4 2400/3904 Training loss: 0.251536
Epoch: 4 3200/3904 Training loss: 0.374269
Training loss: 0.346798
Test loss: 0.467975; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 5 0/3904 Training loss: 0.228417
Epoch: 5 800/3904 Training loss: 0.373034
Epoch: 5 1600/3904 Training loss: 0.278247
Epoch: 5 2400/3904 Training loss: 0.225263
Epoch: 5 3200/3904 Training loss: 0.309991
Training loss: 0.318404
Test loss: 0.480182; True positive: 859; True negative: 23, False Positive: 242, False negative: 44, accuracy: 0.7551369863013698, precision: 0.7801998183469573, recall: 0.9512735326688815
Epoch: 6 0/3904 Training loss: 0.330604
Epoch: 6 800/3904 Training loss: 0.223617
Epoch: 6 1600/3904 Training loss: 0.241196
Epoch: 6 2400/3904 Training loss: 0.304795
Epoch: 6 3200/3904 Training loss: 0.319143
Training loss: 0.292198
Test loss: 0.505820; True positive: 903; True negative: 0, False Positive: 265, False negative: 0, accuracy: 0.7731164383561644, precision: 0.7731164383561644, recall: 1.0
Epoch: 7 0/3904 Training loss: 0.239625
Epoch: 7 800/3904 Training loss: 0.388634
Epoch: 7 1600/3904 Training loss: 0.225155
Epoch: 7 2400/3904 Training loss: 0.229966
Epoch: 7 3200/3904 Training loss: 0.306362
Training loss: 0.261299
Test loss: 0.467168; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 8 0/3904 Training loss: 0.384258
Epoch: 8 800/3904 Training loss: 0.090682
Epoch: 8 1600/3904 Training loss: 0.300835
Epoch: 8 2400/3904 Training loss: 0.172658
Epoch: 8 3200/3904 Training loss: 0.393693
Training loss: 0.253272
Test loss: 0.486431; True positive: 903; True negative: 0, False Positive: 265, False negative: 0, accuracy: 0.7731164383561644, precision: 0.7731164383561644, recall: 1.0
Epoch: 9 0/3904 Training loss: 0.219060
Epoch: 9 800/3904 Training loss: 0.309307
Epoch: 9 1600/3904 Training loss: 0.174560
Epoch: 9 2400/3904 Training loss: 0.152253
Epoch: 9 3200/3904 Training loss: 0.323383
Training loss: 0.235761
Test loss: 0.463790; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 10 0/3904 Training loss: 0.343828
Epoch: 10 800/3904 Training loss: 0.046508
Epoch: 10 1600/3904 Training loss: 0.172606
Epoch: 10 2400/3904 Training loss: 0.155926
Epoch: 10 3200/3904 Training loss: 0.303201
Training loss: 0.212069
Test loss: 0.528185; True positive: 903; True negative: 0, False Positive: 265, False negative: 0, accuracy: 0.7731164383561644, precision: 0.7731164383561644, recall: 1.0
Epoch: 11 0/3904 Training loss: 0.109764
Epoch: 11 800/3904 Training loss: 0.343536
Epoch: 11 1600/3904 Training loss: 0.158041
Epoch: 11 2400/3904 Training loss: 0.162637
Epoch: 11 3200/3904 Training loss: 0.292881
Training loss: 0.205267
Test loss: 0.471143; True positive: 837; True negative: 117, False Positive: 148, False negative: 66, accuracy: 0.8167808219178082, precision: 0.849746192893401, recall: 0.9269102990033222
Epoch: 12 0/3904 Training loss: 0.177433
Epoch: 12 800/3904 Training loss: 0.103810
Epoch: 12 1600/3904 Training loss: 0.092052
Epoch: 12 2400/3904 Training loss: 0.058266
Epoch: 12 3200/3904 Training loss: 0.279565
Training loss: 0.195454
Test loss: 0.491591; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 13 0/3904 Training loss: 0.088929
Epoch: 13 800/3904 Training loss: 0.110536
Epoch: 13 1600/3904 Training loss: 0.114356
Epoch: 13 2400/3904 Training loss: 0.107258
Epoch: 13 3200/3904 Training loss: 0.296019
Training loss: 0.184205
Test loss: 0.530400; True positive: 903; True negative: 0, False Positive: 265, False negative: 0, accuracy: 0.7731164383561644, precision: 0.7731164383561644, recall: 1.0
Epoch: 14 0/3904 Training loss: 0.060824
Epoch: 14 800/3904 Training loss: 0.221509
Epoch: 14 1600/3904 Training loss: 0.112611
Epoch: 14 2400/3904 Training loss: 0.060894
Epoch: 14 3200/3904 Training loss: 0.277603
Training loss: 0.180365
Test loss: 0.622290; True positive: 837; True negative: 117, False Positive: 148, False negative: 66, accuracy: 0.8167808219178082, precision: 0.849746192893401, recall: 0.9269102990033222
Epoch: 15 0/3904 Training loss: 0.140886
Epoch: 15 800/3904 Training loss: 0.108244
Epoch: 15 1600/3904 Training loss: 0.132248
Epoch: 15 2400/3904 Training loss: 0.196102
Epoch: 15 3200/3904 Training loss: 0.136447
Training loss: 0.166982
Test loss: 0.615583; True positive: 835; True negative: 117, False Positive: 148, False negative: 68, accuracy: 0.815068493150685, precision: 0.8494404883011191, recall: 0.9246954595791805
Epoch: 16 0/3904 Training loss: 0.076378
Epoch: 16 800/3904 Training loss: 0.020394
Epoch: 16 1600/3904 Training loss: 0.178038
Epoch: 16 2400/3904 Training loss: 0.112482
Epoch: 16 3200/3904 Training loss: 0.298736
Training loss: 0.151511
Test loss: 0.948572; True positive: 440; True negative: 175, False Positive: 90, False negative: 463, accuracy: 0.526541095890411, precision: 0.8301886792452831, recall: 0.48726467331118495
Epoch: 17 0/3904 Training loss: 0.155740
Epoch: 17 800/3904 Training loss: 0.106690
Epoch: 17 1600/3904 Training loss: 0.061782
Epoch: 17 2400/3904 Training loss: 0.030097
Epoch: 17 3200/3904 Training loss: 0.172401
Training loss: 0.168730
Test loss: 0.519643; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 18 0/3904 Training loss: 0.155344
Epoch: 18 800/3904 Training loss: 0.076605
Epoch: 18 1600/3904 Training loss: 0.118812
Epoch: 18 2400/3904 Training loss: 0.017375
Epoch: 18 3200/3904 Training loss: 0.140577
Training loss: 0.131995
Test loss: 0.739525; True positive: 703; True negative: 137, False Positive: 128, False negative: 200, accuracy: 0.7191780821917808, precision: 0.8459687123947052, recall: 0.778516057585825
Epoch: 19 0/3904 Training loss: 0.086239
Epoch: 19 800/3904 Training loss: 0.059040
Epoch: 19 1600/3904 Training loss: 0.159332
Epoch: 19 2400/3904 Training loss: 0.059056
Epoch: 19 3200/3904 Training loss: 0.151062
Training loss: 0.126456
Test loss: 2.692536; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
starting trial 194
[I 2022-12-05 04:55:17,863] Trial 193 finished with value: 0.8176369863013698 and parameters: {'d_model': 64, 'nhead': 8, 'n_encoders': 1, 'learning_rate': 0.0004824486740974447, 'weight_decay': 3.4061894808065037e-06, 'dropout': 0.1660283574788282, 'max_pool_conv': 64, 'kernel_size': 15, 'd_mlp': 62, 'num_conv_layers': 2, 'encoder_dropout': 0.2648907726395027, 'd_feed_forward': 512, 'max_pool_dim': 8, 'n_mlp_layers': 3}. Best is trial 62 with value: 0.860445205479452.
Epoch: 0 0/3904 Training loss: 0.708947
Epoch: 0 800/3904 Training loss: 0.706489
Epoch: 0 1600/3904 Training loss: 0.374445
Epoch: 0 2400/3904 Training loss: 0.647223
Epoch: 0 3200/3904 Training loss: 0.500082
Training loss: 0.640907
Test loss: 0.684361; True positive: 837; True negative: 118, False Positive: 147, False negative: 66, accuracy: 0.8176369863013698, precision: 0.850609756097561, recall: 0.9269102990033222
Epoch: 1 0/3904 Training loss: 0.568763
Epoch: 1 800/3904 Training loss: 0.601802
Epoch: 1 1600/3904 Training loss: 0.233592
Epoch: 1 2400/3904 Training loss: 0.426748
Epoch: 1 3200/3904 Training loss: 0.358462
Training loss: 0.477660
Test loss: 1.525821; True positive: 19; True negative: 263, False Positive: 2, False negative: 884, accuracy: 0.24143835616438356, precision: 0.9047619047619048, recall: 0.021040974529346623
Epoch: 2 0/3904 Training loss: 0.381623
Epoch: 2 800/3904 Training loss: 0.300546
Epoch: 2 1600/3904 Training loss: 0.202718
Epoch: 2 2400/3904 Training loss: 0.240170
Epoch: 2 3200/3904 Training loss: 0.441514
Training loss: 0.407838
Test loss: 0.578749; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 3 0/3904 Training loss: 0.330612
Epoch: 3 800/3904 Training loss: 0.255569
Epoch: 3 1600/3904 Training loss: 0.169135
Epoch: 3 2400/3904 Training loss: 0.218906
Epoch: 3 3200/3904 Training loss: 0.303722
Training loss: 0.359557
Test loss: 0.578174; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 4 0/3904 Training loss: 0.285597
Epoch: 4 800/3904 Training loss: 0.264630
Epoch: 4 1600/3904 Training loss: 0.119891
Epoch: 4 2400/3904 Training loss: 0.307721
Epoch: 4 3200/3904 Training loss: 0.412063
Training loss: 0.312557
Test loss: 0.629534; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 5 0/3904 Training loss: 0.216926
Epoch: 5 800/3904 Training loss: 0.147394
Epoch: 5 1600/3904 Training loss: 0.158743
Epoch: 5 2400/3904 Training loss: 0.144638
Epoch: 5 3200/3904 Training loss: 0.425380
Training loss: 0.287773
Test loss: 0.646627; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 6 0/3904 Training loss: 0.186301
Epoch: 6 800/3904 Training loss: 0.173684
Epoch: 6 1600/3904 Training loss: 0.107080
Epoch: 6 2400/3904 Training loss: 0.118308
Epoch: 6 3200/3904 Training loss: 0.425731
Training loss: 0.257106
Test loss: 0.686703; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 7 0/3904 Training loss: 0.156845
Epoch: 7 800/3904 Training loss: 0.190177
Epoch: 7 1600/3904 Training loss: 0.119449
Epoch: 7 2400/3904 Training loss: 0.157042
Epoch: 7 3200/3904 Training loss: 0.369179
Training loss: 0.257672
Test loss: 0.701801; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 8 0/3904 Training loss: 0.163755
Epoch: 8 800/3904 Training loss: 0.130698
Epoch: 8 1600/3904 Training loss: 0.083587
Epoch: 8 2400/3904 Training loss: 0.125009
Epoch: 8 3200/3904 Training loss: 0.274825
Training loss: 0.235607
Test loss: 0.746380; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 9 0/3904 Training loss: 0.198316
Epoch: 9 800/3904 Training loss: 0.082196
Epoch: 9 1600/3904 Training loss: 0.092567
Epoch: 9 2400/3904 Training loss: 0.231951
Epoch: 9 3200/3904 Training loss: 0.441384
Training loss: 0.216876
Test loss: 0.755960; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 10 0/3904 Training loss: 0.232545
Epoch: 10 800/3904 Training loss: 0.207236
Epoch: 10 1600/3904 Training loss: 0.098748
Epoch: 10 2400/3904 Training loss: 0.129295
Epoch: 10 3200/3904 Training loss: 0.406125
Training loss: 0.205919
Test loss: 0.767998; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 11 0/3904 Training loss: 0.121453
Epoch: 11 800/3904 Training loss: 0.106069
Epoch: 11 1600/3904 Training loss: 0.102120
Epoch: 11 2400/3904 Training loss: 0.222242
Epoch: 11 3200/3904 Training loss: 0.292659
Training loss: 0.191911
Test loss: 0.792311; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 12 0/3904 Training loss: 0.226957
Epoch: 12 800/3904 Training loss: 0.065910
Epoch: 12 1600/3904 Training loss: 0.120292
Epoch: 12 2400/3904 Training loss: 0.083142
Epoch: 12 3200/3904 Training loss: 0.424087
Training loss: 0.175904
Test loss: 0.691949; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 13 0/3904 Training loss: 0.150301
Epoch: 13 800/3904 Training loss: 0.323043
Epoch: 13 1600/3904 Training loss: 0.151316
Epoch: 13 2400/3904 Training loss: 0.035921
Epoch: 13 3200/3904 Training loss: 0.282837
Training loss: 0.166143
Test loss: 0.907755; True positive: 836; True negative: 119, False Positive: 146, False negative: 67, accuracy: 0.8176369863013698, precision: 0.8513238289205702, recall: 0.9258028792912514
starting trial 195
[I 2022-12-05 04:56:16,177] Trial 194 finished with value: 0.8176369863013698 and parameters: {'d_model': 64, 'nhead': 8, 'n_encoders': 1, 'learning_rate': 0.0003947217700904752, 'weight_decay': 3.70473582003693e-06, 'dropout': 0.15165772691701968, 'max_pool_conv': 64, 'kernel_size': 14, 'd_mlp': 62, 'num_conv_layers': 2, 'encoder_dropout': 0.3209543547893845, 'd_feed_forward': 512, 'max_pool_dim': 8, 'n_mlp_layers': 3}. Best is trial 62 with value: 0.860445205479452.
Epoch: 0 0/3904 Training loss: 0.696655
Epoch: 0 800/3904 Training loss: 0.722608
Epoch: 0 1600/3904 Training loss: 0.428662
Epoch: 0 2400/3904 Training loss: 0.762004
Epoch: 0 3200/3904 Training loss: 0.536629
Training loss: 0.663563
Test loss: 0.802155; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 1 0/3904 Training loss: 0.703088
Epoch: 1 800/3904 Training loss: 0.737541
Epoch: 1 1600/3904 Training loss: 0.328176
Epoch: 1 2400/3904 Training loss: 0.735715
Epoch: 1 3200/3904 Training loss: 0.447474
Training loss: 0.605259
Test loss: 0.562393; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 2 0/3904 Training loss: 0.581824
Epoch: 2 800/3904 Training loss: 0.432302
Epoch: 2 1600/3904 Training loss: 0.228429
Epoch: 2 2400/3904 Training loss: 0.652601
Epoch: 2 3200/3904 Training loss: 0.368554
Training loss: 0.495114
Test loss: 0.553769; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 3 0/3904 Training loss: 0.506662
Epoch: 3 800/3904 Training loss: 0.317267
Epoch: 3 1600/3904 Training loss: 0.207476
Epoch: 3 2400/3904 Training loss: 0.496411
Epoch: 3 3200/3904 Training loss: 0.414266
Training loss: 0.436013
Test loss: 0.555633; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 4 0/3904 Training loss: 0.430067
Epoch: 4 800/3904 Training loss: 0.332765
Epoch: 4 1600/3904 Training loss: 0.175502
Epoch: 4 2400/3904 Training loss: 0.491551
Epoch: 4 3200/3904 Training loss: 0.344256
Training loss: 0.409067
Test loss: 0.553172; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 5 0/3904 Training loss: 0.409009
Epoch: 5 800/3904 Training loss: 0.210873
Epoch: 5 1600/3904 Training loss: 0.193146
Epoch: 5 2400/3904 Training loss: 0.343599
Epoch: 5 3200/3904 Training loss: 0.402185
Training loss: 0.397388
Test loss: 0.550175; True positive: 838; True negative: 126, False Positive: 139, False negative: 65, accuracy: 0.8253424657534246, precision: 0.857727737973388, recall: 0.9280177187153932
Epoch: 6 0/3904 Training loss: 0.403357
Epoch: 6 800/3904 Training loss: 0.257187
Epoch: 6 1600/3904 Training loss: 0.158878
Epoch: 6 2400/3904 Training loss: 0.390680
Epoch: 6 3200/3904 Training loss: 0.330118
Training loss: 0.388303
Test loss: 0.572081; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 7 0/3904 Training loss: 0.351692
Epoch: 7 800/3904 Training loss: 0.242804
Epoch: 7 1600/3904 Training loss: 0.099097
Epoch: 7 2400/3904 Training loss: 0.300744
Epoch: 7 3200/3904 Training loss: 0.387096
Training loss: 0.383203
Test loss: 0.581943; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 8 0/3904 Training loss: 0.332041
Epoch: 8 800/3904 Training loss: 0.253072
Epoch: 8 1600/3904 Training loss: 0.162899
Epoch: 8 2400/3904 Training loss: 0.215487
Epoch: 8 3200/3904 Training loss: 0.436677
Training loss: 0.372011
Test loss: 0.585442; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 9 0/3904 Training loss: 0.256273
Epoch: 9 800/3904 Training loss: 0.201935
Epoch: 9 1600/3904 Training loss: 0.131085
Epoch: 9 2400/3904 Training loss: 0.251164
Epoch: 9 3200/3904 Training loss: 0.369272
Training loss: 0.368380
Test loss: 0.578972; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 10 0/3904 Training loss: 0.224713
Epoch: 10 800/3904 Training loss: 0.250652
Epoch: 10 1600/3904 Training loss: 0.108725
Epoch: 10 2400/3904 Training loss: 0.236756
Epoch: 10 3200/3904 Training loss: 0.362546
Training loss: 0.366370
Test loss: 0.588982; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 11 0/3904 Training loss: 0.323205
Epoch: 11 800/3904 Training loss: 0.384712
Epoch: 11 1600/3904 Training loss: 0.148198
Epoch: 11 2400/3904 Training loss: 0.407165
Epoch: 11 3200/3904 Training loss: 0.440401
Training loss: 0.375982
Test loss: 0.594676; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 12 0/3904 Training loss: 0.267293
Epoch: 12 800/3904 Training loss: 0.337425
Epoch: 12 1600/3904 Training loss: 0.148284
Epoch: 12 2400/3904 Training loss: 0.208602
Epoch: 12 3200/3904 Training loss: 0.464447
Training loss: 0.365017
Test loss: 0.572289; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 13 0/3904 Training loss: 0.263438
Epoch: 13 800/3904 Training loss: 0.228512
Epoch: 13 1600/3904 Training loss: 0.157768
Epoch: 13 2400/3904 Training loss: 0.185540
Epoch: 13 3200/3904 Training loss: 0.382182
Training loss: 0.352084
Test loss: 0.583901; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 14 0/3904 Training loss: 0.314508
Epoch: 14 800/3904 Training loss: 0.231695
Epoch: 14 1600/3904 Training loss: 0.157302
Epoch: 14 2400/3904 Training loss: 0.177231
Epoch: 14 3200/3904 Training loss: 0.382524
Training loss: 0.352099
Test loss: 0.584204; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 15 0/3904 Training loss: 0.415430
Epoch: 15 800/3904 Training loss: 0.189690
Epoch: 15 1600/3904 Training loss: 0.193587
Epoch: 15 2400/3904 Training loss: 0.209759
Epoch: 15 3200/3904 Training loss: 0.271829
Training loss: 0.345120
Test loss: 0.593224; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
starting trial 196
[I 2022-12-05 04:59:32,104] Trial 195 finished with value: 0.8253424657534246 and parameters: {'d_model': 64, 'nhead': 8, 'n_encoders': 1, 'learning_rate': 0.00015470704135984396, 'weight_decay': 2.802439198483277e-06, 'dropout': 0.21579638640389934, 'max_pool_conv': 16, 'kernel_size': 12, 'd_mlp': 16, 'num_conv_layers': 7, 'encoder_dropout': 0.1359188079241469, 'd_feed_forward': 128, 'max_pool_dim': 8, 'n_mlp_layers': 3}. Best is trial 62 with value: 0.860445205479452.
Epoch: 0 0/3904 Training loss: 0.694614
Epoch: 0 800/3904 Training loss: 0.739049
Epoch: 0 1600/3904 Training loss: 0.451167
Epoch: 0 2400/3904 Training loss: 0.797684
Epoch: 0 3200/3904 Training loss: 0.561139
Training loss: 0.664437
Test loss: 0.818337; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 1 0/3904 Training loss: 0.710302
Epoch: 1 800/3904 Training loss: 0.730138
Epoch: 1 1600/3904 Training loss: 0.415511
Epoch: 1 2400/3904 Training loss: 0.719141
Epoch: 1 3200/3904 Training loss: 0.463253
Training loss: 0.641426
Test loss: 0.663017; True positive: 790; True negative: 187, False Positive: 78, False negative: 113, accuracy: 0.836472602739726, precision: 0.9101382488479263, recall: 0.8748615725359912
Epoch: 2 0/3904 Training loss: 0.655774
Epoch: 2 800/3904 Training loss: 0.572664
Epoch: 2 1600/3904 Training loss: 0.266518
Epoch: 2 2400/3904 Training loss: 0.685597
Epoch: 2 3200/3904 Training loss: 0.349906
Training loss: 0.538289
Test loss: 2.080901; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 3 0/3904 Training loss: 0.484507
Epoch: 3 800/3904 Training loss: 0.434912
Epoch: 3 1600/3904 Training loss: 0.225059
Epoch: 3 2400/3904 Training loss: 0.422427
Epoch: 3 3200/3904 Training loss: 0.353582
Training loss: 0.453743
Test loss: 2.313302; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 4 0/3904 Training loss: 0.423586
Epoch: 4 800/3904 Training loss: 0.359468
Epoch: 4 1600/3904 Training loss: 0.250067
Epoch: 4 2400/3904 Training loss: 0.379632
Epoch: 4 3200/3904 Training loss: 0.349074
Training loss: 0.417765
Test loss: 2.496924; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 5 0/3904 Training loss: 0.435743
Epoch: 5 800/3904 Training loss: 0.326328
Epoch: 5 1600/3904 Training loss: 0.233351
Epoch: 5 2400/3904 Training loss: 0.354445
Epoch: 5 3200/3904 Training loss: 0.383836
Training loss: 0.401595
Test loss: 2.713683; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 6 0/3904 Training loss: 0.357690
Epoch: 6 800/3904 Training loss: 0.296756
Epoch: 6 1600/3904 Training loss: 0.274342
Epoch: 6 2400/3904 Training loss: 0.269801
Epoch: 6 3200/3904 Training loss: 0.408604
Training loss: 0.396024
Test loss: 2.931118; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 7 0/3904 Training loss: 0.329866
Epoch: 7 800/3904 Training loss: 0.283196
Epoch: 7 1600/3904 Training loss: 0.226162
Epoch: 7 2400/3904 Training loss: 0.238631
Epoch: 7 3200/3904 Training loss: 0.446443
Training loss: 0.387511
Test loss: 3.075030; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 8 0/3904 Training loss: 0.376367
Epoch: 8 800/3904 Training loss: 0.314636
Epoch: 8 1600/3904 Training loss: 0.227050
Epoch: 8 2400/3904 Training loss: 0.226406
Epoch: 8 3200/3904 Training loss: 0.400569
Training loss: 0.375060
Test loss: 1.582070; True positive: 456; True negative: 190, False Positive: 75, False negative: 447, accuracy: 0.553082191780822, precision: 0.8587570621468926, recall: 0.5049833887043189
Epoch: 9 0/3904 Training loss: 0.358159
Epoch: 9 800/3904 Training loss: 0.371780
Epoch: 9 1600/3904 Training loss: 0.175267
Epoch: 9 2400/3904 Training loss: 0.216576
Epoch: 9 3200/3904 Training loss: 0.387211
Training loss: 0.367579
Test loss: 3.285626; True positive: 32; True negative: 256, False Positive: 9, False negative: 871, accuracy: 0.2465753424657534, precision: 0.7804878048780488, recall: 0.035437430786267994
Epoch: 10 0/3904 Training loss: 0.300536
Epoch: 10 800/3904 Training loss: 0.211121
Epoch: 10 1600/3904 Training loss: 0.228128
Epoch: 10 2400/3904 Training loss: 0.207616
Epoch: 10 3200/3904 Training loss: 0.390231
Training loss: 0.367861
Test loss: 2.951044; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 11 0/3904 Training loss: 0.297963
Epoch: 11 800/3904 Training loss: 0.254413
Epoch: 11 1600/3904 Training loss: 0.160889
Epoch: 11 2400/3904 Training loss: 0.202513
Epoch: 11 3200/3904 Training loss: 0.399847
Training loss: 0.363759
Test loss: 3.096649; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
starting trial 197
[I 2022-12-05 05:01:59,235] Trial 196 finished with value: 0.836472602739726 and parameters: {'d_model': 64, 'nhead': 8, 'n_encoders': 1, 'learning_rate': 0.00012404819969546302, 'weight_decay': 2.6283685535081735e-06, 'dropout': 0.2179214060402016, 'max_pool_conv': 16, 'kernel_size': 12, 'd_mlp': 16, 'num_conv_layers': 7, 'encoder_dropout': 0.13553292478880075, 'd_feed_forward': 128, 'max_pool_dim': 8, 'n_mlp_layers': 3}. Best is trial 62 with value: 0.860445205479452.
Epoch: 0 0/3904 Training loss: 0.698017
Epoch: 0 800/3904 Training loss: 0.724189
Epoch: 0 1600/3904 Training loss: 0.499179
Epoch: 0 2400/3904 Training loss: 0.819473
Epoch: 0 3200/3904 Training loss: 0.557063
Training loss: 0.662670
Test loss: 0.859164; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 1 0/3904 Training loss: 0.728169
Epoch: 1 800/3904 Training loss: 0.748567
Epoch: 1 1600/3904 Training loss: 0.487496
Epoch: 1 2400/3904 Training loss: 0.823162
Epoch: 1 3200/3904 Training loss: 0.552235
Training loss: 0.658826
Test loss: 0.865359; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 2 0/3904 Training loss: 0.721950
Epoch: 2 800/3904 Training loss: 0.727574
Epoch: 2 1600/3904 Training loss: 0.345758
Epoch: 2 2400/3904 Training loss: 0.971678
Epoch: 2 3200/3904 Training loss: 0.382946
Training loss: 0.594180
Test loss: 1.183449; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 3 0/3904 Training loss: 0.579993
Epoch: 3 800/3904 Training loss: 0.456269
Epoch: 3 1600/3904 Training loss: 0.263205
Epoch: 3 2400/3904 Training loss: 0.491950
Epoch: 3 3200/3904 Training loss: 0.379396
Training loss: 0.502466
Test loss: 1.266774; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 4 0/3904 Training loss: 0.488000
Epoch: 4 800/3904 Training loss: 0.477798
Epoch: 4 1600/3904 Training loss: 0.219677
Epoch: 4 2400/3904 Training loss: 0.397361
Epoch: 4 3200/3904 Training loss: 0.406240
Training loss: 0.456294
Test loss: 1.362656; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 5 0/3904 Training loss: 0.405991
Epoch: 5 800/3904 Training loss: 0.398493
Epoch: 5 1600/3904 Training loss: 0.198594
Epoch: 5 2400/3904 Training loss: 0.354583
Epoch: 5 3200/3904 Training loss: 0.458899
Training loss: 0.425244
Test loss: 1.439042; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 6 0/3904 Training loss: 0.407723
Epoch: 6 800/3904 Training loss: 0.407287
Epoch: 6 1600/3904 Training loss: 0.206786
Epoch: 6 2400/3904 Training loss: 0.284828
Epoch: 6 3200/3904 Training loss: 0.458968
Training loss: 0.403848
Test loss: 1.561743; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 7 0/3904 Training loss: 0.325183
Epoch: 7 800/3904 Training loss: 0.472314
Epoch: 7 1600/3904 Training loss: 0.177037
Epoch: 7 2400/3904 Training loss: 0.243887
Epoch: 7 3200/3904 Training loss: 0.431738
Training loss: 0.398439
Test loss: 1.638929; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 8 0/3904 Training loss: 0.373907
Epoch: 8 800/3904 Training loss: 0.315447
Epoch: 8 1600/3904 Training loss: 0.225509
Epoch: 8 2400/3904 Training loss: 0.296880
Epoch: 8 3200/3904 Training loss: 0.423156
Training loss: 0.387953
Test loss: 1.675362; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 9 0/3904 Training loss: 0.405988
Epoch: 9 800/3904 Training loss: 0.479495
Epoch: 9 1600/3904 Training loss: 0.158655
Epoch: 9 2400/3904 Training loss: 0.260923
Epoch: 9 3200/3904 Training loss: 0.386507
Training loss: 0.391061
Test loss: 2.136859; True positive: 8; True negative: 261, False Positive: 4, False negative: 895, accuracy: 0.2303082191780822, precision: 0.6666666666666666, recall: 0.008859357696566999
Epoch: 10 0/3904 Training loss: 0.394390
Epoch: 10 800/3904 Training loss: 0.294860
Epoch: 10 1600/3904 Training loss: 0.157215
Epoch: 10 2400/3904 Training loss: 0.291012
Epoch: 10 3200/3904 Training loss: 0.288608
Training loss: 0.377394
Test loss: 2.332869; True positive: 3; True negative: 263, False Positive: 2, False negative: 900, accuracy: 0.22773972602739725, precision: 0.6, recall: 0.0033222591362126247
starting trial 198
[I 2022-12-05 05:04:32,012] Trial 197 finished with value: 0.2303082191780822 and parameters: {'d_model': 64, 'nhead': 8, 'n_encoders': 1, 'learning_rate': 7.032147491787826e-05, 'weight_decay': 2.6755831997224865e-06, 'dropout': 0.21612879918409658, 'max_pool_conv': 16, 'kernel_size': 12, 'd_mlp': 16, 'num_conv_layers': 8, 'encoder_dropout': 0.1404504449416108, 'd_feed_forward': 128, 'max_pool_dim': 8, 'n_mlp_layers': 3}. Best is trial 62 with value: 0.860445205479452.
Epoch: 0 0/3904 Training loss: 0.698220
Epoch: 0 800/3904 Training loss: 0.760635
Epoch: 0 1600/3904 Training loss: 0.475119
Epoch: 0 2400/3904 Training loss: 0.821189
Epoch: 0 3200/3904 Training loss: 0.554457
Training loss: 0.662100
Test loss: 0.852277; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 1 0/3904 Training loss: 0.730488
Epoch: 1 800/3904 Training loss: 0.747059
Epoch: 1 1600/3904 Training loss: 0.478138
Epoch: 1 2400/3904 Training loss: 0.810243
Epoch: 1 3200/3904 Training loss: 0.559462
Training loss: 0.660370
Test loss: 0.870125; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 2 0/3904 Training loss: 0.718078
Epoch: 2 800/3904 Training loss: 0.737842
Epoch: 2 1600/3904 Training loss: 0.347577
Epoch: 2 2400/3904 Training loss: 0.780449
Epoch: 2 3200/3904 Training loss: 0.449252
Training loss: 0.625631
Test loss: 1.560775; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 3 0/3904 Training loss: 0.657990
Epoch: 3 800/3904 Training loss: 0.638661
Epoch: 3 1600/3904 Training loss: 0.238829
Epoch: 3 2400/3904 Training loss: 0.708527
Epoch: 3 3200/3904 Training loss: 0.343411
Training loss: 0.551990
Test loss: 2.396916; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 4 0/3904 Training loss: 0.558932
Epoch: 4 800/3904 Training loss: 0.588110
Epoch: 4 1600/3904 Training loss: 0.237206
Epoch: 4 2400/3904 Training loss: 0.648653
Epoch: 4 3200/3904 Training loss: 0.417086
Training loss: 0.493530
Test loss: 2.987057; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 5 0/3904 Training loss: 0.425313
Epoch: 5 800/3904 Training loss: 0.363623
Epoch: 5 1600/3904 Training loss: 0.204225
Epoch: 5 2400/3904 Training loss: 0.453176
Epoch: 5 3200/3904 Training loss: 0.408550
Training loss: 0.432650
Test loss: 2.687434; True positive: 73; True negative: 264, False Positive: 1, False negative: 830, accuracy: 0.288527397260274, precision: 0.9864864864864865, recall: 0.08084163898117387
Epoch: 6 0/3904 Training loss: 0.389869
Epoch: 6 800/3904 Training loss: 0.300358
Epoch: 6 1600/3904 Training loss: 0.179019
Epoch: 6 2400/3904 Training loss: 0.407138
Epoch: 6 3200/3904 Training loss: 0.371180
Training loss: 0.415726
Test loss: 3.487297; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 7 0/3904 Training loss: 0.398816
Epoch: 7 800/3904 Training loss: 0.350433
Epoch: 7 1600/3904 Training loss: 0.169293
Epoch: 7 2400/3904 Training loss: 0.340804
Epoch: 7 3200/3904 Training loss: 0.400279
Training loss: 0.393161
Test loss: 1.368905; True positive: 512; True negative: 217, False Positive: 48, False negative: 391, accuracy: 0.6241438356164384, precision: 0.9142857142857143, recall: 0.5669988925802879
Epoch: 8 0/3904 Training loss: 0.369344
Epoch: 8 800/3904 Training loss: 0.314989
Epoch: 8 1600/3904 Training loss: 0.227423
Epoch: 8 2400/3904 Training loss: 0.344913
Epoch: 8 3200/3904 Training loss: 0.274360
Training loss: 0.388158
Test loss: 0.622711; True positive: 838; True negative: 120, False Positive: 145, False negative: 65, accuracy: 0.8202054794520548, precision: 0.8524923702950152, recall: 0.9280177187153932
Epoch: 9 0/3904 Training loss: 0.388463
Epoch: 9 800/3904 Training loss: 0.327364
Epoch: 9 1600/3904 Training loss: 0.177592
Epoch: 9 2400/3904 Training loss: 0.268177
Epoch: 9 3200/3904 Training loss: 0.366322
Training loss: 0.379541
Test loss: 0.635649; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 10 0/3904 Training loss: 0.396627
Epoch: 10 800/3904 Training loss: 0.306398
Epoch: 10 1600/3904 Training loss: 0.186529
Epoch: 10 2400/3904 Training loss: 0.376597
Epoch: 10 3200/3904 Training loss: 0.357150
Training loss: 0.374326
Test loss: 0.634120; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 11 0/3904 Training loss: 0.333824
Epoch: 11 800/3904 Training loss: 0.217468
Epoch: 11 1600/3904 Training loss: 0.214296
Epoch: 11 2400/3904 Training loss: 0.252094
Epoch: 11 3200/3904 Training loss: 0.371655
Training loss: 0.366637
Test loss: 0.634553; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 12 0/3904 Training loss: 0.323707
Epoch: 12 800/3904 Training loss: 0.200184
Epoch: 12 1600/3904 Training loss: 0.160441
Epoch: 12 2400/3904 Training loss: 0.205491
Epoch: 12 3200/3904 Training loss: 0.396260
Training loss: 0.358812
Test loss: 0.640174; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 13 0/3904 Training loss: 0.314307
Epoch: 13 800/3904 Training loss: 0.246174
Epoch: 13 1600/3904 Training loss: 0.128505
Epoch: 13 2400/3904 Training loss: 0.200654
Epoch: 13 3200/3904 Training loss: 0.322451
Training loss: 0.358156
Test loss: 0.651239; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 14 0/3904 Training loss: 0.322185
Epoch: 14 800/3904 Training loss: 0.200236
Epoch: 14 1600/3904 Training loss: 0.119015
Epoch: 14 2400/3904 Training loss: 0.201002
Epoch: 14 3200/3904 Training loss: 0.326294
Training loss: 0.350245
Test loss: 0.472190; True positive: 894; True negative: 54, False Positive: 211, False negative: 9, accuracy: 0.8116438356164384, precision: 0.8090497737556561, recall: 0.9900332225913622
Epoch: 15 0/3904 Training loss: 0.307352
Epoch: 15 800/3904 Training loss: 0.213854
Epoch: 15 1600/3904 Training loss: 0.153738
Epoch: 15 2400/3904 Training loss: 0.172370
Epoch: 15 3200/3904 Training loss: 0.396716
Training loss: 0.356027
Test loss: 0.635596; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 16 0/3904 Training loss: 0.319582
Epoch: 16 800/3904 Training loss: 0.185955
Epoch: 16 1600/3904 Training loss: 0.128319
Epoch: 16 2400/3904 Training loss: 0.253275
Epoch: 16 3200/3904 Training loss: 0.338332
Training loss: 0.345357
Test loss: 0.638210; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 17 0/3904 Training loss: 0.363238
Epoch: 17 800/3904 Training loss: 0.199309
Epoch: 17 1600/3904 Training loss: 0.150116
Epoch: 17 2400/3904 Training loss: 0.237047
Epoch: 17 3200/3904 Training loss: 0.338419
Training loss: 0.346945
Test loss: 0.643659; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 18 0/3904 Training loss: 0.375006
Epoch: 18 800/3904 Training loss: 0.215037
Epoch: 18 1600/3904 Training loss: 0.218385
Epoch: 18 2400/3904 Training loss: 0.210878
Epoch: 18 3200/3904 Training loss: 0.201017
Training loss: 0.340085
Test loss: 0.646824; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 19 0/3904 Training loss: 0.363140
Epoch: 19 800/3904 Training loss: 0.271948
Epoch: 19 1600/3904 Training loss: 0.110775
Epoch: 19 2400/3904 Training loss: 0.181053
Epoch: 19 3200/3904 Training loss: 0.339593
Training loss: 0.338975
Test loss: 0.646015; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 20 0/3904 Training loss: 0.344860
Epoch: 20 800/3904 Training loss: 0.235565
Epoch: 20 1600/3904 Training loss: 0.131218
Epoch: 20 2400/3904 Training loss: 0.181004
Epoch: 20 3200/3904 Training loss: 0.163962
Training loss: 0.330533
Test loss: 0.652265; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 21 0/3904 Training loss: 0.278862
Epoch: 21 800/3904 Training loss: 0.165870
Epoch: 21 1600/3904 Training loss: 0.124043
Epoch: 21 2400/3904 Training loss: 0.285698
Epoch: 21 3200/3904 Training loss: 0.208793
Training loss: 0.331781
Test loss: 0.653711; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 22 0/3904 Training loss: 0.352374
Epoch: 22 800/3904 Training loss: 0.204354
Epoch: 22 1600/3904 Training loss: 0.141654
Epoch: 22 2400/3904 Training loss: 0.179869
Epoch: 22 3200/3904 Training loss: 0.265312
Training loss: 0.327898
Test loss: 0.661129; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 23 0/3904 Training loss: 0.358901
Epoch: 23 800/3904 Training loss: 0.260720
Epoch: 23 1600/3904 Training loss: 0.166005
Epoch: 23 2400/3904 Training loss: 0.265537
Epoch: 23 3200/3904 Training loss: 0.188958
Training loss: 0.321968
Test loss: 0.534633; True positive: 903; True negative: 0, False Positive: 265, False negative: 0, accuracy: 0.7731164383561644, precision: 0.7731164383561644, recall: 1.0
Epoch: 24 0/3904 Training loss: 0.322227
Epoch: 24 800/3904 Training loss: 0.251649
Epoch: 24 1600/3904 Training loss: 0.154031
Epoch: 24 2400/3904 Training loss: 0.206378
Epoch: 24 3200/3904 Training loss: 0.196127
Training loss: 0.321738
Test loss: 0.545649; True positive: 903; True negative: 0, False Positive: 265, False negative: 0, accuracy: 0.7731164383561644, precision: 0.7731164383561644, recall: 1.0
starting trial 199
[I 2022-12-05 05:09:44,858] Trial 198 finished with value: 0.8202054794520548 and parameters: {'d_model': 64, 'nhead': 8, 'n_encoders': 1, 'learning_rate': 5.83017117672953e-05, 'weight_decay': 2.8262878023578866e-06, 'dropout': 0.22765495242599101, 'max_pool_conv': 16, 'kernel_size': 11, 'd_mlp': 16, 'num_conv_layers': 8, 'encoder_dropout': 0.1344168039831952, 'd_feed_forward': 128, 'max_pool_dim': 8, 'n_mlp_layers': 3}. Best is trial 62 with value: 0.860445205479452.
Epoch: 0 0/3904 Training loss: 0.700170
Epoch: 0 800/3904 Training loss: 0.700393
Epoch: 0 1600/3904 Training loss: 0.555260
Epoch: 0 2400/3904 Training loss: 0.782119
Epoch: 0 3200/3904 Training loss: 0.574157
Training loss: 0.672743
Test loss: 0.766397; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 1 0/3904 Training loss: 0.696286
Epoch: 1 800/3904 Training loss: 0.741392
Epoch: 1 1600/3904 Training loss: 0.460215
Epoch: 1 2400/3904 Training loss: 0.766493
Epoch: 1 3200/3904 Training loss: 0.520611
Training loss: 0.647585
Test loss: 0.660198; True positive: 903; True negative: 0, False Positive: 265, False negative: 0, accuracy: 0.7731164383561644, precision: 0.7731164383561644, recall: 1.0
Epoch: 2 0/3904 Training loss: 0.649461
Epoch: 2 800/3904 Training loss: 0.614536
Epoch: 2 1600/3904 Training loss: 0.319752
Epoch: 2 2400/3904 Training loss: 0.556032
Epoch: 2 3200/3904 Training loss: 0.383102
Training loss: 0.546573
Test loss: 0.568338; True positive: 903; True negative: 0, False Positive: 265, False negative: 0, accuracy: 0.7731164383561644, precision: 0.7731164383561644, recall: 1.0
Epoch: 3 0/3904 Training loss: 0.505550
Epoch: 3 800/3904 Training loss: 0.452678
Epoch: 3 1600/3904 Training loss: 0.252033
Epoch: 3 2400/3904 Training loss: 0.381789
Epoch: 3 3200/3904 Training loss: 0.367395
Training loss: 0.467277
Test loss: 0.541762; True positive: 903; True negative: 0, False Positive: 265, False negative: 0, accuracy: 0.7731164383561644, precision: 0.7731164383561644, recall: 1.0
Epoch: 4 0/3904 Training loss: 0.409350
Epoch: 4 800/3904 Training loss: 0.415917
Epoch: 4 1600/3904 Training loss: 0.228952
Epoch: 4 2400/3904 Training loss: 0.367672
Epoch: 4 3200/3904 Training loss: 0.344220
Training loss: 0.433765
Test loss: 0.532155; True positive: 903; True negative: 0, False Positive: 265, False negative: 0, accuracy: 0.7731164383561644, precision: 0.7731164383561644, recall: 1.0
Epoch: 5 0/3904 Training loss: 0.397124
Epoch: 5 800/3904 Training loss: 0.389757
Epoch: 5 1600/3904 Training loss: 0.242262
Epoch: 5 2400/3904 Training loss: 0.474628
Epoch: 5 3200/3904 Training loss: 0.395686
Training loss: 0.409366
Test loss: 0.533552; True positive: 903; True negative: 0, False Positive: 265, False negative: 0, accuracy: 0.7731164383561644, precision: 0.7731164383561644, recall: 1.0
Epoch: 6 0/3904 Training loss: 0.334964
Epoch: 6 800/3904 Training loss: 0.405884
Epoch: 6 1600/3904 Training loss: 0.190703
Epoch: 6 2400/3904 Training loss: 0.269873
Epoch: 6 3200/3904 Training loss: 0.406065
Training loss: 0.399943
Test loss: 0.537024; True positive: 903; True negative: 0, False Positive: 265, False negative: 0, accuracy: 0.7731164383561644, precision: 0.7731164383561644, recall: 1.0
Epoch: 7 0/3904 Training loss: 0.338719
Epoch: 7 800/3904 Training loss: 0.438499
Epoch: 7 1600/3904 Training loss: 0.161532
Epoch: 7 2400/3904 Training loss: 0.253017
Epoch: 7 3200/3904 Training loss: 0.340967
Training loss: 0.397530
Test loss: 0.548781; True positive: 903; True negative: 0, False Positive: 265, False negative: 0, accuracy: 0.7731164383561644, precision: 0.7731164383561644, recall: 1.0
Epoch: 8 0/3904 Training loss: 0.387078
Epoch: 8 800/3904 Training loss: 0.361358
Epoch: 8 1600/3904 Training loss: 0.169484
Epoch: 8 2400/3904 Training loss: 0.262339
Epoch: 8 3200/3904 Training loss: 0.363212
Training loss: 0.390271
Test loss: 0.543841; True positive: 903; True negative: 0, False Positive: 265, False negative: 0, accuracy: 0.7731164383561644, precision: 0.7731164383561644, recall: 1.0
Epoch: 9 0/3904 Training loss: 0.392608
Epoch: 9 800/3904 Training loss: 0.517075
Epoch: 9 1600/3904 Training loss: 0.169271
Epoch: 9 2400/3904 Training loss: 0.221006
Epoch: 9 3200/3904 Training loss: 0.385151
Training loss: 0.386760
Test loss: 0.573157; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 10 0/3904 Training loss: 0.366964
Epoch: 10 800/3904 Training loss: 0.316930
Epoch: 10 1600/3904 Training loss: 0.150241
Epoch: 10 2400/3904 Training loss: 0.197055
Epoch: 10 3200/3904 Training loss: 0.347301
Training loss: 0.379993
Test loss: 0.569759; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 11 0/3904 Training loss: 0.281870
Epoch: 11 800/3904 Training loss: 0.402587
Epoch: 11 1600/3904 Training loss: 0.176627
Epoch: 11 2400/3904 Training loss: 0.202848
Epoch: 11 3200/3904 Training loss: 0.350299
Training loss: 0.376188
Test loss: 0.569796; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 12 0/3904 Training loss: 0.449746
Epoch: 12 800/3904 Training loss: 0.302680
Epoch: 12 1600/3904 Training loss: 0.176674
Epoch: 12 2400/3904 Training loss: 0.205987
Epoch: 12 3200/3904 Training loss: 0.337473
Training loss: 0.375569
Test loss: 0.560777; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 13 0/3904 Training loss: 0.368990
Epoch: 13 800/3904 Training loss: 0.391094
Epoch: 13 1600/3904 Training loss: 0.189341
Epoch: 13 2400/3904 Training loss: 0.198016
Epoch: 13 3200/3904 Training loss: 0.415974
Training loss: 0.360775
Test loss: 0.575708; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 14 0/3904 Training loss: 0.539900
Epoch: 14 800/3904 Training loss: 0.256083
Epoch: 14 1600/3904 Training loss: 0.167915
Epoch: 14 2400/3904 Training loss: 0.191416
Epoch: 14 3200/3904 Training loss: 0.317068
Training loss: 0.353980
Test loss: 0.564519; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
starting trial 200
[I 2022-12-05 05:12:42,918] Trial 199 finished with value: 0.8176369863013698 and parameters: {'d_model': 64, 'nhead': 8, 'n_encoders': 1, 'learning_rate': 0.00013946849103337448, 'weight_decay': 1.9989428172405843e-06, 'dropout': 0.20168138567417462, 'max_pool_conv': 32, 'kernel_size': 12, 'd_mlp': 16, 'num_conv_layers': 7, 'encoder_dropout': 0.15489651539894306, 'd_feed_forward': 128, 'max_pool_dim': 8, 'n_mlp_layers': 3}. Best is trial 62 with value: 0.860445205479452.
Epoch: 0 0/3904 Training loss: 0.704302
Epoch: 0 800/3904 Training loss: 0.723507
Epoch: 0 1600/3904 Training loss: 0.437753
Epoch: 0 2400/3904 Training loss: 0.747758
Epoch: 0 3200/3904 Training loss: 0.557646
Training loss: 0.668131
Test loss: 0.735917; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 1 0/3904 Training loss: 0.706026
Epoch: 1 800/3904 Training loss: 0.722504
Epoch: 1 1600/3904 Training loss: 0.411592
Epoch: 1 2400/3904 Training loss: 0.709600
Epoch: 1 3200/3904 Training loss: 0.536367
Training loss: 0.655318
Test loss: 0.731440; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 2 0/3904 Training loss: 0.698901
Epoch: 2 800/3904 Training loss: 0.742706
Epoch: 2 1600/3904 Training loss: 0.297409
Epoch: 2 2400/3904 Training loss: 0.698040
Epoch: 2 3200/3904 Training loss: 0.439567
Training loss: 0.593344
Test loss: 0.627799; True positive: 903; True negative: 0, False Positive: 265, False negative: 0, accuracy: 0.7731164383561644, precision: 0.7731164383561644, recall: 1.0
Epoch: 3 0/3904 Training loss: 0.649514
Epoch: 3 800/3904 Training loss: 0.513545
Epoch: 3 1600/3904 Training loss: 0.235594
Epoch: 3 2400/3904 Training loss: 0.596244
Epoch: 3 3200/3904 Training loss: 0.414014
Training loss: 0.505238
Test loss: 0.619448; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 4 0/3904 Training loss: 0.575939
Epoch: 4 800/3904 Training loss: 0.525307
Epoch: 4 1600/3904 Training loss: 0.213668
Epoch: 4 2400/3904 Training loss: 0.659591
Epoch: 4 3200/3904 Training loss: 0.501411
Training loss: 0.465126
Test loss: 0.596275; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 5 0/3904 Training loss: 0.482821
Epoch: 5 800/3904 Training loss: 0.512333
Epoch: 5 1600/3904 Training loss: 0.197023
Epoch: 5 2400/3904 Training loss: 0.497443
Epoch: 5 3200/3904 Training loss: 0.510882
Training loss: 0.430492
Test loss: 0.543306; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 6 0/3904 Training loss: 0.433756
Epoch: 6 800/3904 Training loss: 0.381863
Epoch: 6 1600/3904 Training loss: 0.232579
Epoch: 6 2400/3904 Training loss: 0.396831
Epoch: 6 3200/3904 Training loss: 0.427066
Training loss: 0.414216
Test loss: 0.527114; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 7 0/3904 Training loss: 0.441820
Epoch: 7 800/3904 Training loss: 0.351028
Epoch: 7 1600/3904 Training loss: 0.173489
Epoch: 7 2400/3904 Training loss: 0.413489
Epoch: 7 3200/3904 Training loss: 0.470971
Training loss: 0.400786
Test loss: 0.518456; True positive: 837; True negative: 117, False Positive: 148, False negative: 66, accuracy: 0.8167808219178082, precision: 0.849746192893401, recall: 0.9269102990033222
Epoch: 8 0/3904 Training loss: 0.377235
Epoch: 8 800/3904 Training loss: 0.361935
Epoch: 8 1600/3904 Training loss: 0.159792
Epoch: 8 2400/3904 Training loss: 0.337134
Epoch: 8 3200/3904 Training loss: 0.385578
Training loss: 0.396532
Test loss: 0.521308; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 9 0/3904 Training loss: 0.436550
Epoch: 9 800/3904 Training loss: 0.303956
Epoch: 9 1600/3904 Training loss: 0.145172
Epoch: 9 2400/3904 Training loss: 0.292941
Epoch: 9 3200/3904 Training loss: 0.380900
Training loss: 0.389528
Test loss: 0.518638; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 10 0/3904 Training loss: 0.471830
Epoch: 10 800/3904 Training loss: 0.350856
Epoch: 10 1600/3904 Training loss: 0.144881
Epoch: 10 2400/3904 Training loss: 0.320228
Epoch: 10 3200/3904 Training loss: 0.481565
Training loss: 0.382410
Test loss: 0.517195; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 11 0/3904 Training loss: 0.304952
Epoch: 11 800/3904 Training loss: 0.303465
Epoch: 11 1600/3904 Training loss: 0.121637
Epoch: 11 2400/3904 Training loss: 0.310180
Epoch: 11 3200/3904 Training loss: 0.384540
Training loss: 0.372139
Test loss: 0.521799; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 12 0/3904 Training loss: 0.344425
Epoch: 12 800/3904 Training loss: 0.233460
Epoch: 12 1600/3904 Training loss: 0.154201
Epoch: 12 2400/3904 Training loss: 0.340579
Epoch: 12 3200/3904 Training loss: 0.429143
Training loss: 0.367864
Test loss: 0.522012; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 13 0/3904 Training loss: 0.315117
Epoch: 13 800/3904 Training loss: 0.210109
Epoch: 13 1600/3904 Training loss: 0.092684
Epoch: 13 2400/3904 Training loss: 0.323515
Epoch: 13 3200/3904 Training loss: 0.423575
Training loss: 0.365556
Test loss: 0.520934; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 14 0/3904 Training loss: 0.282771
Epoch: 14 800/3904 Training loss: 0.370343
Epoch: 14 1600/3904 Training loss: 0.115270
Epoch: 14 2400/3904 Training loss: 0.256309
Epoch: 14 3200/3904 Training loss: 0.453329
Training loss: 0.362268
Test loss: 0.524734; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 15 0/3904 Training loss: 0.302551
Epoch: 15 800/3904 Training loss: 0.262566
Epoch: 15 1600/3904 Training loss: 0.122507
Epoch: 15 2400/3904 Training loss: 0.394588
Epoch: 15 3200/3904 Training loss: 0.449563
Training loss: 0.357482
Test loss: 0.610815; True positive: 772; True negative: 137, False Positive: 128, False negative: 131, accuracy: 0.7782534246575342, precision: 0.8577777777777778, recall: 0.8549280177187154
Epoch: 16 0/3904 Training loss: 0.302782
Epoch: 16 800/3904 Training loss: 0.218361
Epoch: 16 1600/3904 Training loss: 0.103421
Epoch: 16 2400/3904 Training loss: 0.355186
Epoch: 16 3200/3904 Training loss: 0.384002
Training loss: 0.358828
Test loss: 0.693754; True positive: 746; True negative: 135, False Positive: 130, False negative: 157, accuracy: 0.7542808219178082, precision: 0.8515981735159818, recall: 0.8261351052048727
Epoch: 17 0/3904 Training loss: 0.279292
Epoch: 17 800/3904 Training loss: 0.179527
Epoch: 17 1600/3904 Training loss: 0.090924
Epoch: 17 2400/3904 Training loss: 0.260796
Epoch: 17 3200/3904 Training loss: 0.550612
Training loss: 0.344272
Test loss: 0.526913; True positive: 837; True negative: 117, False Positive: 148, False negative: 66, accuracy: 0.8167808219178082, precision: 0.849746192893401, recall: 0.9269102990033222
Epoch: 18 0/3904 Training loss: 0.290527
Epoch: 18 800/3904 Training loss: 0.293746
Epoch: 18 1600/3904 Training loss: 0.076550
Epoch: 18 2400/3904 Training loss: 0.229783
Epoch: 18 3200/3904 Training loss: 0.326313
Training loss: 0.340691
Test loss: 0.531905; True positive: 832; True negative: 118, False Positive: 147, False negative: 71, accuracy: 0.8133561643835616, precision: 0.849846782431052, recall: 0.9213732004429679
Epoch: 19 0/3904 Training loss: 0.245058
Epoch: 19 800/3904 Training loss: 0.242166
Epoch: 19 1600/3904 Training loss: 0.080379
Epoch: 19 2400/3904 Training loss: 0.318885
Epoch: 19 3200/3904 Training loss: 0.425881
Training loss: 0.340518
Test loss: 0.536731; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 20 0/3904 Training loss: 0.372320
Epoch: 20 800/3904 Training loss: 0.244726
Epoch: 20 1600/3904 Training loss: 0.139825
Epoch: 20 2400/3904 Training loss: 0.207183
Epoch: 20 3200/3904 Training loss: 0.485975
Training loss: 0.331070
Test loss: 0.529758; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
starting trial 201
[I 2022-12-05 05:16:35,438] Trial 200 finished with value: 0.8176369863013698 and parameters: {'d_model': 64, 'nhead': 8, 'n_encoders': 1, 'learning_rate': 0.00010494145728945551, 'weight_decay': 2.240540988591612e-06, 'dropout': 0.19125875071407356, 'max_pool_conv': 16, 'kernel_size': 11, 'd_mlp': 16, 'num_conv_layers': 7, 'encoder_dropout': 0.12611988100656635, 'd_feed_forward': 128, 'max_pool_dim': 8, 'n_mlp_layers': 3}. Best is trial 62 with value: 0.860445205479452.
Epoch: 0 0/3904 Training loss: 0.696562
Epoch: 0 800/3904 Training loss: 0.715108
Epoch: 0 1600/3904 Training loss: 0.425871
Epoch: 0 2400/3904 Training loss: 0.783826
Epoch: 0 3200/3904 Training loss: 0.548893
Training loss: 0.665812
Test loss: 0.798048; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 1 0/3904 Training loss: 0.707862
Epoch: 1 800/3904 Training loss: 0.728839
Epoch: 1 1600/3904 Training loss: 0.427153
Epoch: 1 2400/3904 Training loss: 0.822611
Epoch: 1 3200/3904 Training loss: 0.500607
Training loss: 0.644148
Test loss: 0.855227; True positive: 407; True negative: 132, False Positive: 133, False negative: 496, accuracy: 0.461472602739726, precision: 0.7537037037037037, recall: 0.45071982281284606
Epoch: 2 0/3904 Training loss: 0.605573
Epoch: 2 800/3904 Training loss: 0.550287
Epoch: 2 1600/3904 Training loss: 0.225156
Epoch: 2 2400/3904 Training loss: 0.894742
Epoch: 2 3200/3904 Training loss: 0.327176
Training loss: 0.535318
Test loss: 2.138829; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 3 0/3904 Training loss: 0.511794
Epoch: 3 800/3904 Training loss: 0.484239
Epoch: 3 1600/3904 Training loss: 0.186373
Epoch: 3 2400/3904 Training loss: 0.643619
Epoch: 3 3200/3904 Training loss: 0.326677
Training loss: 0.457973
Test loss: 2.690722; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 4 0/3904 Training loss: 0.405528
Epoch: 4 800/3904 Training loss: 0.337030
Epoch: 4 1600/3904 Training loss: 0.164260
Epoch: 4 2400/3904 Training loss: 0.566515
Epoch: 4 3200/3904 Training loss: 0.350328
Training loss: 0.421354
Test loss: 2.846074; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 5 0/3904 Training loss: 0.379468
Epoch: 5 800/3904 Training loss: 0.469829
Epoch: 5 1600/3904 Training loss: 0.179316
Epoch: 5 2400/3904 Training loss: 0.444341
Epoch: 5 3200/3904 Training loss: 0.339636
Training loss: 0.410715
Test loss: 2.990916; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 6 0/3904 Training loss: 0.358262
Epoch: 6 800/3904 Training loss: 0.319786
Epoch: 6 1600/3904 Training loss: 0.190461
Epoch: 6 2400/3904 Training loss: 0.385692
Epoch: 6 3200/3904 Training loss: 0.334067
Training loss: 0.404024
Test loss: 3.087407; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 7 0/3904 Training loss: 0.333067
Epoch: 7 800/3904 Training loss: 0.287249
Epoch: 7 1600/3904 Training loss: 0.175683
Epoch: 7 2400/3904 Training loss: 0.484561
Epoch: 7 3200/3904 Training loss: 0.317309
Training loss: 0.390859
Test loss: 3.280767; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 8 0/3904 Training loss: 0.314438
Epoch: 8 800/3904 Training loss: 0.220544
Epoch: 8 1600/3904 Training loss: 0.166526
Epoch: 8 2400/3904 Training loss: 0.435398
Epoch: 8 3200/3904 Training loss: 0.361317
Training loss: 0.388389
Test loss: 3.566296; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 9 0/3904 Training loss: 0.302590
Epoch: 9 800/3904 Training loss: 0.235274
Epoch: 9 1600/3904 Training loss: 0.165144
Epoch: 9 2400/3904 Training loss: 0.356423
Epoch: 9 3200/3904 Training loss: 0.367399
Training loss: 0.376082
Test loss: 3.310322; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 10 0/3904 Training loss: 0.286065
Epoch: 10 800/3904 Training loss: 0.303935
Epoch: 10 1600/3904 Training loss: 0.152640
Epoch: 10 2400/3904 Training loss: 0.381289
Epoch: 10 3200/3904 Training loss: 0.358807
Training loss: 0.371536
Test loss: 3.307006; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
starting trial 202
[I 2022-12-05 05:18:50,167] Trial 201 finished with value: 0.461472602739726 and parameters: {'d_model': 64, 'nhead': 8, 'n_encoders': 1, 'learning_rate': 0.00012339750015813477, 'weight_decay': 2.5097264236704377e-06, 'dropout': 0.2150619406509822, 'max_pool_conv': 16, 'kernel_size': 12, 'd_mlp': 16, 'num_conv_layers': 7, 'encoder_dropout': 0.1651491919740622, 'd_feed_forward': 128, 'max_pool_dim': 8, 'n_mlp_layers': 3}. Best is trial 62 with value: 0.860445205479452.
Epoch: 0 0/3904 Training loss: 0.706403
Epoch: 0 800/3904 Training loss: 0.732600
Epoch: 0 1600/3904 Training loss: 0.439147
Epoch: 0 2400/3904 Training loss: 0.805430
Epoch: 0 3200/3904 Training loss: 0.552348
Training loss: 0.664149
Test loss: 0.839500; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 1 0/3904 Training loss: 0.716025
Epoch: 1 800/3904 Training loss: 0.748911
Epoch: 1 1600/3904 Training loss: 0.297601
Epoch: 1 2400/3904 Training loss: 0.753658
Epoch: 1 3200/3904 Training loss: 0.369735
Training loss: 0.600999
Test loss: 0.705886; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 2 0/3904 Training loss: 0.566258
Epoch: 2 800/3904 Training loss: 0.556015
Epoch: 2 1600/3904 Training loss: 0.208824
Epoch: 2 2400/3904 Training loss: 0.474155
Epoch: 2 3200/3904 Training loss: 0.390919
Training loss: 0.493634
Test loss: 0.537940; True positive: 903; True negative: 0, False Positive: 265, False negative: 0, accuracy: 0.7731164383561644, precision: 0.7731164383561644, recall: 1.0
Epoch: 3 0/3904 Training loss: 0.387192
Epoch: 3 800/3904 Training loss: 0.330711
Epoch: 3 1600/3904 Training loss: 0.182583
Epoch: 3 2400/3904 Training loss: 0.280101
Epoch: 3 3200/3904 Training loss: 0.391220
Training loss: 0.430030
Test loss: 0.542229; True positive: 903; True negative: 0, False Positive: 265, False negative: 0, accuracy: 0.7731164383561644, precision: 0.7731164383561644, recall: 1.0
Epoch: 4 0/3904 Training loss: 0.369578
Epoch: 4 800/3904 Training loss: 0.301621
Epoch: 4 1600/3904 Training loss: 0.173285
Epoch: 4 2400/3904 Training loss: 0.507385
Epoch: 4 3200/3904 Training loss: 0.474741
Training loss: 0.405338
Test loss: 0.533876; True positive: 903; True negative: 0, False Positive: 265, False negative: 0, accuracy: 0.7731164383561644, precision: 0.7731164383561644, recall: 1.0
Epoch: 5 0/3904 Training loss: 0.372505
Epoch: 5 800/3904 Training loss: 0.344205
Epoch: 5 1600/3904 Training loss: 0.211671
Epoch: 5 2400/3904 Training loss: 0.327413
Epoch: 5 3200/3904 Training loss: 0.340023
Training loss: 0.396993
Test loss: 0.544530; True positive: 902; True negative: 0, False Positive: 265, False negative: 1, accuracy: 0.7722602739726028, precision: 0.7729220222793488, recall: 0.9988925802879292
Epoch: 6 0/3904 Training loss: 0.312817
Epoch: 6 800/3904 Training loss: 0.223000
Epoch: 6 1600/3904 Training loss: 0.181734
Epoch: 6 2400/3904 Training loss: 0.297018
Epoch: 6 3200/3904 Training loss: 0.368792
Training loss: 0.384575
Test loss: 0.620538; True positive: 835; True negative: 118, False Positive: 147, False negative: 68, accuracy: 0.8159246575342466, precision: 0.8503054989816701, recall: 0.9246954595791805
Epoch: 7 0/3904 Training loss: 0.356172
Epoch: 7 800/3904 Training loss: 0.234178
Epoch: 7 1600/3904 Training loss: 0.214029
Epoch: 7 2400/3904 Training loss: 0.373306
Epoch: 7 3200/3904 Training loss: 0.322974
Training loss: 0.381936
Test loss: 0.628000; True positive: 836; True negative: 117, False Positive: 148, False negative: 67, accuracy: 0.8159246575342466, precision: 0.8495934959349594, recall: 0.9258028792912514
Epoch: 8 0/3904 Training loss: 0.344388
Epoch: 8 800/3904 Training loss: 0.283317
Epoch: 8 1600/3904 Training loss: 0.200520
Epoch: 8 2400/3904 Training loss: 0.333935
Epoch: 8 3200/3904 Training loss: 0.305387
Training loss: 0.374011
Test loss: 0.615478; True positive: 837; True negative: 118, False Positive: 147, False negative: 66, accuracy: 0.8176369863013698, precision: 0.850609756097561, recall: 0.9269102990033222
Epoch: 9 0/3904 Training loss: 0.413350
Epoch: 9 800/3904 Training loss: 0.306043
Epoch: 9 1600/3904 Training loss: 0.161115
Epoch: 9 2400/3904 Training loss: 0.209877
Epoch: 9 3200/3904 Training loss: 0.316785
Training loss: 0.371172
Test loss: 0.613542; True positive: 837; True negative: 122, False Positive: 143, False negative: 66, accuracy: 0.8210616438356164, precision: 0.8540816326530613, recall: 0.9269102990033222
Epoch: 10 0/3904 Training loss: 0.353134
Epoch: 10 800/3904 Training loss: 0.171728
Epoch: 10 1600/3904 Training loss: 0.172335
Epoch: 10 2400/3904 Training loss: 0.240859
Epoch: 10 3200/3904 Training loss: 0.396980
Training loss: 0.362878
Test loss: 0.610467; True positive: 832; True negative: 129, False Positive: 136, False negative: 71, accuracy: 0.8227739726027398, precision: 0.859504132231405, recall: 0.9213732004429679
Epoch: 11 0/3904 Training loss: 0.292183
Epoch: 11 800/3904 Training loss: 0.197573
Epoch: 11 1600/3904 Training loss: 0.184623
Epoch: 11 2400/3904 Training loss: 0.208114
Epoch: 11 3200/3904 Training loss: 0.289131
Training loss: 0.353404
Test loss: 0.998463; True positive: 495; True negative: 248, False Positive: 17, False negative: 408, accuracy: 0.6361301369863014, precision: 0.966796875, recall: 0.5481727574750831
Epoch: 12 0/3904 Training loss: 0.281334
Epoch: 12 800/3904 Training loss: 0.170774
Epoch: 12 1600/3904 Training loss: 0.185908
Epoch: 12 2400/3904 Training loss: 0.199727
Epoch: 12 3200/3904 Training loss: 0.366749
Training loss: 0.354777
Test loss: 0.577143; True positive: 816; True negative: 170, False Positive: 95, False negative: 87, accuracy: 0.8441780821917808, precision: 0.8957189901207464, recall: 0.9036544850498339
Epoch: 13 0/3904 Training loss: 0.454396
Epoch: 13 800/3904 Training loss: 0.208850
Epoch: 13 1600/3904 Training loss: 0.214183
Epoch: 13 2400/3904 Training loss: 0.244138
Epoch: 13 3200/3904 Training loss: 0.342972
Training loss: 0.357402
Test loss: 1.687009; True positive: 265; True negative: 255, False Positive: 10, False negative: 638, accuracy: 0.4452054794520548, precision: 0.9636363636363636, recall: 0.29346622369878184
Epoch: 14 0/3904 Training loss: 0.320745
Epoch: 14 800/3904 Training loss: 0.184541
Epoch: 14 1600/3904 Training loss: 0.166882
Epoch: 14 2400/3904 Training loss: 0.151428
Epoch: 14 3200/3904 Training loss: 0.429135
Training loss: 0.341077
Test loss: 0.616002; True positive: 832; True negative: 127, False Positive: 138, False negative: 71, accuracy: 0.8210616438356164, precision: 0.8577319587628865, recall: 0.9213732004429679
starting trial 203
[I 2022-12-05 05:21:57,647] Trial 202 finished with value: 0.8441780821917808 and parameters: {'d_model': 64, 'nhead': 8, 'n_encoders': 1, 'learning_rate': 0.00011433384415835225, 'weight_decay': 3.102005085720589e-06, 'dropout': 0.23409704030695813, 'max_pool_conv': 16, 'kernel_size': 13, 'd_mlp': 16, 'num_conv_layers': 7, 'encoder_dropout': 0.10820608138033808, 'd_feed_forward': 128, 'max_pool_dim': 8, 'n_mlp_layers': 3}. Best is trial 62 with value: 0.860445205479452.
Epoch: 0 0/3904 Training loss: 0.700466
Epoch: 0 800/3904 Training loss: 0.740985
Epoch: 0 1600/3904 Training loss: 0.483737
Epoch: 0 2400/3904 Training loss: 0.789267
Epoch: 0 3200/3904 Training loss: 0.561993
Training loss: 0.662546
Test loss: 0.852818; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 1 0/3904 Training loss: 0.729505
Epoch: 1 800/3904 Training loss: 0.738891
Epoch: 1 1600/3904 Training loss: 0.470441
Epoch: 1 2400/3904 Training loss: 0.830399
Epoch: 1 3200/3904 Training loss: 0.551424
Training loss: 0.660928
Test loss: 0.858542; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 2 0/3904 Training loss: 0.717970
Epoch: 2 800/3904 Training loss: 0.735620
Epoch: 2 1600/3904 Training loss: 0.409406
Epoch: 2 2400/3904 Training loss: 0.760304
Epoch: 2 3200/3904 Training loss: 0.461552
Training loss: 0.634977
Test loss: 0.719735; True positive: 521; True negative: 159, False Positive: 106, False negative: 382, accuracy: 0.5821917808219178, precision: 0.8309409888357256, recall: 0.5769656699889258
Epoch: 3 0/3904 Training loss: 0.692374
Epoch: 3 800/3904 Training loss: 0.603449
Epoch: 3 1600/3904 Training loss: 0.291167
Epoch: 3 2400/3904 Training loss: 0.540211
Epoch: 3 3200/3904 Training loss: 0.428626
Training loss: 0.559079
Test loss: 1.272982; True positive: 242; True negative: 196, False Positive: 69, False negative: 661, accuracy: 0.375, precision: 0.7781350482315113, recall: 0.26799557032115173
Epoch: 4 0/3904 Training loss: 0.657991
Epoch: 4 800/3904 Training loss: 0.382903
Epoch: 4 1600/3904 Training loss: 0.296076
Epoch: 4 2400/3904 Training loss: 0.506568
Epoch: 4 3200/3904 Training loss: 0.374976
Training loss: 0.516324
Test loss: 1.916652; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 5 0/3904 Training loss: 0.547592
Epoch: 5 800/3904 Training loss: 0.414719
Epoch: 5 1600/3904 Training loss: 0.260141
Epoch: 5 2400/3904 Training loss: 0.472716
Epoch: 5 3200/3904 Training loss: 0.404203
Training loss: 0.478048
Test loss: 2.166569; True positive: 1; True negative: 265, False Positive: 0, False negative: 902, accuracy: 0.22773972602739725, precision: 1.0, recall: 0.0011074197120708748
Epoch: 6 0/3904 Training loss: 0.568442
Epoch: 6 800/3904 Training loss: 0.377966
Epoch: 6 1600/3904 Training loss: 0.224895
Epoch: 6 2400/3904 Training loss: 0.516582
Epoch: 6 3200/3904 Training loss: 0.311580
Training loss: 0.452606
Test loss: 2.142089; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 7 0/3904 Training loss: 0.458474
Epoch: 7 800/3904 Training loss: 0.374420
Epoch: 7 1600/3904 Training loss: 0.189872
Epoch: 7 2400/3904 Training loss: 0.380500
Epoch: 7 3200/3904 Training loss: 0.300516
Training loss: 0.427418
Test loss: 2.405847; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 8 0/3904 Training loss: 0.416602
Epoch: 8 800/3904 Training loss: 0.412693
Epoch: 8 1600/3904 Training loss: 0.172608
Epoch: 8 2400/3904 Training loss: 0.355151
Epoch: 8 3200/3904 Training loss: 0.390155
Training loss: 0.410277
Test loss: 2.499053; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 9 0/3904 Training loss: 0.426375
Epoch: 9 800/3904 Training loss: 0.287217
Epoch: 9 1600/3904 Training loss: 0.154034
Epoch: 9 2400/3904 Training loss: 0.329098
Epoch: 9 3200/3904 Training loss: 0.403518
Training loss: 0.397564
Test loss: 2.570016; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 10 0/3904 Training loss: 0.405840
Epoch: 10 800/3904 Training loss: 0.271840
Epoch: 10 1600/3904 Training loss: 0.226310
Epoch: 10 2400/3904 Training loss: 0.296389
Epoch: 10 3200/3904 Training loss: 0.348271
Training loss: 0.393969
Test loss: 2.341840; True positive: 111; True negative: 239, False Positive: 26, False negative: 792, accuracy: 0.2996575342465753, precision: 0.8102189781021898, recall: 0.12292358803986711
Epoch: 11 0/3904 Training loss: 0.385095
Epoch: 11 800/3904 Training loss: 0.331373
Epoch: 11 1600/3904 Training loss: 0.156170
Epoch: 11 2400/3904 Training loss: 0.283246
Epoch: 11 3200/3904 Training loss: 0.355636
Training loss: 0.393825
Test loss: 0.569281; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 12 0/3904 Training loss: 0.381229
Epoch: 12 800/3904 Training loss: 0.421202
Epoch: 12 1600/3904 Training loss: 0.156713
Epoch: 12 2400/3904 Training loss: 0.239839
Epoch: 12 3200/3904 Training loss: 0.356979
Training loss: 0.388435
Test loss: 3.791839; True positive: 0; True negative: 264, False Positive: 1, False negative: 903, accuracy: 0.22602739726027396, precision: 0.0, recall: 0.0
Epoch: 13 0/3904 Training loss: 0.355930
Epoch: 13 800/3904 Training loss: 0.366408
Epoch: 13 1600/3904 Training loss: 0.123606
Epoch: 13 2400/3904 Training loss: 0.302892
Epoch: 13 3200/3904 Training loss: 0.512230
Training loss: 0.373913
Test loss: 2.839218; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 14 0/3904 Training loss: 0.422118
Epoch: 14 800/3904 Training loss: 0.312010
Epoch: 14 1600/3904 Training loss: 0.148658
Epoch: 14 2400/3904 Training loss: 0.233979
Epoch: 14 3200/3904 Training loss: 0.391611
Training loss: 0.383495
Test loss: 3.940991; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 15 0/3904 Training loss: 0.392226
Epoch: 15 800/3904 Training loss: 0.330961
Epoch: 15 1600/3904 Training loss: 0.100374
Epoch: 15 2400/3904 Training loss: 0.257403
Epoch: 15 3200/3904 Training loss: 0.311649
Training loss: 0.379523
Test loss: 2.942260; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 16 0/3904 Training loss: 0.376716
Epoch: 16 800/3904 Training loss: 0.269698
Epoch: 16 1600/3904 Training loss: 0.114466
Epoch: 16 2400/3904 Training loss: 0.240026
Epoch: 16 3200/3904 Training loss: 0.388770
Training loss: 0.378881
Test loss: 3.166026; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 17 0/3904 Training loss: 0.514816
Epoch: 17 800/3904 Training loss: 0.290776
Epoch: 17 1600/3904 Training loss: 0.124189
Epoch: 17 2400/3904 Training loss: 0.223460
Epoch: 17 3200/3904 Training loss: 0.473536
Training loss: 0.378611
Test loss: 3.004178; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 18 0/3904 Training loss: 0.435276
Epoch: 18 800/3904 Training loss: 0.368629
Epoch: 18 1600/3904 Training loss: 0.136280
Epoch: 18 2400/3904 Training loss: 0.245205
Epoch: 18 3200/3904 Training loss: 0.345693
Training loss: 0.371801
Test loss: 2.965204; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 19 0/3904 Training loss: 0.403215
Epoch: 19 800/3904 Training loss: 0.317617
Epoch: 19 1600/3904 Training loss: 0.137397
Epoch: 19 2400/3904 Training loss: 0.222807
Epoch: 19 3200/3904 Training loss: 0.374432
Training loss: 0.366826
Test loss: 2.983935; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 20 0/3904 Training loss: 0.352445
Epoch: 20 800/3904 Training loss: 0.283119
Epoch: 20 1600/3904 Training loss: 0.133918
Epoch: 20 2400/3904 Training loss: 0.246215
Epoch: 20 3200/3904 Training loss: 0.340186
Training loss: 0.362671
Test loss: 3.757714; True positive: 35; True negative: 265, False Positive: 0, False negative: 868, accuracy: 0.2568493150684932, precision: 1.0, recall: 0.03875968992248062
Epoch: 21 0/3904 Training loss: 0.319387
Epoch: 21 800/3904 Training loss: 0.287083
Epoch: 21 1600/3904 Training loss: 0.163914
Epoch: 21 2400/3904 Training loss: 0.252249
Epoch: 21 3200/3904 Training loss: 0.288071
Training loss: 0.373376
Test loss: 0.606247; True positive: 838; True negative: 123, False Positive: 142, False negative: 65, accuracy: 0.8227739726027398, precision: 0.8551020408163266, recall: 0.9280177187153932
starting trial 204
[I 2022-12-05 05:26:32,065] Trial 203 finished with value: 0.8227739726027398 and parameters: {'d_model': 64, 'nhead': 8, 'n_encoders': 1, 'learning_rate': 9.008814576793163e-05, 'weight_decay': 3.193723355364679e-06, 'dropout': 0.3958714084017051, 'max_pool_conv': 16, 'kernel_size': 13, 'd_mlp': 16, 'num_conv_layers': 7, 'encoder_dropout': 0.11810001096693401, 'd_feed_forward': 128, 'max_pool_dim': 8, 'n_mlp_layers': 3}. Best is trial 62 with value: 0.860445205479452.
Epoch: 0 0/3904 Training loss: 0.698893
Epoch: 0 800/3904 Training loss: 0.737592
Epoch: 0 1600/3904 Training loss: 0.441337
Epoch: 0 2400/3904 Training loss: 0.786533
Epoch: 0 3200/3904 Training loss: 0.555242
Training loss: 0.665322
Test loss: 0.804275; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 1 0/3904 Training loss: 0.706976
Epoch: 1 800/3904 Training loss: 0.729064
Epoch: 1 1600/3904 Training loss: 0.424364
Epoch: 1 2400/3904 Training loss: 0.729298
Epoch: 1 3200/3904 Training loss: 0.463580
Training loss: 0.630020
Test loss: 0.642824; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 2 0/3904 Training loss: 0.659552
Epoch: 2 800/3904 Training loss: 0.545959
Epoch: 2 1600/3904 Training loss: 0.260842
Epoch: 2 2400/3904 Training loss: 0.579066
Epoch: 2 3200/3904 Training loss: 0.346265
Training loss: 0.521463
Test loss: 0.652437; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 3 0/3904 Training loss: 0.536120
Epoch: 3 800/3904 Training loss: 0.427215
Epoch: 3 1600/3904 Training loss: 0.221816
Epoch: 3 2400/3904 Training loss: 0.487822
Epoch: 3 3200/3904 Training loss: 0.335972
Training loss: 0.457576
Test loss: 0.588139; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 4 0/3904 Training loss: 0.403868
Epoch: 4 800/3904 Training loss: 0.406534
Epoch: 4 1600/3904 Training loss: 0.196706
Epoch: 4 2400/3904 Training loss: 0.368540
Epoch: 4 3200/3904 Training loss: 0.426145
Training loss: 0.417759
Test loss: 0.578591; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 5 0/3904 Training loss: 0.486861
Epoch: 5 800/3904 Training loss: 0.370870
Epoch: 5 1600/3904 Training loss: 0.201166
Epoch: 5 2400/3904 Training loss: 0.333400
Epoch: 5 3200/3904 Training loss: 0.371153
Training loss: 0.403994
Test loss: 0.613076; True positive: 809; True negative: 121, False Positive: 144, False negative: 94, accuracy: 0.7962328767123288, precision: 0.8488982161594963, recall: 0.8959025470653378
Epoch: 6 0/3904 Training loss: 0.407491
Epoch: 6 800/3904 Training loss: 0.389268
Epoch: 6 1600/3904 Training loss: 0.191956
Epoch: 6 2400/3904 Training loss: 0.328358
Epoch: 6 3200/3904 Training loss: 0.395187
Training loss: 0.390754
Test loss: 0.582316; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 7 0/3904 Training loss: 0.445619
Epoch: 7 800/3904 Training loss: 0.334619
Epoch: 7 1600/3904 Training loss: 0.179574
Epoch: 7 2400/3904 Training loss: 0.348842
Epoch: 7 3200/3904 Training loss: 0.421154
Training loss: 0.394965
Test loss: 0.580679; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 8 0/3904 Training loss: 0.368348
Epoch: 8 800/3904 Training loss: 0.287526
Epoch: 8 1600/3904 Training loss: 0.163607
Epoch: 8 2400/3904 Training loss: 0.267142
Epoch: 8 3200/3904 Training loss: 0.429979
Training loss: 0.381727
Test loss: 0.581997; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 9 0/3904 Training loss: 0.353985
Epoch: 9 800/3904 Training loss: 0.309229
Epoch: 9 1600/3904 Training loss: 0.172935
Epoch: 9 2400/3904 Training loss: 0.335383
Epoch: 9 3200/3904 Training loss: 0.412676
Training loss: 0.375887
Test loss: 0.598205; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 10 0/3904 Training loss: 0.285784
Epoch: 10 800/3904 Training loss: 0.337403
Epoch: 10 1600/3904 Training loss: 0.195432
Epoch: 10 2400/3904 Training loss: 0.298936
Epoch: 10 3200/3904 Training loss: 0.386836
Training loss: 0.379020
Test loss: 0.604901; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 11 0/3904 Training loss: 0.319405
Epoch: 11 800/3904 Training loss: 0.303088
Epoch: 11 1600/3904 Training loss: 0.185081
Epoch: 11 2400/3904 Training loss: 0.404395
Epoch: 11 3200/3904 Training loss: 0.432741
Training loss: 0.382164
Test loss: 0.626234; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 12 0/3904 Training loss: 0.344778
Epoch: 12 800/3904 Training loss: 0.356170
Epoch: 12 1600/3904 Training loss: 0.164872
Epoch: 12 2400/3904 Training loss: 0.270569
Epoch: 12 3200/3904 Training loss: 0.352860
Training loss: 0.375219
Test loss: 0.610305; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 13 0/3904 Training loss: 0.403768
Epoch: 13 800/3904 Training loss: 0.240483
Epoch: 13 1600/3904 Training loss: 0.138355
Epoch: 13 2400/3904 Training loss: 0.223366
Epoch: 13 3200/3904 Training loss: 0.416861
Training loss: 0.370960
Test loss: 0.624041; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 14 0/3904 Training loss: 0.508718
Epoch: 14 800/3904 Training loss: 0.385672
Epoch: 14 1600/3904 Training loss: 0.138862
Epoch: 14 2400/3904 Training loss: 0.191207
Epoch: 14 3200/3904 Training loss: 0.528417
Training loss: 0.369204
Test loss: 0.533430; True positive: 903; True negative: 0, False Positive: 265, False negative: 0, accuracy: 0.7731164383561644, precision: 0.7731164383561644, recall: 1.0
Epoch: 15 0/3904 Training loss: 0.304497
Epoch: 15 800/3904 Training loss: 0.396324
Epoch: 15 1600/3904 Training loss: 0.134980
Epoch: 15 2400/3904 Training loss: 0.251552
Epoch: 15 3200/3904 Training loss: 0.287250
Training loss: 0.371713
Test loss: 0.610423; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 16 0/3904 Training loss: 0.318343
Epoch: 16 800/3904 Training loss: 0.196308
Epoch: 16 1600/3904 Training loss: 0.119082
Epoch: 16 2400/3904 Training loss: 0.210847
Epoch: 16 3200/3904 Training loss: 0.296557
Training loss: 0.372945
Test loss: 0.518444; True positive: 857; True negative: 88, False Positive: 177, False negative: 46, accuracy: 0.8090753424657534, precision: 0.8288201160541586, recall: 0.9490586932447398
Epoch: 17 0/3904 Training loss: 0.319086
Epoch: 17 800/3904 Training loss: 0.310862
Epoch: 17 1600/3904 Training loss: 0.125330
Epoch: 17 2400/3904 Training loss: 0.236199
Epoch: 17 3200/3904 Training loss: 0.392358
Training loss: 0.363804
Test loss: 0.622775; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 18 0/3904 Training loss: 0.353778
Epoch: 18 800/3904 Training loss: 0.383373
Epoch: 18 1600/3904 Training loss: 0.151198
Epoch: 18 2400/3904 Training loss: 0.211583
Epoch: 18 3200/3904 Training loss: 0.298182
Training loss: 0.366724
Test loss: 0.618405; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 19 0/3904 Training loss: 0.288735
Epoch: 19 800/3904 Training loss: 0.276633
Epoch: 19 1600/3904 Training loss: 0.239984
Epoch: 19 2400/3904 Training loss: 0.246437
Epoch: 19 3200/3904 Training loss: 0.329927
Training loss: 0.360473
Test loss: 0.619637; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 20 0/3904 Training loss: 0.347818
Epoch: 20 800/3904 Training loss: 0.206374
Epoch: 20 1600/3904 Training loss: 0.109530
Epoch: 20 2400/3904 Training loss: 0.222447
Epoch: 20 3200/3904 Training loss: 0.302761
Training loss: 0.352467
Test loss: 0.617505; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 21 0/3904 Training loss: 0.356763
Epoch: 21 800/3904 Training loss: 0.244487
Epoch: 21 1600/3904 Training loss: 0.111520
Epoch: 21 2400/3904 Training loss: 0.184458
Epoch: 21 3200/3904 Training loss: 0.430062
Training loss: 0.345510
Test loss: 0.618583; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 22 0/3904 Training loss: 0.290307
Epoch: 22 800/3904 Training loss: 0.258829
Epoch: 22 1600/3904 Training loss: 0.120720
Epoch: 22 2400/3904 Training loss: 0.180325
Epoch: 22 3200/3904 Training loss: 0.338389
Training loss: 0.352432
Test loss: 0.617221; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 23 0/3904 Training loss: 0.314253
Epoch: 23 800/3904 Training loss: 0.279147
Epoch: 23 1600/3904 Training loss: 0.143137
Epoch: 23 2400/3904 Training loss: 0.211184
Epoch: 23 3200/3904 Training loss: 0.342985
Training loss: 0.354391
Test loss: 0.615334; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 24 0/3904 Training loss: 0.321308
Epoch: 24 800/3904 Training loss: 0.230694
Epoch: 24 1600/3904 Training loss: 0.193308
Epoch: 24 2400/3904 Training loss: 0.237444
Epoch: 24 3200/3904 Training loss: 0.351899
Training loss: 0.343872
Test loss: 0.624073; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 25 0/3904 Training loss: 0.277258
Epoch: 25 800/3904 Training loss: 0.283301
Epoch: 25 1600/3904 Training loss: 0.186401
Epoch: 25 2400/3904 Training loss: 0.200293
Epoch: 25 3200/3904 Training loss: 0.289391
Training loss: 0.340454
Test loss: 0.624728; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 26 0/3904 Training loss: 0.289162
Epoch: 26 800/3904 Training loss: 0.317792
Epoch: 26 1600/3904 Training loss: 0.166588
Epoch: 26 2400/3904 Training loss: 0.178336
Epoch: 26 3200/3904 Training loss: 0.305900
Training loss: 0.336512
Test loss: 0.626617; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
starting trial 205
[I 2022-12-05 05:32:09,745] Trial 204 finished with value: 0.8176369863013698 and parameters: {'d_model': 64, 'nhead': 8, 'n_encoders': 1, 'learning_rate': 9.687611083668096e-05, 'weight_decay': 2.6580071636709404e-06, 'dropout': 0.2327612261251701, 'max_pool_conv': 16, 'kernel_size': 13, 'd_mlp': 16, 'num_conv_layers': 7, 'encoder_dropout': 0.10910258007791364, 'd_feed_forward': 128, 'max_pool_dim': 8, 'n_mlp_layers': 3}. Best is trial 62 with value: 0.860445205479452.
Epoch: 0 0/3904 Training loss: 0.696608
Epoch: 0 800/3904 Training loss: 0.736032
Epoch: 0 1600/3904 Training loss: 0.443649
Epoch: 0 2400/3904 Training loss: 0.781817
Epoch: 0 3200/3904 Training loss: 0.551994
Training loss: 0.664865
Test loss: 0.817214; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 1 0/3904 Training loss: 0.717368
Epoch: 1 800/3904 Training loss: 0.731635
Epoch: 1 1600/3904 Training loss: 0.446276
Epoch: 1 2400/3904 Training loss: 0.785861
Epoch: 1 3200/3904 Training loss: 0.518481
Training loss: 0.652098
Test loss: 0.730887; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 2 0/3904 Training loss: 0.692326
Epoch: 2 800/3904 Training loss: 0.676405
Epoch: 2 1600/3904 Training loss: 0.250942
Epoch: 2 2400/3904 Training loss: 0.671706
Epoch: 2 3200/3904 Training loss: 0.371273
Training loss: 0.564177
Test loss: 0.819000; True positive: 13; True negative: 261, False Positive: 4, False negative: 890, accuracy: 0.2345890410958904, precision: 0.7647058823529411, recall: 0.014396456256921373
Epoch: 3 0/3904 Training loss: 0.551353
Epoch: 3 800/3904 Training loss: 0.537408
Epoch: 3 1600/3904 Training loss: 0.242215
Epoch: 3 2400/3904 Training loss: 0.585479
Epoch: 3 3200/3904 Training loss: 0.364884
Training loss: 0.480263
Test loss: 1.266831; True positive: 290; True negative: 245, False Positive: 20, False negative: 613, accuracy: 0.4580479452054795, precision: 0.9354838709677419, recall: 0.3211517165005537
Epoch: 4 0/3904 Training loss: 0.502268
Epoch: 4 800/3904 Training loss: 0.439102
Epoch: 4 1600/3904 Training loss: 0.191524
Epoch: 4 2400/3904 Training loss: 0.394671
Epoch: 4 3200/3904 Training loss: 0.356503
Training loss: 0.432358
Test loss: 2.442744; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 5 0/3904 Training loss: 0.367398
Epoch: 5 800/3904 Training loss: 0.344318
Epoch: 5 1600/3904 Training loss: 0.208493
Epoch: 5 2400/3904 Training loss: 0.298442
Epoch: 5 3200/3904 Training loss: 0.336897
Training loss: 0.417311
Test loss: 2.536000; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 6 0/3904 Training loss: 0.281991
Epoch: 6 800/3904 Training loss: 0.289333
Epoch: 6 1600/3904 Training loss: 0.268247
Epoch: 6 2400/3904 Training loss: 0.313560
Epoch: 6 3200/3904 Training loss: 0.327068
Training loss: 0.400400
Test loss: 2.413187; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 7 0/3904 Training loss: 0.319964
Epoch: 7 800/3904 Training loss: 0.228483
Epoch: 7 1600/3904 Training loss: 0.155876
Epoch: 7 2400/3904 Training loss: 0.264563
Epoch: 7 3200/3904 Training loss: 0.448023
Training loss: 0.388390
Test loss: 2.286507; True positive: 68; True negative: 258, False Positive: 7, False negative: 835, accuracy: 0.2791095890410959, precision: 0.9066666666666666, recall: 0.0753045404208195
Epoch: 8 0/3904 Training loss: 0.299171
Epoch: 8 800/3904 Training loss: 0.407549
Epoch: 8 1600/3904 Training loss: 0.144630
Epoch: 8 2400/3904 Training loss: 0.269827
Epoch: 8 3200/3904 Training loss: 0.385108
Training loss: 0.395065
Test loss: 0.558783; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 9 0/3904 Training loss: 0.346943
Epoch: 9 800/3904 Training loss: 0.279385
Epoch: 9 1600/3904 Training loss: 0.193587
Epoch: 9 2400/3904 Training loss: 0.248720
Epoch: 9 3200/3904 Training loss: 0.288041
Training loss: 0.379856
Test loss: 0.556742; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 10 0/3904 Training loss: 0.324897
Epoch: 10 800/3904 Training loss: 0.242393
Epoch: 10 1600/3904 Training loss: 0.173406
Epoch: 10 2400/3904 Training loss: 0.218764
Epoch: 10 3200/3904 Training loss: 0.360145
Training loss: 0.376005
Test loss: 0.551065; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 11 0/3904 Training loss: 0.284635
Epoch: 11 800/3904 Training loss: 0.249796
Epoch: 11 1600/3904 Training loss: 0.163814
Epoch: 11 2400/3904 Training loss: 0.230289
Epoch: 11 3200/3904 Training loss: 0.307818
Training loss: 0.369012
Test loss: 0.555498; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 12 0/3904 Training loss: 0.337566
Epoch: 12 800/3904 Training loss: 0.202568
Epoch: 12 1600/3904 Training loss: 0.165622
Epoch: 12 2400/3904 Training loss: 0.204894
Epoch: 12 3200/3904 Training loss: 0.352129
Training loss: 0.367318
Test loss: 0.557054; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 13 0/3904 Training loss: 0.469287
Epoch: 13 800/3904 Training loss: 0.245860
Epoch: 13 1600/3904 Training loss: 0.187556
Epoch: 13 2400/3904 Training loss: 0.194845
Epoch: 13 3200/3904 Training loss: 0.371253
Training loss: 0.357832
Test loss: 0.546983; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 14 0/3904 Training loss: 0.345201
Epoch: 14 800/3904 Training loss: 0.283541
Epoch: 14 1600/3904 Training loss: 0.168642
Epoch: 14 2400/3904 Training loss: 0.203628
Epoch: 14 3200/3904 Training loss: 0.395637
Training loss: 0.351303
Test loss: 0.555606; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 15 0/3904 Training loss: 0.323083
Epoch: 15 800/3904 Training loss: 0.211920
Epoch: 15 1600/3904 Training loss: 0.157141
Epoch: 15 2400/3904 Training loss: 0.198288
Epoch: 15 3200/3904 Training loss: 0.388806
Training loss: 0.358016
Test loss: 0.554244; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 16 0/3904 Training loss: 0.365031
Epoch: 16 800/3904 Training loss: 0.287518
Epoch: 16 1600/3904 Training loss: 0.146401
Epoch: 16 2400/3904 Training loss: 0.256625
Epoch: 16 3200/3904 Training loss: 0.380713
Training loss: 0.354351
Test loss: 0.565872; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 17 0/3904 Training loss: 0.332553
Epoch: 17 800/3904 Training loss: 0.181966
Epoch: 17 1600/3904 Training loss: 0.201686
Epoch: 17 2400/3904 Training loss: 0.212102
Epoch: 17 3200/3904 Training loss: 0.344415
Training loss: 0.351137
Test loss: 0.561676; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 18 0/3904 Training loss: 0.332970
Epoch: 18 800/3904 Training loss: 0.296988
Epoch: 18 1600/3904 Training loss: 0.191345
Epoch: 18 2400/3904 Training loss: 0.483236
Epoch: 18 3200/3904 Training loss: 0.372518
Training loss: 0.342459
Test loss: 0.588214; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 19 0/3904 Training loss: 0.344323
Epoch: 19 800/3904 Training loss: 0.219236
Epoch: 19 1600/3904 Training loss: 0.146604
Epoch: 19 2400/3904 Training loss: 0.194372
Epoch: 19 3200/3904 Training loss: 0.392400
Training loss: 0.346856
Test loss: 0.582859; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 20 0/3904 Training loss: 0.346315
Epoch: 20 800/3904 Training loss: 0.250067
Epoch: 20 1600/3904 Training loss: 0.146361
Epoch: 20 2400/3904 Training loss: 0.180251
Epoch: 20 3200/3904 Training loss: 0.289894
Training loss: 0.345060
Test loss: 0.567084; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 21 0/3904 Training loss: 0.397537
Epoch: 21 800/3904 Training loss: 0.202503
Epoch: 21 1600/3904 Training loss: 0.124019
Epoch: 21 2400/3904 Training loss: 0.202406
Epoch: 21 3200/3904 Training loss: 0.312006
Training loss: 0.341410
Test loss: 0.573615; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 22 0/3904 Training loss: 0.335788
Epoch: 22 800/3904 Training loss: 0.246401
Epoch: 22 1600/3904 Training loss: 0.144413
Epoch: 22 2400/3904 Training loss: 0.162136
Epoch: 22 3200/3904 Training loss: 0.290194
Training loss: 0.326710
Test loss: 0.575973; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 23 0/3904 Training loss: 0.272400
Epoch: 23 800/3904 Training loss: 0.301825
Epoch: 23 1600/3904 Training loss: 0.185092
Epoch: 23 2400/3904 Training loss: 0.169707
Epoch: 23 3200/3904 Training loss: 0.340717
Training loss: 0.324833
Test loss: 0.582779; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
starting trial 206
[I 2022-12-05 05:37:22,058] Trial 205 finished with value: 0.8176369863013698 and parameters: {'d_model': 64, 'nhead': 8, 'n_encoders': 2, 'learning_rate': 0.0001072324407801151, 'weight_decay': 3.1781637988531656e-06, 'dropout': 0.2604252511234919, 'max_pool_conv': 16, 'kernel_size': 12, 'd_mlp': 16, 'num_conv_layers': 7, 'encoder_dropout': 0.1280018782051283, 'd_feed_forward': 128, 'max_pool_dim': 8, 'n_mlp_layers': 3}. Best is trial 62 with value: 0.860445205479452.
Epoch: 0 0/3904 Training loss: 0.696278
Epoch: 0 800/3904 Training loss: 0.739080
Epoch: 0 1600/3904 Training loss: 0.469084
Epoch: 0 2400/3904 Training loss: 0.822751
Epoch: 0 3200/3904 Training loss: 0.561702
Training loss: 0.661982
Test loss: 0.852230; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 1 0/3904 Training loss: 0.720940
Epoch: 1 800/3904 Training loss: 0.742652
Epoch: 1 1600/3904 Training loss: 0.452504
Epoch: 1 2400/3904 Training loss: 0.759624
Epoch: 1 3200/3904 Training loss: 0.525566
Training loss: 0.651858
Test loss: 0.738986; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 2 0/3904 Training loss: 0.689579
Epoch: 2 800/3904 Training loss: 0.714029
Epoch: 2 1600/3904 Training loss: 0.301126
Epoch: 2 2400/3904 Training loss: 0.667890
Epoch: 2 3200/3904 Training loss: 0.432843
Training loss: 0.572969
Test loss: 0.672108; True positive: 903; True negative: 0, False Positive: 265, False negative: 0, accuracy: 0.7731164383561644, precision: 0.7731164383561644, recall: 1.0
Epoch: 3 0/3904 Training loss: 0.417193
Epoch: 3 800/3904 Training loss: 0.594870
Epoch: 3 1600/3904 Training loss: 0.207457
Epoch: 3 2400/3904 Training loss: 0.563806
Epoch: 3 3200/3904 Training loss: 0.535958
Training loss: 0.478490
Test loss: 0.642431; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 4 0/3904 Training loss: 0.347261
Epoch: 4 800/3904 Training loss: 0.417101
Epoch: 4 1600/3904 Training loss: 0.154509
Epoch: 4 2400/3904 Training loss: 0.480548
Epoch: 4 3200/3904 Training loss: 0.473470
Training loss: 0.437785
Test loss: 0.643401; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 5 0/3904 Training loss: 0.256945
Epoch: 5 800/3904 Training loss: 0.365221
Epoch: 5 1600/3904 Training loss: 0.106152
Epoch: 5 2400/3904 Training loss: 0.462609
Epoch: 5 3200/3904 Training loss: 0.557975
Training loss: 0.407776
Test loss: 0.628510; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 6 0/3904 Training loss: 0.353007
Epoch: 6 800/3904 Training loss: 0.283803
Epoch: 6 1600/3904 Training loss: 0.098213
Epoch: 6 2400/3904 Training loss: 0.443352
Epoch: 6 3200/3904 Training loss: 0.494360
Training loss: 0.385420
Test loss: 0.621726; True positive: 831; True negative: 119, False Positive: 146, False negative: 72, accuracy: 0.8133561643835616, precision: 0.8505629477993859, recall: 0.920265780730897
Epoch: 7 0/3904 Training loss: 0.256068
Epoch: 7 800/3904 Training loss: 0.224369
Epoch: 7 1600/3904 Training loss: 0.130216
Epoch: 7 2400/3904 Training loss: 0.476103
Epoch: 7 3200/3904 Training loss: 0.563402
Training loss: 0.363737
Test loss: 0.871743; True positive: 675; True negative: 135, False Positive: 130, False negative: 228, accuracy: 0.6934931506849316, precision: 0.8385093167701864, recall: 0.7475083056478405
Epoch: 8 0/3904 Training loss: 0.327126
Epoch: 8 800/3904 Training loss: 0.317588
Epoch: 8 1600/3904 Training loss: 0.114265
Epoch: 8 2400/3904 Training loss: 0.372208
Epoch: 8 3200/3904 Training loss: 0.415717
Training loss: 0.359592
Test loss: 2.908417; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 9 0/3904 Training loss: 0.367299
Epoch: 9 800/3904 Training loss: 0.157133
Epoch: 9 1600/3904 Training loss: 0.153039
Epoch: 9 2400/3904 Training loss: 0.466522
Epoch: 9 3200/3904 Training loss: 0.400588
Training loss: 0.350945
Test loss: 0.646837; True positive: 837; True negative: 117, False Positive: 148, False negative: 66, accuracy: 0.8167808219178082, precision: 0.849746192893401, recall: 0.9269102990033222
Epoch: 10 0/3904 Training loss: 0.382895
Epoch: 10 800/3904 Training loss: 0.426990
Epoch: 10 1600/3904 Training loss: 0.120770
Epoch: 10 2400/3904 Training loss: 0.389480
Epoch: 10 3200/3904 Training loss: 0.355564
Training loss: 0.351927
Test loss: 2.780809; True positive: 41; True negative: 245, False Positive: 20, False negative: 862, accuracy: 0.24486301369863014, precision: 0.6721311475409836, recall: 0.04540420819490587
Epoch: 11 0/3904 Training loss: 0.419532
Epoch: 11 800/3904 Training loss: 0.157866
Epoch: 11 1600/3904 Training loss: 0.154069
Epoch: 11 2400/3904 Training loss: 0.340643
Epoch: 11 3200/3904 Training loss: 0.311539
Training loss: 0.337046
Test loss: 3.282680; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 12 0/3904 Training loss: 0.522923
Epoch: 12 800/3904 Training loss: 0.229428
Epoch: 12 1600/3904 Training loss: 0.180798
Epoch: 12 2400/3904 Training loss: 0.263529
Epoch: 12 3200/3904 Training loss: 0.372092
Training loss: 0.329069
Test loss: 3.268851; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 13 0/3904 Training loss: 0.438240
Epoch: 13 800/3904 Training loss: 0.231300
Epoch: 13 1600/3904 Training loss: 0.172694
Epoch: 13 2400/3904 Training loss: 0.243016
Epoch: 13 3200/3904 Training loss: 0.310524
Training loss: 0.319966
Test loss: 3.267715; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 14 0/3904 Training loss: 0.521416
Epoch: 14 800/3904 Training loss: 0.146852
Epoch: 14 1600/3904 Training loss: 0.135425
Epoch: 14 2400/3904 Training loss: 0.306816
Epoch: 14 3200/3904 Training loss: 0.330612
Training loss: 0.315664
Test loss: 3.256696; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 15 0/3904 Training loss: 0.424990
Epoch: 15 800/3904 Training loss: 0.166337
Epoch: 15 1600/3904 Training loss: 0.086898
Epoch: 15 2400/3904 Training loss: 0.219147
Epoch: 15 3200/3904 Training loss: 0.337421
Training loss: 0.297427
Test loss: 3.486996; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 16 0/3904 Training loss: 0.507171
Epoch: 16 800/3904 Training loss: 0.158537
Epoch: 16 1600/3904 Training loss: 0.148969
Epoch: 16 2400/3904 Training loss: 0.154456
Epoch: 16 3200/3904 Training loss: 0.348426
Training loss: 0.289072
Test loss: 3.558796; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
starting trial 207
[I 2022-12-05 05:40:50,510] Trial 206 finished with value: 0.8176369863013698 and parameters: {'d_model': 64, 'nhead': 8, 'n_encoders': 1, 'learning_rate': 0.00011866061977824026, 'weight_decay': 2.3414010752186873e-06, 'dropout': 0.24252205876080823, 'max_pool_conv': 16, 'kernel_size': 10, 'd_mlp': 16, 'num_conv_layers': 8, 'encoder_dropout': 0.10407188123618072, 'd_feed_forward': 128, 'max_pool_dim': 8, 'n_mlp_layers': 3}. Best is trial 62 with value: 0.860445205479452.
Epoch: 0 0/3904 Training loss: 0.699915
Epoch: 0 800/3904 Training loss: 0.714372
Epoch: 0 1600/3904 Training loss: 0.425416
Epoch: 0 2400/3904 Training loss: 0.750421
Epoch: 0 3200/3904 Training loss: 0.554242
Training loss: 0.665845
Test loss: 0.799776; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 1 0/3904 Training loss: 0.708885
Epoch: 1 800/3904 Training loss: 0.741389
Epoch: 1 1600/3904 Training loss: 0.439984
Epoch: 1 2400/3904 Training loss: 0.753817
Epoch: 1 3200/3904 Training loss: 0.534804
Training loss: 0.661694
Test loss: 0.761798; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 2 0/3904 Training loss: 0.698437
Epoch: 2 800/3904 Training loss: 0.652669
Epoch: 2 1600/3904 Training loss: 0.259383
Epoch: 2 2400/3904 Training loss: 0.646690
Epoch: 2 3200/3904 Training loss: 0.427134
Training loss: 0.586549
Test loss: 1.912156; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 3 0/3904 Training loss: 0.486278
Epoch: 3 800/3904 Training loss: 0.477409
Epoch: 3 1600/3904 Training loss: 0.225840
Epoch: 3 2400/3904 Training loss: 0.511888
Epoch: 3 3200/3904 Training loss: 0.362494
Training loss: 0.475821
Test loss: 2.668616; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 4 0/3904 Training loss: 0.401164
Epoch: 4 800/3904 Training loss: 0.443739
Epoch: 4 1600/3904 Training loss: 0.177354
Epoch: 4 2400/3904 Training loss: 0.357898
Epoch: 4 3200/3904 Training loss: 0.442189
Training loss: 0.443420
Test loss: 3.127716; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 5 0/3904 Training loss: 0.476232
Epoch: 5 800/3904 Training loss: 0.450187
Epoch: 5 1600/3904 Training loss: 0.125301
Epoch: 5 2400/3904 Training loss: 0.345884
Epoch: 5 3200/3904 Training loss: 0.407713
Training loss: 0.420992
Test loss: 3.129164; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 6 0/3904 Training loss: 0.463398
Epoch: 6 800/3904 Training loss: 0.436951
Epoch: 6 1600/3904 Training loss: 0.221962
Epoch: 6 2400/3904 Training loss: 0.304149
Epoch: 6 3200/3904 Training loss: 0.414397
Training loss: 0.439261
Test loss: 3.379926; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 7 0/3904 Training loss: 0.344066
Epoch: 7 800/3904 Training loss: 0.603176
Epoch: 7 1600/3904 Training loss: 0.102477
Epoch: 7 2400/3904 Training loss: 0.339750
Epoch: 7 3200/3904 Training loss: 0.393838
Training loss: 0.416576
Test loss: 3.038864; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 8 0/3904 Training loss: 0.353959
Epoch: 8 800/3904 Training loss: 0.518425
Epoch: 8 1600/3904 Training loss: 0.131398
Epoch: 8 2400/3904 Training loss: 0.247350
Epoch: 8 3200/3904 Training loss: 0.367481
Training loss: 0.401470
Test loss: 3.223121; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 9 0/3904 Training loss: 0.319206
Epoch: 9 800/3904 Training loss: 0.365786
Epoch: 9 1600/3904 Training loss: 0.167299
Epoch: 9 2400/3904 Training loss: 0.279402
Epoch: 9 3200/3904 Training loss: 0.366091
Training loss: 0.399213
Test loss: 3.371174; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 10 0/3904 Training loss: 0.312949
Epoch: 10 800/3904 Training loss: 0.484291
Epoch: 10 1600/3904 Training loss: 0.179135
Epoch: 10 2400/3904 Training loss: 0.316827
Epoch: 10 3200/3904 Training loss: 0.378215
Training loss: 0.403054
Test loss: 3.404949; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 11 0/3904 Training loss: 0.318650
Epoch: 11 800/3904 Training loss: 0.443458
Epoch: 11 1600/3904 Training loss: 0.133898
Epoch: 11 2400/3904 Training loss: 0.254000
Epoch: 11 3200/3904 Training loss: 0.506443
Training loss: 0.395456
Test loss: 3.594882; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
starting trial 208
[I 2022-12-05 05:43:36,552] Trial 207 finished with value: 0.2268835616438356 and parameters: {'d_model': 64, 'nhead': 8, 'n_encoders': 1, 'learning_rate': 0.00015406005535138363, 'weight_decay': 3.0476184719922005e-06, 'dropout': 0.22301977263489736, 'max_pool_conv': 16, 'kernel_size': 12, 'd_mlp': 32, 'num_conv_layers': 8, 'encoder_dropout': 0.14489331559194413, 'd_feed_forward': 128, 'max_pool_dim': 8, 'n_mlp_layers': 3}. Best is trial 62 with value: 0.860445205479452.
Epoch: 0 0/3904 Training loss: 0.699987
Epoch: 0 800/3904 Training loss: 0.733193
Epoch: 0 1600/3904 Training loss: 0.517978
Epoch: 0 2400/3904 Training loss: 0.806519
Epoch: 0 3200/3904 Training loss: 0.567459
Training loss: 0.661144
Test loss: 0.867142; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 1 0/3904 Training loss: 0.723553
Epoch: 1 800/3904 Training loss: 0.736682
Epoch: 1 1600/3904 Training loss: 0.491509
Epoch: 1 2400/3904 Training loss: 0.827536
Epoch: 1 3200/3904 Training loss: 0.558940
Training loss: 0.659228
Test loss: 0.870170; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 2 0/3904 Training loss: 0.726590
Epoch: 2 800/3904 Training loss: 0.754354
Epoch: 2 1600/3904 Training loss: 0.444775
Epoch: 2 2400/3904 Training loss: 0.793298
Epoch: 2 3200/3904 Training loss: 0.445731
Training loss: 0.624543
Test loss: 0.606635; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 3 0/3904 Training loss: 0.578254
Epoch: 3 800/3904 Training loss: 0.394442
Epoch: 3 1600/3904 Training loss: 0.228659
Epoch: 3 2400/3904 Training loss: 0.482969
Epoch: 3 3200/3904 Training loss: 0.359318
Training loss: 0.482226
Test loss: 0.552339; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 4 0/3904 Training loss: 0.396283
Epoch: 4 800/3904 Training loss: 0.308253
Epoch: 4 1600/3904 Training loss: 0.171516
Epoch: 4 2400/3904 Training loss: 0.418725
Epoch: 4 3200/3904 Training loss: 0.426706
Training loss: 0.436772
Test loss: 0.558500; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 5 0/3904 Training loss: 0.424342
Epoch: 5 800/3904 Training loss: 0.358165
Epoch: 5 1600/3904 Training loss: 0.193484
Epoch: 5 2400/3904 Training loss: 0.405074
Epoch: 5 3200/3904 Training loss: 0.459021
Training loss: 0.416418
Test loss: 0.574093; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 6 0/3904 Training loss: 0.351322
Epoch: 6 800/3904 Training loss: 0.276962
Epoch: 6 1600/3904 Training loss: 0.194035
Epoch: 6 2400/3904 Training loss: 0.303660
Epoch: 6 3200/3904 Training loss: 0.440490
Training loss: 0.400516
Test loss: 0.578700; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 7 0/3904 Training loss: 0.377272
Epoch: 7 800/3904 Training loss: 0.284493
Epoch: 7 1600/3904 Training loss: 0.183438
Epoch: 7 2400/3904 Training loss: 0.259669
Epoch: 7 3200/3904 Training loss: 0.429750
Training loss: 0.393815
Test loss: 0.578516; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 8 0/3904 Training loss: 0.350431
Epoch: 8 800/3904 Training loss: 0.225053
Epoch: 8 1600/3904 Training loss: 0.179872
Epoch: 8 2400/3904 Training loss: 0.259261
Epoch: 8 3200/3904 Training loss: 0.444066
Training loss: 0.389281
Test loss: 0.589242; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 9 0/3904 Training loss: 0.367919
Epoch: 9 800/3904 Training loss: 0.252816
Epoch: 9 1600/3904 Training loss: 0.189223
Epoch: 9 2400/3904 Training loss: 0.280912
Epoch: 9 3200/3904 Training loss: 0.416848
Training loss: 0.383212
Test loss: 0.595380; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 10 0/3904 Training loss: 0.329711
Epoch: 10 800/3904 Training loss: 0.273175
Epoch: 10 1600/3904 Training loss: 0.208775
Epoch: 10 2400/3904 Training loss: 0.243084
Epoch: 10 3200/3904 Training loss: 0.375494
Training loss: 0.380192
Test loss: 0.608484; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 11 0/3904 Training loss: 0.386451
Epoch: 11 800/3904 Training loss: 0.271241
Epoch: 11 1600/3904 Training loss: 0.177349
Epoch: 11 2400/3904 Training loss: 0.363412
Epoch: 11 3200/3904 Training loss: 0.333694
Training loss: 0.379740
Test loss: 0.611325; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 12 0/3904 Training loss: 0.376096
Epoch: 12 800/3904 Training loss: 0.503812
Epoch: 12 1600/3904 Training loss: 0.139354
Epoch: 12 2400/3904 Training loss: 0.306229
Epoch: 12 3200/3904 Training loss: 0.431431
Training loss: 0.375552
Test loss: 0.606062; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 13 0/3904 Training loss: 0.377120
Epoch: 13 800/3904 Training loss: 0.288532
Epoch: 13 1600/3904 Training loss: 0.198929
Epoch: 13 2400/3904 Training loss: 0.330127
Epoch: 13 3200/3904 Training loss: 0.297171
Training loss: 0.378598
Test loss: 0.615048; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
starting trial 209
[I 2022-12-05 05:45:01,551] Trial 208 finished with value: 0.8176369863013698 and parameters: {'d_model': 32, 'nhead': 8, 'n_encoders': 1, 'learning_rate': 0.0001338055853302317, 'weight_decay': 2.8596065020891652e-06, 'dropout': 0.20600711513953707, 'max_pool_conv': 16, 'kernel_size': 13, 'd_mlp': 16, 'num_conv_layers': 7, 'encoder_dropout': 0.11438825111289365, 'd_feed_forward': 128, 'max_pool_dim': 8, 'n_mlp_layers': 4}. Best is trial 62 with value: 0.860445205479452.
Epoch: 0 0/3904 Training loss: 0.692166
Epoch: 0 800/3904 Training loss: 0.759678
Epoch: 0 1600/3904 Training loss: 0.418375
Epoch: 0 2400/3904 Training loss: 0.736346
Epoch: 0 3200/3904 Training loss: 0.552145
Training loss: 0.667843
Test loss: 0.762521; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 1 0/3904 Training loss: 0.700933
Epoch: 1 800/3904 Training loss: 0.726783
Epoch: 1 1600/3904 Training loss: 0.416362
Epoch: 1 2400/3904 Training loss: 0.756992
Epoch: 1 3200/3904 Training loss: 0.549596
Training loss: 0.666777
Test loss: 0.705420; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 2 0/3904 Training loss: 0.694153
Epoch: 2 800/3904 Training loss: 0.718542
Epoch: 2 1600/3904 Training loss: 0.407881
Epoch: 2 2400/3904 Training loss: 0.750634
Epoch: 2 3200/3904 Training loss: 0.557210
Training loss: 0.666511
Test loss: 0.745695; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 3 0/3904 Training loss: 0.700848
Epoch: 3 800/3904 Training loss: 0.723463
Epoch: 3 1600/3904 Training loss: 0.434029
Epoch: 3 2400/3904 Training loss: 0.770044
Epoch: 3 3200/3904 Training loss: 0.558202
Training loss: 0.663735
Test loss: 0.765256; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 4 0/3904 Training loss: 0.707908
Epoch: 4 800/3904 Training loss: 0.726585
Epoch: 4 1600/3904 Training loss: 0.440433
Epoch: 4 2400/3904 Training loss: 0.768400
Epoch: 4 3200/3904 Training loss: 0.553138
Training loss: 0.663644
Test loss: 0.754213; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 5 0/3904 Training loss: 0.702748
Epoch: 5 800/3904 Training loss: 0.722883
Epoch: 5 1600/3904 Training loss: 0.438091
Epoch: 5 2400/3904 Training loss: 0.775488
Epoch: 5 3200/3904 Training loss: 0.559366
Training loss: 0.662918
Test loss: 0.775238; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 6 0/3904 Training loss: 0.704953
Epoch: 6 800/3904 Training loss: 0.727325
Epoch: 6 1600/3904 Training loss: 0.447383
Epoch: 6 2400/3904 Training loss: 0.781065
Epoch: 6 3200/3904 Training loss: 0.558647
Training loss: 0.662448
Test loss: 0.779920; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 7 0/3904 Training loss: 0.708325
Epoch: 7 800/3904 Training loss: 0.729187
Epoch: 7 1600/3904 Training loss: 0.447439
Epoch: 7 2400/3904 Training loss: 0.778209
Epoch: 7 3200/3904 Training loss: 0.558457
Training loss: 0.661952
Test loss: 0.783163; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 8 0/3904 Training loss: 0.708089
Epoch: 8 800/3904 Training loss: 0.731701
Epoch: 8 1600/3904 Training loss: 0.440518
Epoch: 8 2400/3904 Training loss: 0.766689
Epoch: 8 3200/3904 Training loss: 0.555250
Training loss: 0.660452
Test loss: 0.751068; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 9 0/3904 Training loss: 0.687777
Epoch: 9 800/3904 Training loss: 0.725706
Epoch: 9 1600/3904 Training loss: 0.419738
Epoch: 9 2400/3904 Training loss: 0.772932
Epoch: 9 3200/3904 Training loss: 0.550335
Training loss: 0.656613
Test loss: 0.743828; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 10 0/3904 Training loss: 0.674790
Epoch: 10 800/3904 Training loss: 0.772023
Epoch: 10 1600/3904 Training loss: 0.401890
Epoch: 10 2400/3904 Training loss: 0.753035
Epoch: 10 3200/3904 Training loss: 0.575040
Training loss: 0.654363
Test loss: 0.779556; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 11 0/3904 Training loss: 0.678602
Epoch: 11 800/3904 Training loss: 0.770781
Epoch: 11 1600/3904 Training loss: 0.403902
Epoch: 11 2400/3904 Training loss: 0.758732
Epoch: 11 3200/3904 Training loss: 0.548102
Training loss: 0.653180
Test loss: 0.752470; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
starting trial 210
[I 2022-12-05 05:47:13,972] Trial 209 finished with value: 0.2268835616438356 and parameters: {'d_model': 64, 'nhead': 8, 'n_encoders': 1, 'learning_rate': 0.0006830019517733454, 'weight_decay': 4.051842892715134e-06, 'dropout': 0.17245537921938478, 'max_pool_conv': 16, 'kernel_size': 11, 'd_mlp': 32, 'num_conv_layers': 7, 'encoder_dropout': 0.1334098811505383, 'd_feed_forward': 128, 'max_pool_dim': 8, 'n_mlp_layers': 3}. Best is trial 62 with value: 0.860445205479452.
Epoch: 0 0/3904 Training loss: 0.698061
Epoch: 0 800/3904 Training loss: 0.733844
Epoch: 0 1600/3904 Training loss: 0.454743
Epoch: 0 2400/3904 Training loss: 0.794775
Epoch: 0 3200/3904 Training loss: 0.549839
Training loss: 0.664019
Test loss: 0.840460; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 1 0/3904 Training loss: 0.712540
Epoch: 1 800/3904 Training loss: 0.723928
Epoch: 1 1600/3904 Training loss: 0.430499
Epoch: 1 2400/3904 Training loss: 0.714265
Epoch: 1 3200/3904 Training loss: 0.524789
Training loss: 0.651620
Test loss: 0.935102; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 2 0/3904 Training loss: 0.672662
Epoch: 2 800/3904 Training loss: 0.690550
Epoch: 2 1600/3904 Training loss: 0.338187
Epoch: 2 2400/3904 Training loss: 0.746557
Epoch: 2 3200/3904 Training loss: 0.433331
Training loss: 0.596553
Test loss: 1.434261; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 3 0/3904 Training loss: 0.540479
Epoch: 3 800/3904 Training loss: 0.523717
Epoch: 3 1600/3904 Training loss: 0.264351
Epoch: 3 2400/3904 Training loss: 0.809326
Epoch: 3 3200/3904 Training loss: 0.345264
Training loss: 0.514312
Test loss: 1.709939; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 4 0/3904 Training loss: 0.457301
Epoch: 4 800/3904 Training loss: 0.379813
Epoch: 4 1600/3904 Training loss: 0.196958
Epoch: 4 2400/3904 Training loss: 0.722566
Epoch: 4 3200/3904 Training loss: 0.338235
Training loss: 0.456818
Test loss: 1.864375; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 5 0/3904 Training loss: 0.393968
Epoch: 5 800/3904 Training loss: 0.322979
Epoch: 5 1600/3904 Training loss: 0.172776
Epoch: 5 2400/3904 Training loss: 0.637230
Epoch: 5 3200/3904 Training loss: 0.341089
Training loss: 0.421756
Test loss: 1.920088; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 6 0/3904 Training loss: 0.351238
Epoch: 6 800/3904 Training loss: 0.274528
Epoch: 6 1600/3904 Training loss: 0.168755
Epoch: 6 2400/3904 Training loss: 0.629164
Epoch: 6 3200/3904 Training loss: 0.314203
Training loss: 0.378208
Test loss: 2.085509; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 7 0/3904 Training loss: 0.308915
Epoch: 7 800/3904 Training loss: 0.292418
Epoch: 7 1600/3904 Training loss: 0.132416
Epoch: 7 2400/3904 Training loss: 0.514200
Epoch: 7 3200/3904 Training loss: 0.360289
Training loss: 0.331683
Test loss: 0.621528; True positive: 705; True negative: 151, False Positive: 114, False negative: 198, accuracy: 0.7328767123287672, precision: 0.8608058608058609, recall: 0.7807308970099668
Epoch: 8 0/3904 Training loss: 0.301660
Epoch: 8 800/3904 Training loss: 0.144891
Epoch: 8 1600/3904 Training loss: 0.145276
Epoch: 8 2400/3904 Training loss: 0.483352
Epoch: 8 3200/3904 Training loss: 0.391090
Training loss: 0.306823
Test loss: 2.060270; True positive: 2; True negative: 263, False Positive: 2, False negative: 901, accuracy: 0.2268835616438356, precision: 0.5, recall: 0.0022148394241417496
Epoch: 9 0/3904 Training loss: 0.306675
Epoch: 9 800/3904 Training loss: 0.172863
Epoch: 9 1600/3904 Training loss: 0.135958
Epoch: 9 2400/3904 Training loss: 0.374027
Epoch: 9 3200/3904 Training loss: 0.420647
Training loss: 0.288700
Test loss: 2.616252; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 10 0/3904 Training loss: 0.333251
Epoch: 10 800/3904 Training loss: 0.182228
Epoch: 10 1600/3904 Training loss: 0.174480
Epoch: 10 2400/3904 Training loss: 0.271524
Epoch: 10 3200/3904 Training loss: 0.377278
Training loss: 0.273637
Test loss: 2.680870; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 11 0/3904 Training loss: 0.296952
Epoch: 11 800/3904 Training loss: 0.171836
Epoch: 11 1600/3904 Training loss: 0.101180
Epoch: 11 2400/3904 Training loss: 0.286467
Epoch: 11 3200/3904 Training loss: 0.312829
Training loss: 0.258698
Test loss: 2.798284; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 12 0/3904 Training loss: 0.285930
Epoch: 12 800/3904 Training loss: 0.155852
Epoch: 12 1600/3904 Training loss: 0.122589
Epoch: 12 2400/3904 Training loss: 0.296181
Epoch: 12 3200/3904 Training loss: 0.305200
Training loss: 0.246924
Test loss: 2.911832; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 13 0/3904 Training loss: 0.264221
Epoch: 13 800/3904 Training loss: 0.125705
Epoch: 13 1600/3904 Training loss: 0.129338
Epoch: 13 2400/3904 Training loss: 0.291866
Epoch: 13 3200/3904 Training loss: 0.400808
Training loss: 0.235413
Test loss: 3.054196; True positive: 65; True negative: 148, False Positive: 117, False negative: 838, accuracy: 0.18236301369863014, precision: 0.35714285714285715, recall: 0.07198228128460686
Epoch: 14 0/3904 Training loss: 0.339199
Epoch: 14 800/3904 Training loss: 0.120890
Epoch: 14 1600/3904 Training loss: 0.079890
Epoch: 14 2400/3904 Training loss: 0.245572
Epoch: 14 3200/3904 Training loss: 0.349689
Training loss: 0.239657
Test loss: 3.154341; True positive: 65; True negative: 148, False Positive: 117, False negative: 838, accuracy: 0.18236301369863014, precision: 0.35714285714285715, recall: 0.07198228128460686
Epoch: 15 0/3904 Training loss: 0.201604
Epoch: 15 800/3904 Training loss: 0.137527
Epoch: 15 1600/3904 Training loss: 0.135141
Epoch: 15 2400/3904 Training loss: 0.306611
Epoch: 15 3200/3904 Training loss: 0.399093
Training loss: 0.223405
Test loss: 3.094585; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 16 0/3904 Training loss: 0.404260
Epoch: 16 800/3904 Training loss: 0.120743
Epoch: 16 1600/3904 Training loss: 0.130194
Epoch: 16 2400/3904 Training loss: 0.312514
Epoch: 16 3200/3904 Training loss: 0.314451
Training loss: 0.215058
Test loss: 3.406334; True positive: 65; True negative: 148, False Positive: 117, False negative: 838, accuracy: 0.18236301369863014, precision: 0.35714285714285715, recall: 0.07198228128460686
Epoch: 17 0/3904 Training loss: 0.460995
Epoch: 17 800/3904 Training loss: 0.099717
Epoch: 17 1600/3904 Training loss: 0.082112
Epoch: 17 2400/3904 Training loss: 0.257111
Epoch: 17 3200/3904 Training loss: 0.399373
Training loss: 0.207988
Test loss: 3.273062; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
starting trial 211
[I 2022-12-05 05:49:25,573] Trial 210 finished with value: 0.7328767123287672 and parameters: {'d_model': 64, 'nhead': 8, 'n_encoders': 2, 'learning_rate': 6.367126263808106e-05, 'weight_decay': 2.173384220244797e-06, 'dropout': 0.18313014508618483, 'max_pool_conv': 16, 'kernel_size': 14, 'd_mlp': 16, 'num_conv_layers': 3, 'encoder_dropout': 0.08600862271345286, 'd_feed_forward': 128, 'max_pool_dim': 8, 'n_mlp_layers': 3}. Best is trial 62 with value: 0.860445205479452.
Epoch: 0 0/3904 Training loss: 0.701829
Epoch: 0 800/3904 Training loss: 0.738113
Epoch: 0 1600/3904 Training loss: 0.465016
Epoch: 0 2400/3904 Training loss: 0.803617
Epoch: 0 3200/3904 Training loss: 0.551205
Training loss: 0.662186
Test loss: 0.840056; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 1 0/3904 Training loss: 0.720030
Epoch: 1 800/3904 Training loss: 0.735218
Epoch: 1 1600/3904 Training loss: 0.439427
Epoch: 1 2400/3904 Training loss: 0.790571
Epoch: 1 3200/3904 Training loss: 0.523256
Training loss: 0.650149
Test loss: 0.755084; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 2 0/3904 Training loss: 0.702779
Epoch: 2 800/3904 Training loss: 0.660218
Epoch: 2 1600/3904 Training loss: 0.268460
Epoch: 2 2400/3904 Training loss: 0.836530
Epoch: 2 3200/3904 Training loss: 0.364863
Training loss: 0.551415
Test loss: 0.558987; True positive: 903; True negative: 0, False Positive: 265, False negative: 0, accuracy: 0.7731164383561644, precision: 0.7731164383561644, recall: 1.0
Epoch: 3 0/3904 Training loss: 0.462718
Epoch: 3 800/3904 Training loss: 0.428425
Epoch: 3 1600/3904 Training loss: 0.226367
Epoch: 3 2400/3904 Training loss: 0.605025
Epoch: 3 3200/3904 Training loss: 0.463441
Training loss: 0.441967
Test loss: 0.539297; True positive: 903; True negative: 0, False Positive: 265, False negative: 0, accuracy: 0.7731164383561644, precision: 0.7731164383561644, recall: 1.0
Epoch: 4 0/3904 Training loss: 0.382868
Epoch: 4 800/3904 Training loss: 0.360090
Epoch: 4 1600/3904 Training loss: 0.209794
Epoch: 4 2400/3904 Training loss: 0.395017
Epoch: 4 3200/3904 Training loss: 0.436231
Training loss: 0.414863
Test loss: 0.535402; True positive: 903; True negative: 0, False Positive: 265, False negative: 0, accuracy: 0.7731164383561644, precision: 0.7731164383561644, recall: 1.0
Epoch: 5 0/3904 Training loss: 0.368336
Epoch: 5 800/3904 Training loss: 0.401795
Epoch: 5 1600/3904 Training loss: 0.182935
Epoch: 5 2400/3904 Training loss: 0.357935
Epoch: 5 3200/3904 Training loss: 0.441376
Training loss: 0.406092
Test loss: 0.534398; True positive: 903; True negative: 0, False Positive: 265, False negative: 0, accuracy: 0.7731164383561644, precision: 0.7731164383561644, recall: 1.0
Epoch: 6 0/3904 Training loss: 0.464490
Epoch: 6 800/3904 Training loss: 0.343861
Epoch: 6 1600/3904 Training loss: 0.197276
Epoch: 6 2400/3904 Training loss: 0.292920
Epoch: 6 3200/3904 Training loss: 0.389626
Training loss: 0.390598
Test loss: 0.570279; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 7 0/3904 Training loss: 0.394173
Epoch: 7 800/3904 Training loss: 0.305755
Epoch: 7 1600/3904 Training loss: 0.191762
Epoch: 7 2400/3904 Training loss: 0.349815
Epoch: 7 3200/3904 Training loss: 0.328668
Training loss: 0.374963
Test loss: 0.524828; True positive: 903; True negative: 0, False Positive: 265, False negative: 0, accuracy: 0.7731164383561644, precision: 0.7731164383561644, recall: 1.0
Epoch: 8 0/3904 Training loss: 0.487032
Epoch: 8 800/3904 Training loss: 0.224337
Epoch: 8 1600/3904 Training loss: 0.134389
Epoch: 8 2400/3904 Training loss: 0.297994
Epoch: 8 3200/3904 Training loss: 0.414730
Training loss: 0.375122
Test loss: 0.562281; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 9 0/3904 Training loss: 0.481028
Epoch: 9 800/3904 Training loss: 0.207881
Epoch: 9 1600/3904 Training loss: 0.199597
Epoch: 9 2400/3904 Training loss: 0.324713
Epoch: 9 3200/3904 Training loss: 0.376776
Training loss: 0.369146
Test loss: 0.563167; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 10 0/3904 Training loss: 0.364149
Epoch: 10 800/3904 Training loss: 0.253168
Epoch: 10 1600/3904 Training loss: 0.157406
Epoch: 10 2400/3904 Training loss: 0.338213
Epoch: 10 3200/3904 Training loss: 0.430246
Training loss: 0.367087
Test loss: 0.566931; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 11 0/3904 Training loss: 0.370027
Epoch: 11 800/3904 Training loss: 0.263225
Epoch: 11 1600/3904 Training loss: 0.176964
Epoch: 11 2400/3904 Training loss: 0.241308
Epoch: 11 3200/3904 Training loss: 0.417805
Training loss: 0.354590
Test loss: 0.557742; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 12 0/3904 Training loss: 0.372363
Epoch: 12 800/3904 Training loss: 0.231406
Epoch: 12 1600/3904 Training loss: 0.136451
Epoch: 12 2400/3904 Training loss: 0.338941
Epoch: 12 3200/3904 Training loss: 0.359306
Training loss: 0.354549
Test loss: 0.559466; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 13 0/3904 Training loss: 0.373483
Epoch: 13 800/3904 Training loss: 0.211856
Epoch: 13 1600/3904 Training loss: 0.129873
Epoch: 13 2400/3904 Training loss: 0.312764
Epoch: 13 3200/3904 Training loss: 0.374198
Training loss: 0.347842
Test loss: 0.556985; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 14 0/3904 Training loss: 0.320513
Epoch: 14 800/3904 Training loss: 0.169522
Epoch: 14 1600/3904 Training loss: 0.144930
Epoch: 14 2400/3904 Training loss: 0.305029
Epoch: 14 3200/3904 Training loss: 0.371151
Training loss: 0.341010
Test loss: 0.555859; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 15 0/3904 Training loss: 0.322367
Epoch: 15 800/3904 Training loss: 0.213900
Epoch: 15 1600/3904 Training loss: 0.159355
Epoch: 15 2400/3904 Training loss: 0.252924
Epoch: 15 3200/3904 Training loss: 0.375284
Training loss: 0.338292
Test loss: 0.554290; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 16 0/3904 Training loss: 0.344167
Epoch: 16 800/3904 Training loss: 0.198755
Epoch: 16 1600/3904 Training loss: 0.145707
Epoch: 16 2400/3904 Training loss: 0.251244
Epoch: 16 3200/3904 Training loss: 0.339225
Training loss: 0.342895
Test loss: 0.559206; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 17 0/3904 Training loss: 0.256335
Epoch: 17 800/3904 Training loss: 0.174653
Epoch: 17 1600/3904 Training loss: 0.140423
Epoch: 17 2400/3904 Training loss: 0.214104
Epoch: 17 3200/3904 Training loss: 0.306569
Training loss: 0.335587
Test loss: 0.562169; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
starting trial 212
[I 2022-12-05 05:53:10,761] Trial 211 finished with value: 0.8176369863013698 and parameters: {'d_model': 64, 'nhead': 8, 'n_encoders': 1, 'learning_rate': 8.653234088542413e-05, 'weight_decay': 3.2239619271770193e-06, 'dropout': 0.21145979160427095, 'max_pool_conv': 16, 'kernel_size': 13, 'd_mlp': 16, 'num_conv_layers': 7, 'encoder_dropout': 0.11787887827292672, 'd_feed_forward': 128, 'max_pool_dim': 8, 'n_mlp_layers': 3}. Best is trial 62 with value: 0.860445205479452.
Epoch: 0 0/3904 Training loss: 0.694970
Epoch: 0 800/3904 Training loss: 0.733541
Epoch: 0 1600/3904 Training loss: 0.445801
Epoch: 0 2400/3904 Training loss: 0.796250
Epoch: 0 3200/3904 Training loss: 0.557745
Training loss: 0.663869
Test loss: 0.815222; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 1 0/3904 Training loss: 0.719701
Epoch: 1 800/3904 Training loss: 0.727573
Epoch: 1 1600/3904 Training loss: 0.446578
Epoch: 1 2400/3904 Training loss: 0.795396
Epoch: 1 3200/3904 Training loss: 0.545522
Training loss: 0.661528
Test loss: 0.809683; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 2 0/3904 Training loss: 0.709656
Epoch: 2 800/3904 Training loss: 0.724754
Epoch: 2 1600/3904 Training loss: 0.417184
Epoch: 2 2400/3904 Training loss: 0.752875
Epoch: 2 3200/3904 Training loss: 0.478455
Training loss: 0.642313
Test loss: 0.702578; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 3 0/3904 Training loss: 0.626426
Epoch: 3 800/3904 Training loss: 0.640093
Epoch: 3 1600/3904 Training loss: 0.250181
Epoch: 3 2400/3904 Training loss: 0.825014
Epoch: 3 3200/3904 Training loss: 0.376014
Training loss: 0.545415
Test loss: 0.582565; True positive: 903; True negative: 0, False Positive: 265, False negative: 0, accuracy: 0.7731164383561644, precision: 0.7731164383561644, recall: 1.0
Epoch: 4 0/3904 Training loss: 0.509004
Epoch: 4 800/3904 Training loss: 0.481405
Epoch: 4 1600/3904 Training loss: 0.241969
Epoch: 4 2400/3904 Training loss: 0.621153
Epoch: 4 3200/3904 Training loss: 0.410931
Training loss: 0.483604
Test loss: 0.582188; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 5 0/3904 Training loss: 0.477660
Epoch: 5 800/3904 Training loss: 0.564005
Epoch: 5 1600/3904 Training loss: 0.245513
Epoch: 5 2400/3904 Training loss: 0.458621
Epoch: 5 3200/3904 Training loss: 0.380255
Training loss: 0.447943
Test loss: 0.590085; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 6 0/3904 Training loss: 0.389426
Epoch: 6 800/3904 Training loss: 0.422622
Epoch: 6 1600/3904 Training loss: 0.186361
Epoch: 6 2400/3904 Training loss: 0.379023
Epoch: 6 3200/3904 Training loss: 0.296805
Training loss: 0.419167
Test loss: 0.602568; True positive: 826; True negative: 121, False Positive: 144, False negative: 77, accuracy: 0.8107876712328768, precision: 0.8515463917525773, recall: 0.9147286821705426
Epoch: 7 0/3904 Training loss: 0.373657
Epoch: 7 800/3904 Training loss: 0.461780
Epoch: 7 1600/3904 Training loss: 0.230886
Epoch: 7 2400/3904 Training loss: 0.334174
Epoch: 7 3200/3904 Training loss: 0.429826
Training loss: 0.401584
Test loss: 0.596645; True positive: 835; True negative: 119, False Positive: 146, False negative: 68, accuracy: 0.8167808219178082, precision: 0.8511722731906218, recall: 0.9246954595791805
Epoch: 8 0/3904 Training loss: 0.331911
Epoch: 8 800/3904 Training loss: 0.359231
Epoch: 8 1600/3904 Training loss: 0.195798
Epoch: 8 2400/3904 Training loss: 0.260932
Epoch: 8 3200/3904 Training loss: 0.348445
Training loss: 0.389407
Test loss: 0.610986; True positive: 814; True negative: 136, False Positive: 129, False negative: 89, accuracy: 0.8133561643835616, precision: 0.8632025450689289, recall: 0.9014396456256921
Epoch: 9 0/3904 Training loss: 0.437712
Epoch: 9 800/3904 Training loss: 0.358116
Epoch: 9 1600/3904 Training loss: 0.198727
Epoch: 9 2400/3904 Training loss: 0.254857
Epoch: 9 3200/3904 Training loss: 0.415673
Training loss: 0.389322
Test loss: 0.610379; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 10 0/3904 Training loss: 0.333214
Epoch: 10 800/3904 Training loss: 0.335431
Epoch: 10 1600/3904 Training loss: 0.170593
Epoch: 10 2400/3904 Training loss: 0.285341
Epoch: 10 3200/3904 Training loss: 0.356292
Training loss: 0.388321
Test loss: 0.614718; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 11 0/3904 Training loss: 0.397072
Epoch: 11 800/3904 Training loss: 0.325708
Epoch: 11 1600/3904 Training loss: 0.134767
Epoch: 11 2400/3904 Training loss: 0.236522
Epoch: 11 3200/3904 Training loss: 0.378320
Training loss: 0.367931
Test loss: 0.621654; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 12 0/3904 Training loss: 0.315590
Epoch: 12 800/3904 Training loss: 0.298747
Epoch: 12 1600/3904 Training loss: 0.115147
Epoch: 12 2400/3904 Training loss: 0.214036
Epoch: 12 3200/3904 Training loss: 0.335727
Training loss: 0.371431
Test loss: 0.621496; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 13 0/3904 Training loss: 0.333007
Epoch: 13 800/3904 Training loss: 0.398210
Epoch: 13 1600/3904 Training loss: 0.145329
Epoch: 13 2400/3904 Training loss: 0.190869
Epoch: 13 3200/3904 Training loss: 0.456162
Training loss: 0.360652
Test loss: 0.619272; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 14 0/3904 Training loss: 0.360954
Epoch: 14 800/3904 Training loss: 0.243775
Epoch: 14 1600/3904 Training loss: 0.129051
Epoch: 14 2400/3904 Training loss: 0.185531
Epoch: 14 3200/3904 Training loss: 0.456310
Training loss: 0.356879
Test loss: 0.620998; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
starting trial 213
[I 2022-12-05 05:56:14,631] Trial 212 finished with value: 0.8176369863013698 and parameters: {'d_model': 64, 'nhead': 8, 'n_encoders': 1, 'learning_rate': 7.65045480971483e-05, 'weight_decay': 3.577226343834961e-06, 'dropout': 0.3555579077529023, 'max_pool_conv': 16, 'kernel_size': 12, 'd_mlp': 16, 'num_conv_layers': 7, 'encoder_dropout': 0.1188560659421102, 'd_feed_forward': 128, 'max_pool_dim': 8, 'n_mlp_layers': 3}. Best is trial 62 with value: 0.860445205479452.
Epoch: 0 0/3904 Training loss: 0.695441
Epoch: 0 800/3904 Training loss: 0.736892
Epoch: 0 1600/3904 Training loss: 0.476666
Epoch: 0 2400/3904 Training loss: 0.805835
Epoch: 0 3200/3904 Training loss: 0.532327
Training loss: 0.657765
Test loss: 0.877686; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 1 0/3904 Training loss: 0.715801
Epoch: 1 800/3904 Training loss: 0.719482
Epoch: 1 1600/3904 Training loss: 0.420898
Epoch: 1 2400/3904 Training loss: 0.685963
Epoch: 1 3200/3904 Training loss: 0.482129
Training loss: 0.634069
Test loss: 0.931892; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 2 0/3904 Training loss: 0.641352
Epoch: 2 800/3904 Training loss: 0.621147
Epoch: 2 1600/3904 Training loss: 0.353297
Epoch: 2 2400/3904 Training loss: 0.534203
Epoch: 2 3200/3904 Training loss: 0.414976
Training loss: 0.561236
Test loss: 1.099106; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 3 0/3904 Training loss: 0.507216
Epoch: 3 800/3904 Training loss: 0.489751
Epoch: 3 1600/3904 Training loss: 0.272658
Epoch: 3 2400/3904 Training loss: 0.534329
Epoch: 3 3200/3904 Training loss: 0.406345
Training loss: 0.473475
Test loss: 1.340967; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 4 0/3904 Training loss: 0.433100
Epoch: 4 800/3904 Training loss: 0.434899
Epoch: 4 1600/3904 Training loss: 0.236802
Epoch: 4 2400/3904 Training loss: 0.556113
Epoch: 4 3200/3904 Training loss: 0.287172
Training loss: 0.421103
Test loss: 1.531015; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 5 0/3904 Training loss: 0.315652
Epoch: 5 800/3904 Training loss: 0.496245
Epoch: 5 1600/3904 Training loss: 0.175813
Epoch: 5 2400/3904 Training loss: 0.571484
Epoch: 5 3200/3904 Training loss: 0.370065
Training loss: 0.387980
Test loss: 1.729387; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 6 0/3904 Training loss: 0.324431
Epoch: 6 800/3904 Training loss: 0.424793
Epoch: 6 1600/3904 Training loss: 0.202964
Epoch: 6 2400/3904 Training loss: 0.523879
Epoch: 6 3200/3904 Training loss: 0.343484
Training loss: 0.357580
Test loss: 1.392506; True positive: 2; True negative: 264, False Positive: 1, False negative: 901, accuracy: 0.22773972602739725, precision: 0.6666666666666666, recall: 0.0022148394241417496
Epoch: 7 0/3904 Training loss: 0.322705
Epoch: 7 800/3904 Training loss: 0.287340
Epoch: 7 1600/3904 Training loss: 0.124294
Epoch: 7 2400/3904 Training loss: 0.443891
Epoch: 7 3200/3904 Training loss: 0.507684
Training loss: 0.334580
Test loss: 0.811820; True positive: 477; True negative: 221, False Positive: 44, False negative: 426, accuracy: 0.5976027397260274, precision: 0.9155470249520153, recall: 0.5282392026578073
Epoch: 8 0/3904 Training loss: 0.335991
Epoch: 8 800/3904 Training loss: 0.244780
Epoch: 8 1600/3904 Training loss: 0.159702
Epoch: 8 2400/3904 Training loss: 0.451511
Epoch: 8 3200/3904 Training loss: 0.503281
Training loss: 0.317083
Test loss: 0.590301; True positive: 595; True negative: 208, False Positive: 57, False negative: 308, accuracy: 0.6875, precision: 0.9125766871165644, recall: 0.6589147286821705
Epoch: 9 0/3904 Training loss: 0.354886
Epoch: 9 800/3904 Training loss: 0.227034
Epoch: 9 1600/3904 Training loss: 0.134765
Epoch: 9 2400/3904 Training loss: 0.398828
Epoch: 9 3200/3904 Training loss: 0.404156
Training loss: 0.299189
Test loss: 0.515644; True positive: 697; True negative: 154, False Positive: 111, False negative: 206, accuracy: 0.728595890410959, precision: 0.8626237623762376, recall: 0.7718715393133998
Epoch: 10 0/3904 Training loss: 0.316769
Epoch: 10 800/3904 Training loss: 0.282551
Epoch: 10 1600/3904 Training loss: 0.128166
Epoch: 10 2400/3904 Training loss: 0.249056
Epoch: 10 3200/3904 Training loss: 0.259256
Training loss: 0.292864
Test loss: 0.519631; True positive: 677; True negative: 162, False Positive: 103, False negative: 226, accuracy: 0.7183219178082192, precision: 0.867948717948718, recall: 0.7497231450719822
Epoch: 11 0/3904 Training loss: 0.310492
Epoch: 11 800/3904 Training loss: 0.266440
Epoch: 11 1600/3904 Training loss: 0.069623
Epoch: 11 2400/3904 Training loss: 0.386047
Epoch: 11 3200/3904 Training loss: 0.363584
Training loss: 0.270989
Test loss: 0.506280; True positive: 721; True negative: 143, False Positive: 122, False negative: 182, accuracy: 0.7397260273972602, precision: 0.8552787663107948, recall: 0.7984496124031008
Epoch: 12 0/3904 Training loss: 0.287506
Epoch: 12 800/3904 Training loss: 0.202562
Epoch: 12 1600/3904 Training loss: 0.069894
Epoch: 12 2400/3904 Training loss: 0.253115
Epoch: 12 3200/3904 Training loss: 0.360732
Training loss: 0.266382
Test loss: 0.485150; True positive: 801; True negative: 131, False Positive: 134, False negative: 102, accuracy: 0.797945205479452, precision: 0.8566844919786096, recall: 0.8870431893687708
Epoch: 13 0/3904 Training loss: 0.335048
Epoch: 13 800/3904 Training loss: 0.241786
Epoch: 13 1600/3904 Training loss: 0.145992
Epoch: 13 2400/3904 Training loss: 0.181887
Epoch: 13 3200/3904 Training loss: 0.424829
Training loss: 0.252464
Test loss: 0.518348; True positive: 667; True negative: 164, False Positive: 101, False negative: 236, accuracy: 0.711472602739726, precision: 0.8684895833333334, recall: 0.7386489479512736
Epoch: 14 0/3904 Training loss: 0.258720
Epoch: 14 800/3904 Training loss: 0.271002
Epoch: 14 1600/3904 Training loss: 0.190420
Epoch: 14 2400/3904 Training loss: 0.120130
Epoch: 14 3200/3904 Training loss: 0.468617
Training loss: 0.246699
Test loss: 0.622973; True positive: 572; True negative: 212, False Positive: 53, False negative: 331, accuracy: 0.6712328767123288, precision: 0.9152, recall: 0.6334440753045404
Epoch: 15 0/3904 Training loss: 0.233019
Epoch: 15 800/3904 Training loss: 0.203204
Epoch: 15 1600/3904 Training loss: 0.072660
Epoch: 15 2400/3904 Training loss: 0.371871
Epoch: 15 3200/3904 Training loss: 0.316778
Training loss: 0.245618
Test loss: 0.672085; True positive: 570; True negative: 215, False Positive: 50, False negative: 333, accuracy: 0.6720890410958904, precision: 0.9193548387096774, recall: 0.6312292358803987
Epoch: 16 0/3904 Training loss: 0.233121
Epoch: 16 800/3904 Training loss: 0.242755
Epoch: 16 1600/3904 Training loss: 0.098012
Epoch: 16 2400/3904 Training loss: 0.143084
Epoch: 16 3200/3904 Training loss: 0.283665
Training loss: 0.233004
Test loss: 0.639047; True positive: 572; True negative: 213, False Positive: 52, False negative: 331, accuracy: 0.6720890410958904, precision: 0.9166666666666666, recall: 0.6334440753045404
Epoch: 17 0/3904 Training loss: 0.146656
Epoch: 17 800/3904 Training loss: 0.239020
Epoch: 17 1600/3904 Training loss: 0.087194
Epoch: 17 2400/3904 Training loss: 0.090045
Epoch: 17 3200/3904 Training loss: 0.399243
Training loss: 0.222006
Test loss: 0.587177; True positive: 581; True negative: 207, False Positive: 58, False negative: 322, accuracy: 0.6746575342465754, precision: 0.9092331768388107, recall: 0.6434108527131783
Epoch: 18 0/3904 Training loss: 0.240109
Epoch: 18 800/3904 Training loss: 0.185323
Epoch: 18 1600/3904 Training loss: 0.053199
Epoch: 18 2400/3904 Training loss: 0.094110
Epoch: 18 3200/3904 Training loss: 0.428354
Training loss: 0.209777
Test loss: 0.535867; True positive: 637; True negative: 174, False Positive: 91, False negative: 266, accuracy: 0.6943493150684932, precision: 0.875, recall: 0.7054263565891473
Epoch: 19 0/3904 Training loss: 0.258580
Epoch: 19 800/3904 Training loss: 0.201551
Epoch: 19 1600/3904 Training loss: 0.091495
Epoch: 19 2400/3904 Training loss: 0.075370
Epoch: 19 3200/3904 Training loss: 0.188188
Training loss: 0.202860
Test loss: 0.464548; True positive: 831; True negative: 119, False Positive: 146, False negative: 72, accuracy: 0.8133561643835616, precision: 0.8505629477993859, recall: 0.920265780730897
Epoch: 20 0/3904 Training loss: 0.144176
Epoch: 20 800/3904 Training loss: 0.271455
Epoch: 20 1600/3904 Training loss: 0.052818
Epoch: 20 2400/3904 Training loss: 0.131737
Epoch: 20 3200/3904 Training loss: 0.314209
Training loss: 0.205234
Test loss: 0.535632; True positive: 663; True negative: 162, False Positive: 103, False negative: 240, accuracy: 0.7063356164383562, precision: 0.8655352480417755, recall: 0.7342192691029901
Epoch: 21 0/3904 Training loss: 0.245166
Epoch: 21 800/3904 Training loss: 0.286860
Epoch: 21 1600/3904 Training loss: 0.059611
Epoch: 21 2400/3904 Training loss: 0.078330
Epoch: 21 3200/3904 Training loss: 0.354658
Training loss: 0.201236
Test loss: 0.929306; True positive: 267; True negative: 238, False Positive: 27, False negative: 636, accuracy: 0.4323630136986301, precision: 0.9081632653061225, recall: 0.2956810631229236
Epoch: 22 0/3904 Training loss: 0.085736
Epoch: 22 800/3904 Training loss: 0.247695
Epoch: 22 1600/3904 Training loss: 0.061306
Epoch: 22 2400/3904 Training loss: 0.097616
Epoch: 22 3200/3904 Training loss: 0.192466
Training loss: 0.189154
Test loss: 0.536049; True positive: 654; True negative: 164, False Positive: 101, False negative: 249, accuracy: 0.7003424657534246, precision: 0.866225165562914, recall: 0.7242524916943521
Epoch: 23 0/3904 Training loss: 0.180463
Epoch: 23 800/3904 Training loss: 0.405331
Epoch: 23 1600/3904 Training loss: 0.052159
Epoch: 23 2400/3904 Training loss: 0.084221
Epoch: 23 3200/3904 Training loss: 0.128159
Training loss: 0.187637
Test loss: 0.704860; True positive: 562; True negative: 211, False Positive: 54, False negative: 341, accuracy: 0.6618150684931506, precision: 0.9123376623376623, recall: 0.6223698781838317
Epoch: 24 0/3904 Training loss: 0.050706
Epoch: 24 800/3904 Training loss: 0.219167
Epoch: 24 1600/3904 Training loss: 0.048654
Epoch: 24 2400/3904 Training loss: 0.086726
Epoch: 24 3200/3904 Training loss: 0.281326
Training loss: 0.170122
Test loss: 1.108151; True positive: 89; True negative: 251, False Positive: 14, False negative: 814, accuracy: 0.2910958904109589, precision: 0.8640776699029126, recall: 0.09856035437430787
Epoch: 25 0/3904 Training loss: 0.115195
Epoch: 25 800/3904 Training loss: 0.251845
Epoch: 25 1600/3904 Training loss: 0.075557
Epoch: 25 2400/3904 Training loss: 0.120848
Epoch: 25 3200/3904 Training loss: 0.390654
Training loss: 0.173019
Test loss: 0.767700; True positive: 502; True negative: 217, False Positive: 48, False negative: 401, accuracy: 0.615582191780822, precision: 0.9127272727272727, recall: 0.5559246954595792
Epoch: 26 0/3904 Training loss: 0.259923
Epoch: 26 800/3904 Training loss: 0.234953
Epoch: 26 1600/3904 Training loss: 0.031559
Epoch: 26 2400/3904 Training loss: 0.028167
Epoch: 26 3200/3904 Training loss: 0.179595
Training loss: 0.162862
Test loss: 0.724090; True positive: 548; True negative: 217, False Positive: 48, False negative: 355, accuracy: 0.6549657534246576, precision: 0.9194630872483222, recall: 0.6068660022148394
Epoch: 27 0/3904 Training loss: 0.188256
Epoch: 27 800/3904 Training loss: 0.218907
Epoch: 27 1600/3904 Training loss: 0.095579
Epoch: 27 2400/3904 Training loss: 0.027469
Epoch: 27 3200/3904 Training loss: 0.133102
Training loss: 0.165284
Test loss: 0.483720; True positive: 814; True negative: 120, False Positive: 145, False negative: 89, accuracy: 0.7996575342465754, precision: 0.848800834202294, recall: 0.9014396456256921
Epoch: 28 0/3904 Training loss: 0.129971
Epoch: 28 800/3904 Training loss: 0.214922
Epoch: 28 1600/3904 Training loss: 0.053562
Epoch: 28 2400/3904 Training loss: 0.068879
Epoch: 28 3200/3904 Training loss: 0.344646
Training loss: 0.150776
Test loss: 0.467488; True positive: 820; True negative: 120, False Positive: 145, False negative: 83, accuracy: 0.8047945205479452, precision: 0.8497409326424871, recall: 0.9080841638981174
Epoch: 29 0/3904 Training loss: 0.173650
Epoch: 29 800/3904 Training loss: 0.192068
Epoch: 29 1600/3904 Training loss: 0.056507
Epoch: 29 2400/3904 Training loss: 0.153243
Epoch: 29 3200/3904 Training loss: 0.323232
Training loss: 0.150724
Test loss: 0.693556; True positive: 562; True negative: 215, False Positive: 50, False negative: 341, accuracy: 0.6652397260273972, precision: 0.9183006535947712, recall: 0.6223698781838317
starting trial 214
[I 2022-12-05 05:57:37,734] Trial 213 finished with value: 0.8133561643835616 and parameters: {'d_model': 64, 'nhead': 8, 'n_encoders': 1, 'learning_rate': 0.00011437898439073597, 'weight_decay': 4.555902042709825e-06, 'dropout': 0.22539671463784966, 'max_pool_conv': 64, 'kernel_size': 6, 'd_mlp': 16, 'num_conv_layers': 2, 'encoder_dropout': 0.07014438576236233, 'd_feed_forward': 128, 'max_pool_dim': 8, 'n_mlp_layers': 3}. Best is trial 62 with value: 0.860445205479452.
Epoch: 0 0/3904 Training loss: 0.699420
Epoch: 0 800/3904 Training loss: 0.726792
Epoch: 0 1600/3904 Training loss: 0.449591
Epoch: 0 2400/3904 Training loss: 0.828629
Epoch: 0 3200/3904 Training loss: 0.560801
Training loss: 0.664062
Test loss: 0.798057; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 1 0/3904 Training loss: 0.706778
Epoch: 1 800/3904 Training loss: 0.724038
Epoch: 1 1600/3904 Training loss: 0.433532
Epoch: 1 2400/3904 Training loss: 0.767825
Epoch: 1 3200/3904 Training loss: 0.540796
Training loss: 0.652657
Test loss: 0.899771; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 2 0/3904 Training loss: 0.691113
Epoch: 2 800/3904 Training loss: 0.703385
Epoch: 2 1600/3904 Training loss: 0.359709
Epoch: 2 2400/3904 Training loss: 0.648609
Epoch: 2 3200/3904 Training loss: 0.419482
Training loss: 0.605609
Test loss: 1.301325; True positive: 8; True negative: 259, False Positive: 6, False negative: 895, accuracy: 0.2285958904109589, precision: 0.5714285714285714, recall: 0.008859357696566999
Epoch: 3 0/3904 Training loss: 0.615270
Epoch: 3 800/3904 Training loss: 0.581176
Epoch: 3 1600/3904 Training loss: 0.271692
Epoch: 3 2400/3904 Training loss: 0.495397
Epoch: 3 3200/3904 Training loss: 0.384462
Training loss: 0.519478
Test loss: 1.864736; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 4 0/3904 Training loss: 0.447427
Epoch: 4 800/3904 Training loss: 0.546030
Epoch: 4 1600/3904 Training loss: 0.248660
Epoch: 4 2400/3904 Training loss: 0.441751
Epoch: 4 3200/3904 Training loss: 0.345513
Training loss: 0.465049
Test loss: 2.136545; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 5 0/3904 Training loss: 0.361920
Epoch: 5 800/3904 Training loss: 0.477746
Epoch: 5 1600/3904 Training loss: 0.225489
Epoch: 5 2400/3904 Training loss: 0.472613
Epoch: 5 3200/3904 Training loss: 0.363835
Training loss: 0.424224
Test loss: 2.343438; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 6 0/3904 Training loss: 0.307057
Epoch: 6 800/3904 Training loss: 0.428558
Epoch: 6 1600/3904 Training loss: 0.208564
Epoch: 6 2400/3904 Training loss: 0.418366
Epoch: 6 3200/3904 Training loss: 0.354432
Training loss: 0.402218
Test loss: 2.772434; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 7 0/3904 Training loss: 0.352954
Epoch: 7 800/3904 Training loss: 0.329018
Epoch: 7 1600/3904 Training loss: 0.127994
Epoch: 7 2400/3904 Training loss: 0.484687
Epoch: 7 3200/3904 Training loss: 0.303048
Training loss: 0.382706
Test loss: 3.065545; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 8 0/3904 Training loss: 0.290660
Epoch: 8 800/3904 Training loss: 0.422574
Epoch: 8 1600/3904 Training loss: 0.196790
Epoch: 8 2400/3904 Training loss: 0.439367
Epoch: 8 3200/3904 Training loss: 0.437153
Training loss: 0.352516
Test loss: 2.469551; True positive: 2; True negative: 265, False Positive: 0, False negative: 901, accuracy: 0.2285958904109589, precision: 1.0, recall: 0.0022148394241417496
Epoch: 9 0/3904 Training loss: 0.328150
Epoch: 9 800/3904 Training loss: 0.282786
Epoch: 9 1600/3904 Training loss: 0.137389
Epoch: 9 2400/3904 Training loss: 0.377799
Epoch: 9 3200/3904 Training loss: 0.402338
Training loss: 0.325507
Test loss: 0.905427; True positive: 387; True negative: 187, False Positive: 78, False negative: 516, accuracy: 0.4914383561643836, precision: 0.832258064516129, recall: 0.42857142857142855
Epoch: 10 0/3904 Training loss: 0.303230
Epoch: 10 800/3904 Training loss: 0.207363
Epoch: 10 1600/3904 Training loss: 0.180757
Epoch: 10 2400/3904 Training loss: 0.394334
Epoch: 10 3200/3904 Training loss: 0.440611
Training loss: 0.317864
Test loss: 0.589583; True positive: 829; True negative: 119, False Positive: 146, False negative: 74, accuracy: 0.8116438356164384, precision: 0.8502564102564103, recall: 0.9180509413067552
Epoch: 11 0/3904 Training loss: 0.330663
Epoch: 11 800/3904 Training loss: 0.275291
Epoch: 11 1600/3904 Training loss: 0.089646
Epoch: 11 2400/3904 Training loss: 0.331556
Epoch: 11 3200/3904 Training loss: 0.453978
Training loss: 0.305789
Test loss: 0.565316; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 12 0/3904 Training loss: 0.256972
Epoch: 12 800/3904 Training loss: 0.204826
Epoch: 12 1600/3904 Training loss: 0.093124
Epoch: 12 2400/3904 Training loss: 0.199734
Epoch: 12 3200/3904 Training loss: 0.348448
Training loss: 0.298956
Test loss: 0.573350; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 13 0/3904 Training loss: 0.211332
Epoch: 13 800/3904 Training loss: 0.277827
Epoch: 13 1600/3904 Training loss: 0.052849
Epoch: 13 2400/3904 Training loss: 0.333632
Epoch: 13 3200/3904 Training loss: 0.344795
Training loss: 0.278224
Test loss: 0.572888; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 14 0/3904 Training loss: 0.223447
Epoch: 14 800/3904 Training loss: 0.165213
Epoch: 14 1600/3904 Training loss: 0.142731
Epoch: 14 2400/3904 Training loss: 0.272043
Epoch: 14 3200/3904 Training loss: 0.252705
Training loss: 0.277594
Test loss: 0.589715; True positive: 836; True negative: 118, False Positive: 147, False negative: 67, accuracy: 0.8167808219178082, precision: 0.8504577822990844, recall: 0.9258028792912514
Epoch: 15 0/3904 Training loss: 0.284926
Epoch: 15 800/3904 Training loss: 0.128609
Epoch: 15 1600/3904 Training loss: 0.117507
Epoch: 15 2400/3904 Training loss: 0.358081
Epoch: 15 3200/3904 Training loss: 0.322051
Training loss: 0.261711
Test loss: 1.332328; True positive: 64; True negative: 262, False Positive: 3, False negative: 839, accuracy: 0.2791095890410959, precision: 0.9552238805970149, recall: 0.07087486157253599
Epoch: 16 0/3904 Training loss: 0.437480
Epoch: 16 800/3904 Training loss: 0.163644
Epoch: 16 1600/3904 Training loss: 0.051388
Epoch: 16 2400/3904 Training loss: 0.258069
Epoch: 16 3200/3904 Training loss: 0.263651
Training loss: 0.249834
Test loss: 2.304598; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 17 0/3904 Training loss: 0.174103
Epoch: 17 800/3904 Training loss: 0.225637
Epoch: 17 1600/3904 Training loss: 0.082783
Epoch: 17 2400/3904 Training loss: 0.310706
Epoch: 17 3200/3904 Training loss: 0.394511
Training loss: 0.250982
Test loss: 2.662926; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 18 0/3904 Training loss: 0.227327
Epoch: 18 800/3904 Training loss: 0.077160
Epoch: 18 1600/3904 Training loss: 0.091362
Epoch: 18 2400/3904 Training loss: 0.198281
Epoch: 18 3200/3904 Training loss: 0.347387
Training loss: 0.228559
Test loss: 2.498689; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 19 0/3904 Training loss: 0.211152
Epoch: 19 800/3904 Training loss: 0.228164
Epoch: 19 1600/3904 Training loss: 0.043150
Epoch: 19 2400/3904 Training loss: 0.115659
Epoch: 19 3200/3904 Training loss: 0.249391
Training loss: 0.235938
Test loss: 1.931674; True positive: 5; True negative: 264, False Positive: 1, False negative: 898, accuracy: 0.2303082191780822, precision: 0.8333333333333334, recall: 0.005537098560354375
Epoch: 20 0/3904 Training loss: 0.163867
Epoch: 20 800/3904 Training loss: 0.147259
Epoch: 20 1600/3904 Training loss: 0.118405
Epoch: 20 2400/3904 Training loss: 0.229882
Epoch: 20 3200/3904 Training loss: 0.211848
Training loss: 0.222972
Test loss: 2.658103; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 21 0/3904 Training loss: 0.212352
Epoch: 21 800/3904 Training loss: 0.149742
Epoch: 21 1600/3904 Training loss: 0.050931
Epoch: 21 2400/3904 Training loss: 0.123228
Epoch: 21 3200/3904 Training loss: 0.187186
Training loss: 0.213465
Test loss: 2.496930; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
starting trial 215
[I 2022-12-05 05:58:48,187] Trial 214 finished with value: 0.8176369863013698 and parameters: {'d_model': 64, 'nhead': 8, 'n_encoders': 1, 'learning_rate': 0.00012536081579005395, 'weight_decay': 4.2496181300045895e-06, 'dropout': 0.19847977842045103, 'max_pool_conv': 64, 'kernel_size': 5, 'd_mlp': 16, 'num_conv_layers': 3, 'encoder_dropout': 0.10029033860230412, 'd_feed_forward': 128, 'max_pool_dim': 8, 'n_mlp_layers': 3}. Best is trial 62 with value: 0.860445205479452.
Epoch: 0 0/3904 Training loss: 0.703491
Epoch: 0 800/3904 Training loss: 0.726964
Epoch: 0 1600/3904 Training loss: 0.411157
Epoch: 0 2400/3904 Training loss: 0.741094
Epoch: 0 3200/3904 Training loss: 0.520322
Training loss: 0.647820
Test loss: 0.736890; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 1 0/3904 Training loss: 0.648704
Epoch: 1 800/3904 Training loss: 0.616617
Epoch: 1 1600/3904 Training loss: 0.298066
Epoch: 1 2400/3904 Training loss: 0.580266
Epoch: 1 3200/3904 Training loss: 0.324671
Training loss: 0.532776
Test loss: 0.635009; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 2 0/3904 Training loss: 0.406183
Epoch: 2 800/3904 Training loss: 0.357382
Epoch: 2 1600/3904 Training loss: 0.215416
Epoch: 2 2400/3904 Training loss: 0.518349
Epoch: 2 3200/3904 Training loss: 0.355453
Training loss: 0.411844
Test loss: 0.620471; True positive: 837; True negative: 117, False Positive: 148, False negative: 66, accuracy: 0.8167808219178082, precision: 0.849746192893401, recall: 0.9269102990033222
Epoch: 3 0/3904 Training loss: 0.297155
Epoch: 3 800/3904 Training loss: 0.193239
Epoch: 3 1600/3904 Training loss: 0.198933
Epoch: 3 2400/3904 Training loss: 0.477480
Epoch: 3 3200/3904 Training loss: 0.416475
Training loss: 0.358429
Test loss: 0.501860; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 4 0/3904 Training loss: 0.271607
Epoch: 4 800/3904 Training loss: 0.179280
Epoch: 4 1600/3904 Training loss: 0.199178
Epoch: 4 2400/3904 Training loss: 0.393470
Epoch: 4 3200/3904 Training loss: 0.394823
Training loss: 0.312718
Test loss: 0.514761; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 5 0/3904 Training loss: 0.303862
Epoch: 5 800/3904 Training loss: 0.186691
Epoch: 5 1600/3904 Training loss: 0.123419
Epoch: 5 2400/3904 Training loss: 0.273848
Epoch: 5 3200/3904 Training loss: 0.325567
Training loss: 0.287376
Test loss: 0.660458; True positive: 735; True negative: 157, False Positive: 108, False negative: 168, accuracy: 0.7636986301369864, precision: 0.8718861209964412, recall: 0.813953488372093
Epoch: 6 0/3904 Training loss: 0.235157
Epoch: 6 800/3904 Training loss: 0.158790
Epoch: 6 1600/3904 Training loss: 0.095634
Epoch: 6 2400/3904 Training loss: 0.313844
Epoch: 6 3200/3904 Training loss: 0.556560
Training loss: 0.267513
Test loss: 0.752051; True positive: 233; True negative: 229, False Positive: 36, False negative: 670, accuracy: 0.3955479452054795, precision: 0.8661710037174721, recall: 0.25802879291251385
Epoch: 7 0/3904 Training loss: 0.172747
Epoch: 7 800/3904 Training loss: 0.139898
Epoch: 7 1600/3904 Training loss: 0.099905
Epoch: 7 2400/3904 Training loss: 0.299468
Epoch: 7 3200/3904 Training loss: 0.258682
Training loss: 0.253323
Test loss: 1.075543; True positive: 4; True negative: 265, False Positive: 0, False negative: 899, accuracy: 0.2303082191780822, precision: 1.0, recall: 0.004429678848283499
Epoch: 8 0/3904 Training loss: 0.206281
Epoch: 8 800/3904 Training loss: 0.150993
Epoch: 8 1600/3904 Training loss: 0.079211
Epoch: 8 2400/3904 Training loss: 0.265470
Epoch: 8 3200/3904 Training loss: 0.291157
Training loss: 0.240029
Test loss: 0.961653; True positive: 3; True negative: 265, False Positive: 0, False negative: 900, accuracy: 0.22945205479452055, precision: 1.0, recall: 0.0033222591362126247
Epoch: 9 0/3904 Training loss: 0.164576
Epoch: 9 800/3904 Training loss: 0.128076
Epoch: 9 1600/3904 Training loss: 0.053790
Epoch: 9 2400/3904 Training loss: 0.291780
Epoch: 9 3200/3904 Training loss: 0.274107
Training loss: 0.225742
Test loss: 1.067852; True positive: 4; True negative: 265, False Positive: 0, False negative: 899, accuracy: 0.2303082191780822, precision: 1.0, recall: 0.004429678848283499
Epoch: 10 0/3904 Training loss: 0.177944
Epoch: 10 800/3904 Training loss: 0.129788
Epoch: 10 1600/3904 Training loss: 0.073032
Epoch: 10 2400/3904 Training loss: 0.227086
Epoch: 10 3200/3904 Training loss: 0.403916
Training loss: 0.207309
Test loss: 0.909971; True positive: 2; True negative: 265, False Positive: 0, False negative: 901, accuracy: 0.2285958904109589, precision: 1.0, recall: 0.0022148394241417496
Epoch: 11 0/3904 Training loss: 0.164318
Epoch: 11 800/3904 Training loss: 0.082084
Epoch: 11 1600/3904 Training loss: 0.082153
Epoch: 11 2400/3904 Training loss: 0.275004
Epoch: 11 3200/3904 Training loss: 0.306620
Training loss: 0.191012
Test loss: 0.770754; True positive: 164; True negative: 222, False Positive: 43, False negative: 739, accuracy: 0.3304794520547945, precision: 0.7922705314009661, recall: 0.18161683277962348
Epoch: 12 0/3904 Training loss: 0.076119
Epoch: 12 800/3904 Training loss: 0.222392
Epoch: 12 1600/3904 Training loss: 0.049878
Epoch: 12 2400/3904 Training loss: 0.127249
Epoch: 12 3200/3904 Training loss: 0.546507
Training loss: 0.186114
Test loss: 0.861548; True positive: 2; True negative: 265, False Positive: 0, False negative: 901, accuracy: 0.2285958904109589, precision: 1.0, recall: 0.0022148394241417496
Epoch: 13 0/3904 Training loss: 0.049528
Epoch: 13 800/3904 Training loss: 0.070946
Epoch: 13 1600/3904 Training loss: 0.080593
Epoch: 13 2400/3904 Training loss: 0.352566
Epoch: 13 3200/3904 Training loss: 0.408579
Training loss: 0.169065
Test loss: 0.698093; True positive: 740; True negative: 143, False Positive: 122, False negative: 163, accuracy: 0.7559931506849316, precision: 0.8584686774941995, recall: 0.8194905869324474
starting trial 216
[I 2022-12-05 05:59:55,533] Trial 215 finished with value: 0.8176369863013698 and parameters: {'d_model': 64, 'nhead': 8, 'n_encoders': 1, 'learning_rate': 0.00014075842247670604, 'weight_decay': 5.3116884140839605e-06, 'dropout': 0.21809085815354987, 'max_pool_conv': 64, 'kernel_size': 19, 'd_mlp': 32, 'num_conv_layers': 2, 'encoder_dropout': 0.08172107037708329, 'd_feed_forward': 128, 'max_pool_dim': 8, 'n_mlp_layers': 3}. Best is trial 62 with value: 0.860445205479452.
Epoch: 0 0/3904 Training loss: 0.699717
Epoch: 0 800/3904 Training loss: 0.693334
Epoch: 0 1600/3904 Training loss: 0.391721
Epoch: 0 2400/3904 Training loss: 0.730071
Epoch: 0 3200/3904 Training loss: 0.513059
Training loss: 0.651499
Test loss: 0.541688; True positive: 903; True negative: 0, False Positive: 265, False negative: 0, accuracy: 0.7731164383561644, precision: 0.7731164383561644, recall: 1.0
Epoch: 1 0/3904 Training loss: 0.642843
Epoch: 1 800/3904 Training loss: 0.618235
Epoch: 1 1600/3904 Training loss: 0.294858
Epoch: 1 2400/3904 Training loss: 0.491011
Epoch: 1 3200/3904 Training loss: 0.435416
Training loss: 0.608313
Test loss: 1.176695; True positive: 10; True negative: 254, False Positive: 11, False negative: 893, accuracy: 0.22602739726027396, precision: 0.47619047619047616, recall: 0.01107419712070875
Epoch: 2 0/3904 Training loss: 0.632520
Epoch: 2 800/3904 Training loss: 0.504951
Epoch: 2 1600/3904 Training loss: 0.270055
Epoch: 2 2400/3904 Training loss: 0.443117
Epoch: 2 3200/3904 Training loss: 0.433697
Training loss: 0.553919
Test loss: 0.814860; True positive: 189; True negative: 231, False Positive: 34, False negative: 714, accuracy: 0.3595890410958904, precision: 0.8475336322869955, recall: 0.20930232558139536
Epoch: 3 0/3904 Training loss: 0.592274
Epoch: 3 800/3904 Training loss: 0.478872
Epoch: 3 1600/3904 Training loss: 0.234014
Epoch: 3 2400/3904 Training loss: 0.398305
Epoch: 3 3200/3904 Training loss: 0.441564
Training loss: 0.525403
Test loss: 0.739819; True positive: 639; True negative: 71, False Positive: 194, False negative: 264, accuracy: 0.6078767123287672, precision: 0.7671068427370948, recall: 0.707641196013289
Epoch: 4 0/3904 Training loss: 0.364015
Epoch: 4 800/3904 Training loss: 0.268058
Epoch: 4 1600/3904 Training loss: 0.217246
Epoch: 4 2400/3904 Training loss: 0.253000
Epoch: 4 3200/3904 Training loss: 0.471422
Training loss: 0.482614
Test loss: 0.562599; True positive: 878; True negative: 11, False Positive: 254, False negative: 25, accuracy: 0.7611301369863014, precision: 0.7756183745583038, recall: 0.9723145071982281
Epoch: 5 0/3904 Training loss: 0.250680
Epoch: 5 800/3904 Training loss: 0.308103
Epoch: 5 1600/3904 Training loss: 0.219263
Epoch: 5 2400/3904 Training loss: 0.272769
Epoch: 5 3200/3904 Training loss: 0.353894
Training loss: 0.458591
Test loss: 0.544929; True positive: 894; True negative: 7, False Positive: 258, False negative: 9, accuracy: 0.771404109589041, precision: 0.7760416666666666, recall: 0.9900332225913622
Epoch: 6 0/3904 Training loss: 0.335149
Epoch: 6 800/3904 Training loss: 0.266126
Epoch: 6 1600/3904 Training loss: 0.172785
Epoch: 6 2400/3904 Training loss: 0.236150
Epoch: 6 3200/3904 Training loss: 0.421803
Training loss: 0.420736
Test loss: 0.574421; True positive: 895; True negative: 5, False Positive: 260, False negative: 8, accuracy: 0.7705479452054794, precision: 0.7748917748917749, recall: 0.991140642303433
Epoch: 7 0/3904 Training loss: 0.543413
Epoch: 7 800/3904 Training loss: 0.427382
Epoch: 7 1600/3904 Training loss: 0.209687
Epoch: 7 2400/3904 Training loss: 0.359523
Epoch: 7 3200/3904 Training loss: 0.394665
Training loss: 0.502427
Test loss: 0.719436; True positive: 761; True negative: 30, False Positive: 235, False negative: 142, accuracy: 0.6772260273972602, precision: 0.7640562248995983, recall: 0.8427464008859358
Epoch: 8 0/3904 Training loss: 0.333469
Epoch: 8 800/3904 Training loss: 0.362907
Epoch: 8 1600/3904 Training loss: 0.188212
Epoch: 8 2400/3904 Training loss: 0.344112
Epoch: 8 3200/3904 Training loss: 0.375482
Training loss: 0.452672
Test loss: 0.784971; True positive: 716; True negative: 51, False Positive: 214, False negative: 187, accuracy: 0.6566780821917808, precision: 0.7698924731182796, recall: 0.7929125138427464
Epoch: 9 0/3904 Training loss: 0.269709
Epoch: 9 800/3904 Training loss: 0.261673
Epoch: 9 1600/3904 Training loss: 0.187882
Epoch: 9 2400/3904 Training loss: 0.344991
Epoch: 9 3200/3904 Training loss: 0.412967
Training loss: 0.416849
Test loss: 1.631340; True positive: 281; True negative: 141, False Positive: 124, False negative: 622, accuracy: 0.3613013698630137, precision: 0.6938271604938272, recall: 0.31118493909191586
Epoch: 10 0/3904 Training loss: 0.286730
Epoch: 10 800/3904 Training loss: 0.221285
Epoch: 10 1600/3904 Training loss: 0.171909
Epoch: 10 2400/3904 Training loss: 0.281526
Epoch: 10 3200/3904 Training loss: 0.319521
Training loss: 0.388913
Test loss: 0.783164; True positive: 738; True negative: 65, False Positive: 200, False negative: 165, accuracy: 0.6875, precision: 0.7867803837953091, recall: 0.8172757475083057
starting trial 217
[I 2022-12-05 06:01:12,696] Trial 216 finished with value: 0.7731164383561644 and parameters: {'d_model': 64, 'nhead': 8, 'n_encoders': 1, 'learning_rate': 0.0008732548971935293, 'weight_decay': 4.685572842911053e-06, 'dropout': 0.23146199882377622, 'max_pool_conv': 64, 'kernel_size': 5, 'd_mlp': 16, 'num_conv_layers': 8, 'encoder_dropout': 8.893501492947785e-05, 'd_feed_forward': 128, 'max_pool_dim': 8, 'n_mlp_layers': 3}. Best is trial 62 with value: 0.860445205479452.
Epoch: 0 0/3904 Training loss: 0.703388
Epoch: 0 800/3904 Training loss: 0.697539
Epoch: 0 1600/3904 Training loss: 0.469431
Epoch: 0 2400/3904 Training loss: 0.781549
Epoch: 0 3200/3904 Training loss: 0.542767
Training loss: 0.667397
Test loss: 0.858402; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 1 0/3904 Training loss: 0.720730
Epoch: 1 800/3904 Training loss: 0.721970
Epoch: 1 1600/3904 Training loss: 0.434136
Epoch: 1 2400/3904 Training loss: 0.788085
Epoch: 1 3200/3904 Training loss: 0.517379
Training loss: 0.648508
Test loss: 0.781174; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 2 0/3904 Training loss: 0.658186
Epoch: 2 800/3904 Training loss: 0.691452
Epoch: 2 1600/3904 Training loss: 0.352192
Epoch: 2 2400/3904 Training loss: 0.702608
Epoch: 2 3200/3904 Training loss: 0.446723
Training loss: 0.607540
Test loss: 1.156965; True positive: 65; True negative: 148, False Positive: 117, False negative: 838, accuracy: 0.18236301369863014, precision: 0.35714285714285715, recall: 0.07198228128460686
Epoch: 3 0/3904 Training loss: 0.623219
Epoch: 3 800/3904 Training loss: 0.606727
Epoch: 3 1600/3904 Training loss: 0.291609
Epoch: 3 2400/3904 Training loss: 0.711066
Epoch: 3 3200/3904 Training loss: 0.385756
Training loss: 0.525876
Test loss: 2.024169; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 4 0/3904 Training loss: 0.446118
Epoch: 4 800/3904 Training loss: 0.505251
Epoch: 4 1600/3904 Training loss: 0.313638
Epoch: 4 2400/3904 Training loss: 0.727006
Epoch: 4 3200/3904 Training loss: 0.393535
Training loss: 0.460907
Test loss: 2.453958; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 5 0/3904 Training loss: 0.386420
Epoch: 5 800/3904 Training loss: 0.449636
Epoch: 5 1600/3904 Training loss: 0.259520
Epoch: 5 2400/3904 Training loss: 0.715069
Epoch: 5 3200/3904 Training loss: 0.469840
Training loss: 0.416113
Test loss: 2.611203; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 6 0/3904 Training loss: 0.403876
Epoch: 6 800/3904 Training loss: 0.367964
Epoch: 6 1600/3904 Training loss: 0.297191
Epoch: 6 2400/3904 Training loss: 0.767922
Epoch: 6 3200/3904 Training loss: 0.519306
Training loss: 0.395356
Test loss: 2.917994; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 7 0/3904 Training loss: 0.317754
Epoch: 7 800/3904 Training loss: 0.436763
Epoch: 7 1600/3904 Training loss: 0.220940
Epoch: 7 2400/3904 Training loss: 0.676634
Epoch: 7 3200/3904 Training loss: 0.494971
Training loss: 0.365946
Test loss: 2.260352; True positive: 27; True negative: 256, False Positive: 9, False negative: 876, accuracy: 0.2422945205479452, precision: 0.75, recall: 0.029900332225913623
Epoch: 8 0/3904 Training loss: 0.429047
Epoch: 8 800/3904 Training loss: 0.386456
Epoch: 8 1600/3904 Training loss: 0.163573
Epoch: 8 2400/3904 Training loss: 0.631528
Epoch: 8 3200/3904 Training loss: 0.481635
Training loss: 0.350053
Test loss: 2.010550; True positive: 43; True negative: 253, False Positive: 12, False negative: 860, accuracy: 0.2534246575342466, precision: 0.7818181818181819, recall: 0.047619047619047616
Epoch: 9 0/3904 Training loss: 0.510298
Epoch: 9 800/3904 Training loss: 0.248158
Epoch: 9 1600/3904 Training loss: 0.154403
Epoch: 9 2400/3904 Training loss: 0.694960
Epoch: 9 3200/3904 Training loss: 0.461312
Training loss: 0.328824
Test loss: 0.895139; True positive: 578; True negative: 144, False Positive: 121, False negative: 325, accuracy: 0.6181506849315068, precision: 0.82689556509299, recall: 0.6400885935769657
Epoch: 10 0/3904 Training loss: 0.402750
Epoch: 10 800/3904 Training loss: 0.286792
Epoch: 10 1600/3904 Training loss: 0.273333
Epoch: 10 2400/3904 Training loss: 0.591328
Epoch: 10 3200/3904 Training loss: 0.401009
Training loss: 0.315226
Test loss: 0.559732; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 11 0/3904 Training loss: 0.377189
Epoch: 11 800/3904 Training loss: 0.323487
Epoch: 11 1600/3904 Training loss: 0.083993
Epoch: 11 2400/3904 Training loss: 0.324279
Epoch: 11 3200/3904 Training loss: 0.430297
Training loss: 0.301679
Test loss: 0.564742; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 12 0/3904 Training loss: 0.283789
Epoch: 12 800/3904 Training loss: 0.322847
Epoch: 12 1600/3904 Training loss: 0.105593
Epoch: 12 2400/3904 Training loss: 0.537402
Epoch: 12 3200/3904 Training loss: 0.357170
Training loss: 0.290715
Test loss: 0.584398; True positive: 833; True negative: 117, False Positive: 148, False negative: 70, accuracy: 0.8133561643835616, precision: 0.8491335372069317, recall: 0.9224806201550387
Epoch: 13 0/3904 Training loss: 0.408999
Epoch: 13 800/3904 Training loss: 0.305030
Epoch: 13 1600/3904 Training loss: 0.079828
Epoch: 13 2400/3904 Training loss: 0.431794
Epoch: 13 3200/3904 Training loss: 0.448455
Training loss: 0.279723
Test loss: 0.576976; True positive: 837; True negative: 117, False Positive: 148, False negative: 66, accuracy: 0.8167808219178082, precision: 0.849746192893401, recall: 0.9269102990033222
Epoch: 14 0/3904 Training loss: 0.417702
Epoch: 14 800/3904 Training loss: 0.277247
Epoch: 14 1600/3904 Training loss: 0.164316
Epoch: 14 2400/3904 Training loss: 0.312198
Epoch: 14 3200/3904 Training loss: 0.347876
Training loss: 0.275149
Test loss: 0.614914; True positive: 815; True negative: 118, False Positive: 147, False negative: 88, accuracy: 0.7988013698630136, precision: 0.8471933471933472, recall: 0.902547065337763
Epoch: 15 0/3904 Training loss: 0.252392
Epoch: 15 800/3904 Training loss: 0.317154
Epoch: 15 1600/3904 Training loss: 0.150023
Epoch: 15 2400/3904 Training loss: 0.378052
Epoch: 15 3200/3904 Training loss: 0.238495
Training loss: 0.252010
Test loss: 0.595198; True positive: 836; True negative: 117, False Positive: 148, False negative: 67, accuracy: 0.8159246575342466, precision: 0.8495934959349594, recall: 0.9258028792912514
Epoch: 16 0/3904 Training loss: 0.200368
Epoch: 16 800/3904 Training loss: 0.187971
Epoch: 16 1600/3904 Training loss: 0.138300
Epoch: 16 2400/3904 Training loss: 0.532699
Epoch: 16 3200/3904 Training loss: 0.323368
Training loss: 0.245108
Test loss: 0.847278; True positive: 624; True negative: 131, False Positive: 134, False negative: 279, accuracy: 0.646404109589041, precision: 0.8232189973614775, recall: 0.6910299003322259
Epoch: 17 0/3904 Training loss: 0.196660
Epoch: 17 800/3904 Training loss: 0.240585
Epoch: 17 1600/3904 Training loss: 0.056969
Epoch: 17 2400/3904 Training loss: 0.294799
Epoch: 17 3200/3904 Training loss: 0.309035
Training loss: 0.237960
Test loss: 0.682265; True positive: 769; True negative: 120, False Positive: 145, False negative: 134, accuracy: 0.7611301369863014, precision: 0.8413566739606126, recall: 0.8516057585825028
Epoch: 18 0/3904 Training loss: 0.278770
Epoch: 18 800/3904 Training loss: 0.162640
Epoch: 18 1600/3904 Training loss: 0.164120
Epoch: 18 2400/3904 Training loss: 0.404982
Epoch: 18 3200/3904 Training loss: 0.292137
Training loss: 0.241417
Test loss: 0.718118; True positive: 736; True negative: 122, False Positive: 143, False negative: 167, accuracy: 0.7345890410958904, precision: 0.8373151308304891, recall: 0.8150609080841639
Epoch: 19 0/3904 Training loss: 0.375835
Epoch: 19 800/3904 Training loss: 0.294545
Epoch: 19 1600/3904 Training loss: 0.112300
Epoch: 19 2400/3904 Training loss: 0.131742
Epoch: 19 3200/3904 Training loss: 0.268065
Training loss: 0.239794
Test loss: 1.261139; True positive: 379; True negative: 158, False Positive: 107, False negative: 524, accuracy: 0.4597602739726027, precision: 0.779835390946502, recall: 0.41971207087486156
Epoch: 20 0/3904 Training loss: 0.196515
Epoch: 20 800/3904 Training loss: 0.124458
Epoch: 20 1600/3904 Training loss: 0.158790
Epoch: 20 2400/3904 Training loss: 0.456319
Epoch: 20 3200/3904 Training loss: 0.173624
Training loss: 0.224623
Test loss: 1.130940; True positive: 438; True negative: 149, False Positive: 116, False negative: 465, accuracy: 0.502568493150685, precision: 0.7906137184115524, recall: 0.4850498338870432
starting trial 218
[I 2022-12-05 06:02:25,357] Trial 217 finished with value: 0.8176369863013698 and parameters: {'d_model': 64, 'nhead': 8, 'n_encoders': 1, 'learning_rate': 9.920466122721812e-05, 'weight_decay': 3.809440629949183e-06, 'dropout': 0.27960778489924154, 'max_pool_conv': 64, 'kernel_size': 6, 'd_mlp': 32, 'num_conv_layers': 3, 'encoder_dropout': 0.0571926563649241, 'd_feed_forward': 128, 'max_pool_dim': 8, 'n_mlp_layers': 3}. Best is trial 62 with value: 0.860445205479452.
Epoch: 0 0/3904 Training loss: 0.703802
Epoch: 0 800/3904 Training loss: 0.730578
Epoch: 0 1600/3904 Training loss: 0.482132
Epoch: 0 2400/3904 Training loss: 0.819952
Epoch: 0 3200/3904 Training loss: 0.558116
Training loss: 0.662182
Test loss: 0.815443; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 1 0/3904 Training loss: 0.700641
Epoch: 1 800/3904 Training loss: 0.730738
Epoch: 1 1600/3904 Training loss: 0.455361
Epoch: 1 2400/3904 Training loss: 0.822946
Epoch: 1 3200/3904 Training loss: 0.522680
Training loss: 0.651861
Test loss: 0.741908; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 2 0/3904 Training loss: 0.694838
Epoch: 2 800/3904 Training loss: 0.633326
Epoch: 2 1600/3904 Training loss: 0.317276
Epoch: 2 2400/3904 Training loss: 0.712032
Epoch: 2 3200/3904 Training loss: 0.415704
Training loss: 0.575663
Test loss: 1.380051; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 3 0/3904 Training loss: 0.680889
Epoch: 3 800/3904 Training loss: 0.493296
Epoch: 3 1600/3904 Training loss: 0.250509
Epoch: 3 2400/3904 Training loss: 0.702208
Epoch: 3 3200/3904 Training loss: 0.410595
Training loss: 0.523800
Test loss: 1.484731; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 4 0/3904 Training loss: 0.703765
Epoch: 4 800/3904 Training loss: 0.496044
Epoch: 4 1600/3904 Training loss: 0.250329
Epoch: 4 2400/3904 Training loss: 0.828180
Epoch: 4 3200/3904 Training loss: 0.374861
Training loss: 0.492766
Test loss: 1.438118; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 5 0/3904 Training loss: 0.549526
Epoch: 5 800/3904 Training loss: 0.536021
Epoch: 5 1600/3904 Training loss: 0.244467
Epoch: 5 2400/3904 Training loss: 0.597084
Epoch: 5 3200/3904 Training loss: 0.437573
Training loss: 0.472563
Test loss: 1.514750; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 6 0/3904 Training loss: 0.590289
Epoch: 6 800/3904 Training loss: 0.486086
Epoch: 6 1600/3904 Training loss: 0.221214
Epoch: 6 2400/3904 Training loss: 0.558648
Epoch: 6 3200/3904 Training loss: 0.371014
Training loss: 0.445508
Test loss: 1.641374; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 7 0/3904 Training loss: 0.633695
Epoch: 7 800/3904 Training loss: 0.429383
Epoch: 7 1600/3904 Training loss: 0.215820
Epoch: 7 2400/3904 Training loss: 0.587619
Epoch: 7 3200/3904 Training loss: 0.400769
Training loss: 0.427375
Test loss: 1.770621; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 8 0/3904 Training loss: 0.494081
Epoch: 8 800/3904 Training loss: 0.445237
Epoch: 8 1600/3904 Training loss: 0.169207
Epoch: 8 2400/3904 Training loss: 0.464220
Epoch: 8 3200/3904 Training loss: 0.389700
Training loss: 0.421577
Test loss: 2.395375; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 9 0/3904 Training loss: 0.595152
Epoch: 9 800/3904 Training loss: 0.443185
Epoch: 9 1600/3904 Training loss: 0.174795
Epoch: 9 2400/3904 Training loss: 0.439043
Epoch: 9 3200/3904 Training loss: 0.409749
Training loss: 0.409510
Test loss: 0.846185; True positive: 524; True negative: 217, False Positive: 48, False negative: 379, accuracy: 0.634417808219178, precision: 0.916083916083916, recall: 0.5802879291251384
Epoch: 10 0/3904 Training loss: 0.502669
Epoch: 10 800/3904 Training loss: 0.395078
Epoch: 10 1600/3904 Training loss: 0.241956
Epoch: 10 2400/3904 Training loss: 0.510715
Epoch: 10 3200/3904 Training loss: 0.371729
Training loss: 0.415625
Test loss: 2.006961; True positive: 50; True negative: 258, False Positive: 7, False negative: 853, accuracy: 0.2636986301369863, precision: 0.8771929824561403, recall: 0.05537098560354374
Epoch: 11 0/3904 Training loss: 0.543544
Epoch: 11 800/3904 Training loss: 0.345686
Epoch: 11 1600/3904 Training loss: 0.172596
Epoch: 11 2400/3904 Training loss: 0.439724
Epoch: 11 3200/3904 Training loss: 0.317620
Training loss: 0.417966
Test loss: 2.337705; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
starting trial 219
[I 2022-12-05 06:04:55,379] Trial 218 finished with value: 0.634417808219178 and parameters: {'d_model': 64, 'nhead': 8, 'n_encoders': 1, 'learning_rate': 8.908203338796503e-05, 'weight_decay': 3.0384920643344715e-06, 'dropout': 0.3953710282291659, 'max_pool_conv': 16, 'kernel_size': 13, 'd_mlp': 16, 'num_conv_layers': 7, 'encoder_dropout': 0.23852028581762935, 'd_feed_forward': 128, 'max_pool_dim': 8, 'n_mlp_layers': 3}. Best is trial 62 with value: 0.860445205479452.
Epoch: 0 0/3904 Training loss: 0.691471
Epoch: 0 800/3904 Training loss: 0.700511
Epoch: 0 1600/3904 Training loss: 0.581827
Epoch: 0 2400/3904 Training loss: 0.772786
Epoch: 0 3200/3904 Training loss: 0.579515
Training loss: 0.670631
Test loss: 0.839971; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 1 0/3904 Training loss: 0.716075
Epoch: 1 800/3904 Training loss: 0.739172
Epoch: 1 1600/3904 Training loss: 0.492683
Epoch: 1 2400/3904 Training loss: 0.806899
Epoch: 1 3200/3904 Training loss: 0.558209
Training loss: 0.657521
Test loss: 0.848165; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 2 0/3904 Training loss: 0.716979
Epoch: 2 800/3904 Training loss: 0.732063
Epoch: 2 1600/3904 Training loss: 0.463797
Epoch: 2 2400/3904 Training loss: 0.740916
Epoch: 2 3200/3904 Training loss: 0.502296
Training loss: 0.627588
Test loss: 0.669959; True positive: 903; True negative: 0, False Positive: 265, False negative: 0, accuracy: 0.7731164383561644, precision: 0.7731164383561644, recall: 1.0
Epoch: 3 0/3904 Training loss: 0.682669
Epoch: 3 800/3904 Training loss: 0.569219
Epoch: 3 1600/3904 Training loss: 0.303975
Epoch: 3 2400/3904 Training loss: 0.663699
Epoch: 3 3200/3904 Training loss: 0.430368
Training loss: 0.547986
Test loss: 0.899673; True positive: 505; True negative: 127, False Positive: 138, False negative: 398, accuracy: 0.541095890410959, precision: 0.7853810264385692, recall: 0.5592469545957918
Epoch: 4 0/3904 Training loss: 0.552918
Epoch: 4 800/3904 Training loss: 0.510566
Epoch: 4 1600/3904 Training loss: 0.290715
Epoch: 4 2400/3904 Training loss: 0.549452
Epoch: 4 3200/3904 Training loss: 0.450170
Training loss: 0.486212
Test loss: 1.476052; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 5 0/3904 Training loss: 0.486673
Epoch: 5 800/3904 Training loss: 0.401015
Epoch: 5 1600/3904 Training loss: 0.246667
Epoch: 5 2400/3904 Training loss: 0.467521
Epoch: 5 3200/3904 Training loss: 0.470045
Training loss: 0.450316
Test loss: 1.493734; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 6 0/3904 Training loss: 0.453303
Epoch: 6 800/3904 Training loss: 0.424559
Epoch: 6 1600/3904 Training loss: 0.245746
Epoch: 6 2400/3904 Training loss: 0.387443
Epoch: 6 3200/3904 Training loss: 0.477942
Training loss: 0.424644
Test loss: 1.575665; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 7 0/3904 Training loss: 0.420983
Epoch: 7 800/3904 Training loss: 0.340302
Epoch: 7 1600/3904 Training loss: 0.208804
Epoch: 7 2400/3904 Training loss: 0.346522
Epoch: 7 3200/3904 Training loss: 0.486913
Training loss: 0.405641
Test loss: 1.672670; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 8 0/3904 Training loss: 0.403919
Epoch: 8 800/3904 Training loss: 0.330291
Epoch: 8 1600/3904 Training loss: 0.171256
Epoch: 8 2400/3904 Training loss: 0.385507
Epoch: 8 3200/3904 Training loss: 0.498559
Training loss: 0.389808
Test loss: 1.732770; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 9 0/3904 Training loss: 0.440117
Epoch: 9 800/3904 Training loss: 0.300667
Epoch: 9 1600/3904 Training loss: 0.192355
Epoch: 9 2400/3904 Training loss: 0.281239
Epoch: 9 3200/3904 Training loss: 0.464950
Training loss: 0.382947
Test loss: 1.780312; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 10 0/3904 Training loss: 0.312380
Epoch: 10 800/3904 Training loss: 0.235282
Epoch: 10 1600/3904 Training loss: 0.146596
Epoch: 10 2400/3904 Training loss: 0.370957
Epoch: 10 3200/3904 Training loss: 0.525770
Training loss: 0.367191
Test loss: 2.012120; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 11 0/3904 Training loss: 0.320109
Epoch: 11 800/3904 Training loss: 0.235071
Epoch: 11 1600/3904 Training loss: 0.139910
Epoch: 11 2400/3904 Training loss: 0.389643
Epoch: 11 3200/3904 Training loss: 0.514736
Training loss: 0.362407
Test loss: 2.023267; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 12 0/3904 Training loss: 0.371116
Epoch: 12 800/3904 Training loss: 0.294934
Epoch: 12 1600/3904 Training loss: 0.211678
Epoch: 12 2400/3904 Training loss: 0.301648
Epoch: 12 3200/3904 Training loss: 0.383670
Training loss: 0.352907
Test loss: 1.904839; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
starting trial 220
[I 2022-12-05 06:07:50,541] Trial 219 finished with value: 0.7731164383561644 and parameters: {'d_model': 64, 'nhead': 4, 'n_encoders': 1, 'learning_rate': 6.829588197267088e-05, 'weight_decay': 2.569310943831687e-06, 'dropout': 0.32843287449922937, 'max_pool_conv': 16, 'kernel_size': 14, 'd_mlp': 16, 'num_conv_layers': 7, 'encoder_dropout': 0.1212443000714415, 'd_feed_forward': 128, 'max_pool_dim': 8, 'n_mlp_layers': 4}. Best is trial 62 with value: 0.860445205479452.
Epoch: 0 0/3904 Training loss: 0.687267
Epoch: 0 800/3904 Training loss: 0.690732
Epoch: 0 1600/3904 Training loss: 0.414907
Epoch: 0 2400/3904 Training loss: 0.746598
Epoch: 0 3200/3904 Training loss: 0.538393
Training loss: 0.662090
Test loss: 0.782463; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 1 0/3904 Training loss: 0.690877
Epoch: 1 800/3904 Training loss: 0.688450
Epoch: 1 1600/3904 Training loss: 0.363991
Epoch: 1 2400/3904 Training loss: 0.763237
Epoch: 1 3200/3904 Training loss: 0.459254
Training loss: 0.626034
Test loss: 1.483858; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 2 0/3904 Training loss: 0.635094
Epoch: 2 800/3904 Training loss: 0.612208
Epoch: 2 1600/3904 Training loss: 0.287112
Epoch: 2 2400/3904 Training loss: 0.777887
Epoch: 2 3200/3904 Training loss: 0.442783
Training loss: 0.546815
Test loss: 1.890817; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 3 0/3904 Training loss: 0.422363
Epoch: 3 800/3904 Training loss: 0.409094
Epoch: 3 1600/3904 Training loss: 0.210800
Epoch: 3 2400/3904 Training loss: 0.865781
Epoch: 3 3200/3904 Training loss: 0.373239
Training loss: 0.448604
Test loss: 1.956999; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 4 0/3904 Training loss: 0.375661
Epoch: 4 800/3904 Training loss: 0.298001
Epoch: 4 1600/3904 Training loss: 0.156677
Epoch: 4 2400/3904 Training loss: 0.864884
Epoch: 4 3200/3904 Training loss: 0.357677
Training loss: 0.384123
Test loss: 1.490567; True positive: 4; True negative: 265, False Positive: 0, False negative: 899, accuracy: 0.2303082191780822, precision: 1.0, recall: 0.004429678848283499
Epoch: 5 0/3904 Training loss: 0.244019
Epoch: 5 800/3904 Training loss: 0.254952
Epoch: 5 1600/3904 Training loss: 0.128671
Epoch: 5 2400/3904 Training loss: 0.877429
Epoch: 5 3200/3904 Training loss: 0.395384
Training loss: 0.345733
Test loss: 1.577987; True positive: 5; True negative: 265, False Positive: 0, False negative: 898, accuracy: 0.23116438356164384, precision: 1.0, recall: 0.005537098560354375
Epoch: 6 0/3904 Training loss: 0.281716
Epoch: 6 800/3904 Training loss: 0.194841
Epoch: 6 1600/3904 Training loss: 0.206417
Epoch: 6 2400/3904 Training loss: 0.583979
Epoch: 6 3200/3904 Training loss: 0.419117
Training loss: 0.315592
Test loss: 1.644935; True positive: 5; True negative: 265, False Positive: 0, False negative: 898, accuracy: 0.23116438356164384, precision: 1.0, recall: 0.005537098560354375
Epoch: 7 0/3904 Training loss: 0.333655
Epoch: 7 800/3904 Training loss: 0.213958
Epoch: 7 1600/3904 Training loss: 0.144922
Epoch: 7 2400/3904 Training loss: 0.588507
Epoch: 7 3200/3904 Training loss: 0.254719
Training loss: 0.293826
Test loss: 2.075454; True positive: 4; True negative: 265, False Positive: 0, False negative: 899, accuracy: 0.2303082191780822, precision: 1.0, recall: 0.004429678848283499
Epoch: 8 0/3904 Training loss: 0.182029
Epoch: 8 800/3904 Training loss: 0.198847
Epoch: 8 1600/3904 Training loss: 0.127717
Epoch: 8 2400/3904 Training loss: 0.377671
Epoch: 8 3200/3904 Training loss: 0.447859
Training loss: 0.276193
Test loss: 2.338721; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 9 0/3904 Training loss: 0.156291
Epoch: 9 800/3904 Training loss: 0.129580
Epoch: 9 1600/3904 Training loss: 0.098816
Epoch: 9 2400/3904 Training loss: 0.424979
Epoch: 9 3200/3904 Training loss: 0.313307
Training loss: 0.265303
Test loss: 2.702011; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 10 0/3904 Training loss: 0.139296
Epoch: 10 800/3904 Training loss: 0.107740
Epoch: 10 1600/3904 Training loss: 0.095794
Epoch: 10 2400/3904 Training loss: 0.316076
Epoch: 10 3200/3904 Training loss: 0.378273
Training loss: 0.250861
Test loss: 2.805099; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
starting trial 221
[I 2022-12-05 06:08:34,888] Trial 220 finished with value: 0.23116438356164384 and parameters: {'d_model': 64, 'nhead': 8, 'n_encoders': 2, 'learning_rate': 0.0001135820030309096, 'weight_decay': 3.977243722039429e-06, 'dropout': 0.2377106454563258, 'max_pool_conv': 64, 'kernel_size': 11, 'd_mlp': 32, 'num_conv_layers': 2, 'encoder_dropout': 0.10012108224278346, 'd_feed_forward': 128, 'max_pool_dim': 4, 'n_mlp_layers': 3}. Best is trial 62 with value: 0.860445205479452.
Epoch: 0 0/3904 Training loss: 0.703675
Epoch: 0 800/3904 Training loss: 0.713298
Epoch: 0 1600/3904 Training loss: 0.443666
Epoch: 0 2400/3904 Training loss: 0.785953
Epoch: 0 3200/3904 Training loss: 0.556940
Training loss: 0.663551
Test loss: 0.820774; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 1 0/3904 Training loss: 0.718568
Epoch: 1 800/3904 Training loss: 0.738018
Epoch: 1 1600/3904 Training loss: 0.337295
Epoch: 1 2400/3904 Training loss: 0.774864
Epoch: 1 3200/3904 Training loss: 0.532048
Training loss: 0.655648
Test loss: 0.773500; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 2 0/3904 Training loss: 0.705046
Epoch: 2 800/3904 Training loss: 0.726617
Epoch: 2 1600/3904 Training loss: 0.278547
Epoch: 2 2400/3904 Training loss: 0.755183
Epoch: 2 3200/3904 Training loss: 0.511128
Training loss: 0.629045
Test loss: 0.753309; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 3 0/3904 Training loss: 0.685865
Epoch: 3 800/3904 Training loss: 0.678313
Epoch: 3 1600/3904 Training loss: 0.243256
Epoch: 3 2400/3904 Training loss: 0.841319
Epoch: 3 3200/3904 Training loss: 0.439060
Training loss: 0.579387
Test loss: 0.620601; True positive: 902; True negative: 1, False Positive: 264, False negative: 1, accuracy: 0.7731164383561644, precision: 0.7735849056603774, recall: 0.9988925802879292
Epoch: 4 0/3904 Training loss: 0.703222
Epoch: 4 800/3904 Training loss: 0.685816
Epoch: 4 1600/3904 Training loss: 0.234914
Epoch: 4 2400/3904 Training loss: 0.550566
Epoch: 4 3200/3904 Training loss: 0.406172
Training loss: 0.550263
Test loss: 1.060415; True positive: 80; True negative: 255, False Positive: 10, False negative: 823, accuracy: 0.2868150684931507, precision: 0.8888888888888888, recall: 0.08859357696567
Epoch: 5 0/3904 Training loss: 0.641168
Epoch: 5 800/3904 Training loss: 0.697459
Epoch: 5 1600/3904 Training loss: 0.294841
Epoch: 5 2400/3904 Training loss: 0.541504
Epoch: 5 3200/3904 Training loss: 0.385729
Training loss: 0.523349
Test loss: 0.898766; True positive: 164; True negative: 252, False Positive: 13, False negative: 739, accuracy: 0.3561643835616438, precision: 0.9265536723163842, recall: 0.18161683277962348
Epoch: 6 0/3904 Training loss: 0.769819
Epoch: 6 800/3904 Training loss: 0.541894
Epoch: 6 1600/3904 Training loss: 0.252706
Epoch: 6 2400/3904 Training loss: 0.551244
Epoch: 6 3200/3904 Training loss: 0.363361
Training loss: 0.521371
Test loss: 0.567071; True positive: 838; True negative: 119, False Positive: 146, False negative: 65, accuracy: 0.8193493150684932, precision: 0.8516260162601627, recall: 0.9280177187153932
Epoch: 7 0/3904 Training loss: 0.703433
Epoch: 7 800/3904 Training loss: 0.641903
Epoch: 7 1600/3904 Training loss: 0.205760
Epoch: 7 2400/3904 Training loss: 0.469525
Epoch: 7 3200/3904 Training loss: 0.516390
Training loss: 0.488479
Test loss: 0.542505; True positive: 837; True negative: 121, False Positive: 144, False negative: 66, accuracy: 0.8202054794520548, precision: 0.8532110091743119, recall: 0.9269102990033222
Epoch: 8 0/3904 Training loss: 0.655913
Epoch: 8 800/3904 Training loss: 0.581869
Epoch: 8 1600/3904 Training loss: 0.201155
Epoch: 8 2400/3904 Training loss: 0.447587
Epoch: 8 3200/3904 Training loss: 0.391570
Training loss: 0.475621
Test loss: 0.720988; True positive: 494; True negative: 202, False Positive: 63, False negative: 409, accuracy: 0.5958904109589042, precision: 0.8868940754039497, recall: 0.5470653377630121
Epoch: 9 0/3904 Training loss: 0.618500
Epoch: 9 800/3904 Training loss: 0.641814
Epoch: 9 1600/3904 Training loss: 0.181886
Epoch: 9 2400/3904 Training loss: 0.471227
Epoch: 9 3200/3904 Training loss: 0.498390
Training loss: 0.462415
Test loss: 0.535706; True positive: 837; True negative: 119, False Positive: 146, False negative: 66, accuracy: 0.8184931506849316, precision: 0.8514750762970499, recall: 0.9269102990033222
Epoch: 10 0/3904 Training loss: 0.500170
Epoch: 10 800/3904 Training loss: 0.570990
Epoch: 10 1600/3904 Training loss: 0.180209
Epoch: 10 2400/3904 Training loss: 0.444173
Epoch: 10 3200/3904 Training loss: 0.446681
Training loss: 0.442844
Test loss: 0.749375; True positive: 608; True negative: 179, False Positive: 86, False negative: 295, accuracy: 0.6738013698630136, precision: 0.8760806916426513, recall: 0.6733111849390919
Epoch: 11 0/3904 Training loss: 0.498304
Epoch: 11 800/3904 Training loss: 0.615239
Epoch: 11 1600/3904 Training loss: 0.148484
Epoch: 11 2400/3904 Training loss: 0.403378
Epoch: 11 3200/3904 Training loss: 0.381511
Training loss: 0.436813
Test loss: 2.326852; True positive: 70; True negative: 233, False Positive: 32, False negative: 833, accuracy: 0.2594178082191781, precision: 0.6862745098039216, recall: 0.07751937984496124
Epoch: 12 0/3904 Training loss: 0.419866
Epoch: 12 800/3904 Training loss: 0.770541
Epoch: 12 1600/3904 Training loss: 0.142856
Epoch: 12 2400/3904 Training loss: 0.532177
Epoch: 12 3200/3904 Training loss: 0.626251
Training loss: 0.457891
Test loss: 1.947944; True positive: 128; True negative: 257, False Positive: 8, False negative: 775, accuracy: 0.3296232876712329, precision: 0.9411764705882353, recall: 0.14174972314507198
Epoch: 13 0/3904 Training loss: 0.492981
Epoch: 13 800/3904 Training loss: 0.712157
Epoch: 13 1600/3904 Training loss: 0.192350
Epoch: 13 2400/3904 Training loss: 0.958046
Epoch: 13 3200/3904 Training loss: 0.575512
Training loss: 0.434284
Test loss: 2.782737; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 14 0/3904 Training loss: 0.403904
Epoch: 14 800/3904 Training loss: 0.569498
Epoch: 14 1600/3904 Training loss: 0.210719
Epoch: 14 2400/3904 Training loss: 0.312940
Epoch: 14 3200/3904 Training loss: 0.410596
Training loss: 0.423823
Test loss: 3.086066; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 15 0/3904 Training loss: 0.437377
Epoch: 15 800/3904 Training loss: 0.565326
Epoch: 15 1600/3904 Training loss: 0.174651
Epoch: 15 2400/3904 Training loss: 0.479138
Epoch: 15 3200/3904 Training loss: 0.380630
Training loss: 0.427089
Test loss: 1.172076; True positive: 287; True negative: 234, False Positive: 31, False negative: 616, accuracy: 0.4460616438356164, precision: 0.9025157232704403, recall: 0.3178294573643411
Epoch: 16 0/3904 Training loss: 0.518499
Epoch: 16 800/3904 Training loss: 0.592767
Epoch: 16 1600/3904 Training loss: 0.152055
Epoch: 16 2400/3904 Training loss: 0.415718
Epoch: 16 3200/3904 Training loss: 0.402978
Training loss: 0.429779
Test loss: 1.529884; True positive: 283; True negative: 245, False Positive: 20, False negative: 620, accuracy: 0.4520547945205479, precision: 0.933993399339934, recall: 0.3133997785160576
Epoch: 17 0/3904 Training loss: 0.489305
Epoch: 17 800/3904 Training loss: 0.539042
Epoch: 17 1600/3904 Training loss: 0.225615
Epoch: 17 2400/3904 Training loss: 0.315283
Epoch: 17 3200/3904 Training loss: 0.429166
Training loss: 0.417047
Test loss: 2.020420; True positive: 174; True negative: 253, False Positive: 12, False negative: 729, accuracy: 0.3655821917808219, precision: 0.9354838709677419, recall: 0.19269102990033224
Epoch: 18 0/3904 Training loss: 0.510082
Epoch: 18 800/3904 Training loss: 0.536620
Epoch: 18 1600/3904 Training loss: 0.142650
Epoch: 18 2400/3904 Training loss: 0.365256
Epoch: 18 3200/3904 Training loss: 0.348163
Training loss: 0.444054
Test loss: 0.603024; True positive: 832; True negative: 124, False Positive: 141, False negative: 71, accuracy: 0.8184931506849316, precision: 0.8550873586844809, recall: 0.9213732004429679
Epoch: 19 0/3904 Training loss: 0.498439
Epoch: 19 800/3904 Training loss: 0.537018
Epoch: 19 1600/3904 Training loss: 0.193736
Epoch: 19 2400/3904 Training loss: 0.358243
Epoch: 19 3200/3904 Training loss: 0.339987
Training loss: 0.425854
Test loss: 1.683465; True positive: 276; True negative: 243, False Positive: 22, False negative: 627, accuracy: 0.4443493150684932, precision: 0.9261744966442953, recall: 0.30564784053156147
starting trial 222
[I 2022-12-05 06:12:43,824] Trial 221 finished with value: 0.8202054794520548 and parameters: {'d_model': 64, 'nhead': 8, 'n_encoders': 1, 'learning_rate': 0.00016517758026763686, 'weight_decay': 3.297937328753301e-06, 'dropout': 0.43191475347169317, 'max_pool_conv': 16, 'kernel_size': 13, 'd_mlp': 16, 'num_conv_layers': 7, 'encoder_dropout': 0.345393549131191, 'd_feed_forward': 128, 'max_pool_dim': 8, 'n_mlp_layers': 3}. Best is trial 62 with value: 0.860445205479452.
Epoch: 0 0/3904 Training loss: 0.697785
Epoch: 0 800/3904 Training loss: 0.739735
Epoch: 0 1600/3904 Training loss: 0.452099
Epoch: 0 2400/3904 Training loss: 0.793259
Epoch: 0 3200/3904 Training loss: 0.554625
Training loss: 0.660929
Test loss: 0.883537; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 1 0/3904 Training loss: 0.705679
Epoch: 1 800/3904 Training loss: 0.734160
Epoch: 1 1600/3904 Training loss: 0.401432
Epoch: 1 2400/3904 Training loss: 0.727653
Epoch: 1 3200/3904 Training loss: 0.465259
Training loss: 0.633324
Test loss: 0.977436; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 2 0/3904 Training loss: 0.646134
Epoch: 2 800/3904 Training loss: 0.674194
Epoch: 2 1600/3904 Training loss: 0.263000
Epoch: 2 2400/3904 Training loss: 0.842736
Epoch: 2 3200/3904 Training loss: 0.342366
Training loss: 0.552502
Test loss: 1.861983; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 3 0/3904 Training loss: 0.515631
Epoch: 3 800/3904 Training loss: 0.460554
Epoch: 3 1600/3904 Training loss: 0.253260
Epoch: 3 2400/3904 Training loss: 0.613774
Epoch: 3 3200/3904 Training loss: 0.324359
Training loss: 0.464923
Test loss: 2.096600; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 4 0/3904 Training loss: 0.365466
Epoch: 4 800/3904 Training loss: 0.369660
Epoch: 4 1600/3904 Training loss: 0.232239
Epoch: 4 2400/3904 Training loss: 0.432378
Epoch: 4 3200/3904 Training loss: 0.340846
Training loss: 0.420726
Test loss: 2.292000; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 5 0/3904 Training loss: 0.396293
Epoch: 5 800/3904 Training loss: 0.390553
Epoch: 5 1600/3904 Training loss: 0.199763
Epoch: 5 2400/3904 Training loss: 0.408546
Epoch: 5 3200/3904 Training loss: 0.457331
Training loss: 0.393650
Test loss: 2.509744; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 6 0/3904 Training loss: 0.279892
Epoch: 6 800/3904 Training loss: 0.320154
Epoch: 6 1600/3904 Training loss: 0.204845
Epoch: 6 2400/3904 Training loss: 0.421669
Epoch: 6 3200/3904 Training loss: 0.415626
Training loss: 0.362021
Test loss: 2.699977; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 7 0/3904 Training loss: 0.337367
Epoch: 7 800/3904 Training loss: 0.219902
Epoch: 7 1600/3904 Training loss: 0.145315
Epoch: 7 2400/3904 Training loss: 0.489166
Epoch: 7 3200/3904 Training loss: 0.331889
Training loss: 0.321979
Test loss: 2.993167; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 8 0/3904 Training loss: 0.338406
Epoch: 8 800/3904 Training loss: 0.208734
Epoch: 8 1600/3904 Training loss: 0.149389
Epoch: 8 2400/3904 Training loss: 0.464538
Epoch: 8 3200/3904 Training loss: 0.312671
Training loss: 0.284227
Test loss: 3.525239; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 9 0/3904 Training loss: 0.483798
Epoch: 9 800/3904 Training loss: 0.304088
Epoch: 9 1600/3904 Training loss: 0.100318
Epoch: 9 2400/3904 Training loss: 0.366593
Epoch: 9 3200/3904 Training loss: 0.314529
Training loss: 0.266239
Test loss: 3.472028; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 10 0/3904 Training loss: 0.470530
Epoch: 10 800/3904 Training loss: 0.179018
Epoch: 10 1600/3904 Training loss: 0.197058
Epoch: 10 2400/3904 Training loss: 0.268827
Epoch: 10 3200/3904 Training loss: 0.392808
Training loss: 0.245311
Test loss: 3.703476; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
starting trial 223
[I 2022-12-05 06:13:48,653] Trial 222 finished with value: 0.2268835616438356 and parameters: {'d_model': 64, 'nhead': 8, 'n_encoders': 1, 'learning_rate': 0.00012592471317251084, 'weight_decay': 2.804908683743458e-06, 'dropout': 0.20595883599614023, 'max_pool_conv': 16, 'kernel_size': 12, 'd_mlp': 16, 'num_conv_layers': 3, 'encoder_dropout': 0.13446977836270646, 'd_feed_forward': 128, 'max_pool_dim': 8, 'n_mlp_layers': 3}. Best is trial 62 with value: 0.860445205479452.
Epoch: 0 0/3904 Training loss: 0.702588
Epoch: 0 800/3904 Training loss: 0.739089
Epoch: 0 1600/3904 Training loss: 0.442431
Epoch: 0 2400/3904 Training loss: 0.790244
Epoch: 0 3200/3904 Training loss: 0.533708
Training loss: 0.661649
Test loss: 0.824366; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 1 0/3904 Training loss: 0.701507
Epoch: 1 800/3904 Training loss: 0.694596
Epoch: 1 1600/3904 Training loss: 0.339103
Epoch: 1 2400/3904 Training loss: 0.842505
Epoch: 1 3200/3904 Training loss: 0.435434
Training loss: 0.592890
Test loss: 1.308343; True positive: 133; True negative: 146, False Positive: 119, False negative: 770, accuracy: 0.23886986301369864, precision: 0.5277777777777778, recall: 0.14728682170542637
Epoch: 2 0/3904 Training loss: 0.593681
Epoch: 2 800/3904 Training loss: 0.559637
Epoch: 2 1600/3904 Training loss: 0.250789
Epoch: 2 2400/3904 Training loss: 0.706131
Epoch: 2 3200/3904 Training loss: 0.386562
Training loss: 0.513428
Test loss: 0.761744; True positive: 593; True negative: 161, False Positive: 104, False negative: 310, accuracy: 0.6455479452054794, precision: 0.8507890961262554, recall: 0.6566998892580288
Epoch: 3 0/3904 Training loss: 0.597122
Epoch: 3 800/3904 Training loss: 0.619802
Epoch: 3 1600/3904 Training loss: 0.188086
Epoch: 3 2400/3904 Training loss: 0.506744
Epoch: 3 3200/3904 Training loss: 0.377440
Training loss: 0.459729
Test loss: 0.562913; True positive: 903; True negative: 0, False Positive: 265, False negative: 0, accuracy: 0.7731164383561644, precision: 0.7731164383561644, recall: 1.0
Epoch: 4 0/3904 Training loss: 0.450179
Epoch: 4 800/3904 Training loss: 0.590725
Epoch: 4 1600/3904 Training loss: 0.220243
Epoch: 4 2400/3904 Training loss: 0.598472
Epoch: 4 3200/3904 Training loss: 0.361585
Training loss: 0.432116
Test loss: 2.447391; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 5 0/3904 Training loss: 0.403990
Epoch: 5 800/3904 Training loss: 0.438724
Epoch: 5 1600/3904 Training loss: 0.199720
Epoch: 5 2400/3904 Training loss: 0.481835
Epoch: 5 3200/3904 Training loss: 0.422031
Training loss: 0.407119
Test loss: 2.775995; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 6 0/3904 Training loss: 0.390037
Epoch: 6 800/3904 Training loss: 0.579845
Epoch: 6 1600/3904 Training loss: 0.217729
Epoch: 6 2400/3904 Training loss: 0.463339
Epoch: 6 3200/3904 Training loss: 0.319960
Training loss: 0.402693
Test loss: 2.894998; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 7 0/3904 Training loss: 0.396783
Epoch: 7 800/3904 Training loss: 0.396211
Epoch: 7 1600/3904 Training loss: 0.165186
Epoch: 7 2400/3904 Training loss: 0.369683
Epoch: 7 3200/3904 Training loss: 0.296771
Training loss: 0.392780
Test loss: 3.087395; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 8 0/3904 Training loss: 0.435472
Epoch: 8 800/3904 Training loss: 0.378072
Epoch: 8 1600/3904 Training loss: 0.130276
Epoch: 8 2400/3904 Training loss: 0.359312
Epoch: 8 3200/3904 Training loss: 0.472940
Training loss: 0.388954
Test loss: 2.903770; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 9 0/3904 Training loss: 0.365115
Epoch: 9 800/3904 Training loss: 0.434480
Epoch: 9 1600/3904 Training loss: 0.114785
Epoch: 9 2400/3904 Training loss: 0.415133
Epoch: 9 3200/3904 Training loss: 0.293328
Training loss: 0.381639
Test loss: 2.847924; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 10 0/3904 Training loss: 0.355305
Epoch: 10 800/3904 Training loss: 0.414218
Epoch: 10 1600/3904 Training loss: 0.204371
Epoch: 10 2400/3904 Training loss: 0.378915
Epoch: 10 3200/3904 Training loss: 0.437528
Training loss: 0.378654
Test loss: 2.893232; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 11 0/3904 Training loss: 0.414893
Epoch: 11 800/3904 Training loss: 0.425340
Epoch: 11 1600/3904 Training loss: 0.168188
Epoch: 11 2400/3904 Training loss: 0.390595
Epoch: 11 3200/3904 Training loss: 0.338957
Training loss: 0.375932
Test loss: 2.953563; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 12 0/3904 Training loss: 0.293970
Epoch: 12 800/3904 Training loss: 0.429997
Epoch: 12 1600/3904 Training loss: 0.126930
Epoch: 12 2400/3904 Training loss: 0.302723
Epoch: 12 3200/3904 Training loss: 0.434621
Training loss: 0.371999
Test loss: 3.038056; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 13 0/3904 Training loss: 0.385255
Epoch: 13 800/3904 Training loss: 0.365703
Epoch: 13 1600/3904 Training loss: 0.099146
Epoch: 13 2400/3904 Training loss: 0.313936
Epoch: 13 3200/3904 Training loss: 0.360157
Training loss: 0.366150
Test loss: 2.958719; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
starting trial 224
[I 2022-12-05 06:17:14,251] Trial 223 finished with value: 0.7731164383561644 and parameters: {'d_model': 64, 'nhead': 8, 'n_encoders': 1, 'learning_rate': 9.078873475956194e-05, 'weight_decay': 3.537514918652288e-06, 'dropout': 0.3714833363848522, 'max_pool_conv': 32, 'kernel_size': 16, 'd_mlp': 16, 'num_conv_layers': 7, 'encoder_dropout': 0.11145666140236543, 'd_feed_forward': 128, 'max_pool_dim': 8, 'n_mlp_layers': 3}. Best is trial 62 with value: 0.860445205479452.
Epoch: 0 0/3904 Training loss: 0.689677
Epoch: 0 800/3904 Training loss: 0.719700
Epoch: 0 1600/3904 Training loss: 0.606325
Epoch: 0 2400/3904 Training loss: 0.745125
Epoch: 0 3200/3904 Training loss: 0.612315
Training loss: 0.670976
Test loss: 0.781428; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 1 0/3904 Training loss: 0.698496
Epoch: 1 800/3904 Training loss: 0.727586
Epoch: 1 1600/3904 Training loss: 0.568392
Epoch: 1 2400/3904 Training loss: 0.774252
Epoch: 1 3200/3904 Training loss: 0.601178
Training loss: 0.663355
Test loss: 0.814117; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 2 0/3904 Training loss: 0.701898
Epoch: 2 800/3904 Training loss: 0.738083
Epoch: 2 1600/3904 Training loss: 0.526094
Epoch: 2 2400/3904 Training loss: 0.778759
Epoch: 2 3200/3904 Training loss: 0.583029
Training loss: 0.659110
Test loss: 0.832852; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 3 0/3904 Training loss: 0.714605
Epoch: 3 800/3904 Training loss: 0.737296
Epoch: 3 1600/3904 Training loss: 0.515535
Epoch: 3 2400/3904 Training loss: 0.803171
Epoch: 3 3200/3904 Training loss: 0.577220
Training loss: 0.656655
Test loss: 0.844183; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 4 0/3904 Training loss: 0.715394
Epoch: 4 800/3904 Training loss: 0.739079
Epoch: 4 1600/3904 Training loss: 0.511317
Epoch: 4 2400/3904 Training loss: 0.806035
Epoch: 4 3200/3904 Training loss: 0.563393
Training loss: 0.654174
Test loss: 0.853728; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 5 0/3904 Training loss: 0.713646
Epoch: 5 800/3904 Training loss: 0.716796
Epoch: 5 1600/3904 Training loss: 0.496950
Epoch: 5 2400/3904 Training loss: 0.796756
Epoch: 5 3200/3904 Training loss: 0.568388
Training loss: 0.648994
Test loss: 0.842292; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 6 0/3904 Training loss: 0.701597
Epoch: 6 800/3904 Training loss: 0.668762
Epoch: 6 1600/3904 Training loss: 0.501191
Epoch: 6 2400/3904 Training loss: 0.783674
Epoch: 6 3200/3904 Training loss: 0.531067
Training loss: 0.638408
Test loss: 0.860721; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 7 0/3904 Training loss: 0.704224
Epoch: 7 800/3904 Training loss: 0.652821
Epoch: 7 1600/3904 Training loss: 0.463261
Epoch: 7 2400/3904 Training loss: 0.735178
Epoch: 7 3200/3904 Training loss: 0.538510
Training loss: 0.618579
Test loss: 0.882115; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 8 0/3904 Training loss: 0.631900
Epoch: 8 800/3904 Training loss: 0.599933
Epoch: 8 1600/3904 Training loss: 0.442469
Epoch: 8 2400/3904 Training loss: 0.682187
Epoch: 8 3200/3904 Training loss: 0.509640
Training loss: 0.590773
Test loss: 0.914990; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 9 0/3904 Training loss: 0.634493
Epoch: 9 800/3904 Training loss: 0.567432
Epoch: 9 1600/3904 Training loss: 0.380245
Epoch: 9 2400/3904 Training loss: 0.688941
Epoch: 9 3200/3904 Training loss: 0.462527
Training loss: 0.552946
Test loss: 0.928205; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 10 0/3904 Training loss: 0.543157
Epoch: 10 800/3904 Training loss: 0.576663
Epoch: 10 1600/3904 Training loss: 0.356476
Epoch: 10 2400/3904 Training loss: 0.699806
Epoch: 10 3200/3904 Training loss: 0.465786
Training loss: 0.507588
Test loss: 0.980096; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
starting trial 225
[I 2022-12-05 06:17:59,792] Trial 224 finished with value: 0.2268835616438356 and parameters: {'d_model': 64, 'nhead': 8, 'n_encoders': 1, 'learning_rate': 2.7547321069435306e-05, 'weight_decay': 4.415001458235686e-06, 'dropout': 0.38715077595636876, 'max_pool_conv': 64, 'kernel_size': 14, 'd_mlp': 16, 'num_conv_layers': 2, 'encoder_dropout': 0.21589665065432495, 'd_feed_forward': 128, 'max_pool_dim': 8, 'n_mlp_layers': 3}. Best is trial 62 with value: 0.860445205479452.
Epoch: 0 0/3904 Training loss: 0.701603
Epoch: 0 800/3904 Training loss: 0.722885
Epoch: 0 1600/3904 Training loss: 0.420191
Epoch: 0 2400/3904 Training loss: 0.722482
Epoch: 0 3200/3904 Training loss: 0.531306
Training loss: 0.653795
Test loss: 0.611216; True positive: 903; True negative: 0, False Positive: 265, False negative: 0, accuracy: 0.7731164383561644, precision: 0.7731164383561644, recall: 1.0
Epoch: 1 0/3904 Training loss: 0.712260
Epoch: 1 800/3904 Training loss: 0.642650
Epoch: 1 1600/3904 Training loss: 0.335574
Epoch: 1 2400/3904 Training loss: 0.519330
Epoch: 1 3200/3904 Training loss: 0.425578
Training loss: 0.560601
Test loss: 0.544106; True positive: 903; True negative: 0, False Positive: 265, False negative: 0, accuracy: 0.7731164383561644, precision: 0.7731164383561644, recall: 1.0
Epoch: 2 0/3904 Training loss: 0.585132
Epoch: 2 800/3904 Training loss: 0.317471
Epoch: 2 1600/3904 Training loss: 0.229785
Epoch: 2 2400/3904 Training loss: 0.519557
Epoch: 2 3200/3904 Training loss: 0.313488
Training loss: 0.454778
Test loss: 0.545792; True positive: 903; True negative: 0, False Positive: 265, False negative: 0, accuracy: 0.7731164383561644, precision: 0.7731164383561644, recall: 1.0
Epoch: 3 0/3904 Training loss: 0.483442
Epoch: 3 800/3904 Training loss: 0.388862
Epoch: 3 1600/3904 Training loss: 0.228143
Epoch: 3 2400/3904 Training loss: 0.311213
Epoch: 3 3200/3904 Training loss: 0.420723
Training loss: 0.402037
Test loss: 0.599010; True positive: 903; True negative: 0, False Positive: 265, False negative: 0, accuracy: 0.7731164383561644, precision: 0.7731164383561644, recall: 1.0
Epoch: 4 0/3904 Training loss: 0.467617
Epoch: 4 800/3904 Training loss: 0.174052
Epoch: 4 1600/3904 Training loss: 0.138344
Epoch: 4 2400/3904 Training loss: 0.247754
Epoch: 4 3200/3904 Training loss: 0.421513
Training loss: 0.363644
Test loss: 0.602593; True positive: 903; True negative: 0, False Positive: 265, False negative: 0, accuracy: 0.7731164383561644, precision: 0.7731164383561644, recall: 1.0
Epoch: 5 0/3904 Training loss: 0.419921
Epoch: 5 800/3904 Training loss: 0.415438
Epoch: 5 1600/3904 Training loss: 0.182759
Epoch: 5 2400/3904 Training loss: 0.358546
Epoch: 5 3200/3904 Training loss: 0.472755
Training loss: 0.354886
Test loss: 0.647873; True positive: 903; True negative: 0, False Positive: 265, False negative: 0, accuracy: 0.7731164383561644, precision: 0.7731164383561644, recall: 1.0
Epoch: 6 0/3904 Training loss: 0.378481
Epoch: 6 800/3904 Training loss: 0.314235
Epoch: 6 1600/3904 Training loss: 0.249734
Epoch: 6 2400/3904 Training loss: 0.253782
Epoch: 6 3200/3904 Training loss: 0.389114
Training loss: 0.332373
Test loss: 0.712868; True positive: 903; True negative: 0, False Positive: 265, False negative: 0, accuracy: 0.7731164383561644, precision: 0.7731164383561644, recall: 1.0
Epoch: 7 0/3904 Training loss: 0.318327
Epoch: 7 800/3904 Training loss: 0.292364
Epoch: 7 1600/3904 Training loss: 0.158799
Epoch: 7 2400/3904 Training loss: 0.173468
Epoch: 7 3200/3904 Training loss: 0.519796
Training loss: 0.342096
Test loss: 0.670364; True positive: 903; True negative: 0, False Positive: 265, False negative: 0, accuracy: 0.7731164383561644, precision: 0.7731164383561644, recall: 1.0
Epoch: 8 0/3904 Training loss: 0.353467
Epoch: 8 800/3904 Training loss: 0.399187
Epoch: 8 1600/3904 Training loss: 0.147330
Epoch: 8 2400/3904 Training loss: 0.324530
Epoch: 8 3200/3904 Training loss: 0.385249
Training loss: 0.322645
Test loss: 0.711003; True positive: 903; True negative: 0, False Positive: 265, False negative: 0, accuracy: 0.7731164383561644, precision: 0.7731164383561644, recall: 1.0
Epoch: 9 0/3904 Training loss: 0.410897
Epoch: 9 800/3904 Training loss: 0.103554
Epoch: 9 1600/3904 Training loss: 0.133624
Epoch: 9 2400/3904 Training loss: 0.221809
Epoch: 9 3200/3904 Training loss: 0.362112
Training loss: 0.309604
Test loss: 0.747102; True positive: 903; True negative: 0, False Positive: 265, False negative: 0, accuracy: 0.7731164383561644, precision: 0.7731164383561644, recall: 1.0
Epoch: 10 0/3904 Training loss: 0.301461
Epoch: 10 800/3904 Training loss: 0.308223
Epoch: 10 1600/3904 Training loss: 0.170117
Epoch: 10 2400/3904 Training loss: 0.165245
Epoch: 10 3200/3904 Training loss: 0.430986
Training loss: 0.289426
Test loss: 0.789442; True positive: 903; True negative: 0, False Positive: 265, False negative: 0, accuracy: 0.7731164383561644, precision: 0.7731164383561644, recall: 1.0
Epoch: 11 0/3904 Training loss: 0.418983
Epoch: 11 800/3904 Training loss: 0.119814
Epoch: 11 1600/3904 Training loss: 0.106231
Epoch: 11 2400/3904 Training loss: 0.194772
Epoch: 11 3200/3904 Training loss: 0.391865
Training loss: 0.286256
Test loss: 0.905464; True positive: 903; True negative: 0, False Positive: 265, False negative: 0, accuracy: 0.7731164383561644, precision: 0.7731164383561644, recall: 1.0
starting trial 226
[I 2022-12-05 06:18:41,522] Trial 225 finished with value: 0.7731164383561644 and parameters: {'d_model': 32, 'nhead': 8, 'n_encoders': 1, 'learning_rate': 0.0005958002761918628, 'weight_decay': 1.8584117033292875e-06, 'dropout': 0.21851710694556942, 'max_pool_conv': 64, 'kernel_size': 17, 'd_mlp': 16, 'num_conv_layers': 3, 'encoder_dropout': 0.10816632551406159, 'd_feed_forward': 64, 'max_pool_dim': 8, 'n_mlp_layers': 3}. Best is trial 62 with value: 0.860445205479452.
Epoch: 0 0/3904 Training loss: 0.693487
Epoch: 0 800/3904 Training loss: 0.742076
Epoch: 0 1600/3904 Training loss: 0.470057
Epoch: 0 2400/3904 Training loss: 0.809016
Epoch: 0 3200/3904 Training loss: 0.560663
Training loss: 0.661638
Test loss: 0.871623; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 1 0/3904 Training loss: 0.712115
Epoch: 1 800/3904 Training loss: 0.736626
Epoch: 1 1600/3904 Training loss: 0.436164
Epoch: 1 2400/3904 Training loss: 0.797827
Epoch: 1 3200/3904 Training loss: 0.523652
Training loss: 0.650954
Test loss: 1.088058; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 2 0/3904 Training loss: 0.700227
Epoch: 2 800/3904 Training loss: 0.716507
Epoch: 2 1600/3904 Training loss: 0.345453
Epoch: 2 2400/3904 Training loss: 0.842135
Epoch: 2 3200/3904 Training loss: 0.443990
Training loss: 0.583523
Test loss: 1.784768; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 3 0/3904 Training loss: 0.526928
Epoch: 3 800/3904 Training loss: 0.545081
Epoch: 3 1600/3904 Training loss: 0.247719
Epoch: 3 2400/3904 Training loss: 0.508767
Epoch: 3 3200/3904 Training loss: 0.462164
Training loss: 0.481469
Test loss: 1.983922; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 4 0/3904 Training loss: 0.485429
Epoch: 4 800/3904 Training loss: 0.392317
Epoch: 4 1600/3904 Training loss: 0.222853
Epoch: 4 2400/3904 Training loss: 0.322248
Epoch: 4 3200/3904 Training loss: 0.484126
Training loss: 0.438849
Test loss: 2.119411; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 5 0/3904 Training loss: 0.421965
Epoch: 5 800/3904 Training loss: 0.316947
Epoch: 5 1600/3904 Training loss: 0.165524
Epoch: 5 2400/3904 Training loss: 0.341464
Epoch: 5 3200/3904 Training loss: 0.481298
Training loss: 0.418559
Test loss: 2.218572; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 6 0/3904 Training loss: 0.447987
Epoch: 6 800/3904 Training loss: 0.399176
Epoch: 6 1600/3904 Training loss: 0.181354
Epoch: 6 2400/3904 Training loss: 0.269026
Epoch: 6 3200/3904 Training loss: 0.351115
Training loss: 0.402965
Test loss: 2.246567; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 7 0/3904 Training loss: 0.386836
Epoch: 7 800/3904 Training loss: 0.417779
Epoch: 7 1600/3904 Training loss: 0.198238
Epoch: 7 2400/3904 Training loss: 0.246175
Epoch: 7 3200/3904 Training loss: 0.302764
Training loss: 0.389914
Test loss: 2.361716; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 8 0/3904 Training loss: 0.439727
Epoch: 8 800/3904 Training loss: 0.289791
Epoch: 8 1600/3904 Training loss: 0.149060
Epoch: 8 2400/3904 Training loss: 0.270426
Epoch: 8 3200/3904 Training loss: 0.363955
Training loss: 0.387615
Test loss: 2.353925; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 9 0/3904 Training loss: 0.364231
Epoch: 9 800/3904 Training loss: 0.331396
Epoch: 9 1600/3904 Training loss: 0.154197
Epoch: 9 2400/3904 Training loss: 0.253431
Epoch: 9 3200/3904 Training loss: 0.277568
Training loss: 0.382650
Test loss: 2.355672; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 10 0/3904 Training loss: 0.304385
Epoch: 10 800/3904 Training loss: 0.386865
Epoch: 10 1600/3904 Training loss: 0.184883
Epoch: 10 2400/3904 Training loss: 0.233505
Epoch: 10 3200/3904 Training loss: 0.343500
Training loss: 0.366030
Test loss: 2.415935; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
starting trial 227
[I 2022-12-05 06:20:00,216] Trial 226 finished with value: 0.2268835616438356 and parameters: {'d_model': 64, 'nhead': 4, 'n_encoders': 1, 'learning_rate': 8.070117060311424e-05, 'weight_decay': 1.5116822184873575e-06, 'dropout': 0.40533918186882245, 'max_pool_conv': 32, 'kernel_size': 13, 'd_mlp': 32, 'num_conv_layers': 4, 'encoder_dropout': 0.09174375959069687, 'd_feed_forward': 128, 'max_pool_dim': 8, 'n_mlp_layers': 3}. Best is trial 62 with value: 0.860445205479452.
Epoch: 0 0/3904 Training loss: 0.696719
Epoch: 0 800/3904 Training loss: 0.714461
Epoch: 0 1600/3904 Training loss: 0.485880
Epoch: 0 2400/3904 Training loss: 0.780676
Epoch: 0 3200/3904 Training loss: 0.543895
Training loss: 0.661554
Test loss: 0.846580; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 1 0/3904 Training loss: 0.679881
Epoch: 1 800/3904 Training loss: 0.714547
Epoch: 1 1600/3904 Training loss: 0.389884
Epoch: 1 2400/3904 Training loss: 0.717937
Epoch: 1 3200/3904 Training loss: 0.472653
Training loss: 0.602268
Test loss: 0.912110; True positive: 1; True negative: 265, False Positive: 0, False negative: 902, accuracy: 0.22773972602739725, precision: 1.0, recall: 0.0011074197120708748
Epoch: 2 0/3904 Training loss: 0.552706
Epoch: 2 800/3904 Training loss: 0.542490
Epoch: 2 1600/3904 Training loss: 0.275819
Epoch: 2 2400/3904 Training loss: 0.713244
Epoch: 2 3200/3904 Training loss: 0.413158
Training loss: 0.475628
Test loss: 1.122950; True positive: 1; True negative: 265, False Positive: 0, False negative: 902, accuracy: 0.22773972602739725, precision: 1.0, recall: 0.0011074197120708748
Epoch: 3 0/3904 Training loss: 0.389159
Epoch: 3 800/3904 Training loss: 0.366069
Epoch: 3 1600/3904 Training loss: 0.206564
Epoch: 3 2400/3904 Training loss: 0.753853
Epoch: 3 3200/3904 Training loss: 0.408157
Training loss: 0.396556
Test loss: 1.273596; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 4 0/3904 Training loss: 0.303268
Epoch: 4 800/3904 Training loss: 0.343698
Epoch: 4 1600/3904 Training loss: 0.200725
Epoch: 4 2400/3904 Training loss: 0.618264
Epoch: 4 3200/3904 Training loss: 0.400855
Training loss: 0.357250
Test loss: 1.130836; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 5 0/3904 Training loss: 0.386063
Epoch: 5 800/3904 Training loss: 0.264337
Epoch: 5 1600/3904 Training loss: 0.223120
Epoch: 5 2400/3904 Training loss: 0.511364
Epoch: 5 3200/3904 Training loss: 0.414095
Training loss: 0.321819
Test loss: 0.516847; True positive: 838; True negative: 118, False Positive: 147, False negative: 65, accuracy: 0.8184931506849316, precision: 0.8507614213197969, recall: 0.9280177187153932
Epoch: 6 0/3904 Training loss: 0.270644
Epoch: 6 800/3904 Training loss: 0.224305
Epoch: 6 1600/3904 Training loss: 0.175578
Epoch: 6 2400/3904 Training loss: 0.345867
Epoch: 6 3200/3904 Training loss: 0.477327
Training loss: 0.298657
Test loss: 0.907505; True positive: 31; True negative: 264, False Positive: 1, False negative: 872, accuracy: 0.2525684931506849, precision: 0.96875, recall: 0.03433001107419712
Epoch: 7 0/3904 Training loss: 0.285261
Epoch: 7 800/3904 Training loss: 0.179832
Epoch: 7 1600/3904 Training loss: 0.213233
Epoch: 7 2400/3904 Training loss: 0.439471
Epoch: 7 3200/3904 Training loss: 0.440714
Training loss: 0.273326
Test loss: 1.494458; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 8 0/3904 Training loss: 0.142578
Epoch: 8 800/3904 Training loss: 0.244661
Epoch: 8 1600/3904 Training loss: 0.084135
Epoch: 8 2400/3904 Training loss: 0.374289
Epoch: 8 3200/3904 Training loss: 0.460458
Training loss: 0.261879
Test loss: 1.416746; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 9 0/3904 Training loss: 0.270459
Epoch: 9 800/3904 Training loss: 0.320932
Epoch: 9 1600/3904 Training loss: 0.083314
Epoch: 9 2400/3904 Training loss: 0.369972
Epoch: 9 3200/3904 Training loss: 0.430807
Training loss: 0.253947
Test loss: 1.753515; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 10 0/3904 Training loss: 0.200068
Epoch: 10 800/3904 Training loss: 0.177955
Epoch: 10 1600/3904 Training loss: 0.136108
Epoch: 10 2400/3904 Training loss: 0.207380
Epoch: 10 3200/3904 Training loss: 0.332679
Training loss: 0.238465
Test loss: 1.708934; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 11 0/3904 Training loss: 0.258564
Epoch: 11 800/3904 Training loss: 0.136794
Epoch: 11 1600/3904 Training loss: 0.079787
Epoch: 11 2400/3904 Training loss: 0.180054
Epoch: 11 3200/3904 Training loss: 0.438023
Training loss: 0.225481
Test loss: 1.100062; True positive: 19; True negative: 265, False Positive: 0, False negative: 884, accuracy: 0.24315068493150685, precision: 1.0, recall: 0.021040974529346623
Epoch: 12 0/3904 Training loss: 0.131645
Epoch: 12 800/3904 Training loss: 0.213468
Epoch: 12 1600/3904 Training loss: 0.118978
Epoch: 12 2400/3904 Training loss: 0.183849
Epoch: 12 3200/3904 Training loss: 0.430507
Training loss: 0.220658
Test loss: 0.897844; True positive: 154; True negative: 259, False Positive: 6, False negative: 749, accuracy: 0.3535958904109589, precision: 0.9625, recall: 0.17054263565891473
Epoch: 13 0/3904 Training loss: 0.145811
Epoch: 13 800/3904 Training loss: 0.092986
Epoch: 13 1600/3904 Training loss: 0.093840
Epoch: 13 2400/3904 Training loss: 0.167573
Epoch: 13 3200/3904 Training loss: 0.396881
Training loss: 0.211629
Test loss: 0.882797; True positive: 161; True negative: 260, False Positive: 5, False negative: 742, accuracy: 0.3604452054794521, precision: 0.9698795180722891, recall: 0.17829457364341086
Epoch: 14 0/3904 Training loss: 0.188635
Epoch: 14 800/3904 Training loss: 0.148285
Epoch: 14 1600/3904 Training loss: 0.087998
Epoch: 14 2400/3904 Training loss: 0.088185
Epoch: 14 3200/3904 Training loss: 0.337347
Training loss: 0.199649
Test loss: 0.487703; True positive: 835; True negative: 117, False Positive: 148, False negative: 68, accuracy: 0.815068493150685, precision: 0.8494404883011191, recall: 0.9246954595791805
Epoch: 15 0/3904 Training loss: 0.149133
Epoch: 15 800/3904 Training loss: 0.182211
Epoch: 15 1600/3904 Training loss: 0.135067
Epoch: 15 2400/3904 Training loss: 0.218930
Epoch: 15 3200/3904 Training loss: 0.252109
Training loss: 0.189414
Test loss: 0.578178; True positive: 719; True negative: 155, False Positive: 110, False negative: 184, accuracy: 0.7482876712328768, precision: 0.8673100120627262, recall: 0.7962347729789591
Epoch: 16 0/3904 Training loss: 0.206509
Epoch: 16 800/3904 Training loss: 0.061790
Epoch: 16 1600/3904 Training loss: 0.062537
Epoch: 16 2400/3904 Training loss: 0.181982
Epoch: 16 3200/3904 Training loss: 0.321510
Training loss: 0.185943
Test loss: 0.633264; True positive: 433; True negative: 226, False Positive: 39, False negative: 470, accuracy: 0.5642123287671232, precision: 0.9173728813559322, recall: 0.4795127353266888
Epoch: 17 0/3904 Training loss: 0.124968
Epoch: 17 800/3904 Training loss: 0.075523
Epoch: 17 1600/3904 Training loss: 0.047037
Epoch: 17 2400/3904 Training loss: 0.138819
Epoch: 17 3200/3904 Training loss: 0.319332
Training loss: 0.167790
Test loss: 0.567912; True positive: 659; True negative: 184, False Positive: 81, False negative: 244, accuracy: 0.7217465753424658, precision: 0.8905405405405405, recall: 0.7297895902547066
Epoch: 18 0/3904 Training loss: 0.133139
Epoch: 18 800/3904 Training loss: 0.181188
Epoch: 18 1600/3904 Training loss: 0.115455
Epoch: 18 2400/3904 Training loss: 0.069684
Epoch: 18 3200/3904 Training loss: 0.198749
Training loss: 0.162715
Test loss: 0.534883; True positive: 821; True negative: 126, False Positive: 139, False negative: 82, accuracy: 0.8107876712328768, precision: 0.8552083333333333, recall: 0.9091915836101883
Epoch: 19 0/3904 Training loss: 0.185530
Epoch: 19 800/3904 Training loss: 0.103060
Epoch: 19 1600/3904 Training loss: 0.032185
Epoch: 19 2400/3904 Training loss: 0.197428
Epoch: 19 3200/3904 Training loss: 0.190415
Training loss: 0.152075
Test loss: 0.546469; True positive: 837; True negative: 117, False Positive: 148, False negative: 66, accuracy: 0.8167808219178082, precision: 0.849746192893401, recall: 0.9269102990033222
Epoch: 20 0/3904 Training loss: 0.090220
Epoch: 20 800/3904 Training loss: 0.101959
Epoch: 20 1600/3904 Training loss: 0.103823
Epoch: 20 2400/3904 Training loss: 0.049049
Epoch: 20 3200/3904 Training loss: 0.326072
Training loss: 0.151944
Test loss: 0.534768; True positive: 899; True negative: 14, False Positive: 251, False negative: 4, accuracy: 0.7816780821917808, precision: 0.7817391304347826, recall: 0.9955703211517165
Epoch: 21 0/3904 Training loss: 0.086318
Epoch: 21 800/3904 Training loss: 0.048515
Epoch: 21 1600/3904 Training loss: 0.106728
Epoch: 21 2400/3904 Training loss: 0.077233
Epoch: 21 3200/3904 Training loss: 0.369347
Training loss: 0.144009
Test loss: 0.496567; True positive: 892; True negative: 33, False Positive: 232, False negative: 11, accuracy: 0.7919520547945206, precision: 0.7935943060498221, recall: 0.9878183831672204
Epoch: 22 0/3904 Training loss: 0.301425
Epoch: 22 800/3904 Training loss: 0.100263
Epoch: 22 1600/3904 Training loss: 0.108540
Epoch: 22 2400/3904 Training loss: 0.255017
Epoch: 22 3200/3904 Training loss: 0.264077
Training loss: 0.138752
Test loss: 0.498369; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 23 0/3904 Training loss: 0.065136
Epoch: 23 800/3904 Training loss: 0.210156
Epoch: 23 1600/3904 Training loss: 0.024560
Epoch: 23 2400/3904 Training loss: 0.060152
Epoch: 23 3200/3904 Training loss: 0.430547
Training loss: 0.124831
Test loss: 0.504854; True positive: 869; True negative: 64, False Positive: 201, False negative: 34, accuracy: 0.7988013698630136, precision: 0.8121495327102803, recall: 0.9623477297895903
Epoch: 24 0/3904 Training loss: 0.075451
Epoch: 24 800/3904 Training loss: 0.126731
Epoch: 24 1600/3904 Training loss: 0.015103
Epoch: 24 2400/3904 Training loss: 0.083693
Epoch: 24 3200/3904 Training loss: 0.195333
Training loss: 0.130072
Test loss: 0.510019; True positive: 835; True negative: 115, False Positive: 150, False negative: 68, accuracy: 0.8133561643835616, precision: 0.8477157360406091, recall: 0.9246954595791805
starting trial 228
[I 2022-12-05 06:21:44,759] Trial 227 finished with value: 0.8184931506849316 and parameters: {'d_model': 64, 'nhead': 8, 'n_encoders': 1, 'learning_rate': 0.00010229580897093566, 'weight_decay': 3.090881427508094e-06, 'dropout': 0.25080440452468716, 'max_pool_conv': 64, 'kernel_size': 15, 'd_mlp': 16, 'num_conv_layers': 2, 'encoder_dropout': 0.008407243546401686, 'd_feed_forward': 128, 'max_pool_dim': 8, 'n_mlp_layers': 3}. Best is trial 62 with value: 0.860445205479452.
Epoch: 0 0/3904 Training loss: 0.700442
Epoch: 0 800/3904 Training loss: 0.731848
Epoch: 0 1600/3904 Training loss: 0.433848
Epoch: 0 2400/3904 Training loss: 0.764093
Epoch: 0 3200/3904 Training loss: 0.552629
Training loss: 0.664419
Test loss: 0.805534; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 1 0/3904 Training loss: 0.716222
Epoch: 1 800/3904 Training loss: 0.728892
Epoch: 1 1600/3904 Training loss: 0.414876
Epoch: 1 2400/3904 Training loss: 0.777248
Epoch: 1 3200/3904 Training loss: 0.509260
Training loss: 0.644219
Test loss: 0.630090; True positive: 903; True negative: 0, False Positive: 265, False negative: 0, accuracy: 0.7731164383561644, precision: 0.7731164383561644, recall: 1.0
Epoch: 2 0/3904 Training loss: 0.639867
Epoch: 2 800/3904 Training loss: 0.598982
Epoch: 2 1600/3904 Training loss: 0.260805
Epoch: 2 2400/3904 Training loss: 0.758066
Epoch: 2 3200/3904 Training loss: 0.330812
Training loss: 0.542007
Test loss: 0.594028; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 3 0/3904 Training loss: 0.501041
Epoch: 3 800/3904 Training loss: 0.366429
Epoch: 3 1600/3904 Training loss: 0.242485
Epoch: 3 2400/3904 Training loss: 0.549112
Epoch: 3 3200/3904 Training loss: 0.350750
Training loss: 0.456788
Test loss: 0.591684; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 4 0/3904 Training loss: 0.400932
Epoch: 4 800/3904 Training loss: 0.424949
Epoch: 4 1600/3904 Training loss: 0.189229
Epoch: 4 2400/3904 Training loss: 0.500056
Epoch: 4 3200/3904 Training loss: 0.272829
Training loss: 0.417562
Test loss: 0.582704; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 5 0/3904 Training loss: 0.341325
Epoch: 5 800/3904 Training loss: 0.362837
Epoch: 5 1600/3904 Training loss: 0.149221
Epoch: 5 2400/3904 Training loss: 0.357214
Epoch: 5 3200/3904 Training loss: 0.469340
Training loss: 0.391006
Test loss: 0.583918; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 6 0/3904 Training loss: 0.324304
Epoch: 6 800/3904 Training loss: 0.322162
Epoch: 6 1600/3904 Training loss: 0.106345
Epoch: 6 2400/3904 Training loss: 0.353306
Epoch: 6 3200/3904 Training loss: 0.411389
Training loss: 0.373392
Test loss: 0.576924; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 7 0/3904 Training loss: 0.323946
Epoch: 7 800/3904 Training loss: 0.269749
Epoch: 7 1600/3904 Training loss: 0.119538
Epoch: 7 2400/3904 Training loss: 0.317925
Epoch: 7 3200/3904 Training loss: 0.297162
Training loss: 0.349793
Test loss: 0.585042; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 8 0/3904 Training loss: 0.326408
Epoch: 8 800/3904 Training loss: 0.191990
Epoch: 8 1600/3904 Training loss: 0.151287
Epoch: 8 2400/3904 Training loss: 0.258433
Epoch: 8 3200/3904 Training loss: 0.357884
Training loss: 0.325664
Test loss: 0.598794; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 9 0/3904 Training loss: 0.248008
Epoch: 9 800/3904 Training loss: 0.161578
Epoch: 9 1600/3904 Training loss: 0.096998
Epoch: 9 2400/3904 Training loss: 0.302018
Epoch: 9 3200/3904 Training loss: 0.307077
Training loss: 0.296276
Test loss: 0.632110; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 10 0/3904 Training loss: 0.235393
Epoch: 10 800/3904 Training loss: 0.099957
Epoch: 10 1600/3904 Training loss: 0.169594
Epoch: 10 2400/3904 Training loss: 0.263601
Epoch: 10 3200/3904 Training loss: 0.308046
Training loss: 0.283873
Test loss: 0.650409; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 11 0/3904 Training loss: 0.216404
Epoch: 11 800/3904 Training loss: 0.147927
Epoch: 11 1600/3904 Training loss: 0.095097
Epoch: 11 2400/3904 Training loss: 0.202502
Epoch: 11 3200/3904 Training loss: 0.285359
Training loss: 0.264176
Test loss: 0.697940; True positive: 836; True negative: 118, False Positive: 147, False negative: 67, accuracy: 0.8167808219178082, precision: 0.8504577822990844, recall: 0.9258028792912514
Epoch: 12 0/3904 Training loss: 0.186275
Epoch: 12 800/3904 Training loss: 0.085215
Epoch: 12 1600/3904 Training loss: 0.110854
Epoch: 12 2400/3904 Training loss: 0.176912
Epoch: 12 3200/3904 Training loss: 0.361677
Training loss: 0.252938
Test loss: 0.771124; True positive: 828; True negative: 119, False Positive: 146, False negative: 75, accuracy: 0.8107876712328768, precision: 0.8501026694045175, recall: 0.9169435215946844
Epoch: 13 0/3904 Training loss: 0.169060
Epoch: 13 800/3904 Training loss: 0.164123
Epoch: 13 1600/3904 Training loss: 0.113867
Epoch: 13 2400/3904 Training loss: 0.238527
Epoch: 13 3200/3904 Training loss: 0.275814
Training loss: 0.237392
Test loss: 0.771897; True positive: 833; True negative: 118, False Positive: 147, False negative: 70, accuracy: 0.8142123287671232, precision: 0.85, recall: 0.9224806201550387
Epoch: 14 0/3904 Training loss: 0.226084
Epoch: 14 800/3904 Training loss: 0.058115
Epoch: 14 1600/3904 Training loss: 0.093746
Epoch: 14 2400/3904 Training loss: 0.181269
Epoch: 14 3200/3904 Training loss: 0.322123
Training loss: 0.227390
Test loss: 0.746481; True positive: 838; True negative: 118, False Positive: 147, False negative: 65, accuracy: 0.8184931506849316, precision: 0.8507614213197969, recall: 0.9280177187153932
Epoch: 15 0/3904 Training loss: 0.280117
Epoch: 15 800/3904 Training loss: 0.044788
Epoch: 15 1600/3904 Training loss: 0.218636
Epoch: 15 2400/3904 Training loss: 0.174640
Epoch: 15 3200/3904 Training loss: 0.181553
Training loss: 0.220891
Test loss: 0.742738; True positive: 838; True negative: 118, False Positive: 147, False negative: 65, accuracy: 0.8184931506849316, precision: 0.8507614213197969, recall: 0.9280177187153932
Epoch: 16 0/3904 Training loss: 0.147188
Epoch: 16 800/3904 Training loss: 0.062600
Epoch: 16 1600/3904 Training loss: 0.067390
Epoch: 16 2400/3904 Training loss: 0.159075
Epoch: 16 3200/3904 Training loss: 0.314214
Training loss: 0.204516
Test loss: 0.774181; True positive: 838; True negative: 118, False Positive: 147, False negative: 65, accuracy: 0.8184931506849316, precision: 0.8507614213197969, recall: 0.9280177187153932
starting trial 229
[I 2022-12-05 06:23:24,938] Trial 228 finished with value: 0.8184931506849316 and parameters: {'d_model': 64, 'nhead': 8, 'n_encoders': 1, 'learning_rate': 0.0001393085469405181, 'weight_decay': 4.959858950231987e-06, 'dropout': 0.20132721647240256, 'max_pool_conv': 16, 'kernel_size': 12, 'd_mlp': 32, 'num_conv_layers': 3, 'encoder_dropout': 0.06525038735942015, 'd_feed_forward': 128, 'max_pool_dim': 8, 'n_mlp_layers': 3}. Best is trial 62 with value: 0.860445205479452.
Epoch: 0 0/3904 Training loss: 0.704278
Epoch: 0 800/3904 Training loss: 0.716373
Epoch: 0 1600/3904 Training loss: 0.489208
Epoch: 0 2400/3904 Training loss: 0.782868
Epoch: 0 3200/3904 Training loss: 0.537833
Training loss: 0.659249
Test loss: 0.860543; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 1 0/3904 Training loss: 0.733181
Epoch: 1 800/3904 Training loss: 0.727123
Epoch: 1 1600/3904 Training loss: 0.440186
Epoch: 1 2400/3904 Training loss: 0.782812
Epoch: 1 3200/3904 Training loss: 0.533258
Training loss: 0.644258
Test loss: 0.837613; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 2 0/3904 Training loss: 0.718925
Epoch: 2 800/3904 Training loss: 0.692093
Epoch: 2 1600/3904 Training loss: 0.403810
Epoch: 2 2400/3904 Training loss: 0.693835
Epoch: 2 3200/3904 Training loss: 0.521993
Training loss: 0.596307
Test loss: 0.980703; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 3 0/3904 Training loss: 0.546312
Epoch: 3 800/3904 Training loss: 0.610144
Epoch: 3 1600/3904 Training loss: 0.307945
Epoch: 3 2400/3904 Training loss: 0.662286
Epoch: 3 3200/3904 Training loss: 0.406102
Training loss: 0.521278
Test loss: 1.427071; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 4 0/3904 Training loss: 0.473415
Epoch: 4 800/3904 Training loss: 0.515365
Epoch: 4 1600/3904 Training loss: 0.250571
Epoch: 4 2400/3904 Training loss: 0.597198
Epoch: 4 3200/3904 Training loss: 0.426148
Training loss: 0.465805
Test loss: 1.621038; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 5 0/3904 Training loss: 0.373721
Epoch: 5 800/3904 Training loss: 0.414789
Epoch: 5 1600/3904 Training loss: 0.199325
Epoch: 5 2400/3904 Training loss: 0.667697
Epoch: 5 3200/3904 Training loss: 0.475433
Training loss: 0.423736
Test loss: 1.677510; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 6 0/3904 Training loss: 0.321829
Epoch: 6 800/3904 Training loss: 0.412557
Epoch: 6 1600/3904 Training loss: 0.194028
Epoch: 6 2400/3904 Training loss: 0.659251
Epoch: 6 3200/3904 Training loss: 0.461642
Training loss: 0.383005
Test loss: 1.665401; True positive: 1; True negative: 265, False Positive: 0, False negative: 902, accuracy: 0.22773972602739725, precision: 1.0, recall: 0.0011074197120708748
Epoch: 7 0/3904 Training loss: 0.516113
Epoch: 7 800/3904 Training loss: 0.353778
Epoch: 7 1600/3904 Training loss: 0.208016
Epoch: 7 2400/3904 Training loss: 0.615128
Epoch: 7 3200/3904 Training loss: 0.372725
Training loss: 0.362835
Test loss: 1.696066; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 8 0/3904 Training loss: 0.304249
Epoch: 8 800/3904 Training loss: 0.368886
Epoch: 8 1600/3904 Training loss: 0.229764
Epoch: 8 2400/3904 Training loss: 0.461143
Epoch: 8 3200/3904 Training loss: 0.465002
Training loss: 0.343080
Test loss: 1.630911; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 9 0/3904 Training loss: 0.206944
Epoch: 9 800/3904 Training loss: 0.329605
Epoch: 9 1600/3904 Training loss: 0.094117
Epoch: 9 2400/3904 Training loss: 0.363912
Epoch: 9 3200/3904 Training loss: 0.431704
Training loss: 0.313775
Test loss: 1.732887; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 10 0/3904 Training loss: 0.328724
Epoch: 10 800/3904 Training loss: 0.287413
Epoch: 10 1600/3904 Training loss: 0.072747
Epoch: 10 2400/3904 Training loss: 0.465335
Epoch: 10 3200/3904 Training loss: 0.418287
Training loss: 0.298178
Test loss: 1.733453; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 11 0/3904 Training loss: 0.418145
Epoch: 11 800/3904 Training loss: 0.298036
Epoch: 11 1600/3904 Training loss: 0.102669
Epoch: 11 2400/3904 Training loss: 0.269410
Epoch: 11 3200/3904 Training loss: 0.509338
Training loss: 0.287023
Test loss: 1.774994; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
starting trial 230
[I 2022-12-05 06:24:07,399] Trial 229 finished with value: 0.22773972602739725 and parameters: {'d_model': 64, 'nhead': 8, 'n_encoders': 1, 'learning_rate': 0.00011185618085964868, 'weight_decay': 3.4683311373479633e-06, 'dropout': 0.4523124190771557, 'max_pool_conv': 64, 'kernel_size': 11, 'd_mlp': 16, 'num_conv_layers': 2, 'encoder_dropout': 0.12297656137156503, 'd_feed_forward': 128, 'max_pool_dim': 16, 'n_mlp_layers': 3}. Best is trial 62 with value: 0.860445205479452.
Epoch: 0 0/3904 Training loss: 0.682329
Epoch: 0 800/3904 Training loss: 0.723653
Epoch: 0 1600/3904 Training loss: 0.485255
Epoch: 0 2400/3904 Training loss: 0.806809
Epoch: 0 3200/3904 Training loss: 0.550411
Training loss: 0.661795
Test loss: 0.898945; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 1 0/3904 Training loss: 0.701245
Epoch: 1 800/3904 Training loss: 0.741952
Epoch: 1 1600/3904 Training loss: 0.457903
Epoch: 1 2400/3904 Training loss: 0.807048
Epoch: 1 3200/3904 Training loss: 0.529932
Training loss: 0.648757
Test loss: 0.872097; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 2 0/3904 Training loss: 0.713890
Epoch: 2 800/3904 Training loss: 0.759571
Epoch: 2 1600/3904 Training loss: 0.359113
Epoch: 2 2400/3904 Training loss: 0.611210
Epoch: 2 3200/3904 Training loss: 0.467272
Training loss: 0.611016
Test loss: 0.891569; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 3 0/3904 Training loss: 0.599930
Epoch: 3 800/3904 Training loss: 0.606528
Epoch: 3 1600/3904 Training loss: 0.281114
Epoch: 3 2400/3904 Training loss: 0.505465
Epoch: 3 3200/3904 Training loss: 0.410176
Training loss: 0.555655
Test loss: 0.941379; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 4 0/3904 Training loss: 0.482700
Epoch: 4 800/3904 Training loss: 0.463313
Epoch: 4 1600/3904 Training loss: 0.295057
Epoch: 4 2400/3904 Training loss: 0.457054
Epoch: 4 3200/3904 Training loss: 0.423799
Training loss: 0.522799
Test loss: 1.027425; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 5 0/3904 Training loss: 0.436145
Epoch: 5 800/3904 Training loss: 0.488803
Epoch: 5 1600/3904 Training loss: 0.283352
Epoch: 5 2400/3904 Training loss: 0.463673
Epoch: 5 3200/3904 Training loss: 0.442285
Training loss: 0.496528
Test loss: 1.104066; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 6 0/3904 Training loss: 0.492123
Epoch: 6 800/3904 Training loss: 0.440172
Epoch: 6 1600/3904 Training loss: 0.246847
Epoch: 6 2400/3904 Training loss: 0.411293
Epoch: 6 3200/3904 Training loss: 0.389664
Training loss: 0.471068
Test loss: 1.118641; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 7 0/3904 Training loss: 0.349298
Epoch: 7 800/3904 Training loss: 0.517221
Epoch: 7 1600/3904 Training loss: 0.180797
Epoch: 7 2400/3904 Training loss: 0.441657
Epoch: 7 3200/3904 Training loss: 0.269751
Training loss: 0.461553
Test loss: 1.179850; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 8 0/3904 Training loss: 0.399467
Epoch: 8 800/3904 Training loss: 0.476396
Epoch: 8 1600/3904 Training loss: 0.193125
Epoch: 8 2400/3904 Training loss: 0.423415
Epoch: 8 3200/3904 Training loss: 0.301918
Training loss: 0.439174
Test loss: 1.249132; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 9 0/3904 Training loss: 0.382181
Epoch: 9 800/3904 Training loss: 0.380803
Epoch: 9 1600/3904 Training loss: 0.287137
Epoch: 9 2400/3904 Training loss: 0.365013
Epoch: 9 3200/3904 Training loss: 0.274865
Training loss: 0.434996
Test loss: 1.216973; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 10 0/3904 Training loss: 0.382451
Epoch: 10 800/3904 Training loss: 0.374045
Epoch: 10 1600/3904 Training loss: 0.185936
Epoch: 10 2400/3904 Training loss: 0.389311
Epoch: 10 3200/3904 Training loss: 0.370359
Training loss: 0.418464
Test loss: 0.780349; True positive: 330; True negative: 197, False Positive: 68, False negative: 573, accuracy: 0.4511986301369863, precision: 0.8291457286432161, recall: 0.3654485049833887
Epoch: 11 0/3904 Training loss: 0.399697
Epoch: 11 800/3904 Training loss: 0.372035
Epoch: 11 1600/3904 Training loss: 0.141992
Epoch: 11 2400/3904 Training loss: 0.324713
Epoch: 11 3200/3904 Training loss: 0.328387
Training loss: 0.418734
Test loss: 0.477630; True positive: 833; True negative: 121, False Positive: 144, False negative: 70, accuracy: 0.8167808219178082, precision: 0.8526100307062436, recall: 0.9224806201550387
Epoch: 12 0/3904 Training loss: 0.366297
Epoch: 12 800/3904 Training loss: 0.361541
Epoch: 12 1600/3904 Training loss: 0.145931
Epoch: 12 2400/3904 Training loss: 0.386347
Epoch: 12 3200/3904 Training loss: 0.328827
Training loss: 0.415772
Test loss: 0.458517; True positive: 811; True negative: 139, False Positive: 126, False negative: 92, accuracy: 0.8133561643835616, precision: 0.8655282817502669, recall: 0.8981173864894795
Epoch: 13 0/3904 Training loss: 0.258359
Epoch: 13 800/3904 Training loss: 0.365100
Epoch: 13 1600/3904 Training loss: 0.171347
Epoch: 13 2400/3904 Training loss: 0.305075
Epoch: 13 3200/3904 Training loss: 0.320183
Training loss: 0.393230
Test loss: 0.464949; True positive: 786; True negative: 159, False Positive: 106, False negative: 117, accuracy: 0.8090753424657534, precision: 0.8811659192825112, recall: 0.8704318936877077
Epoch: 14 0/3904 Training loss: 0.302858
Epoch: 14 800/3904 Training loss: 0.515976
Epoch: 14 1600/3904 Training loss: 0.133735
Epoch: 14 2400/3904 Training loss: 0.463059
Epoch: 14 3200/3904 Training loss: 0.340732
Training loss: 0.399088
Test loss: 0.589831; True positive: 649; True negative: 200, False Positive: 65, False negative: 254, accuracy: 0.7268835616438356, precision: 0.9089635854341737, recall: 0.7187153931339978
Epoch: 15 0/3904 Training loss: 0.319478
Epoch: 15 800/3904 Training loss: 0.388641
Epoch: 15 1600/3904 Training loss: 0.165042
Epoch: 15 2400/3904 Training loss: 0.349995
Epoch: 15 3200/3904 Training loss: 0.290469
Training loss: 0.389590
Test loss: 1.420400; True positive: 151; True negative: 260, False Positive: 5, False negative: 752, accuracy: 0.3518835616438356, precision: 0.967948717948718, recall: 0.1672203765227021
Epoch: 16 0/3904 Training loss: 0.268691
Epoch: 16 800/3904 Training loss: 0.215112
Epoch: 16 1600/3904 Training loss: 0.103402
Epoch: 16 2400/3904 Training loss: 0.479465
Epoch: 16 3200/3904 Training loss: 0.267869
Training loss: 0.380204
Test loss: 1.582239; True positive: 104; True negative: 264, False Positive: 1, False negative: 799, accuracy: 0.3150684931506849, precision: 0.9904761904761905, recall: 0.11517165005537099
Epoch: 17 0/3904 Training loss: 0.258208
Epoch: 17 800/3904 Training loss: 0.325586
Epoch: 17 1600/3904 Training loss: 0.115313
Epoch: 17 2400/3904 Training loss: 0.437036
Epoch: 17 3200/3904 Training loss: 0.306453
Training loss: 0.380471
Test loss: 1.780601; True positive: 31; True negative: 265, False Positive: 0, False negative: 872, accuracy: 0.2534246575342466, precision: 1.0, recall: 0.03433001107419712
Epoch: 18 0/3904 Training loss: 0.305139
Epoch: 18 800/3904 Training loss: 0.313111
Epoch: 18 1600/3904 Training loss: 0.111272
Epoch: 18 2400/3904 Training loss: 0.374379
Epoch: 18 3200/3904 Training loss: 0.264171
Training loss: 0.376198
Test loss: 1.985905; True positive: 10; True negative: 265, False Positive: 0, False negative: 893, accuracy: 0.23544520547945205, precision: 1.0, recall: 0.01107419712070875
Epoch: 19 0/3904 Training loss: 0.385471
Epoch: 19 800/3904 Training loss: 0.330759
Epoch: 19 1600/3904 Training loss: 0.196404
Epoch: 19 2400/3904 Training loss: 0.628570
Epoch: 19 3200/3904 Training loss: 0.234085
Training loss: 0.359111
Test loss: 2.272755; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 20 0/3904 Training loss: 0.310501
Epoch: 20 800/3904 Training loss: 0.281210
Epoch: 20 1600/3904 Training loss: 0.183827
Epoch: 20 2400/3904 Training loss: 0.369660
Epoch: 20 3200/3904 Training loss: 0.209746
Training loss: 0.363867
Test loss: 2.192200; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 21 0/3904 Training loss: 0.336877
Epoch: 21 800/3904 Training loss: 0.293731
Epoch: 21 1600/3904 Training loss: 0.144619
Epoch: 21 2400/3904 Training loss: 0.429556
Epoch: 21 3200/3904 Training loss: 0.308124
Training loss: 0.355416
Test loss: 2.043662; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 22 0/3904 Training loss: 0.314565
Epoch: 22 800/3904 Training loss: 0.331335
Epoch: 22 1600/3904 Training loss: 0.159170
Epoch: 22 2400/3904 Training loss: 0.370123
Epoch: 22 3200/3904 Training loss: 0.245498
Training loss: 0.351749
Test loss: 2.037283; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
starting trial 231
[I 2022-12-05 06:25:07,007] Trial 230 finished with value: 0.8167808219178082 and parameters: {'d_model': 16, 'nhead': 4, 'n_encoders': 1, 'learning_rate': 0.00012285082347793407, 'weight_decay': 3.873395599000276e-06, 'dropout': 0.20960510035616334, 'max_pool_conv': 64, 'kernel_size': 6, 'd_mlp': 62, 'num_conv_layers': 3, 'encoder_dropout': 0.04372641906561207, 'd_feed_forward': 128, 'max_pool_dim': 8, 'n_mlp_layers': 3}. Best is trial 62 with value: 0.860445205479452.
Epoch: 0 0/3904 Training loss: 0.685819
Epoch: 0 800/3904 Training loss: 0.705825
Epoch: 0 1600/3904 Training loss: 0.318474
Epoch: 0 2400/3904 Training loss: 0.644516
Epoch: 0 3200/3904 Training loss: 0.486194
Training loss: 0.624056
Test loss: 0.602343; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 1 0/3904 Training loss: 0.490446
Epoch: 1 800/3904 Training loss: 0.496915
Epoch: 1 1600/3904 Training loss: 0.244212
Epoch: 1 2400/3904 Training loss: 0.473651
Epoch: 1 3200/3904 Training loss: 0.397832
Training loss: 0.470411
Test loss: 1.467050; True positive: 4; True negative: 261, False Positive: 4, False negative: 899, accuracy: 0.2268835616438356, precision: 0.5, recall: 0.004429678848283499
Epoch: 2 0/3904 Training loss: 0.305809
Epoch: 2 800/3904 Training loss: 0.289903
Epoch: 2 1600/3904 Training loss: 0.206190
Epoch: 2 2400/3904 Training loss: 0.381421
Epoch: 2 3200/3904 Training loss: 0.373689
Training loss: 0.417645
Test loss: 2.271894; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 3 0/3904 Training loss: 0.288677
Epoch: 3 800/3904 Training loss: 0.348425
Epoch: 3 1600/3904 Training loss: 0.299371
Epoch: 3 2400/3904 Training loss: 0.323987
Epoch: 3 3200/3904 Training loss: 0.371559
Training loss: 0.376349
Test loss: 2.358361; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 4 0/3904 Training loss: 0.239502
Epoch: 4 800/3904 Training loss: 0.196286
Epoch: 4 1600/3904 Training loss: 0.188204
Epoch: 4 2400/3904 Training loss: 0.205458
Epoch: 4 3200/3904 Training loss: 0.318421
Training loss: 0.340391
Test loss: 3.135630; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 5 0/3904 Training loss: 0.271522
Epoch: 5 800/3904 Training loss: 0.135325
Epoch: 5 1600/3904 Training loss: 0.143808
Epoch: 5 2400/3904 Training loss: 0.092925
Epoch: 5 3200/3904 Training loss: 0.390650
Training loss: 0.316041
Test loss: 3.643163; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 6 0/3904 Training loss: 0.222824
Epoch: 6 800/3904 Training loss: 0.227192
Epoch: 6 1600/3904 Training loss: 0.159974
Epoch: 6 2400/3904 Training loss: 0.128119
Epoch: 6 3200/3904 Training loss: 0.304319
Training loss: 0.289213
Test loss: 3.969161; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 7 0/3904 Training loss: 0.246262
Epoch: 7 800/3904 Training loss: 0.135460
Epoch: 7 1600/3904 Training loss: 0.143724
Epoch: 7 2400/3904 Training loss: 0.196203
Epoch: 7 3200/3904 Training loss: 0.349216
Training loss: 0.259246
Test loss: 4.219379; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 8 0/3904 Training loss: 0.216489
Epoch: 8 800/3904 Training loss: 0.176790
Epoch: 8 1600/3904 Training loss: 0.103422
Epoch: 8 2400/3904 Training loss: 0.129556
Epoch: 8 3200/3904 Training loss: 0.473451
Training loss: 0.241186
Test loss: 4.128572; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 9 0/3904 Training loss: 0.126843
Epoch: 9 800/3904 Training loss: 0.079243
Epoch: 9 1600/3904 Training loss: 0.087035
Epoch: 9 2400/3904 Training loss: 0.189834
Epoch: 9 3200/3904 Training loss: 0.622468
Training loss: 0.226332
Test loss: 4.338981; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 10 0/3904 Training loss: 0.247017
Epoch: 10 800/3904 Training loss: 0.048972
Epoch: 10 1600/3904 Training loss: 0.138328
Epoch: 10 2400/3904 Training loss: 0.112761
Epoch: 10 3200/3904 Training loss: 0.304882
Training loss: 0.213912
Test loss: 4.967594; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
starting trial 232
[I 2022-12-05 06:25:53,079] Trial 231 finished with value: 0.8176369863013698 and parameters: {'d_model': 64, 'nhead': 8, 'n_encoders': 1, 'learning_rate': 0.00048060200447690236, 'weight_decay': 3.387355636732017e-06, 'dropout': 0.15797020924865973, 'max_pool_conv': 64, 'kernel_size': 15, 'd_mlp': 62, 'num_conv_layers': 2, 'encoder_dropout': 0.4020124563129328, 'd_feed_forward': 512, 'max_pool_dim': 8, 'n_mlp_layers': 3}. Best is trial 62 with value: 0.860445205479452.
Epoch: 0 0/3904 Training loss: 0.698913
Epoch: 0 800/3904 Training loss: 0.710954
Epoch: 0 1600/3904 Training loss: 0.557294
Epoch: 0 2400/3904 Training loss: 0.790617
Epoch: 0 3200/3904 Training loss: 0.569460
Training loss: 0.667713
Test loss: 0.851457; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 1 0/3904 Training loss: 0.717756
Epoch: 1 800/3904 Training loss: 0.747347
Epoch: 1 1600/3904 Training loss: 0.505566
Epoch: 1 2400/3904 Training loss: 0.821478
Epoch: 1 3200/3904 Training loss: 0.562049
Training loss: 0.660476
Test loss: 0.864210; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 2 0/3904 Training loss: 0.737218
Epoch: 2 800/3904 Training loss: 0.771613
Epoch: 2 1600/3904 Training loss: 0.497221
Epoch: 2 2400/3904 Training loss: 0.828995
Epoch: 2 3200/3904 Training loss: 0.576601
Training loss: 0.661350
Test loss: 0.858878; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 3 0/3904 Training loss: 0.715975
Epoch: 3 800/3904 Training loss: 0.767054
Epoch: 3 1600/3904 Training loss: 0.488830
Epoch: 3 2400/3904 Training loss: 0.810508
Epoch: 3 3200/3904 Training loss: 0.579901
Training loss: 0.659812
Test loss: 0.868438; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 4 0/3904 Training loss: 0.729104
Epoch: 4 800/3904 Training loss: 0.749001
Epoch: 4 1600/3904 Training loss: 0.477235
Epoch: 4 2400/3904 Training loss: 0.829015
Epoch: 4 3200/3904 Training loss: 0.565180
Training loss: 0.657376
Test loss: 0.856199; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 5 0/3904 Training loss: 0.714316
Epoch: 5 800/3904 Training loss: 0.749713
Epoch: 5 1600/3904 Training loss: 0.488681
Epoch: 5 2400/3904 Training loss: 0.829499
Epoch: 5 3200/3904 Training loss: 0.571560
Training loss: 0.655402
Test loss: 0.830260; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 6 0/3904 Training loss: 0.699378
Epoch: 6 800/3904 Training loss: 0.720295
Epoch: 6 1600/3904 Training loss: 0.480261
Epoch: 6 2400/3904 Training loss: 0.845436
Epoch: 6 3200/3904 Training loss: 0.559580
Training loss: 0.643553
Test loss: 0.752902; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 7 0/3904 Training loss: 0.663338
Epoch: 7 800/3904 Training loss: 0.705154
Epoch: 7 1600/3904 Training loss: 0.341532
Epoch: 7 2400/3904 Training loss: 0.911723
Epoch: 7 3200/3904 Training loss: 0.427822
Training loss: 0.608480
Test loss: 0.667600; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 8 0/3904 Training loss: 0.638275
Epoch: 8 800/3904 Training loss: 0.594104
Epoch: 8 1600/3904 Training loss: 0.358644
Epoch: 8 2400/3904 Training loss: 0.921307
Epoch: 8 3200/3904 Training loss: 0.449377
Training loss: 0.553220
Test loss: 0.579968; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 9 0/3904 Training loss: 0.621529
Epoch: 9 800/3904 Training loss: 0.564535
Epoch: 9 1600/3904 Training loss: 0.258170
Epoch: 9 2400/3904 Training loss: 0.501173
Epoch: 9 3200/3904 Training loss: 0.307772
Training loss: 0.532927
Test loss: 0.576399; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 10 0/3904 Training loss: 0.552479
Epoch: 10 800/3904 Training loss: 0.591213
Epoch: 10 1600/3904 Training loss: 0.319053
Epoch: 10 2400/3904 Training loss: 0.572390
Epoch: 10 3200/3904 Training loss: 0.436596
Training loss: 0.505921
Test loss: 0.551740; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 11 0/3904 Training loss: 0.538612
Epoch: 11 800/3904 Training loss: 0.483268
Epoch: 11 1600/3904 Training loss: 0.207097
Epoch: 11 2400/3904 Training loss: 0.577270
Epoch: 11 3200/3904 Training loss: 0.379699
Training loss: 0.502671
Test loss: 0.548131; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 12 0/3904 Training loss: 0.618983
Epoch: 12 800/3904 Training loss: 0.504516
Epoch: 12 1600/3904 Training loss: 0.224126
Epoch: 12 2400/3904 Training loss: 0.722813
Epoch: 12 3200/3904 Training loss: 0.319342
Training loss: 0.502372
Test loss: 0.538968; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 13 0/3904 Training loss: 0.518122
Epoch: 13 800/3904 Training loss: 0.496052
Epoch: 13 1600/3904 Training loss: 0.191822
Epoch: 13 2400/3904 Training loss: 0.897186
Epoch: 13 3200/3904 Training loss: 0.474170
Training loss: 0.480228
Test loss: 0.535296; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 14 0/3904 Training loss: 0.620062
Epoch: 14 800/3904 Training loss: 0.499072
Epoch: 14 1600/3904 Training loss: 0.171051
Epoch: 14 2400/3904 Training loss: 0.764139
Epoch: 14 3200/3904 Training loss: 0.405020
Training loss: 0.490349
Test loss: 0.545884; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 15 0/3904 Training loss: 0.668792
Epoch: 15 800/3904 Training loss: 0.418407
Epoch: 15 1600/3904 Training loss: 0.167231
Epoch: 15 2400/3904 Training loss: 0.465867
Epoch: 15 3200/3904 Training loss: 0.413404
Training loss: 0.474831
Test loss: 0.533780; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 16 0/3904 Training loss: 0.587361
Epoch: 16 800/3904 Training loss: 0.554078
Epoch: 16 1600/3904 Training loss: 0.131407
Epoch: 16 2400/3904 Training loss: 0.544766
Epoch: 16 3200/3904 Training loss: 0.492288
Training loss: 0.476476
Test loss: 0.536110; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 17 0/3904 Training loss: 0.662259
Epoch: 17 800/3904 Training loss: 0.405744
Epoch: 17 1600/3904 Training loss: 0.228847
Epoch: 17 2400/3904 Training loss: 0.483124
Epoch: 17 3200/3904 Training loss: 0.477058
Training loss: 0.477180
Test loss: 0.546906; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 18 0/3904 Training loss: 0.569369
Epoch: 18 800/3904 Training loss: 0.460731
Epoch: 18 1600/3904 Training loss: 0.252388
Epoch: 18 2400/3904 Training loss: 0.506733
Epoch: 18 3200/3904 Training loss: 0.342583
Training loss: 0.474798
Test loss: 0.557728; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 19 0/3904 Training loss: 0.503502
Epoch: 19 800/3904 Training loss: 0.432679
Epoch: 19 1600/3904 Training loss: 0.214530
Epoch: 19 2400/3904 Training loss: 0.871139
Epoch: 19 3200/3904 Training loss: 0.372479
Training loss: 0.469363
Test loss: 0.553874; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 20 0/3904 Training loss: 0.559282
Epoch: 20 800/3904 Training loss: 0.360654
Epoch: 20 1600/3904 Training loss: 0.264405
Epoch: 20 2400/3904 Training loss: 0.746503
Epoch: 20 3200/3904 Training loss: 0.289875
Training loss: 0.459421
Test loss: 0.555036; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 21 0/3904 Training loss: 0.450494
Epoch: 21 800/3904 Training loss: 0.401773
Epoch: 21 1600/3904 Training loss: 0.188381
Epoch: 21 2400/3904 Training loss: 0.765406
Epoch: 21 3200/3904 Training loss: 0.425194
Training loss: 0.456174
Test loss: 0.549019; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 22 0/3904 Training loss: 0.661823
Epoch: 22 800/3904 Training loss: 0.463949
Epoch: 22 1600/3904 Training loss: 0.293101
Epoch: 22 2400/3904 Training loss: 0.499538
Epoch: 22 3200/3904 Training loss: 0.302543
Training loss: 0.449357
Test loss: 0.552192; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 23 0/3904 Training loss: 0.705948
Epoch: 23 800/3904 Training loss: 0.405196
Epoch: 23 1600/3904 Training loss: 0.252189
Epoch: 23 2400/3904 Training loss: 0.603026
Epoch: 23 3200/3904 Training loss: 0.405222
Training loss: 0.448756
Test loss: 0.556279; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 24 0/3904 Training loss: 0.544797
Epoch: 24 800/3904 Training loss: 0.388332
Epoch: 24 1600/3904 Training loss: 0.221558
Epoch: 24 2400/3904 Training loss: 0.635535
Epoch: 24 3200/3904 Training loss: 0.327629
Training loss: 0.448984
Test loss: 0.557756; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 25 0/3904 Training loss: 0.524786
Epoch: 25 800/3904 Training loss: 0.442136
Epoch: 25 1600/3904 Training loss: 0.198977
Epoch: 25 2400/3904 Training loss: 0.510092
Epoch: 25 3200/3904 Training loss: 0.433963
Training loss: 0.439210
Test loss: 0.560966; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
starting trial 233
[I 2022-12-05 06:27:31,390] Trial 232 finished with value: 0.8176369863013698 and parameters: {'d_model': 16, 'nhead': 2, 'n_encoders': 2, 'learning_rate': 0.00015256995410192076, 'weight_decay': 2.668683472222261e-06, 'dropout': 0.41782716479068305, 'max_pool_conv': 128, 'kernel_size': 7, 'd_mlp': 32, 'num_conv_layers': 6, 'encoder_dropout': 0.021552174158952303, 'd_feed_forward': 256, 'max_pool_dim': 16, 'n_mlp_layers': 3}. Best is trial 62 with value: 0.860445205479452.
Epoch: 0 0/3904 Training loss: 0.695234
Epoch: 0 800/3904 Training loss: 0.704090
Epoch: 0 1600/3904 Training loss: 0.346380
Epoch: 0 2400/3904 Training loss: 0.689801
Epoch: 0 3200/3904 Training loss: 0.489117
Training loss: 0.644953
Test loss: 0.627749; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 1 0/3904 Training loss: 0.639469
Epoch: 1 800/3904 Training loss: 0.628196
Epoch: 1 1600/3904 Training loss: 0.222924
Epoch: 1 2400/3904 Training loss: 0.552209
Epoch: 1 3200/3904 Training loss: 0.426643
Training loss: 0.502654
Test loss: 0.535565; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 2 0/3904 Training loss: 0.376448
Epoch: 2 800/3904 Training loss: 0.478501
Epoch: 2 1600/3904 Training loss: 0.262638
Epoch: 2 2400/3904 Training loss: 0.529034
Epoch: 2 3200/3904 Training loss: 0.471678
Training loss: 0.438504
Test loss: 0.494651; True positive: 903; True negative: 0, False Positive: 265, False negative: 0, accuracy: 0.7731164383561644, precision: 0.7731164383561644, recall: 1.0
Epoch: 3 0/3904 Training loss: 0.416908
Epoch: 3 800/3904 Training loss: 0.483634
Epoch: 3 1600/3904 Training loss: 0.213014
Epoch: 3 2400/3904 Training loss: 0.505023
Epoch: 3 3200/3904 Training loss: 0.563969
Training loss: 0.418140
Test loss: 0.450713; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 4 0/3904 Training loss: 0.490335
Epoch: 4 800/3904 Training loss: 0.330730
Epoch: 4 1600/3904 Training loss: 0.162855
Epoch: 4 2400/3904 Training loss: 0.770160
Epoch: 4 3200/3904 Training loss: 0.401278
Training loss: 0.400232
Test loss: 0.489207; True positive: 903; True negative: 0, False Positive: 265, False negative: 0, accuracy: 0.7731164383561644, precision: 0.7731164383561644, recall: 1.0
Epoch: 5 0/3904 Training loss: 0.390846
Epoch: 5 800/3904 Training loss: 0.311472
Epoch: 5 1600/3904 Training loss: 0.236571
Epoch: 5 2400/3904 Training loss: 0.408605
Epoch: 5 3200/3904 Training loss: 0.379180
Training loss: 0.387383
Test loss: 0.512540; True positive: 903; True negative: 0, False Positive: 265, False negative: 0, accuracy: 0.7731164383561644, precision: 0.7731164383561644, recall: 1.0
Epoch: 6 0/3904 Training loss: 0.298044
Epoch: 6 800/3904 Training loss: 0.307629
Epoch: 6 1600/3904 Training loss: 0.157566
Epoch: 6 2400/3904 Training loss: 0.701725
Epoch: 6 3200/3904 Training loss: 0.373530
Training loss: 0.367782
Test loss: 0.476551; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 7 0/3904 Training loss: 0.341235
Epoch: 7 800/3904 Training loss: 0.417557
Epoch: 7 1600/3904 Training loss: 0.166568
Epoch: 7 2400/3904 Training loss: 0.474519
Epoch: 7 3200/3904 Training loss: 0.458889
Training loss: 0.334615
Test loss: 0.485851; True positive: 838; True negative: 118, False Positive: 147, False negative: 65, accuracy: 0.8184931506849316, precision: 0.8507614213197969, recall: 0.9280177187153932
Epoch: 8 0/3904 Training loss: 0.409838
Epoch: 8 800/3904 Training loss: 0.325915
Epoch: 8 1600/3904 Training loss: 0.169560
Epoch: 8 2400/3904 Training loss: 0.604665
Epoch: 8 3200/3904 Training loss: 0.468883
Training loss: 0.324930
Test loss: 0.496000; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 9 0/3904 Training loss: 0.297554
Epoch: 9 800/3904 Training loss: 0.314129
Epoch: 9 1600/3904 Training loss: 0.172263
Epoch: 9 2400/3904 Training loss: 0.553644
Epoch: 9 3200/3904 Training loss: 0.342293
Training loss: 0.314787
Test loss: 0.553407; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 10 0/3904 Training loss: 0.423702
Epoch: 10 800/3904 Training loss: 0.208720
Epoch: 10 1600/3904 Training loss: 0.252214
Epoch: 10 2400/3904 Training loss: 0.482186
Epoch: 10 3200/3904 Training loss: 0.384863
Training loss: 0.290421
Test loss: 0.667514; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 11 0/3904 Training loss: 0.347504
Epoch: 11 800/3904 Training loss: 0.115235
Epoch: 11 1600/3904 Training loss: 0.125092
Epoch: 11 2400/3904 Training loss: 0.400313
Epoch: 11 3200/3904 Training loss: 0.364147
Training loss: 0.279628
Test loss: 0.799464; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 12 0/3904 Training loss: 0.324492
Epoch: 12 800/3904 Training loss: 0.260582
Epoch: 12 1600/3904 Training loss: 0.193628
Epoch: 12 2400/3904 Training loss: 0.400719
Epoch: 12 3200/3904 Training loss: 0.428953
Training loss: 0.273612
Test loss: 0.751096; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 13 0/3904 Training loss: 0.449265
Epoch: 13 800/3904 Training loss: 0.112860
Epoch: 13 1600/3904 Training loss: 0.104593
Epoch: 13 2400/3904 Training loss: 0.435865
Epoch: 13 3200/3904 Training loss: 0.545858
Training loss: 0.263909
Test loss: 0.750907; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
starting trial 234
[I 2022-12-05 06:28:43,211] Trial 233 finished with value: 0.8184931506849316 and parameters: {'d_model': 64, 'nhead': 8, 'n_encoders': 1, 'learning_rate': 0.0005461868682582603, 'weight_decay': 3.6969904731602387e-06, 'dropout': 0.3023104228689023, 'max_pool_conv': 64, 'kernel_size': 21, 'd_mlp': 62, 'num_conv_layers': 2, 'encoder_dropout': 0.38197235514071315, 'd_feed_forward': 512, 'max_pool_dim': 8, 'n_mlp_layers': 3}. Best is trial 62 with value: 0.860445205479452.
Epoch: 0 0/3904 Training loss: 0.706601
Epoch: 0 800/3904 Training loss: 0.728870
Epoch: 0 1600/3904 Training loss: 0.436106
Epoch: 0 2400/3904 Training loss: 0.792083
Epoch: 0 3200/3904 Training loss: 0.545574
Training loss: 0.658698
Test loss: 0.864578; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 1 0/3904 Training loss: 0.712779
Epoch: 1 800/3904 Training loss: 0.711386
Epoch: 1 1600/3904 Training loss: 0.355119
Epoch: 1 2400/3904 Training loss: 0.732947
Epoch: 1 3200/3904 Training loss: 0.378587
Training loss: 0.609511
Test loss: 0.640503; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 2 0/3904 Training loss: 0.516755
Epoch: 2 800/3904 Training loss: 0.645133
Epoch: 2 1600/3904 Training loss: 0.248638
Epoch: 2 2400/3904 Training loss: 0.723908
Epoch: 2 3200/3904 Training loss: 0.428778
Training loss: 0.516852
Test loss: 1.824368; True positive: 7; True negative: 265, False Positive: 0, False negative: 896, accuracy: 0.2328767123287671, precision: 1.0, recall: 0.007751937984496124
Epoch: 3 0/3904 Training loss: 0.407809
Epoch: 3 800/3904 Training loss: 0.375609
Epoch: 3 1600/3904 Training loss: 0.139465
Epoch: 3 2400/3904 Training loss: 0.553439
Epoch: 3 3200/3904 Training loss: 0.424848
Training loss: 0.462105
Test loss: 2.024082; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 4 0/3904 Training loss: 0.327523
Epoch: 4 800/3904 Training loss: 0.389525
Epoch: 4 1600/3904 Training loss: 0.147330
Epoch: 4 2400/3904 Training loss: 0.290966
Epoch: 4 3200/3904 Training loss: 0.448310
Training loss: 0.436420
Test loss: 2.419771; True positive: 5; True negative: 262, False Positive: 3, False negative: 898, accuracy: 0.2285958904109589, precision: 0.625, recall: 0.005537098560354375
Epoch: 5 0/3904 Training loss: 0.443850
Epoch: 5 800/3904 Training loss: 0.490016
Epoch: 5 1600/3904 Training loss: 0.195575
Epoch: 5 2400/3904 Training loss: 0.340220
Epoch: 5 3200/3904 Training loss: 0.347511
Training loss: 0.421605
Test loss: 2.261654; True positive: 94; True negative: 209, False Positive: 56, False negative: 809, accuracy: 0.2594178082191781, precision: 0.6266666666666667, recall: 0.10409745293466224
Epoch: 6 0/3904 Training loss: 0.394499
Epoch: 6 800/3904 Training loss: 0.298326
Epoch: 6 1600/3904 Training loss: 0.154552
Epoch: 6 2400/3904 Training loss: 0.323421
Epoch: 6 3200/3904 Training loss: 0.328955
Training loss: 0.396033
Test loss: 0.524162; True positive: 835; True negative: 117, False Positive: 148, False negative: 68, accuracy: 0.815068493150685, precision: 0.8494404883011191, recall: 0.9246954595791805
Epoch: 7 0/3904 Training loss: 0.413985
Epoch: 7 800/3904 Training loss: 0.305102
Epoch: 7 1600/3904 Training loss: 0.144734
Epoch: 7 2400/3904 Training loss: 0.342044
Epoch: 7 3200/3904 Training loss: 0.372672
Training loss: 0.382315
Test loss: 0.524465; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 8 0/3904 Training loss: 0.361807
Epoch: 8 800/3904 Training loss: 0.256920
Epoch: 8 1600/3904 Training loss: 0.171638
Epoch: 8 2400/3904 Training loss: 0.379140
Epoch: 8 3200/3904 Training loss: 0.411541
Training loss: 0.362884
Test loss: 1.524316; True positive: 396; True negative: 228, False Positive: 37, False negative: 507, accuracy: 0.5342465753424658, precision: 0.9145496535796767, recall: 0.43853820598006643
Epoch: 9 0/3904 Training loss: 0.460856
Epoch: 9 800/3904 Training loss: 0.252672
Epoch: 9 1600/3904 Training loss: 0.144923
Epoch: 9 2400/3904 Training loss: 0.379186
Epoch: 9 3200/3904 Training loss: 0.348965
Training loss: 0.344942
Test loss: 0.540496; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 10 0/3904 Training loss: 0.381751
Epoch: 10 800/3904 Training loss: 0.269403
Epoch: 10 1600/3904 Training loss: 0.134565
Epoch: 10 2400/3904 Training loss: 0.304752
Epoch: 10 3200/3904 Training loss: 0.362383
Training loss: 0.328424
Test loss: 0.554632; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 11 0/3904 Training loss: 0.465371
Epoch: 11 800/3904 Training loss: 0.261894
Epoch: 11 1600/3904 Training loss: 0.161342
Epoch: 11 2400/3904 Training loss: 0.293024
Epoch: 11 3200/3904 Training loss: 0.345171
Training loss: 0.327864
Test loss: 0.569893; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 12 0/3904 Training loss: 0.338151
Epoch: 12 800/3904 Training loss: 0.418141
Epoch: 12 1600/3904 Training loss: 0.148135
Epoch: 12 2400/3904 Training loss: 0.218456
Epoch: 12 3200/3904 Training loss: 0.375829
Training loss: 0.322249
Test loss: 0.571632; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 13 0/3904 Training loss: 0.330032
Epoch: 13 800/3904 Training loss: 0.319767
Epoch: 13 1600/3904 Training loss: 0.144465
Epoch: 13 2400/3904 Training loss: 0.312297
Epoch: 13 3200/3904 Training loss: 0.429785
Training loss: 0.309013
Test loss: 0.586849; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 14 0/3904 Training loss: 0.474229
Epoch: 14 800/3904 Training loss: 0.325042
Epoch: 14 1600/3904 Training loss: 0.110785
Epoch: 14 2400/3904 Training loss: 0.243390
Epoch: 14 3200/3904 Training loss: 0.416228
Training loss: 0.301631
Test loss: 0.610809; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 15 0/3904 Training loss: 0.351926
Epoch: 15 800/3904 Training loss: 0.251310
Epoch: 15 1600/3904 Training loss: 0.115005
Epoch: 15 2400/3904 Training loss: 0.137415
Epoch: 15 3200/3904 Training loss: 0.305120
Training loss: 0.282571
Test loss: 0.648990; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 16 0/3904 Training loss: 0.282216
Epoch: 16 800/3904 Training loss: 0.537471
Epoch: 16 1600/3904 Training loss: 0.125829
Epoch: 16 2400/3904 Training loss: 0.154839
Epoch: 16 3200/3904 Training loss: 0.481566
Training loss: 0.282327
Test loss: 0.650913; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
starting trial 235
[I 2022-12-05 06:29:29,413] Trial 234 finished with value: 0.8176369863013698 and parameters: {'d_model': 16, 'nhead': 4, 'n_encoders': 1, 'learning_rate': 0.00031826623885118454, 'weight_decay': 5.465192852924253e-06, 'dropout': 0.24045492668767632, 'max_pool_conv': 32, 'kernel_size': 14, 'd_mlp': 32, 'num_conv_layers': 3, 'encoder_dropout': 0.09841930062116203, 'd_feed_forward': 128, 'max_pool_dim': 16, 'n_mlp_layers': 3}. Best is trial 62 with value: 0.860445205479452.
Epoch: 0 0/3904 Training loss: 0.698230
Epoch: 0 800/3904 Training loss: 0.714283
Epoch: 0 1600/3904 Training loss: 0.273083
Epoch: 0 2400/3904 Training loss: 0.590856
Epoch: 0 3200/3904 Training loss: 0.454739
Training loss: 0.605880
Test loss: 1.787560; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 1 0/3904 Training loss: 0.451080
Epoch: 1 800/3904 Training loss: 0.680154
Epoch: 1 1600/3904 Training loss: 0.229907
Epoch: 1 2400/3904 Training loss: 0.372050
Epoch: 1 3200/3904 Training loss: 0.422779
Training loss: 0.465879
Test loss: 2.365633; True positive: 65; True negative: 148, False Positive: 117, False negative: 838, accuracy: 0.18236301369863014, precision: 0.35714285714285715, recall: 0.07198228128460686
Epoch: 2 0/3904 Training loss: 0.400902
Epoch: 2 800/3904 Training loss: 0.324409
Epoch: 2 1600/3904 Training loss: 0.215290
Epoch: 2 2400/3904 Training loss: 0.441166
Epoch: 2 3200/3904 Training loss: 0.363320
Training loss: 0.420579
Test loss: 3.141308; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 3 0/3904 Training loss: 0.314138
Epoch: 3 800/3904 Training loss: 0.370895
Epoch: 3 1600/3904 Training loss: 0.218276
Epoch: 3 2400/3904 Training loss: 0.473403
Epoch: 3 3200/3904 Training loss: 0.401903
Training loss: 0.384849
Test loss: 2.788042; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 4 0/3904 Training loss: 0.343075
Epoch: 4 800/3904 Training loss: 0.290618
Epoch: 4 1600/3904 Training loss: 0.230086
Epoch: 4 2400/3904 Training loss: 0.458039
Epoch: 4 3200/3904 Training loss: 0.480435
Training loss: 0.355663
Test loss: 0.528763; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 5 0/3904 Training loss: 0.476174
Epoch: 5 800/3904 Training loss: 0.306615
Epoch: 5 1600/3904 Training loss: 0.160664
Epoch: 5 2400/3904 Training loss: 0.180460
Epoch: 5 3200/3904 Training loss: 0.331114
Training loss: 0.322535
Test loss: 0.533175; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 6 0/3904 Training loss: 0.299588
Epoch: 6 800/3904 Training loss: 0.481112
Epoch: 6 1600/3904 Training loss: 0.133912
Epoch: 6 2400/3904 Training loss: 0.345248
Epoch: 6 3200/3904 Training loss: 0.308410
Training loss: 0.289985
Test loss: 1.680836; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 7 0/3904 Training loss: 0.262159
Epoch: 7 800/3904 Training loss: 0.096667
Epoch: 7 1600/3904 Training loss: 0.183216
Epoch: 7 2400/3904 Training loss: 0.371085
Epoch: 7 3200/3904 Training loss: 0.274315
Training loss: 0.269532
Test loss: 4.695738; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 8 0/3904 Training loss: 0.245414
Epoch: 8 800/3904 Training loss: 0.211991
Epoch: 8 1600/3904 Training loss: 0.134126
Epoch: 8 2400/3904 Training loss: 0.309061
Epoch: 8 3200/3904 Training loss: 0.316485
Training loss: 0.255992
Test loss: 5.998191; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 9 0/3904 Training loss: 0.289844
Epoch: 9 800/3904 Training loss: 0.071088
Epoch: 9 1600/3904 Training loss: 0.106150
Epoch: 9 2400/3904 Training loss: 0.481803
Epoch: 9 3200/3904 Training loss: 0.199887
Training loss: 0.225774
Test loss: 2.767802; True positive: 7; True negative: 263, False Positive: 2, False negative: 896, accuracy: 0.23116438356164384, precision: 0.7777777777777778, recall: 0.007751937984496124
Epoch: 10 0/3904 Training loss: 0.387877
Epoch: 10 800/3904 Training loss: 0.147208
Epoch: 10 1600/3904 Training loss: 0.182255
Epoch: 10 2400/3904 Training loss: 0.298809
Epoch: 10 3200/3904 Training loss: 0.153315
Training loss: 0.213561
Test loss: 4.444468; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 11 0/3904 Training loss: 0.310656
Epoch: 11 800/3904 Training loss: 0.052141
Epoch: 11 1600/3904 Training loss: 0.094319
Epoch: 11 2400/3904 Training loss: 0.270424
Epoch: 11 3200/3904 Training loss: 0.288308
Training loss: 0.212953
Test loss: 3.279694; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 12 0/3904 Training loss: 0.210136
Epoch: 12 800/3904 Training loss: 0.121151
Epoch: 12 1600/3904 Training loss: 0.146149
Epoch: 12 2400/3904 Training loss: 0.227977
Epoch: 12 3200/3904 Training loss: 0.247465
Training loss: 0.203258
Test loss: 8.375892; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 13 0/3904 Training loss: 0.335280
Epoch: 13 800/3904 Training loss: 0.065401
Epoch: 13 1600/3904 Training loss: 0.160305
Epoch: 13 2400/3904 Training loss: 0.089932
Epoch: 13 3200/3904 Training loss: 0.219212
Training loss: 0.184816
Test loss: 9.165603; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 14 0/3904 Training loss: 0.583341
Epoch: 14 800/3904 Training loss: 0.098203
Epoch: 14 1600/3904 Training loss: 0.100073
Epoch: 14 2400/3904 Training loss: 0.453028
Epoch: 14 3200/3904 Training loss: 0.264807
Training loss: 0.181476
Test loss: 8.907290; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
starting trial 236
[I 2022-12-05 06:30:32,375] Trial 235 finished with value: 0.8176369863013698 and parameters: {'d_model': 64, 'nhead': 8, 'n_encoders': 1, 'learning_rate': 0.0006526220966529273, 'weight_decay': 4.280775915733278e-06, 'dropout': 0.14987079804938017, 'max_pool_conv': 64, 'kernel_size': 15, 'd_mlp': 62, 'num_conv_layers': 2, 'encoder_dropout': 0.07712151209273134, 'd_feed_forward': 512, 'max_pool_dim': 8, 'n_mlp_layers': 3}. Best is trial 62 with value: 0.860445205479452.
Epoch: 0 0/3904 Training loss: 0.696447
Epoch: 0 800/3904 Training loss: 0.728271
Epoch: 0 1600/3904 Training loss: 0.446544
Epoch: 0 2400/3904 Training loss: 0.795298
Epoch: 0 3200/3904 Training loss: 0.528719
Training loss: 0.657827
Test loss: 0.805820; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 1 0/3904 Training loss: 0.687562
Epoch: 1 800/3904 Training loss: 0.709779
Epoch: 1 1600/3904 Training loss: 0.366819
Epoch: 1 2400/3904 Training loss: 0.709977
Epoch: 1 3200/3904 Training loss: 0.451620
Training loss: 0.620718
Test loss: 0.791455; True positive: 3; True negative: 265, False Positive: 0, False negative: 900, accuracy: 0.22945205479452055, precision: 1.0, recall: 0.0033222591362126247
Epoch: 2 0/3904 Training loss: 0.615997
Epoch: 2 800/3904 Training loss: 0.604066
Epoch: 2 1600/3904 Training loss: 0.235853
Epoch: 2 2400/3904 Training loss: 0.701092
Epoch: 2 3200/3904 Training loss: 0.410563
Training loss: 0.530101
Test loss: 0.746108; True positive: 83; True negative: 262, False Positive: 3, False negative: 820, accuracy: 0.2953767123287671, precision: 0.9651162790697675, recall: 0.09191583610188261
Epoch: 3 0/3904 Training loss: 0.384411
Epoch: 3 800/3904 Training loss: 0.425795
Epoch: 3 1600/3904 Training loss: 0.206796
Epoch: 3 2400/3904 Training loss: 0.704691
Epoch: 3 3200/3904 Training loss: 0.385377
Training loss: 0.439972
Test loss: 0.551878; True positive: 838; True negative: 118, False Positive: 147, False negative: 65, accuracy: 0.8184931506849316, precision: 0.8507614213197969, recall: 0.9280177187153932
Epoch: 4 0/3904 Training loss: 0.380796
Epoch: 4 800/3904 Training loss: 0.368331
Epoch: 4 1600/3904 Training loss: 0.155661
Epoch: 4 2400/3904 Training loss: 0.835197
Epoch: 4 3200/3904 Training loss: 0.401641
Training loss: 0.385691
Test loss: 0.473441; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 5 0/3904 Training loss: 0.403666
Epoch: 5 800/3904 Training loss: 0.313161
Epoch: 5 1600/3904 Training loss: 0.099298
Epoch: 5 2400/3904 Training loss: 0.637318
Epoch: 5 3200/3904 Training loss: 0.390967
Training loss: 0.353198
Test loss: 0.454564; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 6 0/3904 Training loss: 0.302421
Epoch: 6 800/3904 Training loss: 0.268649
Epoch: 6 1600/3904 Training loss: 0.126865
Epoch: 6 2400/3904 Training loss: 0.576662
Epoch: 6 3200/3904 Training loss: 0.304596
Training loss: 0.324400
Test loss: 0.455698; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 7 0/3904 Training loss: 0.400795
Epoch: 7 800/3904 Training loss: 0.247989
Epoch: 7 1600/3904 Training loss: 0.202551
Epoch: 7 2400/3904 Training loss: 0.439435
Epoch: 7 3200/3904 Training loss: 0.285857
Training loss: 0.309155
Test loss: 0.489463; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 8 0/3904 Training loss: 0.349857
Epoch: 8 800/3904 Training loss: 0.300764
Epoch: 8 1600/3904 Training loss: 0.112521
Epoch: 8 2400/3904 Training loss: 0.554578
Epoch: 8 3200/3904 Training loss: 0.207157
Training loss: 0.287596
Test loss: 0.527279; True positive: 838; True negative: 118, False Positive: 147, False negative: 65, accuracy: 0.8184931506849316, precision: 0.8507614213197969, recall: 0.9280177187153932
Epoch: 9 0/3904 Training loss: 0.259651
Epoch: 9 800/3904 Training loss: 0.166802
Epoch: 9 1600/3904 Training loss: 0.082556
Epoch: 9 2400/3904 Training loss: 0.465093
Epoch: 9 3200/3904 Training loss: 0.364645
Training loss: 0.279703
Test loss: 0.561046; True positive: 837; True negative: 119, False Positive: 146, False negative: 66, accuracy: 0.8184931506849316, precision: 0.8514750762970499, recall: 0.9269102990033222
Epoch: 10 0/3904 Training loss: 0.229763
Epoch: 10 800/3904 Training loss: 0.276244
Epoch: 10 1600/3904 Training loss: 0.139861
Epoch: 10 2400/3904 Training loss: 0.383240
Epoch: 10 3200/3904 Training loss: 0.386548
Training loss: 0.261317
Test loss: 0.702358; True positive: 569; True negative: 221, False Positive: 44, False negative: 334, accuracy: 0.6763698630136986, precision: 0.9282218597063622, recall: 0.6301218161683277
Epoch: 11 0/3904 Training loss: 0.329411
Epoch: 11 800/3904 Training loss: 0.285017
Epoch: 11 1600/3904 Training loss: 0.063533
Epoch: 11 2400/3904 Training loss: 0.395408
Epoch: 11 3200/3904 Training loss: 0.327267
Training loss: 0.259395
Test loss: 0.989135; True positive: 85; True negative: 262, False Positive: 3, False negative: 818, accuracy: 0.2970890410958904, precision: 0.9659090909090909, recall: 0.09413067552602436
Epoch: 12 0/3904 Training loss: 0.382863
Epoch: 12 800/3904 Training loss: 0.171788
Epoch: 12 1600/3904 Training loss: 0.077347
Epoch: 12 2400/3904 Training loss: 0.327183
Epoch: 12 3200/3904 Training loss: 0.318562
Training loss: 0.245278
Test loss: 1.264963; True positive: 5; True negative: 265, False Positive: 0, False negative: 898, accuracy: 0.23116438356164384, precision: 1.0, recall: 0.005537098560354375
Epoch: 13 0/3904 Training loss: 0.235774
Epoch: 13 800/3904 Training loss: 0.291154
Epoch: 13 1600/3904 Training loss: 0.066012
Epoch: 13 2400/3904 Training loss: 0.350444
Epoch: 13 3200/3904 Training loss: 0.407685
Training loss: 0.232494
Test loss: 1.540380; True positive: 4; True negative: 265, False Positive: 0, False negative: 899, accuracy: 0.2303082191780822, precision: 1.0, recall: 0.004429678848283499
Epoch: 14 0/3904 Training loss: 0.218090
Epoch: 14 800/3904 Training loss: 0.094600
Epoch: 14 1600/3904 Training loss: 0.059683
Epoch: 14 2400/3904 Training loss: 0.284270
Epoch: 14 3200/3904 Training loss: 0.413713
Training loss: 0.225253
Test loss: 1.286675; True positive: 5; True negative: 265, False Positive: 0, False negative: 898, accuracy: 0.23116438356164384, precision: 1.0, recall: 0.005537098560354375
Epoch: 15 0/3904 Training loss: 0.211210
Epoch: 15 800/3904 Training loss: 0.130004
Epoch: 15 1600/3904 Training loss: 0.035270
Epoch: 15 2400/3904 Training loss: 0.177799
Epoch: 15 3200/3904 Training loss: 0.319077
Training loss: 0.209985
Test loss: 1.886271; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
starting trial 237
[I 2022-12-05 06:31:28,472] Trial 236 finished with value: 0.8184931506849316 and parameters: {'d_model': 64, 'nhead': 8, 'n_encoders': 1, 'learning_rate': 7.431279762981384e-05, 'weight_decay': 2.941188208505911e-06, 'dropout': 0.1373822526858914, 'max_pool_conv': 64, 'kernel_size': 10, 'd_mlp': 62, 'num_conv_layers': 2, 'encoder_dropout': 0.13080654834673622, 'd_feed_forward': 128, 'max_pool_dim': 8, 'n_mlp_layers': 3}. Best is trial 62 with value: 0.860445205479452.
Epoch: 0 0/3904 Training loss: 0.710539
Epoch: 0 800/3904 Training loss: 0.749493
Epoch: 0 1600/3904 Training loss: 0.513932
Epoch: 0 2400/3904 Training loss: 0.815166
Epoch: 0 3200/3904 Training loss: 0.573982
Training loss: 0.662448
Test loss: 0.866249; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 1 0/3904 Training loss: 0.729272
Epoch: 1 800/3904 Training loss: 0.747389
Epoch: 1 1600/3904 Training loss: 0.503295
Epoch: 1 2400/3904 Training loss: 0.821984
Epoch: 1 3200/3904 Training loss: 0.562662
Training loss: 0.659056
Test loss: 0.879498; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 2 0/3904 Training loss: 0.733867
Epoch: 2 800/3904 Training loss: 0.750208
Epoch: 2 1600/3904 Training loss: 0.457358
Epoch: 2 2400/3904 Training loss: 0.817101
Epoch: 2 3200/3904 Training loss: 0.521655
Training loss: 0.651500
Test loss: 0.804731; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 3 0/3904 Training loss: 0.688581
Epoch: 3 800/3904 Training loss: 0.717950
Epoch: 3 1600/3904 Training loss: 0.397900
Epoch: 3 2400/3904 Training loss: 0.844450
Epoch: 3 3200/3904 Training loss: 0.461509
Training loss: 0.605903
Test loss: 1.270727; True positive: 3; True negative: 262, False Positive: 3, False negative: 900, accuracy: 0.2268835616438356, precision: 0.5, recall: 0.0033222591362126247
Epoch: 4 0/3904 Training loss: 0.628749
Epoch: 4 800/3904 Training loss: 0.537388
Epoch: 4 1600/3904 Training loss: 0.337915
Epoch: 4 2400/3904 Training loss: 0.891529
Epoch: 4 3200/3904 Training loss: 0.437650
Training loss: 0.541923
Test loss: 1.307051; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 5 0/3904 Training loss: 0.568813
Epoch: 5 800/3904 Training loss: 0.456120
Epoch: 5 1600/3904 Training loss: 0.261051
Epoch: 5 2400/3904 Training loss: 0.912962
Epoch: 5 3200/3904 Training loss: 0.386791
Training loss: 0.496910
Test loss: 1.479502; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 6 0/3904 Training loss: 0.466956
Epoch: 6 800/3904 Training loss: 0.392128
Epoch: 6 1600/3904 Training loss: 0.243160
Epoch: 6 2400/3904 Training loss: 0.654347
Epoch: 6 3200/3904 Training loss: 0.378802
Training loss: 0.465928
Test loss: 1.565714; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 7 0/3904 Training loss: 0.452918
Epoch: 7 800/3904 Training loss: 0.419563
Epoch: 7 1600/3904 Training loss: 0.244984
Epoch: 7 2400/3904 Training loss: 0.634217
Epoch: 7 3200/3904 Training loss: 0.407774
Training loss: 0.450154
Test loss: 1.613631; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 8 0/3904 Training loss: 0.587031
Epoch: 8 800/3904 Training loss: 0.370526
Epoch: 8 1600/3904 Training loss: 0.247463
Epoch: 8 2400/3904 Training loss: 0.613232
Epoch: 8 3200/3904 Training loss: 0.358243
Training loss: 0.436529
Test loss: 1.734605; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 9 0/3904 Training loss: 0.401911
Epoch: 9 800/3904 Training loss: 0.398829
Epoch: 9 1600/3904 Training loss: 0.260918
Epoch: 9 2400/3904 Training loss: 0.679752
Epoch: 9 3200/3904 Training loss: 0.326975
Training loss: 0.425372
Test loss: 1.692547; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 10 0/3904 Training loss: 0.377032
Epoch: 10 800/3904 Training loss: 0.400923
Epoch: 10 1600/3904 Training loss: 0.289238
Epoch: 10 2400/3904 Training loss: 0.529955
Epoch: 10 3200/3904 Training loss: 0.398625
Training loss: 0.408866
Test loss: 1.782685; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 11 0/3904 Training loss: 0.344905
Epoch: 11 800/3904 Training loss: 0.377084
Epoch: 11 1600/3904 Training loss: 0.279068
Epoch: 11 2400/3904 Training loss: 0.619089
Epoch: 11 3200/3904 Training loss: 0.417642
Training loss: 0.408061
Test loss: 1.871972; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 12 0/3904 Training loss: 0.322283
Epoch: 12 800/3904 Training loss: 0.388381
Epoch: 12 1600/3904 Training loss: 0.244712
Epoch: 12 2400/3904 Training loss: 0.455595
Epoch: 12 3200/3904 Training loss: 0.473069
Training loss: 0.399062
Test loss: 1.881578; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
starting trial 238
[I 2022-12-05 06:32:18,709] Trial 237 finished with value: 0.2268835616438356 and parameters: {'d_model': 16, 'nhead': 8, 'n_encoders': 2, 'learning_rate': 0.00017037902893509235, 'weight_decay': 2.3166439793254304e-06, 'dropout': 0.14108487504791728, 'max_pool_conv': 128, 'kernel_size': 8, 'd_mlp': 16, 'num_conv_layers': 5, 'encoder_dropout': 0.017523486967503506, 'd_feed_forward': 256, 'max_pool_dim': 16, 'n_mlp_layers': 3}. Best is trial 62 with value: 0.860445205479452.
Epoch: 0 0/3904 Training loss: 0.714110
Epoch: 0 800/3904 Training loss: 0.729382
Epoch: 0 1600/3904 Training loss: 0.553507
Epoch: 0 2400/3904 Training loss: 0.776077
Epoch: 0 3200/3904 Training loss: 0.596240
Training loss: 0.662020
Test loss: 0.806310; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 1 0/3904 Training loss: 0.709859
Epoch: 1 800/3904 Training loss: 0.732277
Epoch: 1 1600/3904 Training loss: 0.547702
Epoch: 1 2400/3904 Training loss: 0.778861
Epoch: 1 3200/3904 Training loss: 0.591122
Training loss: 0.661261
Test loss: 0.811388; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 2 0/3904 Training loss: 0.710403
Epoch: 2 800/3904 Training loss: 0.735311
Epoch: 2 1600/3904 Training loss: 0.542907
Epoch: 2 2400/3904 Training loss: 0.786899
Epoch: 2 3200/3904 Training loss: 0.589682
Training loss: 0.660812
Test loss: 0.816580; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 3 0/3904 Training loss: 0.713624
Epoch: 3 800/3904 Training loss: 0.737843
Epoch: 3 1600/3904 Training loss: 0.541780
Epoch: 3 2400/3904 Training loss: 0.790773
Epoch: 3 3200/3904 Training loss: 0.582743
Training loss: 0.660076
Test loss: 0.824027; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 4 0/3904 Training loss: 0.714298
Epoch: 4 800/3904 Training loss: 0.740865
Epoch: 4 1600/3904 Training loss: 0.534172
Epoch: 4 2400/3904 Training loss: 0.796192
Epoch: 4 3200/3904 Training loss: 0.585734
Training loss: 0.659968
Test loss: 0.830486; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 5 0/3904 Training loss: 0.722936
Epoch: 5 800/3904 Training loss: 0.739199
Epoch: 5 1600/3904 Training loss: 0.529548
Epoch: 5 2400/3904 Training loss: 0.797572
Epoch: 5 3200/3904 Training loss: 0.582819
Training loss: 0.659376
Test loss: 0.836768; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 6 0/3904 Training loss: 0.714581
Epoch: 6 800/3904 Training loss: 0.746241
Epoch: 6 1600/3904 Training loss: 0.521870
Epoch: 6 2400/3904 Training loss: 0.798234
Epoch: 6 3200/3904 Training loss: 0.572391
Training loss: 0.659151
Test loss: 0.842085; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 7 0/3904 Training loss: 0.719166
Epoch: 7 800/3904 Training loss: 0.746869
Epoch: 7 1600/3904 Training loss: 0.513281
Epoch: 7 2400/3904 Training loss: 0.809526
Epoch: 7 3200/3904 Training loss: 0.574203
Training loss: 0.658931
Test loss: 0.847298; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 8 0/3904 Training loss: 0.718416
Epoch: 8 800/3904 Training loss: 0.750956
Epoch: 8 1600/3904 Training loss: 0.514042
Epoch: 8 2400/3904 Training loss: 0.812805
Epoch: 8 3200/3904 Training loss: 0.572107
Training loss: 0.658490
Test loss: 0.850793; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 9 0/3904 Training loss: 0.721666
Epoch: 9 800/3904 Training loss: 0.743250
Epoch: 9 1600/3904 Training loss: 0.510866
Epoch: 9 2400/3904 Training loss: 0.815763
Epoch: 9 3200/3904 Training loss: 0.567564
Training loss: 0.658296
Test loss: 0.855257; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 10 0/3904 Training loss: 0.724768
Epoch: 10 800/3904 Training loss: 0.754891
Epoch: 10 1600/3904 Training loss: 0.508895
Epoch: 10 2400/3904 Training loss: 0.810930
Epoch: 10 3200/3904 Training loss: 0.567840
Training loss: 0.658286
Test loss: 0.858381; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
starting trial 239
[I 2022-12-05 06:32:55,592] Trial 238 finished with value: 0.2268835616438356 and parameters: {'d_model': 16, 'nhead': 8, 'n_encoders': 1, 'learning_rate': 1.3512437764738048e-05, 'weight_decay': 4.936559124469338e-05, 'dropout': 0.3434212055866274, 'max_pool_conv': 16, 'kernel_size': 7, 'd_mlp': 16, 'num_conv_layers': 7, 'encoder_dropout': 0.03183104418317647, 'd_feed_forward': 256, 'max_pool_dim': 16, 'n_mlp_layers': 4}. Best is trial 62 with value: 0.860445205479452.
Epoch: 0 0/3904 Training loss: 0.691642
Epoch: 0 800/3904 Training loss: 0.704889
Epoch: 0 1600/3904 Training loss: 0.410790
Epoch: 0 2400/3904 Training loss: 0.757662
Epoch: 0 3200/3904 Training loss: 0.549640
Training loss: 0.666259
Test loss: 0.783569; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 1 0/3904 Training loss: 0.705332
Epoch: 1 800/3904 Training loss: 0.725731
Epoch: 1 1600/3904 Training loss: 0.425541
Epoch: 1 2400/3904 Training loss: 0.764925
Epoch: 1 3200/3904 Training loss: 0.544814
Training loss: 0.664056
Test loss: 0.790746; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 2 0/3904 Training loss: 0.704670
Epoch: 2 800/3904 Training loss: 0.728316
Epoch: 2 1600/3904 Training loss: 0.436310
Epoch: 2 2400/3904 Training loss: 0.781607
Epoch: 2 3200/3904 Training loss: 0.559199
Training loss: 0.663212
Test loss: 0.815718; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 3 0/3904 Training loss: 0.709497
Epoch: 3 800/3904 Training loss: 0.728212
Epoch: 3 1600/3904 Training loss: 0.448740
Epoch: 3 2400/3904 Training loss: 0.789234
Epoch: 3 3200/3904 Training loss: 0.561176
Training loss: 0.662304
Test loss: 0.820066; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 4 0/3904 Training loss: 0.716572
Epoch: 4 800/3904 Training loss: 0.724071
Epoch: 4 1600/3904 Training loss: 0.464087
Epoch: 4 2400/3904 Training loss: 0.795548
Epoch: 4 3200/3904 Training loss: 0.559378
Training loss: 0.662253
Test loss: 0.831351; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 5 0/3904 Training loss: 0.722164
Epoch: 5 800/3904 Training loss: 0.728145
Epoch: 5 1600/3904 Training loss: 0.452768
Epoch: 5 2400/3904 Training loss: 0.766080
Epoch: 5 3200/3904 Training loss: 0.558233
Training loss: 0.662868
Test loss: 0.827970; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 6 0/3904 Training loss: 0.713859
Epoch: 6 800/3904 Training loss: 0.724650
Epoch: 6 1600/3904 Training loss: 0.463766
Epoch: 6 2400/3904 Training loss: 0.800739
Epoch: 6 3200/3904 Training loss: 0.563471
Training loss: 0.662079
Test loss: 0.835036; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 7 0/3904 Training loss: 0.717523
Epoch: 7 800/3904 Training loss: 0.735419
Epoch: 7 1600/3904 Training loss: 0.471806
Epoch: 7 2400/3904 Training loss: 0.802619
Epoch: 7 3200/3904 Training loss: 0.562082
Training loss: 0.661252
Test loss: 0.846662; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 8 0/3904 Training loss: 0.725124
Epoch: 8 800/3904 Training loss: 0.738285
Epoch: 8 1600/3904 Training loss: 0.478266
Epoch: 8 2400/3904 Training loss: 0.807917
Epoch: 8 3200/3904 Training loss: 0.562887
Training loss: 0.661368
Test loss: 0.855114; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 9 0/3904 Training loss: 0.717851
Epoch: 9 800/3904 Training loss: 0.738770
Epoch: 9 1600/3904 Training loss: 0.472285
Epoch: 9 2400/3904 Training loss: 0.810799
Epoch: 9 3200/3904 Training loss: 0.561102
Training loss: 0.660982
Test loss: 0.851660; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 10 0/3904 Training loss: 0.716790
Epoch: 10 800/3904 Training loss: 0.735764
Epoch: 10 1600/3904 Training loss: 0.479540
Epoch: 10 2400/3904 Training loss: 0.811130
Epoch: 10 3200/3904 Training loss: 0.558966
Training loss: 0.661358
Test loss: 0.849934; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
starting trial 240
[I 2022-12-05 06:35:25,958] Trial 239 finished with value: 0.2268835616438356 and parameters: {'d_model': 64, 'nhead': 8, 'n_encoders': 1, 'learning_rate': 0.000586881585269692, 'weight_decay': 3.20819926351835e-06, 'dropout': 0.16197014088194356, 'max_pool_conv': 64, 'kernel_size': 13, 'd_mlp': 62, 'num_conv_layers': 8, 'encoder_dropout': 0.11518467715737649, 'd_feed_forward': 512, 'max_pool_dim': 8, 'n_mlp_layers': 3}. Best is trial 62 with value: 0.860445205479452.
Epoch: 0 0/3904 Training loss: 0.688281
Epoch: 0 800/3904 Training loss: 0.732178
Epoch: 0 1600/3904 Training loss: 0.405128
Epoch: 0 2400/3904 Training loss: 0.669653
Epoch: 0 3200/3904 Training loss: 0.483117
Training loss: 0.640595
Test loss: 0.695600; True positive: 364; True negative: 110, False Positive: 155, False negative: 539, accuracy: 0.4058219178082192, precision: 0.7013487475915221, recall: 0.40310077519379844
Epoch: 1 0/3904 Training loss: 0.594770
Epoch: 1 800/3904 Training loss: 0.576284
Epoch: 1 1600/3904 Training loss: 0.266733
Epoch: 1 2400/3904 Training loss: 0.585674
Epoch: 1 3200/3904 Training loss: 0.371039
Training loss: 0.506080
Test loss: 1.110624; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 2 0/3904 Training loss: 0.367916
Epoch: 2 800/3904 Training loss: 0.376904
Epoch: 2 1600/3904 Training loss: 0.261671
Epoch: 2 2400/3904 Training loss: 0.542118
Epoch: 2 3200/3904 Training loss: 0.443125
Training loss: 0.409660
Test loss: 1.462533; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 3 0/3904 Training loss: 0.252182
Epoch: 3 800/3904 Training loss: 0.248479
Epoch: 3 1600/3904 Training loss: 0.187094
Epoch: 3 2400/3904 Training loss: 0.500335
Epoch: 3 3200/3904 Training loss: 0.457297
Training loss: 0.366581
Test loss: 0.883797; True positive: 51; True negative: 261, False Positive: 4, False negative: 852, accuracy: 0.2671232876712329, precision: 0.9272727272727272, recall: 0.05647840531561462
Epoch: 4 0/3904 Training loss: 0.220789
Epoch: 4 800/3904 Training loss: 0.190777
Epoch: 4 1600/3904 Training loss: 0.169775
Epoch: 4 2400/3904 Training loss: 0.458249
Epoch: 4 3200/3904 Training loss: 0.483018
Training loss: 0.323738
Test loss: 0.495067; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 5 0/3904 Training loss: 0.224000
Epoch: 5 800/3904 Training loss: 0.211371
Epoch: 5 1600/3904 Training loss: 0.191646
Epoch: 5 2400/3904 Training loss: 0.409001
Epoch: 5 3200/3904 Training loss: 0.362757
Training loss: 0.290718
Test loss: 0.496779; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 6 0/3904 Training loss: 0.124607
Epoch: 6 800/3904 Training loss: 0.214217
Epoch: 6 1600/3904 Training loss: 0.187968
Epoch: 6 2400/3904 Training loss: 0.338958
Epoch: 6 3200/3904 Training loss: 0.444894
Training loss: 0.262726
Test loss: 0.519628; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 7 0/3904 Training loss: 0.153710
Epoch: 7 800/3904 Training loss: 0.155798
Epoch: 7 1600/3904 Training loss: 0.140898
Epoch: 7 2400/3904 Training loss: 0.309396
Epoch: 7 3200/3904 Training loss: 0.472257
Training loss: 0.246797
Test loss: 0.522485; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 8 0/3904 Training loss: 0.171416
Epoch: 8 800/3904 Training loss: 0.205005
Epoch: 8 1600/3904 Training loss: 0.092883
Epoch: 8 2400/3904 Training loss: 0.237331
Epoch: 8 3200/3904 Training loss: 0.548127
Training loss: 0.223624
Test loss: 0.538181; True positive: 837; True negative: 118, False Positive: 147, False negative: 66, accuracy: 0.8176369863013698, precision: 0.850609756097561, recall: 0.9269102990033222
Epoch: 9 0/3904 Training loss: 0.204066
Epoch: 9 800/3904 Training loss: 0.111855
Epoch: 9 1600/3904 Training loss: 0.118716
Epoch: 9 2400/3904 Training loss: 0.158451
Epoch: 9 3200/3904 Training loss: 0.483729
Training loss: 0.218037
Test loss: 0.576277; True positive: 832; True negative: 117, False Positive: 148, False negative: 71, accuracy: 0.8125, precision: 0.8489795918367347, recall: 0.9213732004429679
Epoch: 10 0/3904 Training loss: 0.194256
Epoch: 10 800/3904 Training loss: 0.213181
Epoch: 10 1600/3904 Training loss: 0.090623
Epoch: 10 2400/3904 Training loss: 0.156187
Epoch: 10 3200/3904 Training loss: 0.309620
Training loss: 0.204843
Test loss: 0.678127; True positive: 704; True negative: 152, False Positive: 113, False negative: 199, accuracy: 0.7328767123287672, precision: 0.8616891064871481, recall: 0.7796234772978959
Epoch: 11 0/3904 Training loss: 0.093276
Epoch: 11 800/3904 Training loss: 0.214987
Epoch: 11 1600/3904 Training loss: 0.072831
Epoch: 11 2400/3904 Training loss: 0.148831
Epoch: 11 3200/3904 Training loss: 0.638644
Training loss: 0.187630
Test loss: 0.720380; True positive: 578; True negative: 147, False Positive: 118, False negative: 325, accuracy: 0.6207191780821918, precision: 0.8304597701149425, recall: 0.6400885935769657
Epoch: 12 0/3904 Training loss: 0.067163
Epoch: 12 800/3904 Training loss: 0.243605
Epoch: 12 1600/3904 Training loss: 0.042664
Epoch: 12 2400/3904 Training loss: 0.067961
Epoch: 12 3200/3904 Training loss: 0.229750
Training loss: 0.171871
Test loss: 0.831116; True positive: 101; True negative: 231, False Positive: 34, False negative: 802, accuracy: 0.2842465753424658, precision: 0.7481481481481481, recall: 0.11184939091915837
Epoch: 13 0/3904 Training loss: 0.120729
Epoch: 13 800/3904 Training loss: 0.136100
Epoch: 13 1600/3904 Training loss: 0.130221
Epoch: 13 2400/3904 Training loss: 0.061458
Epoch: 13 3200/3904 Training loss: 0.368539
Training loss: 0.161430
Test loss: 0.945699; True positive: 1; True negative: 262, False Positive: 3, False negative: 902, accuracy: 0.22517123287671234, precision: 0.25, recall: 0.0011074197120708748
Epoch: 14 0/3904 Training loss: 0.120704
Epoch: 14 800/3904 Training loss: 0.107687
Epoch: 14 1600/3904 Training loss: 0.080746
Epoch: 14 2400/3904 Training loss: 0.043330
Epoch: 14 3200/3904 Training loss: 0.144490
Training loss: 0.150343
Test loss: 1.239760; True positive: 5; True negative: 265, False Positive: 0, False negative: 898, accuracy: 0.23116438356164384, precision: 1.0, recall: 0.005537098560354375
starting trial 241
[I 2022-12-05 06:36:42,941] Trial 240 finished with value: 0.8176369863013698 and parameters: {'d_model': 64, 'nhead': 8, 'n_encoders': 1, 'learning_rate': 0.00013133996959110143, 'weight_decay': 3.6399176815278275e-06, 'dropout': 0.17184131056915214, 'max_pool_conv': 64, 'kernel_size': 20, 'd_mlp': 32, 'num_conv_layers': 2, 'encoder_dropout': 0.14387203792667627, 'd_feed_forward': 128, 'max_pool_dim': 8, 'n_mlp_layers': 3}. Best is trial 62 with value: 0.860445205479452.
Epoch: 0 0/3904 Training loss: 0.693974
Epoch: 0 800/3904 Training loss: 0.707192
Epoch: 0 1600/3904 Training loss: 0.581128
Epoch: 0 2400/3904 Training loss: 0.766256
Epoch: 0 3200/3904 Training loss: 0.589318
Training loss: 0.668767
Test loss: 0.839618; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 1 0/3904 Training loss: 0.721481
Epoch: 1 800/3904 Training loss: 0.732303
Epoch: 1 1600/3904 Training loss: 0.516869
Epoch: 1 2400/3904 Training loss: 0.824182
Epoch: 1 3200/3904 Training loss: 0.567791
Training loss: 0.659524
Test loss: 0.875583; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 2 0/3904 Training loss: 0.733018
Epoch: 2 800/3904 Training loss: 0.747055
Epoch: 2 1600/3904 Training loss: 0.506189
Epoch: 2 2400/3904 Training loss: 0.834683
Epoch: 2 3200/3904 Training loss: 0.561519
Training loss: 0.659564
Test loss: 0.868951; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 3 0/3904 Training loss: 0.709866
Epoch: 3 800/3904 Training loss: 0.747015
Epoch: 3 1600/3904 Training loss: 0.490859
Epoch: 3 2400/3904 Training loss: 0.812769
Epoch: 3 3200/3904 Training loss: 0.557595
Training loss: 0.659447
Test loss: 0.871732; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 4 0/3904 Training loss: 0.721942
Epoch: 4 800/3904 Training loss: 0.759315
Epoch: 4 1600/3904 Training loss: 0.492685
Epoch: 4 2400/3904 Training loss: 0.841456
Epoch: 4 3200/3904 Training loss: 0.550997
Training loss: 0.657710
Test loss: 0.872374; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 5 0/3904 Training loss: 0.709747
Epoch: 5 800/3904 Training loss: 0.756766
Epoch: 5 1600/3904 Training loss: 0.490305
Epoch: 5 2400/3904 Training loss: 0.831765
Epoch: 5 3200/3904 Training loss: 0.564222
Training loss: 0.655652
Test loss: 0.877305; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 6 0/3904 Training loss: 0.723981
Epoch: 6 800/3904 Training loss: 0.715151
Epoch: 6 1600/3904 Training loss: 0.458298
Epoch: 6 2400/3904 Training loss: 0.755469
Epoch: 6 3200/3904 Training loss: 0.520889
Training loss: 0.634834
Test loss: 0.974376; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 7 0/3904 Training loss: 0.610142
Epoch: 7 800/3904 Training loss: 0.617392
Epoch: 7 1600/3904 Training loss: 0.337119
Epoch: 7 2400/3904 Training loss: 0.601689
Epoch: 7 3200/3904 Training loss: 0.507937
Training loss: 0.576726
Test loss: 1.145238; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 8 0/3904 Training loss: 0.528108
Epoch: 8 800/3904 Training loss: 0.536495
Epoch: 8 1600/3904 Training loss: 0.270584
Epoch: 8 2400/3904 Training loss: 0.619259
Epoch: 8 3200/3904 Training loss: 0.408801
Training loss: 0.523812
Test loss: 1.342900; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 9 0/3904 Training loss: 0.469936
Epoch: 9 800/3904 Training loss: 0.488669
Epoch: 9 1600/3904 Training loss: 0.284376
Epoch: 9 2400/3904 Training loss: 0.575473
Epoch: 9 3200/3904 Training loss: 0.410424
Training loss: 0.490665
Test loss: 1.433748; True positive: 65; True negative: 148, False Positive: 117, False negative: 838, accuracy: 0.18236301369863014, precision: 0.35714285714285715, recall: 0.07198228128460686
Epoch: 10 0/3904 Training loss: 0.550562
Epoch: 10 800/3904 Training loss: 0.486398
Epoch: 10 1600/3904 Training loss: 0.255475
Epoch: 10 2400/3904 Training loss: 0.650211
Epoch: 10 3200/3904 Training loss: 0.313004
Training loss: 0.469920
Test loss: 1.551777; True positive: 65; True negative: 148, False Positive: 117, False negative: 838, accuracy: 0.18236301369863014, precision: 0.35714285714285715, recall: 0.07198228128460686
starting trial 242
[I 2022-12-05 06:37:32,200] Trial 241 finished with value: 0.2268835616438356 and parameters: {'d_model': 16, 'nhead': 4, 'n_encoders': 3, 'learning_rate': 0.00014532239562305916, 'weight_decay': 8.303317488012571e-06, 'dropout': 0.22661026472759932, 'max_pool_conv': 128, 'kernel_size': 5, 'd_mlp': 32, 'num_conv_layers': 6, 'encoder_dropout': 0.09458745253425596, 'd_feed_forward': 128, 'max_pool_dim': 16, 'n_mlp_layers': 3}. Best is trial 62 with value: 0.860445205479452.
Epoch: 0 0/3904 Training loss: 0.697199
Epoch: 0 800/3904 Training loss: 0.697583
Epoch: 0 1600/3904 Training loss: 0.598359
Epoch: 0 2400/3904 Training loss: 0.763707
Epoch: 0 3200/3904 Training loss: 0.560180
Training loss: 0.674930
Test loss: 0.890106; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 1 0/3904 Training loss: 0.720984
Epoch: 1 800/3904 Training loss: 0.733815
Epoch: 1 1600/3904 Training loss: 0.483059
Epoch: 1 2400/3904 Training loss: 0.774674
Epoch: 1 3200/3904 Training loss: 0.536710
Training loss: 0.651718
Test loss: 0.931875; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 2 0/3904 Training loss: 0.708916
Epoch: 2 800/3904 Training loss: 0.721573
Epoch: 2 1600/3904 Training loss: 0.455965
Epoch: 2 2400/3904 Training loss: 0.750189
Epoch: 2 3200/3904 Training loss: 0.529024
Training loss: 0.639655
Test loss: 0.985660; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 3 0/3904 Training loss: 0.677948
Epoch: 3 800/3904 Training loss: 0.677855
Epoch: 3 1600/3904 Training loss: 0.409234
Epoch: 3 2400/3904 Training loss: 0.743974
Epoch: 3 3200/3904 Training loss: 0.480072
Training loss: 0.600847
Test loss: 0.676173; True positive: 903; True negative: 0, False Positive: 265, False negative: 0, accuracy: 0.7731164383561644, precision: 0.7731164383561644, recall: 1.0
Epoch: 4 0/3904 Training loss: 0.624148
Epoch: 4 800/3904 Training loss: 0.570626
Epoch: 4 1600/3904 Training loss: 0.340710
Epoch: 4 2400/3904 Training loss: 0.760872
Epoch: 4 3200/3904 Training loss: 0.443636
Training loss: 0.543143
Test loss: 0.612346; True positive: 890; True negative: 0, False Positive: 265, False negative: 13, accuracy: 0.761986301369863, precision: 0.7705627705627706, recall: 0.9856035437430787
Epoch: 5 0/3904 Training loss: 0.586304
Epoch: 5 800/3904 Training loss: 0.504173
Epoch: 5 1600/3904 Training loss: 0.289534
Epoch: 5 2400/3904 Training loss: 0.701519
Epoch: 5 3200/3904 Training loss: 0.458814
Training loss: 0.498420
Test loss: 1.320241; True positive: 62; True negative: 252, False Positive: 13, False negative: 841, accuracy: 0.2688356164383562, precision: 0.8266666666666667, recall: 0.06866002214839424
Epoch: 6 0/3904 Training loss: 0.540744
Epoch: 6 800/3904 Training loss: 0.449998
Epoch: 6 1600/3904 Training loss: 0.278327
Epoch: 6 2400/3904 Training loss: 0.592854
Epoch: 6 3200/3904 Training loss: 0.405272
Training loss: 0.471311
Test loss: 1.376102; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 7 0/3904 Training loss: 0.499248
Epoch: 7 800/3904 Training loss: 0.416391
Epoch: 7 1600/3904 Training loss: 0.266002
Epoch: 7 2400/3904 Training loss: 0.514634
Epoch: 7 3200/3904 Training loss: 0.446857
Training loss: 0.447132
Test loss: 1.432491; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 8 0/3904 Training loss: 0.468711
Epoch: 8 800/3904 Training loss: 0.335022
Epoch: 8 1600/3904 Training loss: 0.243253
Epoch: 8 2400/3904 Training loss: 0.396532
Epoch: 8 3200/3904 Training loss: 0.483285
Training loss: 0.431875
Test loss: 1.467495; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 9 0/3904 Training loss: 0.375073
Epoch: 9 800/3904 Training loss: 0.374862
Epoch: 9 1600/3904 Training loss: 0.231960
Epoch: 9 2400/3904 Training loss: 0.355938
Epoch: 9 3200/3904 Training loss: 0.508874
Training loss: 0.416649
Test loss: 1.537932; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 10 0/3904 Training loss: 0.371530
Epoch: 10 800/3904 Training loss: 0.336030
Epoch: 10 1600/3904 Training loss: 0.240016
Epoch: 10 2400/3904 Training loss: 0.352024
Epoch: 10 3200/3904 Training loss: 0.378954
Training loss: 0.407060
Test loss: 1.601952; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 11 0/3904 Training loss: 0.385154
Epoch: 11 800/3904 Training loss: 0.288428
Epoch: 11 1600/3904 Training loss: 0.255977
Epoch: 11 2400/3904 Training loss: 0.310582
Epoch: 11 3200/3904 Training loss: 0.424440
Training loss: 0.399704
Test loss: 1.687942; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 12 0/3904 Training loss: 0.378582
Epoch: 12 800/3904 Training loss: 0.279175
Epoch: 12 1600/3904 Training loss: 0.231546
Epoch: 12 2400/3904 Training loss: 0.326984
Epoch: 12 3200/3904 Training loss: 0.368438
Training loss: 0.391035
Test loss: 1.697846; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 13 0/3904 Training loss: 0.386877
Epoch: 13 800/3904 Training loss: 0.306599
Epoch: 13 1600/3904 Training loss: 0.221150
Epoch: 13 2400/3904 Training loss: 0.292296
Epoch: 13 3200/3904 Training loss: 0.382018
Training loss: 0.380267
Test loss: 1.753039; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 14 0/3904 Training loss: 0.388552
Epoch: 14 800/3904 Training loss: 0.298405
Epoch: 14 1600/3904 Training loss: 0.207513
Epoch: 14 2400/3904 Training loss: 0.276871
Epoch: 14 3200/3904 Training loss: 0.345264
Training loss: 0.373067
Test loss: 1.815355; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
starting trial 243
[I 2022-12-05 06:41:33,168] Trial 242 finished with value: 0.7731164383561644 and parameters: {'d_model': 64, 'nhead': 8, 'n_encoders': 1, 'learning_rate': 2.0011897306074623e-05, 'weight_decay': 4.035863541396784e-06, 'dropout': 0.1124597417290735, 'max_pool_conv': 64, 'kernel_size': 18, 'd_mlp': 16, 'num_conv_layers': 7, 'encoder_dropout': 0.007158021129632917, 'd_feed_forward': 256, 'max_pool_dim': 8, 'n_mlp_layers': 3}. Best is trial 62 with value: 0.860445205479452.
Epoch: 0 0/3904 Training loss: 0.699685
Epoch: 0 800/3904 Training loss: 0.720377
Epoch: 0 1600/3904 Training loss: 0.457450
Epoch: 0 2400/3904 Training loss: 0.789003
Epoch: 0 3200/3904 Training loss: 0.543129
Training loss: 0.663241
Test loss: 0.758910; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 1 0/3904 Training loss: 0.701209
Epoch: 1 800/3904 Training loss: 0.715949
Epoch: 1 1600/3904 Training loss: 0.391511
Epoch: 1 2400/3904 Training loss: 0.688789
Epoch: 1 3200/3904 Training loss: 0.482277
Training loss: 0.618366
Test loss: 0.633993; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 2 0/3904 Training loss: 0.597178
Epoch: 2 800/3904 Training loss: 0.467711
Epoch: 2 1600/3904 Training loss: 0.240046
Epoch: 2 2400/3904 Training loss: 0.664851
Epoch: 2 3200/3904 Training loss: 0.515425
Training loss: 0.507310
Test loss: 0.556544; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 3 0/3904 Training loss: 0.496156
Epoch: 3 800/3904 Training loss: 0.441663
Epoch: 3 1600/3904 Training loss: 0.252761
Epoch: 3 2400/3904 Training loss: 0.550548
Epoch: 3 3200/3904 Training loss: 0.460717
Training loss: 0.449263
Test loss: 0.550890; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 4 0/3904 Training loss: 0.530392
Epoch: 4 800/3904 Training loss: 0.334521
Epoch: 4 1600/3904 Training loss: 0.163845
Epoch: 4 2400/3904 Training loss: 0.322585
Epoch: 4 3200/3904 Training loss: 0.412356
Training loss: 0.430346
Test loss: 0.549815; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 5 0/3904 Training loss: 0.353809
Epoch: 5 800/3904 Training loss: 0.325745
Epoch: 5 1600/3904 Training loss: 0.279538
Epoch: 5 2400/3904 Training loss: 0.264175
Epoch: 5 3200/3904 Training loss: 0.457136
Training loss: 0.425850
Test loss: 0.549481; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 6 0/3904 Training loss: 0.486394
Epoch: 6 800/3904 Training loss: 0.468663
Epoch: 6 1600/3904 Training loss: 0.204209
Epoch: 6 2400/3904 Training loss: 0.242328
Epoch: 6 3200/3904 Training loss: 0.561963
Training loss: 0.408701
Test loss: 0.551920; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 7 0/3904 Training loss: 0.473857
Epoch: 7 800/3904 Training loss: 0.419894
Epoch: 7 1600/3904 Training loss: 0.237064
Epoch: 7 2400/3904 Training loss: 0.259938
Epoch: 7 3200/3904 Training loss: 0.478768
Training loss: 0.404887
Test loss: 0.549291; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 8 0/3904 Training loss: 0.443776
Epoch: 8 800/3904 Training loss: 0.385045
Epoch: 8 1600/3904 Training loss: 0.236863
Epoch: 8 2400/3904 Training loss: 0.296014
Epoch: 8 3200/3904 Training loss: 0.473379
Training loss: 0.393963
Test loss: 0.531697; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 9 0/3904 Training loss: 0.479775
Epoch: 9 800/3904 Training loss: 0.258277
Epoch: 9 1600/3904 Training loss: 0.234859
Epoch: 9 2400/3904 Training loss: 0.290581
Epoch: 9 3200/3904 Training loss: 0.336845
Training loss: 0.378763
Test loss: 0.531909; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 10 0/3904 Training loss: 0.539594
Epoch: 10 800/3904 Training loss: 0.270669
Epoch: 10 1600/3904 Training loss: 0.235265
Epoch: 10 2400/3904 Training loss: 0.330622
Epoch: 10 3200/3904 Training loss: 0.390072
Training loss: 0.382767
Test loss: 0.527646; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 11 0/3904 Training loss: 0.503918
Epoch: 11 800/3904 Training loss: 0.185959
Epoch: 11 1600/3904 Training loss: 0.162916
Epoch: 11 2400/3904 Training loss: 0.279950
Epoch: 11 3200/3904 Training loss: 0.371288
Training loss: 0.363538
Test loss: 0.541408; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 12 0/3904 Training loss: 0.689367
Epoch: 12 800/3904 Training loss: 0.264302
Epoch: 12 1600/3904 Training loss: 0.166951
Epoch: 12 2400/3904 Training loss: 0.236468
Epoch: 12 3200/3904 Training loss: 0.379617
Training loss: 0.357299
Test loss: 0.556327; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 13 0/3904 Training loss: 0.578185
Epoch: 13 800/3904 Training loss: 0.278479
Epoch: 13 1600/3904 Training loss: 0.118791
Epoch: 13 2400/3904 Training loss: 0.284770
Epoch: 13 3200/3904 Training loss: 0.422972
Training loss: 0.343749
Test loss: 0.576083; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 14 0/3904 Training loss: 0.374193
Epoch: 14 800/3904 Training loss: 0.130235
Epoch: 14 1600/3904 Training loss: 0.159050
Epoch: 14 2400/3904 Training loss: 0.228217
Epoch: 14 3200/3904 Training loss: 0.482398
Training loss: 0.337143
Test loss: 0.568914; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 15 0/3904 Training loss: 0.563531
Epoch: 15 800/3904 Training loss: 0.224895
Epoch: 15 1600/3904 Training loss: 0.240582
Epoch: 15 2400/3904 Training loss: 0.356615
Epoch: 15 3200/3904 Training loss: 0.414143
Training loss: 0.316382
Test loss: 0.581650; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 16 0/3904 Training loss: 0.639404
Epoch: 16 800/3904 Training loss: 0.352935
Epoch: 16 1600/3904 Training loss: 0.183421
Epoch: 16 2400/3904 Training loss: 0.241909
Epoch: 16 3200/3904 Training loss: 0.372900
Training loss: 0.310893
Test loss: 0.593650; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 17 0/3904 Training loss: 0.429561
Epoch: 17 800/3904 Training loss: 0.284716
Epoch: 17 1600/3904 Training loss: 0.207134
Epoch: 17 2400/3904 Training loss: 0.155118
Epoch: 17 3200/3904 Training loss: 0.387154
Training loss: 0.310454
Test loss: 0.583529; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 18 0/3904 Training loss: 0.438659
Epoch: 18 800/3904 Training loss: 0.276561
Epoch: 18 1600/3904 Training loss: 0.165900
Epoch: 18 2400/3904 Training loss: 0.136892
Epoch: 18 3200/3904 Training loss: 0.346155
Training loss: 0.300102
Test loss: 0.585870; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 19 0/3904 Training loss: 0.452391
Epoch: 19 800/3904 Training loss: 0.127667
Epoch: 19 1600/3904 Training loss: 0.175240
Epoch: 19 2400/3904 Training loss: 0.274572
Epoch: 19 3200/3904 Training loss: 0.300051
Training loss: 0.290353
Test loss: 0.586372; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 20 0/3904 Training loss: 0.484096
Epoch: 20 800/3904 Training loss: 0.124451
Epoch: 20 1600/3904 Training loss: 0.170411
Epoch: 20 2400/3904 Training loss: 0.188601
Epoch: 20 3200/3904 Training loss: 0.411354
Training loss: 0.288659
Test loss: 0.599833; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
starting trial 244
[I 2022-12-05 06:42:30,386] Trial 243 finished with value: 0.8176369863013698 and parameters: {'d_model': 16, 'nhead': 4, 'n_encoders': 1, 'learning_rate': 0.00026876477323295797, 'weight_decay': 4.872589804040192e-06, 'dropout': 0.19211818421366672, 'max_pool_conv': 32, 'kernel_size': 15, 'd_mlp': 32, 'num_conv_layers': 3, 'encoder_dropout': 0.27758050664184475, 'd_feed_forward': 128, 'max_pool_dim': 16, 'n_mlp_layers': 3}. Best is trial 62 with value: 0.860445205479452.
Epoch: 0 0/3904 Training loss: 0.704617
Epoch: 0 800/3904 Training loss: 0.724192
Epoch: 0 1600/3904 Training loss: 0.423821
Epoch: 0 2400/3904 Training loss: 0.734818
Epoch: 0 3200/3904 Training loss: 0.541453
Training loss: 0.658092
Test loss: 0.764050; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 1 0/3904 Training loss: 0.686844
Epoch: 1 800/3904 Training loss: 0.721770
Epoch: 1 1600/3904 Training loss: 0.271661
Epoch: 1 2400/3904 Training loss: 0.560835
Epoch: 1 3200/3904 Training loss: 0.567455
Training loss: 0.602071
Test loss: 0.678419; True positive: 903; True negative: 0, False Positive: 265, False negative: 0, accuracy: 0.7731164383561644, precision: 0.7731164383561644, recall: 1.0
Epoch: 2 0/3904 Training loss: 0.506565
Epoch: 2 800/3904 Training loss: 0.572520
Epoch: 2 1600/3904 Training loss: 0.203963
Epoch: 2 2400/3904 Training loss: 0.399750
Epoch: 2 3200/3904 Training loss: 0.389082
Training loss: 0.480327
Test loss: 0.557557; True positive: 903; True negative: 0, False Positive: 265, False negative: 0, accuracy: 0.7731164383561644, precision: 0.7731164383561644, recall: 1.0
Epoch: 3 0/3904 Training loss: 0.388470
Epoch: 3 800/3904 Training loss: 0.376582
Epoch: 3 1600/3904 Training loss: 0.146324
Epoch: 3 2400/3904 Training loss: 0.283392
Epoch: 3 3200/3904 Training loss: 0.335524
Training loss: 0.444084
Test loss: 0.563739; True positive: 903; True negative: 0, False Positive: 265, False negative: 0, accuracy: 0.7731164383561644, precision: 0.7731164383561644, recall: 1.0
Epoch: 4 0/3904 Training loss: 0.392483
Epoch: 4 800/3904 Training loss: 0.451251
Epoch: 4 1600/3904 Training loss: 0.177260
Epoch: 4 2400/3904 Training loss: 0.207371
Epoch: 4 3200/3904 Training loss: 0.371491
Training loss: 0.428459
Test loss: 0.547939; True positive: 903; True negative: 0, False Positive: 265, False negative: 0, accuracy: 0.7731164383561644, precision: 0.7731164383561644, recall: 1.0
Epoch: 5 0/3904 Training loss: 0.438627
Epoch: 5 800/3904 Training loss: 0.472199
Epoch: 5 1600/3904 Training loss: 0.155380
Epoch: 5 2400/3904 Training loss: 0.278023
Epoch: 5 3200/3904 Training loss: 0.291755
Training loss: 0.407017
Test loss: 0.601797; True positive: 903; True negative: 0, False Positive: 265, False negative: 0, accuracy: 0.7731164383561644, precision: 0.7731164383561644, recall: 1.0
Epoch: 6 0/3904 Training loss: 0.506617
Epoch: 6 800/3904 Training loss: 0.233884
Epoch: 6 1600/3904 Training loss: 0.206059
Epoch: 6 2400/3904 Training loss: 0.174270
Epoch: 6 3200/3904 Training loss: 0.469924
Training loss: 0.394218
Test loss: 0.636757; True positive: 903; True negative: 0, False Positive: 265, False negative: 0, accuracy: 0.7731164383561644, precision: 0.7731164383561644, recall: 1.0
Epoch: 7 0/3904 Training loss: 0.436113
Epoch: 7 800/3904 Training loss: 0.295653
Epoch: 7 1600/3904 Training loss: 0.200853
Epoch: 7 2400/3904 Training loss: 0.201604
Epoch: 7 3200/3904 Training loss: 0.407970
Training loss: 0.382890
Test loss: 0.774503; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 8 0/3904 Training loss: 0.421583
Epoch: 8 800/3904 Training loss: 0.231627
Epoch: 8 1600/3904 Training loss: 0.106657
Epoch: 8 2400/3904 Training loss: 0.174124
Epoch: 8 3200/3904 Training loss: 0.370791
Training loss: 0.370948
Test loss: 0.799513; True positive: 775; True negative: 119, False Positive: 146, False negative: 128, accuracy: 0.7654109589041096, precision: 0.8414766558089034, recall: 0.858250276854928
Epoch: 9 0/3904 Training loss: 0.387886
Epoch: 9 800/3904 Training loss: 0.239288
Epoch: 9 1600/3904 Training loss: 0.163821
Epoch: 9 2400/3904 Training loss: 0.167391
Epoch: 9 3200/3904 Training loss: 0.303818
Training loss: 0.382875
Test loss: 0.649884; True positive: 903; True negative: 0, False Positive: 265, False negative: 0, accuracy: 0.7731164383561644, precision: 0.7731164383561644, recall: 1.0
Epoch: 10 0/3904 Training loss: 0.348837
Epoch: 10 800/3904 Training loss: 0.194927
Epoch: 10 1600/3904 Training loss: 0.148749
Epoch: 10 2400/3904 Training loss: 0.270430
Epoch: 10 3200/3904 Training loss: 0.402307
Training loss: 0.365308
Test loss: 1.679768; True positive: 479; True negative: 238, False Positive: 27, False negative: 424, accuracy: 0.6138698630136986, precision: 0.9466403162055336, recall: 0.530454042081949
Epoch: 11 0/3904 Training loss: 0.355851
Epoch: 11 800/3904 Training loss: 0.177418
Epoch: 11 1600/3904 Training loss: 0.155496
Epoch: 11 2400/3904 Training loss: 0.223281
Epoch: 11 3200/3904 Training loss: 0.459686
Training loss: 0.373502
Test loss: 1.300101; True positive: 515; True negative: 232, False Positive: 33, False negative: 388, accuracy: 0.639554794520548, precision: 0.9397810218978102, recall: 0.5703211517165006
Epoch: 12 0/3904 Training loss: 0.352359
Epoch: 12 800/3904 Training loss: 0.236402
Epoch: 12 1600/3904 Training loss: 0.177955
Epoch: 12 2400/3904 Training loss: 0.607986
Epoch: 12 3200/3904 Training loss: 0.382910
Training loss: 0.390586
Test loss: 1.044951; True positive: 631; True negative: 201, False Positive: 64, False negative: 272, accuracy: 0.7123287671232876, precision: 0.9079136690647482, recall: 0.698781838316722
Epoch: 13 0/3904 Training loss: 0.399048
Epoch: 13 800/3904 Training loss: 0.257507
Epoch: 13 1600/3904 Training loss: 0.174099
Epoch: 13 2400/3904 Training loss: 0.155613
Epoch: 13 3200/3904 Training loss: 0.410951
Training loss: 0.405605
Test loss: 0.651042; True positive: 902; True negative: 0, False Positive: 265, False negative: 1, accuracy: 0.7722602739726028, precision: 0.7729220222793488, recall: 0.9988925802879292
Epoch: 14 0/3904 Training loss: 0.382486
Epoch: 14 800/3904 Training loss: 0.433435
Epoch: 14 1600/3904 Training loss: 0.293156
Epoch: 14 2400/3904 Training loss: 0.170432
Epoch: 14 3200/3904 Training loss: 0.384971
Training loss: 0.414519
Test loss: 0.657297; True positive: 903; True negative: 0, False Positive: 265, False negative: 0, accuracy: 0.7731164383561644, precision: 0.7731164383561644, recall: 1.0
starting trial 245
[I 2022-12-05 06:43:58,757] Trial 244 finished with value: 0.8176369863013698 and parameters: {'d_model': 64, 'nhead': 4, 'n_encoders': 1, 'learning_rate': 0.000524871806045278, 'weight_decay': 4.3787057372024486e-06, 'dropout': 0.21717822091837075, 'max_pool_conv': 64, 'kernel_size': 14, 'd_mlp': 32, 'num_conv_layers': 3, 'encoder_dropout': 0.10974282478425627, 'd_feed_forward': 128, 'max_pool_dim': 8, 'n_mlp_layers': 3}. Best is trial 62 with value: 0.860445205479452.
Epoch: 0 0/3904 Training loss: 0.697727
Epoch: 0 800/3904 Training loss: 0.713998
Epoch: 0 1600/3904 Training loss: 0.438830
Epoch: 0 2400/3904 Training loss: 0.793309
Epoch: 0 3200/3904 Training loss: 0.548083
Training loss: 0.661339
Test loss: 0.790491; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 1 0/3904 Training loss: 0.705508
Epoch: 1 800/3904 Training loss: 0.726235
Epoch: 1 1600/3904 Training loss: 0.428867
Epoch: 1 2400/3904 Training loss: 0.752122
Epoch: 1 3200/3904 Training loss: 0.525693
Training loss: 0.649821
Test loss: 0.790770; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 2 0/3904 Training loss: 0.670263
Epoch: 2 800/3904 Training loss: 0.679050
Epoch: 2 1600/3904 Training loss: 0.288019
Epoch: 2 2400/3904 Training loss: 0.766503
Epoch: 2 3200/3904 Training loss: 0.443838
Training loss: 0.592607
Test loss: 1.163135; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 3 0/3904 Training loss: 0.539248
Epoch: 3 800/3904 Training loss: 0.500365
Epoch: 3 1600/3904 Training loss: 0.247265
Epoch: 3 2400/3904 Training loss: 0.753172
Epoch: 3 3200/3904 Training loss: 0.370383
Training loss: 0.513812
Test loss: 1.599866; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 4 0/3904 Training loss: 0.424877
Epoch: 4 800/3904 Training loss: 0.514326
Epoch: 4 1600/3904 Training loss: 0.213755
Epoch: 4 2400/3904 Training loss: 0.611405
Epoch: 4 3200/3904 Training loss: 0.367035
Training loss: 0.451862
Test loss: 1.629109; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 5 0/3904 Training loss: 0.321393
Epoch: 5 800/3904 Training loss: 0.376706
Epoch: 5 1600/3904 Training loss: 0.136939
Epoch: 5 2400/3904 Training loss: 0.494242
Epoch: 5 3200/3904 Training loss: 0.355883
Training loss: 0.412462
Test loss: 1.685573; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 6 0/3904 Training loss: 0.319384
Epoch: 6 800/3904 Training loss: 0.286617
Epoch: 6 1600/3904 Training loss: 0.135346
Epoch: 6 2400/3904 Training loss: 0.575869
Epoch: 6 3200/3904 Training loss: 0.342427
Training loss: 0.379052
Test loss: 1.715266; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 7 0/3904 Training loss: 0.249169
Epoch: 7 800/3904 Training loss: 0.385809
Epoch: 7 1600/3904 Training loss: 0.125998
Epoch: 7 2400/3904 Training loss: 0.680318
Epoch: 7 3200/3904 Training loss: 0.360315
Training loss: 0.353737
Test loss: 1.373470; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 8 0/3904 Training loss: 0.325176
Epoch: 8 800/3904 Training loss: 0.212315
Epoch: 8 1600/3904 Training loss: 0.157128
Epoch: 8 2400/3904 Training loss: 0.540350
Epoch: 8 3200/3904 Training loss: 0.363386
Training loss: 0.340727
Test loss: 1.486669; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 9 0/3904 Training loss: 0.264902
Epoch: 9 800/3904 Training loss: 0.203178
Epoch: 9 1600/3904 Training loss: 0.081653
Epoch: 9 2400/3904 Training loss: 0.402878
Epoch: 9 3200/3904 Training loss: 0.308849
Training loss: 0.314045
Test loss: 0.886000; True positive: 91; True negative: 148, False Positive: 117, False negative: 812, accuracy: 0.2046232876712329, precision: 0.4375, recall: 0.10077519379844961
Epoch: 10 0/3904 Training loss: 0.215464
Epoch: 10 800/3904 Training loss: 0.286397
Epoch: 10 1600/3904 Training loss: 0.114923
Epoch: 10 2400/3904 Training loss: 0.349948
Epoch: 10 3200/3904 Training loss: 0.357078
Training loss: 0.307879
Test loss: 1.478459; True positive: 4; True negative: 263, False Positive: 2, False negative: 899, accuracy: 0.2285958904109589, precision: 0.6666666666666666, recall: 0.004429678848283499
starting trial 246
[I 2022-12-05 06:44:29,260] Trial 245 finished with value: 0.2285958904109589 and parameters: {'d_model': 64, 'nhead': 8, 'n_encoders': 1, 'learning_rate': 0.00011830209241272322, 'weight_decay': 3.3678601981142125e-06, 'dropout': 0.3631660269830589, 'max_pool_conv': 64, 'kernel_size': 6, 'd_mlp': 128, 'num_conv_layers': 2, 'encoder_dropout': 0.0214182385959309, 'd_feed_forward': 128, 'max_pool_dim': 8, 'n_mlp_layers': 3}. Best is trial 62 with value: 0.860445205479452.
Epoch: 0 0/3904 Training loss: 0.702629
Epoch: 0 800/3904 Training loss: 0.729440
Epoch: 0 1600/3904 Training loss: 0.499802
Epoch: 0 2400/3904 Training loss: 0.808802
Epoch: 0 3200/3904 Training loss: 0.561643
Training loss: 0.661652
Test loss: 0.865140; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 1 0/3904 Training loss: 0.702826
Epoch: 1 800/3904 Training loss: 0.733413
Epoch: 1 1600/3904 Training loss: 0.472805
Epoch: 1 2400/3904 Training loss: 0.793282
Epoch: 1 3200/3904 Training loss: 0.551388
Training loss: 0.655933
Test loss: 0.792982; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 2 0/3904 Training loss: 0.710775
Epoch: 2 800/3904 Training loss: 0.711290
Epoch: 2 1600/3904 Training loss: 0.354339
Epoch: 2 2400/3904 Training loss: 0.762753
Epoch: 2 3200/3904 Training loss: 0.404462
Training loss: 0.599231
Test loss: 1.205394; True positive: 5; True negative: 264, False Positive: 1, False negative: 898, accuracy: 0.2303082191780822, precision: 0.8333333333333334, recall: 0.005537098560354375
Epoch: 3 0/3904 Training loss: 0.618437
Epoch: 3 800/3904 Training loss: 0.476185
Epoch: 3 1600/3904 Training loss: 0.247502
Epoch: 3 2400/3904 Training loss: 0.559864
Epoch: 3 3200/3904 Training loss: 0.454798
Training loss: 0.533033
Test loss: 0.693063; True positive: 716; True negative: 131, False Positive: 134, False negative: 187, accuracy: 0.7251712328767124, precision: 0.8423529411764706, recall: 0.7929125138427464
Epoch: 4 0/3904 Training loss: 0.456536
Epoch: 4 800/3904 Training loss: 0.453056
Epoch: 4 1600/3904 Training loss: 0.307376
Epoch: 4 2400/3904 Training loss: 0.549663
Epoch: 4 3200/3904 Training loss: 0.377800
Training loss: 0.494789
Test loss: 0.519143; True positive: 834; True negative: 120, False Positive: 145, False negative: 69, accuracy: 0.8167808219178082, precision: 0.8518896833503575, recall: 0.9235880398671097
Epoch: 5 0/3904 Training loss: 0.452712
Epoch: 5 800/3904 Training loss: 0.490900
Epoch: 5 1600/3904 Training loss: 0.215685
Epoch: 5 2400/3904 Training loss: 0.390170
Epoch: 5 3200/3904 Training loss: 0.478890
Training loss: 0.470976
Test loss: 0.515988; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 6 0/3904 Training loss: 0.429588
Epoch: 6 800/3904 Training loss: 0.425515
Epoch: 6 1600/3904 Training loss: 0.222661
Epoch: 6 2400/3904 Training loss: 0.466859
Epoch: 6 3200/3904 Training loss: 0.496068
Training loss: 0.486227
Test loss: 0.519300; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 7 0/3904 Training loss: 0.540432
Epoch: 7 800/3904 Training loss: 0.382059
Epoch: 7 1600/3904 Training loss: 0.250017
Epoch: 7 2400/3904 Training loss: 0.327876
Epoch: 7 3200/3904 Training loss: 0.456933
Training loss: 0.451694
Test loss: 0.508444; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 8 0/3904 Training loss: 0.531598
Epoch: 8 800/3904 Training loss: 0.538737
Epoch: 8 1600/3904 Training loss: 0.269205
Epoch: 8 2400/3904 Training loss: 0.595131
Epoch: 8 3200/3904 Training loss: 0.386721
Training loss: 0.452632
Test loss: 0.509113; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 9 0/3904 Training loss: 0.486529
Epoch: 9 800/3904 Training loss: 0.405393
Epoch: 9 1600/3904 Training loss: 0.205452
Epoch: 9 2400/3904 Training loss: 0.394875
Epoch: 9 3200/3904 Training loss: 0.410292
Training loss: 0.445318
Test loss: 0.507235; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 10 0/3904 Training loss: 0.562002
Epoch: 10 800/3904 Training loss: 0.451026
Epoch: 10 1600/3904 Training loss: 0.270513
Epoch: 10 2400/3904 Training loss: 0.373690
Epoch: 10 3200/3904 Training loss: 0.455448
Training loss: 0.439519
Test loss: 0.514830; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 11 0/3904 Training loss: 0.445687
Epoch: 11 800/3904 Training loss: 0.303360
Epoch: 11 1600/3904 Training loss: 0.232060
Epoch: 11 2400/3904 Training loss: 0.478361
Epoch: 11 3200/3904 Training loss: 0.402335
Training loss: 0.434656
Test loss: 0.514903; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 12 0/3904 Training loss: 0.622865
Epoch: 12 800/3904 Training loss: 0.379856
Epoch: 12 1600/3904 Training loss: 0.375771
Epoch: 12 2400/3904 Training loss: 0.406168
Epoch: 12 3200/3904 Training loss: 0.427345
Training loss: 0.441671
Test loss: 0.516853; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 13 0/3904 Training loss: 0.553800
Epoch: 13 800/3904 Training loss: 0.453603
Epoch: 13 1600/3904 Training loss: 0.249441
Epoch: 13 2400/3904 Training loss: 0.370073
Epoch: 13 3200/3904 Training loss: 0.526497
Training loss: 0.426841
Test loss: 0.512336; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 14 0/3904 Training loss: 0.551234
Epoch: 14 800/3904 Training loss: 0.475391
Epoch: 14 1600/3904 Training loss: 0.309159
Epoch: 14 2400/3904 Training loss: 0.399253
Epoch: 14 3200/3904 Training loss: 0.408578
Training loss: 0.429277
Test loss: 0.515129; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 15 0/3904 Training loss: 0.549958
Epoch: 15 800/3904 Training loss: 0.435006
Epoch: 15 1600/3904 Training loss: 0.227710
Epoch: 15 2400/3904 Training loss: 0.396919
Epoch: 15 3200/3904 Training loss: 0.505772
Training loss: 0.431366
Test loss: 0.517398; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 16 0/3904 Training loss: 0.364194
Epoch: 16 800/3904 Training loss: 0.382739
Epoch: 16 1600/3904 Training loss: 0.232994
Epoch: 16 2400/3904 Training loss: 0.366136
Epoch: 16 3200/3904 Training loss: 0.497895
Training loss: 0.432945
Test loss: 0.515178; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 17 0/3904 Training loss: 0.449666
Epoch: 17 800/3904 Training loss: 0.438244
Epoch: 17 1600/3904 Training loss: 0.185877
Epoch: 17 2400/3904 Training loss: 0.438442
Epoch: 17 3200/3904 Training loss: 0.446191
Training loss: 0.436659
Test loss: 0.516021; True positive: 835; True negative: 120, False Positive: 145, False negative: 68, accuracy: 0.8176369863013698, precision: 0.8520408163265306, recall: 0.9246954595791805
Epoch: 18 0/3904 Training loss: 0.418098
Epoch: 18 800/3904 Training loss: 0.234907
Epoch: 18 1600/3904 Training loss: 0.275333
Epoch: 18 2400/3904 Training loss: 0.376214
Epoch: 18 3200/3904 Training loss: 0.423338
Training loss: 0.425240
Test loss: 0.513100; True positive: 835; True negative: 120, False Positive: 145, False negative: 68, accuracy: 0.8176369863013698, precision: 0.8520408163265306, recall: 0.9246954595791805
Epoch: 19 0/3904 Training loss: 0.509671
Epoch: 19 800/3904 Training loss: 0.583042
Epoch: 19 1600/3904 Training loss: 0.207891
Epoch: 19 2400/3904 Training loss: 0.485070
Epoch: 19 3200/3904 Training loss: 0.370461
Training loss: 0.424019
Test loss: 0.530835; True positive: 835; True negative: 120, False Positive: 145, False negative: 68, accuracy: 0.8176369863013698, precision: 0.8520408163265306, recall: 0.9246954595791805
starting trial 247
[I 2022-12-05 06:46:00,948] Trial 246 finished with value: 0.8176369863013698 and parameters: {'d_model': 16, 'nhead': 4, 'n_encoders': 3, 'learning_rate': 0.0002795820025802708, 'weight_decay': 2.9976454899256876e-05, 'dropout': 0.2533093275012146, 'max_pool_conv': 128, 'kernel_size': 12, 'd_mlp': 32, 'num_conv_layers': 5, 'encoder_dropout': 0.05307014013563018, 'd_feed_forward': 128, 'max_pool_dim': 16, 'n_mlp_layers': 3}. Best is trial 62 with value: 0.860445205479452.
Epoch: 0 0/3904 Training loss: 0.698695
Epoch: 0 800/3904 Training loss: 0.690966
Epoch: 0 1600/3904 Training loss: 0.366119
Epoch: 0 2400/3904 Training loss: 0.735940
Epoch: 0 3200/3904 Training loss: 0.528904
Training loss: 0.661553
Test loss: 0.661575; True positive: 898; True negative: 5, False Positive: 260, False negative: 5, accuracy: 0.7731164383561644, precision: 0.7754749568221071, recall: 0.9944629014396457
Epoch: 1 0/3904 Training loss: 0.665380
Epoch: 1 800/3904 Training loss: 0.798997
Epoch: 1 1600/3904 Training loss: 0.287685
Epoch: 1 2400/3904 Training loss: 0.554256
Epoch: 1 3200/3904 Training loss: 0.417540
Training loss: 0.537772
Test loss: 0.624237; True positive: 813; True negative: 124, False Positive: 141, False negative: 90, accuracy: 0.8022260273972602, precision: 0.8522012578616353, recall: 0.9003322259136213
Epoch: 2 0/3904 Training loss: 0.412001
Epoch: 2 800/3904 Training loss: 0.421943
Epoch: 2 1600/3904 Training loss: 0.211727
Epoch: 2 2400/3904 Training loss: 0.384327
Epoch: 2 3200/3904 Training loss: 0.394245
Training loss: 0.421504
Test loss: 1.442717; True positive: 5; True negative: 265, False Positive: 0, False negative: 898, accuracy: 0.23116438356164384, precision: 1.0, recall: 0.005537098560354375
Epoch: 3 0/3904 Training loss: 0.306042
Epoch: 3 800/3904 Training loss: 0.539206
Epoch: 3 1600/3904 Training loss: 0.218470
Epoch: 3 2400/3904 Training loss: 0.431987
Epoch: 3 3200/3904 Training loss: 0.460835
Training loss: 0.373969
Test loss: 0.763350; True positive: 374; True negative: 257, False Positive: 8, False negative: 529, accuracy: 0.5402397260273972, precision: 0.9790575916230366, recall: 0.4141749723145072
Epoch: 4 0/3904 Training loss: 0.275142
Epoch: 4 800/3904 Training loss: 0.295956
Epoch: 4 1600/3904 Training loss: 0.193649
Epoch: 4 2400/3904 Training loss: 0.405962
Epoch: 4 3200/3904 Training loss: 0.418139
Training loss: 0.334497
Test loss: 0.862368; True positive: 122; True negative: 246, False Positive: 19, False negative: 781, accuracy: 0.3150684931506849, precision: 0.8652482269503546, recall: 0.13510520487264674
Epoch: 5 0/3904 Training loss: 0.180364
Epoch: 5 800/3904 Training loss: 0.435926
Epoch: 5 1600/3904 Training loss: 0.215976
Epoch: 5 2400/3904 Training loss: 0.484250
Epoch: 5 3200/3904 Training loss: 0.436829
Training loss: 0.308506
Test loss: 1.371564; True positive: 5; True negative: 265, False Positive: 0, False negative: 898, accuracy: 0.23116438356164384, precision: 1.0, recall: 0.005537098560354375
Epoch: 6 0/3904 Training loss: 0.210437
Epoch: 6 800/3904 Training loss: 0.309269
Epoch: 6 1600/3904 Training loss: 0.262236
Epoch: 6 2400/3904 Training loss: 0.281341
Epoch: 6 3200/3904 Training loss: 0.409686
Training loss: 0.273519
Test loss: 1.196564; True positive: 1; True negative: 265, False Positive: 0, False negative: 902, accuracy: 0.22773972602739725, precision: 1.0, recall: 0.0011074197120708748
Epoch: 7 0/3904 Training loss: 0.138487
Epoch: 7 800/3904 Training loss: 0.226357
Epoch: 7 1600/3904 Training loss: 0.123948
Epoch: 7 2400/3904 Training loss: 0.277756
Epoch: 7 3200/3904 Training loss: 0.280933
Training loss: 0.247949
Test loss: 1.334475; True positive: 5; True negative: 265, False Positive: 0, False negative: 898, accuracy: 0.23116438356164384, precision: 1.0, recall: 0.005537098560354375
Epoch: 8 0/3904 Training loss: 0.180673
Epoch: 8 800/3904 Training loss: 0.190047
Epoch: 8 1600/3904 Training loss: 0.233677
Epoch: 8 2400/3904 Training loss: 0.241028
Epoch: 8 3200/3904 Training loss: 0.259245
Training loss: 0.231643
Test loss: 1.630701; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 9 0/3904 Training loss: 0.116401
Epoch: 9 800/3904 Training loss: 0.297508
Epoch: 9 1600/3904 Training loss: 0.098035
Epoch: 9 2400/3904 Training loss: 0.222001
Epoch: 9 3200/3904 Training loss: 0.318290
Training loss: 0.217229
Test loss: 3.305617; True positive: 5; True negative: 265, False Positive: 0, False negative: 898, accuracy: 0.23116438356164384, precision: 1.0, recall: 0.005537098560354375
Epoch: 10 0/3904 Training loss: 0.091000
Epoch: 10 800/3904 Training loss: 0.170481
Epoch: 10 1600/3904 Training loss: 0.138169
Epoch: 10 2400/3904 Training loss: 0.325017
Epoch: 10 3200/3904 Training loss: 0.195910
Training loss: 0.208863
Test loss: 4.973709; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 11 0/3904 Training loss: 0.186343
Epoch: 11 800/3904 Training loss: 0.142931
Epoch: 11 1600/3904 Training loss: 0.113149
Epoch: 11 2400/3904 Training loss: 0.219945
Epoch: 11 3200/3904 Training loss: 0.291956
Training loss: 0.193884
Test loss: 4.727500; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
starting trial 248
[I 2022-12-05 06:47:00,878] Trial 247 finished with value: 0.8022260273972602 and parameters: {'d_model': 64, 'nhead': 8, 'n_encoders': 1, 'learning_rate': 0.0004594548799007081, 'weight_decay': 2.7503722833522415e-06, 'dropout': 0.16350413720068588, 'max_pool_conv': 16, 'kernel_size': 16, 'd_mlp': 62, 'num_conv_layers': 2, 'encoder_dropout': 0.026725719153546636, 'd_feed_forward': 256, 'max_pool_dim': 8, 'n_mlp_layers': 3}. Best is trial 62 with value: 0.860445205479452.
Epoch: 0 0/3904 Training loss: 0.700640
Epoch: 0 800/3904 Training loss: 0.727671
Epoch: 0 1600/3904 Training loss: 0.511598
Epoch: 0 2400/3904 Training loss: 0.800488
Epoch: 0 3200/3904 Training loss: 0.563355
Training loss: 0.661799
Test loss: 0.799599; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 1 0/3904 Training loss: 0.720660
Epoch: 1 800/3904 Training loss: 0.729446
Epoch: 1 1600/3904 Training loss: 0.392006
Epoch: 1 2400/3904 Training loss: 0.806154
Epoch: 1 3200/3904 Training loss: 0.474098
Training loss: 0.639131
Test loss: 1.069351; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 2 0/3904 Training loss: 0.668063
Epoch: 2 800/3904 Training loss: 0.588779
Epoch: 2 1600/3904 Training loss: 0.259172
Epoch: 2 2400/3904 Training loss: 0.628861
Epoch: 2 3200/3904 Training loss: 0.425085
Training loss: 0.568594
Test loss: 1.304527; True positive: 65; True negative: 148, False Positive: 117, False negative: 838, accuracy: 0.18236301369863014, precision: 0.35714285714285715, recall: 0.07198228128460686
Epoch: 3 0/3904 Training loss: 0.662506
Epoch: 3 800/3904 Training loss: 0.605673
Epoch: 3 1600/3904 Training loss: 0.381180
Epoch: 3 2400/3904 Training loss: 0.650623
Epoch: 3 3200/3904 Training loss: 0.540194
Training loss: 0.525198
Test loss: 1.447381; True positive: 65; True negative: 148, False Positive: 117, False negative: 838, accuracy: 0.18236301369863014, precision: 0.35714285714285715, recall: 0.07198228128460686
Epoch: 4 0/3904 Training loss: 0.454132
Epoch: 4 800/3904 Training loss: 0.507062
Epoch: 4 1600/3904 Training loss: 0.213518
Epoch: 4 2400/3904 Training loss: 0.578124
Epoch: 4 3200/3904 Training loss: 0.523957
Training loss: 0.494037
Test loss: 1.613308; True positive: 65; True negative: 148, False Positive: 117, False negative: 838, accuracy: 0.18236301369863014, precision: 0.35714285714285715, recall: 0.07198228128460686
Epoch: 5 0/3904 Training loss: 0.455539
Epoch: 5 800/3904 Training loss: 0.464985
Epoch: 5 1600/3904 Training loss: 0.305973
Epoch: 5 2400/3904 Training loss: 0.731341
Epoch: 5 3200/3904 Training loss: 0.565371
Training loss: 0.464128
Test loss: 1.711048; True positive: 65; True negative: 148, False Positive: 117, False negative: 838, accuracy: 0.18236301369863014, precision: 0.35714285714285715, recall: 0.07198228128460686
Epoch: 6 0/3904 Training loss: 0.529499
Epoch: 6 800/3904 Training loss: 0.437595
Epoch: 6 1600/3904 Training loss: 0.228171
Epoch: 6 2400/3904 Training loss: 0.705848
Epoch: 6 3200/3904 Training loss: 0.453518
Training loss: 0.446842
Test loss: 1.739004; True positive: 151; True negative: 116, False Positive: 149, False negative: 752, accuracy: 0.2285958904109589, precision: 0.5033333333333333, recall: 0.1672203765227021
Epoch: 7 0/3904 Training loss: 0.528207
Epoch: 7 800/3904 Training loss: 0.366893
Epoch: 7 1600/3904 Training loss: 0.228833
Epoch: 7 2400/3904 Training loss: 0.812682
Epoch: 7 3200/3904 Training loss: 0.600209
Training loss: 0.424709
Test loss: 1.902843; True positive: 65; True negative: 148, False Positive: 117, False negative: 838, accuracy: 0.18236301369863014, precision: 0.35714285714285715, recall: 0.07198228128460686
Epoch: 8 0/3904 Training loss: 0.357366
Epoch: 8 800/3904 Training loss: 0.477956
Epoch: 8 1600/3904 Training loss: 0.152105
Epoch: 8 2400/3904 Training loss: 0.599894
Epoch: 8 3200/3904 Training loss: 0.570780
Training loss: 0.409988
Test loss: 2.295173; True positive: 65; True negative: 148, False Positive: 117, False negative: 838, accuracy: 0.18236301369863014, precision: 0.35714285714285715, recall: 0.07198228128460686
Epoch: 9 0/3904 Training loss: 0.490275
Epoch: 9 800/3904 Training loss: 0.361216
Epoch: 9 1600/3904 Training loss: 0.190183
Epoch: 9 2400/3904 Training loss: 0.479861
Epoch: 9 3200/3904 Training loss: 0.461888
Training loss: 0.386455
Test loss: 2.077258; True positive: 65; True negative: 148, False Positive: 117, False negative: 838, accuracy: 0.18236301369863014, precision: 0.35714285714285715, recall: 0.07198228128460686
Epoch: 10 0/3904 Training loss: 0.686316
Epoch: 10 800/3904 Training loss: 0.292195
Epoch: 10 1600/3904 Training loss: 0.118291
Epoch: 10 2400/3904 Training loss: 0.462083
Epoch: 10 3200/3904 Training loss: 0.522240
Training loss: 0.373487
Test loss: 0.946537; True positive: 504; True negative: 69, False Positive: 196, False negative: 399, accuracy: 0.4905821917808219, precision: 0.72, recall: 0.5581395348837209
starting trial 249
[I 2022-12-05 06:47:45,040] Trial 248 finished with value: 0.4905821917808219 and parameters: {'d_model': 16, 'nhead': 4, 'n_encoders': 3, 'learning_rate': 0.0003391806845063663, 'weight_decay': 5.970206322432177e-06, 'dropout': 0.23331372262065184, 'max_pool_conv': 128, 'kernel_size': 13, 'd_mlp': 32, 'num_conv_layers': 3, 'encoder_dropout': 0.08714658590105169, 'd_feed_forward': 128, 'max_pool_dim': 16, 'n_mlp_layers': 3}. Best is trial 62 with value: 0.860445205479452.
Epoch: 0 0/3904 Training loss: 0.696999
Epoch: 0 800/3904 Training loss: 0.710344
Epoch: 0 1600/3904 Training loss: 0.492466
Epoch: 0 2400/3904 Training loss: 0.776195
Epoch: 0 3200/3904 Training loss: 0.557483
Training loss: 0.665794
Test loss: 0.834958; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 1 0/3904 Training loss: 0.711680
Epoch: 1 800/3904 Training loss: 0.730649
Epoch: 1 1600/3904 Training loss: 0.413698
Epoch: 1 2400/3904 Training loss: 0.880773
Epoch: 1 3200/3904 Training loss: 0.457804
Training loss: 0.618927
Test loss: 0.625028; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 2 0/3904 Training loss: 0.556267
Epoch: 2 800/3904 Training loss: 0.535322
Epoch: 2 1600/3904 Training loss: 0.257941
Epoch: 2 2400/3904 Training loss: 0.654243
Epoch: 2 3200/3904 Training loss: 0.379532
Training loss: 0.513215
Test loss: 0.510118; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 3 0/3904 Training loss: 0.404073
Epoch: 3 800/3904 Training loss: 0.498140
Epoch: 3 1600/3904 Training loss: 0.249234
Epoch: 3 2400/3904 Training loss: 0.478979
Epoch: 3 3200/3904 Training loss: 0.379738
Training loss: 0.460883
Test loss: 0.516203; True positive: 827; True negative: 117, False Positive: 148, False negative: 76, accuracy: 0.8082191780821918, precision: 0.8482051282051282, recall: 0.9158361018826136
Epoch: 4 0/3904 Training loss: 0.381463
Epoch: 4 800/3904 Training loss: 0.443731
Epoch: 4 1600/3904 Training loss: 0.179274
Epoch: 4 2400/3904 Training loss: 0.499515
Epoch: 4 3200/3904 Training loss: 0.337129
Training loss: 0.437570
Test loss: 1.672925; True positive: 59; True negative: 252, False Positive: 13, False negative: 844, accuracy: 0.2662671232876712, precision: 0.8194444444444444, recall: 0.06533776301218161
Epoch: 5 0/3904 Training loss: 0.329554
Epoch: 5 800/3904 Training loss: 0.449159
Epoch: 5 1600/3904 Training loss: 0.184779
Epoch: 5 2400/3904 Training loss: 0.281569
Epoch: 5 3200/3904 Training loss: 0.391451
Training loss: 0.425019
Test loss: 2.285865; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 6 0/3904 Training loss: 0.384955
Epoch: 6 800/3904 Training loss: 0.492936
Epoch: 6 1600/3904 Training loss: 0.174710
Epoch: 6 2400/3904 Training loss: 0.272446
Epoch: 6 3200/3904 Training loss: 0.354969
Training loss: 0.411882
Test loss: 2.020185; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 7 0/3904 Training loss: 0.358294
Epoch: 7 800/3904 Training loss: 0.401171
Epoch: 7 1600/3904 Training loss: 0.138437
Epoch: 7 2400/3904 Training loss: 0.265018
Epoch: 7 3200/3904 Training loss: 0.326273
Training loss: 0.399406
Test loss: 2.112573; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 8 0/3904 Training loss: 0.374502
Epoch: 8 800/3904 Training loss: 0.427412
Epoch: 8 1600/3904 Training loss: 0.137688
Epoch: 8 2400/3904 Training loss: 0.224399
Epoch: 8 3200/3904 Training loss: 0.356464
Training loss: 0.386926
Test loss: 2.060019; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 9 0/3904 Training loss: 0.486786
Epoch: 9 800/3904 Training loss: 0.400527
Epoch: 9 1600/3904 Training loss: 0.129147
Epoch: 9 2400/3904 Training loss: 0.254288
Epoch: 9 3200/3904 Training loss: 0.329245
Training loss: 0.390283
Test loss: 2.088964; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 10 0/3904 Training loss: 0.411054
Epoch: 10 800/3904 Training loss: 0.521516
Epoch: 10 1600/3904 Training loss: 0.141811
Epoch: 10 2400/3904 Training loss: 0.241480
Epoch: 10 3200/3904 Training loss: 0.377588
Training loss: 0.370598
Test loss: 2.006742; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 11 0/3904 Training loss: 0.411766
Epoch: 11 800/3904 Training loss: 0.347533
Epoch: 11 1600/3904 Training loss: 0.161700
Epoch: 11 2400/3904 Training loss: 0.255652
Epoch: 11 3200/3904 Training loss: 0.389400
Training loss: 0.363944
Test loss: 2.094067; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 12 0/3904 Training loss: 0.315348
Epoch: 12 800/3904 Training loss: 0.410252
Epoch: 12 1600/3904 Training loss: 0.150104
Epoch: 12 2400/3904 Training loss: 0.232828
Epoch: 12 3200/3904 Training loss: 0.343414
Training loss: 0.361530
Test loss: 2.140075; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
starting trial 250
[I 2022-12-05 06:49:24,746] Trial 249 finished with value: 0.8176369863013698 and parameters: {'d_model': 64, 'nhead': 8, 'n_encoders': 1, 'learning_rate': 0.000133902441385549, 'weight_decay': 2.4791857890189603e-06, 'dropout': 0.13143062852449794, 'max_pool_conv': 64, 'kernel_size': 7, 'd_mlp': 16, 'num_conv_layers': 7, 'encoder_dropout': 0.043003409925205544, 'd_feed_forward': 512, 'max_pool_dim': 8, 'n_mlp_layers': 3}. Best is trial 62 with value: 0.860445205479452.
Epoch: 0 0/3904 Training loss: 0.705347
Epoch: 0 800/3904 Training loss: 0.700802
Epoch: 0 1600/3904 Training loss: 0.530325
Epoch: 0 2400/3904 Training loss: 0.737201
Epoch: 0 3200/3904 Training loss: 0.546024
Training loss: 0.666032
Test loss: 0.726814; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 1 0/3904 Training loss: 0.695091
Epoch: 1 800/3904 Training loss: 0.690974
Epoch: 1 1600/3904 Training loss: 0.417636
Epoch: 1 2400/3904 Training loss: 0.642685
Epoch: 1 3200/3904 Training loss: 0.479441
Training loss: 0.605944
Test loss: 0.644887; True positive: 903; True negative: 12, False Positive: 253, False negative: 0, accuracy: 0.7833904109589042, precision: 0.7811418685121108, recall: 1.0
Epoch: 2 0/3904 Training loss: 0.601524
Epoch: 2 800/3904 Training loss: 0.520262
Epoch: 2 1600/3904 Training loss: 0.321025
Epoch: 2 2400/3904 Training loss: 0.458433
Epoch: 2 3200/3904 Training loss: 0.355548
Training loss: 0.531291
Test loss: 0.536183; True positive: 835; True negative: 117, False Positive: 148, False negative: 68, accuracy: 0.815068493150685, precision: 0.8494404883011191, recall: 0.9246954595791805
Epoch: 3 0/3904 Training loss: 0.606057
Epoch: 3 800/3904 Training loss: 0.369617
Epoch: 3 1600/3904 Training loss: 0.301927
Epoch: 3 2400/3904 Training loss: 0.606562
Epoch: 3 3200/3904 Training loss: 0.387127
Training loss: 0.498798
Test loss: 1.912889; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 4 0/3904 Training loss: 0.605023
Epoch: 4 800/3904 Training loss: 0.340150
Epoch: 4 1600/3904 Training loss: 0.225551
Epoch: 4 2400/3904 Training loss: 0.441578
Epoch: 4 3200/3904 Training loss: 0.505816
Training loss: 0.464667
Test loss: 1.015128; True positive: 403; True negative: 181, False Positive: 84, False negative: 500, accuracy: 0.5, precision: 0.8275154004106776, recall: 0.44629014396456257
Epoch: 5 0/3904 Training loss: 0.519766
Epoch: 5 800/3904 Training loss: 0.405489
Epoch: 5 1600/3904 Training loss: 0.137280
Epoch: 5 2400/3904 Training loss: 0.398091
Epoch: 5 3200/3904 Training loss: 0.416176
Training loss: 0.455432
Test loss: 1.173023; True positive: 464; True negative: 159, False Positive: 106, False negative: 439, accuracy: 0.5333904109589042, precision: 0.8140350877192982, recall: 0.5138427464008859
Epoch: 6 0/3904 Training loss: 0.353695
Epoch: 6 800/3904 Training loss: 0.283545
Epoch: 6 1600/3904 Training loss: 0.154410
Epoch: 6 2400/3904 Training loss: 0.313260
Epoch: 6 3200/3904 Training loss: 0.387875
Training loss: 0.451689
Test loss: 2.221856; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 7 0/3904 Training loss: 0.418811
Epoch: 7 800/3904 Training loss: 0.378485
Epoch: 7 1600/3904 Training loss: 0.137756
Epoch: 7 2400/3904 Training loss: 0.297352
Epoch: 7 3200/3904 Training loss: 0.558613
Training loss: 0.450895
Test loss: 1.376177; True positive: 316; True negative: 184, False Positive: 81, False negative: 587, accuracy: 0.4280821917808219, precision: 0.7959697732997482, recall: 0.34994462901439644
Epoch: 8 0/3904 Training loss: 0.440142
Epoch: 8 800/3904 Training loss: 0.248893
Epoch: 8 1600/3904 Training loss: 0.134616
Epoch: 8 2400/3904 Training loss: 0.270259
Epoch: 8 3200/3904 Training loss: 0.405952
Training loss: 0.438728
Test loss: 0.741383; True positive: 635; True negative: 172, False Positive: 93, False negative: 268, accuracy: 0.6909246575342466, precision: 0.8722527472527473, recall: 0.7032115171650055
Epoch: 9 0/3904 Training loss: 0.370723
Epoch: 9 800/3904 Training loss: 0.252909
Epoch: 9 1600/3904 Training loss: 0.193265
Epoch: 9 2400/3904 Training loss: 0.279018
Epoch: 9 3200/3904 Training loss: 0.430118
Training loss: 0.436514
Test loss: 2.347224; True positive: 28; True negative: 265, False Positive: 0, False negative: 875, accuracy: 0.2508561643835616, precision: 1.0, recall: 0.031007751937984496
Epoch: 10 0/3904 Training loss: 0.371138
Epoch: 10 800/3904 Training loss: 0.269609
Epoch: 10 1600/3904 Training loss: 0.136363
Epoch: 10 2400/3904 Training loss: 0.307423
Epoch: 10 3200/3904 Training loss: 0.421849
Training loss: 0.430639
Test loss: 2.461787; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 11 0/3904 Training loss: 0.451749
Epoch: 11 800/3904 Training loss: 0.237104
Epoch: 11 1600/3904 Training loss: 0.175915
Epoch: 11 2400/3904 Training loss: 0.255600
Epoch: 11 3200/3904 Training loss: 0.511398
Training loss: 0.424579
Test loss: 2.442813; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 12 0/3904 Training loss: 0.451055
Epoch: 12 800/3904 Training loss: 0.212641
Epoch: 12 1600/3904 Training loss: 0.160670
Epoch: 12 2400/3904 Training loss: 0.215781
Epoch: 12 3200/3904 Training loss: 0.418671
Training loss: 0.424028
Test loss: 2.656401; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
starting trial 251
[I 2022-12-05 06:50:28,849] Trial 250 finished with value: 0.815068493150685 and parameters: {'d_model': 16, 'nhead': 4, 'n_encoders': 3, 'learning_rate': 0.00024053176504593043, 'weight_decay': 6.556540849420945e-06, 'dropout': 0.2653479745157583, 'max_pool_conv': 128, 'kernel_size': 24, 'd_mlp': 32, 'num_conv_layers': 6, 'encoder_dropout': 0.00030489340908444653, 'd_feed_forward': 128, 'max_pool_dim': 16, 'n_mlp_layers': 3}. Best is trial 62 with value: 0.860445205479452.
Epoch: 0 0/3904 Training loss: 0.695395
Epoch: 0 800/3904 Training loss: 0.705505
Epoch: 0 1600/3904 Training loss: 0.515833
Epoch: 0 2400/3904 Training loss: 0.759184
Epoch: 0 3200/3904 Training loss: 0.564017
Training loss: 0.666845
Test loss: 0.791344; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 1 0/3904 Training loss: 0.698801
Epoch: 1 800/3904 Training loss: 0.722532
Epoch: 1 1600/3904 Training loss: 0.382953
Epoch: 1 2400/3904 Training loss: 0.724631
Epoch: 1 3200/3904 Training loss: 0.456761
Training loss: 0.608048
Test loss: 0.611822; True positive: 903; True negative: 0, False Positive: 265, False negative: 0, accuracy: 0.7731164383561644, precision: 0.7731164383561644, recall: 1.0
Epoch: 2 0/3904 Training loss: 0.603183
Epoch: 2 800/3904 Training loss: 0.458316
Epoch: 2 1600/3904 Training loss: 0.250559
Epoch: 2 2400/3904 Training loss: 0.503984
Epoch: 2 3200/3904 Training loss: 0.394463
Training loss: 0.485511
Test loss: 1.838934; True positive: 72; True negative: 265, False Positive: 0, False negative: 831, accuracy: 0.288527397260274, precision: 1.0, recall: 0.07973421926910298
Epoch: 3 0/3904 Training loss: 0.339680
Epoch: 3 800/3904 Training loss: 0.332634
Epoch: 3 1600/3904 Training loss: 0.232994
Epoch: 3 2400/3904 Training loss: 0.413279
Epoch: 3 3200/3904 Training loss: 0.351947
Training loss: 0.428402
Test loss: 0.520001; True positive: 837; True negative: 124, False Positive: 141, False negative: 66, accuracy: 0.8227739726027398, precision: 0.8558282208588958, recall: 0.9269102990033222
Epoch: 4 0/3904 Training loss: 0.320058
Epoch: 4 800/3904 Training loss: 0.276385
Epoch: 4 1600/3904 Training loss: 0.203800
Epoch: 4 2400/3904 Training loss: 0.287643
Epoch: 4 3200/3904 Training loss: 0.428202
Training loss: 0.391598
Test loss: 1.895457; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 5 0/3904 Training loss: 0.349642
Epoch: 5 800/3904 Training loss: 0.225513
Epoch: 5 1600/3904 Training loss: 0.213199
Epoch: 5 2400/3904 Training loss: 0.362744
Epoch: 5 3200/3904 Training loss: 0.431312
Training loss: 0.368385
Test loss: 1.837548; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 6 0/3904 Training loss: 0.313377
Epoch: 6 800/3904 Training loss: 0.231156
Epoch: 6 1600/3904 Training loss: 0.212143
Epoch: 6 2400/3904 Training loss: 0.304035
Epoch: 6 3200/3904 Training loss: 0.361002
Training loss: 0.358101
Test loss: 2.021086; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 7 0/3904 Training loss: 0.405504
Epoch: 7 800/3904 Training loss: 0.407504
Epoch: 7 1600/3904 Training loss: 0.166607
Epoch: 7 2400/3904 Training loss: 0.303684
Epoch: 7 3200/3904 Training loss: 0.400722
Training loss: 0.340425
Test loss: 1.929602; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 8 0/3904 Training loss: 0.359479
Epoch: 8 800/3904 Training loss: 0.165726
Epoch: 8 1600/3904 Training loss: 0.177483
Epoch: 8 2400/3904 Training loss: 0.193249
Epoch: 8 3200/3904 Training loss: 0.546277
Training loss: 0.334153
Test loss: 1.997919; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 9 0/3904 Training loss: 0.350700
Epoch: 9 800/3904 Training loss: 0.210563
Epoch: 9 1600/3904 Training loss: 0.227820
Epoch: 9 2400/3904 Training loss: 0.182662
Epoch: 9 3200/3904 Training loss: 0.556762
Training loss: 0.318393
Test loss: 2.180438; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 10 0/3904 Training loss: 0.318245
Epoch: 10 800/3904 Training loss: 0.139139
Epoch: 10 1600/3904 Training loss: 0.238568
Epoch: 10 2400/3904 Training loss: 0.192404
Epoch: 10 3200/3904 Training loss: 0.377115
Training loss: 0.312749
Test loss: 2.215024; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 11 0/3904 Training loss: 0.300913
Epoch: 11 800/3904 Training loss: 0.153365
Epoch: 11 1600/3904 Training loss: 0.119072
Epoch: 11 2400/3904 Training loss: 0.172249
Epoch: 11 3200/3904 Training loss: 0.444730
Training loss: 0.284391
Test loss: 2.373114; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 12 0/3904 Training loss: 0.307236
Epoch: 12 800/3904 Training loss: 0.197260
Epoch: 12 1600/3904 Training loss: 0.142101
Epoch: 12 2400/3904 Training loss: 0.227340
Epoch: 12 3200/3904 Training loss: 0.402409
Training loss: 0.286259
Test loss: 2.430895; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 13 0/3904 Training loss: 0.306636
Epoch: 13 800/3904 Training loss: 0.262276
Epoch: 13 1600/3904 Training loss: 0.109892
Epoch: 13 2400/3904 Training loss: 0.172954
Epoch: 13 3200/3904 Training loss: 0.342735
Training loss: 0.276166
Test loss: 3.308510; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
starting trial 252
[I 2022-12-05 06:53:11,683] Trial 251 finished with value: 0.8227739726027398 and parameters: {'d_model': 64, 'nhead': 8, 'n_encoders': 1, 'learning_rate': 0.00010969249553503265, 'weight_decay': 3.941604265136989e-06, 'dropout': 0.14668887465609062, 'max_pool_conv': 32, 'kernel_size': 18, 'd_mlp': 16, 'num_conv_layers': 5, 'encoder_dropout': 0.12580618885442071, 'd_feed_forward': 128, 'max_pool_dim': 8, 'n_mlp_layers': 3}. Best is trial 62 with value: 0.860445205479452.
Epoch: 0 0/3904 Training loss: 0.701545
Epoch: 0 800/3904 Training loss: 0.719310
Epoch: 0 1600/3904 Training loss: 0.464344
Epoch: 0 2400/3904 Training loss: 0.761730
Epoch: 0 3200/3904 Training loss: 0.537556
Training loss: 0.659323
Test loss: 0.772516; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 1 0/3904 Training loss: 0.692610
Epoch: 1 800/3904 Training loss: 0.664998
Epoch: 1 1600/3904 Training loss: 0.332397
Epoch: 1 2400/3904 Training loss: 0.747276
Epoch: 1 3200/3904 Training loss: 0.385795
Training loss: 0.572508
Test loss: 0.651125; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 2 0/3904 Training loss: 0.598561
Epoch: 2 800/3904 Training loss: 0.527996
Epoch: 2 1600/3904 Training loss: 0.220834
Epoch: 2 2400/3904 Training loss: 0.678538
Epoch: 2 3200/3904 Training loss: 0.444576
Training loss: 0.491869
Test loss: 1.150865; True positive: 155; True negative: 253, False Positive: 12, False negative: 748, accuracy: 0.3493150684931507, precision: 0.9281437125748503, recall: 0.1716500553709856
Epoch: 3 0/3904 Training loss: 0.528282
Epoch: 3 800/3904 Training loss: 0.517909
Epoch: 3 1600/3904 Training loss: 0.201642
Epoch: 3 2400/3904 Training loss: 0.562361
Epoch: 3 3200/3904 Training loss: 0.403052
Training loss: 0.452188
Test loss: 0.651323; True positive: 837; True negative: 117, False Positive: 148, False negative: 66, accuracy: 0.8167808219178082, precision: 0.849746192893401, recall: 0.9269102990033222
Epoch: 4 0/3904 Training loss: 0.422208
Epoch: 4 800/3904 Training loss: 0.439368
Epoch: 4 1600/3904 Training loss: 0.201021
Epoch: 4 2400/3904 Training loss: 0.486324
Epoch: 4 3200/3904 Training loss: 0.352484
Training loss: 0.420348
Test loss: 0.659028; True positive: 755; True negative: 130, False Positive: 135, False negative: 148, accuracy: 0.7577054794520548, precision: 0.848314606741573, recall: 0.8361018826135105
Epoch: 5 0/3904 Training loss: 0.384727
Epoch: 5 800/3904 Training loss: 0.491170
Epoch: 5 1600/3904 Training loss: 0.210646
Epoch: 5 2400/3904 Training loss: 0.397350
Epoch: 5 3200/3904 Training loss: 0.344866
Training loss: 0.401681
Test loss: 3.241264; True positive: 0; True negative: 264, False Positive: 1, False negative: 903, accuracy: 0.22602739726027396, precision: 0.0, recall: 0.0
Epoch: 6 0/3904 Training loss: 0.371225
Epoch: 6 800/3904 Training loss: 0.440192
Epoch: 6 1600/3904 Training loss: 0.182653
Epoch: 6 2400/3904 Training loss: 0.380439
Epoch: 6 3200/3904 Training loss: 0.314096
Training loss: 0.384388
Test loss: 2.960804; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 7 0/3904 Training loss: 0.397711
Epoch: 7 800/3904 Training loss: 0.515594
Epoch: 7 1600/3904 Training loss: 0.176572
Epoch: 7 2400/3904 Training loss: 0.309772
Epoch: 7 3200/3904 Training loss: 0.297419
Training loss: 0.375907
Test loss: 2.007359; True positive: 150; True negative: 209, False Positive: 56, False negative: 753, accuracy: 0.3073630136986301, precision: 0.7281553398058253, recall: 0.16611295681063123
Epoch: 8 0/3904 Training loss: 0.383759
Epoch: 8 800/3904 Training loss: 0.418024
Epoch: 8 1600/3904 Training loss: 0.195616
Epoch: 8 2400/3904 Training loss: 0.276404
Epoch: 8 3200/3904 Training loss: 0.341777
Training loss: 0.365137
Test loss: 1.041995; True positive: 501; True negative: 166, False Positive: 99, False negative: 402, accuracy: 0.5710616438356164, precision: 0.835, recall: 0.5548172757475083
Epoch: 9 0/3904 Training loss: 0.334732
Epoch: 9 800/3904 Training loss: 0.515458
Epoch: 9 1600/3904 Training loss: 0.178376
Epoch: 9 2400/3904 Training loss: 0.270607
Epoch: 9 3200/3904 Training loss: 0.378682
Training loss: 0.363024
Test loss: 2.083015; True positive: 238; True negative: 171, False Positive: 94, False negative: 665, accuracy: 0.3501712328767123, precision: 0.7168674698795181, recall: 0.26356589147286824
Epoch: 10 0/3904 Training loss: 0.328365
Epoch: 10 800/3904 Training loss: 0.291831
Epoch: 10 1600/3904 Training loss: 0.177322
Epoch: 10 2400/3904 Training loss: 0.271249
Epoch: 10 3200/3904 Training loss: 0.407497
Training loss: 0.350594
Test loss: 0.655510; True positive: 759; True negative: 129, False Positive: 136, False negative: 144, accuracy: 0.7602739726027398, precision: 0.8480446927374302, recall: 0.840531561461794
Epoch: 11 0/3904 Training loss: 0.246735
Epoch: 11 800/3904 Training loss: 0.423019
Epoch: 11 1600/3904 Training loss: 0.176041
Epoch: 11 2400/3904 Training loss: 0.374680
Epoch: 11 3200/3904 Training loss: 0.404845
Training loss: 0.339795
Test loss: 3.422698; True positive: 48; True negative: 263, False Positive: 2, False negative: 855, accuracy: 0.2662671232876712, precision: 0.96, recall: 0.053156146179401995
starting trial 253
[I 2022-12-05 06:55:31,049] Trial 252 finished with value: 0.8176369863013698 and parameters: {'d_model': 64, 'nhead': 8, 'n_encoders': 1, 'learning_rate': 0.00010397956699250658, 'weight_decay': 4.634758129988875e-06, 'dropout': 0.14766105001452856, 'max_pool_conv': 32, 'kernel_size': 18, 'd_mlp': 16, 'num_conv_layers': 5, 'encoder_dropout': 0.12864713711518452, 'd_feed_forward': 128, 'max_pool_dim': 8, 'n_mlp_layers': 3}. Best is trial 62 with value: 0.860445205479452.
Epoch: 0 0/3904 Training loss: 0.694013
Epoch: 0 800/3904 Training loss: 0.703564
Epoch: 0 1600/3904 Training loss: 0.536248
Epoch: 0 2400/3904 Training loss: 0.785706
Epoch: 0 3200/3904 Training loss: 0.563873
Training loss: 0.667717
Test loss: 0.843339; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 1 0/3904 Training loss: 0.719808
Epoch: 1 800/3904 Training loss: 0.730553
Epoch: 1 1600/3904 Training loss: 0.450516
Epoch: 1 2400/3904 Training loss: 0.664508
Epoch: 1 3200/3904 Training loss: 0.474075
Training loss: 0.618205
Test loss: 0.655605; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 2 0/3904 Training loss: 0.608133
Epoch: 2 800/3904 Training loss: 0.522072
Epoch: 2 1600/3904 Training loss: 0.262068
Epoch: 2 2400/3904 Training loss: 0.579219
Epoch: 2 3200/3904 Training loss: 0.420459
Training loss: 0.509379
Test loss: 0.666443; True positive: 739; True negative: 144, False Positive: 121, False negative: 164, accuracy: 0.7559931506849316, precision: 0.8593023255813953, recall: 0.8183831672203765
Epoch: 3 0/3904 Training loss: 0.489824
Epoch: 3 800/3904 Training loss: 0.595153
Epoch: 3 1600/3904 Training loss: 0.241305
Epoch: 3 2400/3904 Training loss: 0.487270
Epoch: 3 3200/3904 Training loss: 0.395623
Training loss: 0.453473
Test loss: 2.034204; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 4 0/3904 Training loss: 0.460041
Epoch: 4 800/3904 Training loss: 0.398152
Epoch: 4 1600/3904 Training loss: 0.164258
Epoch: 4 2400/3904 Training loss: 0.388006
Epoch: 4 3200/3904 Training loss: 0.374430
Training loss: 0.417885
Test loss: 1.744359; True positive: 256; True negative: 188, False Positive: 77, False negative: 647, accuracy: 0.3801369863013699, precision: 0.7687687687687688, recall: 0.28349944629014395
Epoch: 5 0/3904 Training loss: 0.420385
Epoch: 5 800/3904 Training loss: 0.303321
Epoch: 5 1600/3904 Training loss: 0.170626
Epoch: 5 2400/3904 Training loss: 0.366313
Epoch: 5 3200/3904 Training loss: 0.337678
Training loss: 0.391054
Test loss: 2.220482; True positive: 111; True negative: 210, False Positive: 55, False negative: 792, accuracy: 0.2748287671232877, precision: 0.6686746987951807, recall: 0.12292358803986711
Epoch: 6 0/3904 Training loss: 0.380648
Epoch: 6 800/3904 Training loss: 0.233318
Epoch: 6 1600/3904 Training loss: 0.156922
Epoch: 6 2400/3904 Training loss: 0.288206
Epoch: 6 3200/3904 Training loss: 0.378834
Training loss: 0.380647
Test loss: 0.581887; True positive: 797; True negative: 124, False Positive: 141, False negative: 106, accuracy: 0.788527397260274, precision: 0.849680170575693, recall: 0.8826135105204873
Epoch: 7 0/3904 Training loss: 0.324767
Epoch: 7 800/3904 Training loss: 0.218729
Epoch: 7 1600/3904 Training loss: 0.258216
Epoch: 7 2400/3904 Training loss: 0.289943
Epoch: 7 3200/3904 Training loss: 0.343682
Training loss: 0.369510
Test loss: 0.557397; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 8 0/3904 Training loss: 0.391696
Epoch: 8 800/3904 Training loss: 0.177264
Epoch: 8 1600/3904 Training loss: 0.178167
Epoch: 8 2400/3904 Training loss: 0.236151
Epoch: 8 3200/3904 Training loss: 0.370003
Training loss: 0.362655
Test loss: 0.550948; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 9 0/3904 Training loss: 0.279398
Epoch: 9 800/3904 Training loss: 0.176141
Epoch: 9 1600/3904 Training loss: 0.151459
Epoch: 9 2400/3904 Training loss: 0.272401
Epoch: 9 3200/3904 Training loss: 0.425796
Training loss: 0.361382
Test loss: 0.554856; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 10 0/3904 Training loss: 0.341141
Epoch: 10 800/3904 Training loss: 0.363550
Epoch: 10 1600/3904 Training loss: 0.168137
Epoch: 10 2400/3904 Training loss: 0.237816
Epoch: 10 3200/3904 Training loss: 0.440186
Training loss: 0.353917
Test loss: 0.531298; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 11 0/3904 Training loss: 0.288796
Epoch: 11 800/3904 Training loss: 0.164857
Epoch: 11 1600/3904 Training loss: 0.150268
Epoch: 11 2400/3904 Training loss: 0.207385
Epoch: 11 3200/3904 Training loss: 0.431293
Training loss: 0.347345
Test loss: 0.522484; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 12 0/3904 Training loss: 0.314430
Epoch: 12 800/3904 Training loss: 0.162818
Epoch: 12 1600/3904 Training loss: 0.161380
Epoch: 12 2400/3904 Training loss: 0.258174
Epoch: 12 3200/3904 Training loss: 0.340848
Training loss: 0.335421
Test loss: 0.576429; True positive: 836; True negative: 117, False Positive: 148, False negative: 67, accuracy: 0.8159246575342466, precision: 0.8495934959349594, recall: 0.9258028792912514
Epoch: 13 0/3904 Training loss: 0.490903
Epoch: 13 800/3904 Training loss: 0.209774
Epoch: 13 1600/3904 Training loss: 0.153290
Epoch: 13 2400/3904 Training loss: 0.224442
Epoch: 13 3200/3904 Training loss: 0.323798
Training loss: 0.322919
Test loss: 2.379785; True positive: 196; True negative: 224, False Positive: 41, False negative: 707, accuracy: 0.3595890410958904, precision: 0.8270042194092827, recall: 0.21705426356589147
Epoch: 14 0/3904 Training loss: 0.468212
Epoch: 14 800/3904 Training loss: 0.124690
Epoch: 14 1600/3904 Training loss: 0.148803
Epoch: 14 2400/3904 Training loss: 0.176022
Epoch: 14 3200/3904 Training loss: 0.313242
Training loss: 0.310535
Test loss: 3.048867; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 15 0/3904 Training loss: 0.429377
Epoch: 15 800/3904 Training loss: 0.148156
Epoch: 15 1600/3904 Training loss: 0.194452
Epoch: 15 2400/3904 Training loss: 0.183644
Epoch: 15 3200/3904 Training loss: 0.267816
Training loss: 0.289783
Test loss: 3.225864; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 16 0/3904 Training loss: 0.380294
Epoch: 16 800/3904 Training loss: 0.104762
Epoch: 16 1600/3904 Training loss: 0.132916
Epoch: 16 2400/3904 Training loss: 0.150188
Epoch: 16 3200/3904 Training loss: 0.241266
Training loss: 0.277568
Test loss: 3.249101; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 17 0/3904 Training loss: 0.447831
Epoch: 17 800/3904 Training loss: 0.121262
Epoch: 17 1600/3904 Training loss: 0.123167
Epoch: 17 2400/3904 Training loss: 0.137138
Epoch: 17 3200/3904 Training loss: 0.325401
Training loss: 0.271957
Test loss: 3.221823; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 18 0/3904 Training loss: 0.394747
Epoch: 18 800/3904 Training loss: 0.080829
Epoch: 18 1600/3904 Training loss: 0.119560
Epoch: 18 2400/3904 Training loss: 0.199228
Epoch: 18 3200/3904 Training loss: 0.268415
Training loss: 0.241491
Test loss: 3.522881; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 19 0/3904 Training loss: 0.184689
Epoch: 19 800/3904 Training loss: 0.062448
Epoch: 19 1600/3904 Training loss: 0.131019
Epoch: 19 2400/3904 Training loss: 0.115729
Epoch: 19 3200/3904 Training loss: 0.223680
Training loss: 0.238835
Test loss: 3.502868; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 20 0/3904 Training loss: 0.386846
Epoch: 20 800/3904 Training loss: 0.060899
Epoch: 20 1600/3904 Training loss: 0.100028
Epoch: 20 2400/3904 Training loss: 0.185513
Epoch: 20 3200/3904 Training loss: 0.254209
Training loss: 0.224047
Test loss: 3.664021; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 21 0/3904 Training loss: 0.255846
Epoch: 21 800/3904 Training loss: 0.082196
Epoch: 21 1600/3904 Training loss: 0.115122
Epoch: 21 2400/3904 Training loss: 0.106806
Epoch: 21 3200/3904 Training loss: 0.222598
Training loss: 0.208291
Test loss: 3.652830; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
starting trial 254
[I 2022-12-05 06:59:51,197] Trial 253 finished with value: 0.8176369863013698 and parameters: {'d_model': 64, 'nhead': 2, 'n_encoders': 2, 'learning_rate': 9.343712139334167e-05, 'weight_decay': 3.969499760646351e-06, 'dropout': 0.1273976655051536, 'max_pool_conv': 32, 'kernel_size': 18, 'd_mlp': 16, 'num_conv_layers': 5, 'encoder_dropout': 0.11946570110394601, 'd_feed_forward': 128, 'max_pool_dim': 8, 'n_mlp_layers': 4}. Best is trial 62 with value: 0.860445205479452.
Epoch: 0 0/3904 Training loss: 0.692100
Epoch: 0 800/3904 Training loss: 0.691745
Epoch: 0 1600/3904 Training loss: 0.604992
Epoch: 0 2400/3904 Training loss: 0.763988
Epoch: 0 3200/3904 Training loss: 0.586812
Training loss: 0.678307
Test loss: 0.798322; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 1 0/3904 Training loss: 0.711189
Epoch: 1 800/3904 Training loss: 0.732382
Epoch: 1 1600/3904 Training loss: 0.458395
Epoch: 1 2400/3904 Training loss: 0.759822
Epoch: 1 3200/3904 Training loss: 0.501982
Training loss: 0.624519
Test loss: 0.638823; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 2 0/3904 Training loss: 0.634749
Epoch: 2 800/3904 Training loss: 0.431415
Epoch: 2 1600/3904 Training loss: 0.289209
Epoch: 2 2400/3904 Training loss: 0.555520
Epoch: 2 3200/3904 Training loss: 0.453740
Training loss: 0.510167
Test loss: 0.540351; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 3 0/3904 Training loss: 0.501880
Epoch: 3 800/3904 Training loss: 0.358069
Epoch: 3 1600/3904 Training loss: 0.258089
Epoch: 3 2400/3904 Training loss: 0.426869
Epoch: 3 3200/3904 Training loss: 0.458259
Training loss: 0.466232
Test loss: 0.500566; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 4 0/3904 Training loss: 0.449799
Epoch: 4 800/3904 Training loss: 0.305231
Epoch: 4 1600/3904 Training loss: 0.229069
Epoch: 4 2400/3904 Training loss: 0.380403
Epoch: 4 3200/3904 Training loss: 0.449422
Training loss: 0.435430
Test loss: 0.516688; True positive: 830; True negative: 119, False Positive: 146, False negative: 73, accuracy: 0.8125, precision: 0.8504098360655737, recall: 0.9191583610188261
Epoch: 5 0/3904 Training loss: 0.479446
Epoch: 5 800/3904 Training loss: 0.310479
Epoch: 5 1600/3904 Training loss: 0.233467
Epoch: 5 2400/3904 Training loss: 0.402349
Epoch: 5 3200/3904 Training loss: 0.518501
Training loss: 0.408425
Test loss: 0.537366; True positive: 835; True negative: 119, False Positive: 146, False negative: 68, accuracy: 0.8167808219178082, precision: 0.8511722731906218, recall: 0.9246954595791805
Epoch: 6 0/3904 Training loss: 0.427855
Epoch: 6 800/3904 Training loss: 0.351834
Epoch: 6 1600/3904 Training loss: 0.217889
Epoch: 6 2400/3904 Training loss: 0.328733
Epoch: 6 3200/3904 Training loss: 0.510600
Training loss: 0.393942
Test loss: 2.131000; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 7 0/3904 Training loss: 0.391934
Epoch: 7 800/3904 Training loss: 0.320447
Epoch: 7 1600/3904 Training loss: 0.207482
Epoch: 7 2400/3904 Training loss: 0.285040
Epoch: 7 3200/3904 Training loss: 0.423313
Training loss: 0.375660
Test loss: 2.842125; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 8 0/3904 Training loss: 0.449100
Epoch: 8 800/3904 Training loss: 0.265329
Epoch: 8 1600/3904 Training loss: 0.204140
Epoch: 8 2400/3904 Training loss: 0.290385
Epoch: 8 3200/3904 Training loss: 0.517007
Training loss: 0.364961
Test loss: 2.815825; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 9 0/3904 Training loss: 0.376913
Epoch: 9 800/3904 Training loss: 0.289973
Epoch: 9 1600/3904 Training loss: 0.188808
Epoch: 9 2400/3904 Training loss: 0.232225
Epoch: 9 3200/3904 Training loss: 0.522041
Training loss: 0.358853
Test loss: 2.909130; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 10 0/3904 Training loss: 0.337564
Epoch: 10 800/3904 Training loss: 0.278083
Epoch: 10 1600/3904 Training loss: 0.159432
Epoch: 10 2400/3904 Training loss: 0.206466
Epoch: 10 3200/3904 Training loss: 0.408400
Training loss: 0.355615
Test loss: 3.183981; True positive: 1; True negative: 265, False Positive: 0, False negative: 902, accuracy: 0.22773972602739725, precision: 1.0, recall: 0.0011074197120708748
Epoch: 11 0/3904 Training loss: 0.330806
Epoch: 11 800/3904 Training loss: 0.228437
Epoch: 11 1600/3904 Training loss: 0.173231
Epoch: 11 2400/3904 Training loss: 0.199940
Epoch: 11 3200/3904 Training loss: 0.452518
Training loss: 0.342416
Test loss: 0.575163; True positive: 824; True negative: 141, False Positive: 124, False negative: 79, accuracy: 0.8261986301369864, precision: 0.869198312236287, recall: 0.9125138427464009
Epoch: 12 0/3904 Training loss: 0.345937
Epoch: 12 800/3904 Training loss: 0.228558
Epoch: 12 1600/3904 Training loss: 0.150399
Epoch: 12 2400/3904 Training loss: 0.244133
Epoch: 12 3200/3904 Training loss: 0.527247
Training loss: 0.334336
Test loss: 3.085541; True positive: 14; True negative: 265, False Positive: 0, False negative: 889, accuracy: 0.23886986301369864, precision: 1.0, recall: 0.015503875968992248
Epoch: 13 0/3904 Training loss: 0.299952
Epoch: 13 800/3904 Training loss: 0.272013
Epoch: 13 1600/3904 Training loss: 0.183657
Epoch: 13 2400/3904 Training loss: 0.248863
Epoch: 13 3200/3904 Training loss: 0.412212
Training loss: 0.325977
Test loss: 3.666396; True positive: 16; True negative: 265, False Positive: 0, False negative: 887, accuracy: 0.2405821917808219, precision: 1.0, recall: 0.017718715393133997
starting trial 255
[I 2022-12-05 07:02:34,870] Trial 254 finished with value: 0.8261986301369864 and parameters: {'d_model': 64, 'nhead': 8, 'n_encoders': 1, 'learning_rate': 0.00011069455314489185, 'weight_decay': 4.063377742307222e-06, 'dropout': 0.21282293036712413, 'max_pool_conv': 32, 'kernel_size': 19, 'd_mlp': 16, 'num_conv_layers': 5, 'encoder_dropout': 0.014438088972279316, 'd_feed_forward': 128, 'max_pool_dim': 4, 'n_mlp_layers': 3}. Best is trial 62 with value: 0.860445205479452.
Epoch: 0 0/3904 Training loss: 0.701714
Epoch: 0 800/3904 Training loss: 0.735198
Epoch: 0 1600/3904 Training loss: 0.440780
Epoch: 0 2400/3904 Training loss: 0.786490
Epoch: 0 3200/3904 Training loss: 0.529738
Training loss: 0.653539
Test loss: 0.760946; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 1 0/3904 Training loss: 0.683823
Epoch: 1 800/3904 Training loss: 0.657458
Epoch: 1 1600/3904 Training loss: 0.252394
Epoch: 1 2400/3904 Training loss: 0.552142
Epoch: 1 3200/3904 Training loss: 0.414696
Training loss: 0.550251
Test loss: 2.027953; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 2 0/3904 Training loss: 0.460964
Epoch: 2 800/3904 Training loss: 0.402221
Epoch: 2 1600/3904 Training loss: 0.255189
Epoch: 2 2400/3904 Training loss: 0.537212
Epoch: 2 3200/3904 Training loss: 0.380378
Training loss: 0.452804
Test loss: 2.129710; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 3 0/3904 Training loss: 0.363003
Epoch: 3 800/3904 Training loss: 0.426745
Epoch: 3 1600/3904 Training loss: 0.221721
Epoch: 3 2400/3904 Training loss: 0.389712
Epoch: 3 3200/3904 Training loss: 0.432981
Training loss: 0.431575
Test loss: 2.581319; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 4 0/3904 Training loss: 0.378435
Epoch: 4 800/3904 Training loss: 0.338980
Epoch: 4 1600/3904 Training loss: 0.181399
Epoch: 4 2400/3904 Training loss: 0.383269
Epoch: 4 3200/3904 Training loss: 0.461552
Training loss: 0.401025
Test loss: 2.420660; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 5 0/3904 Training loss: 0.371970
Epoch: 5 800/3904 Training loss: 0.345355
Epoch: 5 1600/3904 Training loss: 0.158254
Epoch: 5 2400/3904 Training loss: 0.292130
Epoch: 5 3200/3904 Training loss: 0.348195
Training loss: 0.385937
Test loss: 2.305176; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 6 0/3904 Training loss: 0.299715
Epoch: 6 800/3904 Training loss: 0.382284
Epoch: 6 1600/3904 Training loss: 0.112000
Epoch: 6 2400/3904 Training loss: 0.300914
Epoch: 6 3200/3904 Training loss: 0.401006
Training loss: 0.384272
Test loss: 2.722421; True positive: 1; True negative: 264, False Positive: 1, False negative: 902, accuracy: 0.2268835616438356, precision: 0.5, recall: 0.0011074197120708748
Epoch: 7 0/3904 Training loss: 0.305281
Epoch: 7 800/3904 Training loss: 0.300723
Epoch: 7 1600/3904 Training loss: 0.177574
Epoch: 7 2400/3904 Training loss: 0.290056
Epoch: 7 3200/3904 Training loss: 0.331649
Training loss: 0.372399
Test loss: 0.535003; True positive: 829; True negative: 139, False Positive: 126, False negative: 74, accuracy: 0.8287671232876712, precision: 0.8680628272251308, recall: 0.9180509413067552
Epoch: 8 0/3904 Training loss: 0.371829
Epoch: 8 800/3904 Training loss: 0.346477
Epoch: 8 1600/3904 Training loss: 0.156995
Epoch: 8 2400/3904 Training loss: 0.253930
Epoch: 8 3200/3904 Training loss: 0.355892
Training loss: 0.366848
Test loss: 0.601648; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 9 0/3904 Training loss: 0.361467
Epoch: 9 800/3904 Training loss: 0.300626
Epoch: 9 1600/3904 Training loss: 0.141143
Epoch: 9 2400/3904 Training loss: 0.194556
Epoch: 9 3200/3904 Training loss: 0.363958
Training loss: 0.362726
Test loss: 3.466199; True positive: 1; True negative: 265, False Positive: 0, False negative: 902, accuracy: 0.22773972602739725, precision: 1.0, recall: 0.0011074197120708748
Epoch: 10 0/3904 Training loss: 0.324631
Epoch: 10 800/3904 Training loss: 0.315345
Epoch: 10 1600/3904 Training loss: 0.132565
Epoch: 10 2400/3904 Training loss: 0.210735
Epoch: 10 3200/3904 Training loss: 0.446092
Training loss: 0.341462
Test loss: 0.554534; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 11 0/3904 Training loss: 0.291854
Epoch: 11 800/3904 Training loss: 0.334139
Epoch: 11 1600/3904 Training loss: 0.110412
Epoch: 11 2400/3904 Training loss: 0.215636
Epoch: 11 3200/3904 Training loss: 0.348601
Training loss: 0.332409
Test loss: 0.559452; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 12 0/3904 Training loss: 0.294854
Epoch: 12 800/3904 Training loss: 0.470475
Epoch: 12 1600/3904 Training loss: 0.124635
Epoch: 12 2400/3904 Training loss: 0.175786
Epoch: 12 3200/3904 Training loss: 0.418313
Training loss: 0.325813
Test loss: 0.553830; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 13 0/3904 Training loss: 0.278083
Epoch: 13 800/3904 Training loss: 0.288774
Epoch: 13 1600/3904 Training loss: 0.132948
Epoch: 13 2400/3904 Training loss: 0.160662
Epoch: 13 3200/3904 Training loss: 0.257221
Training loss: 0.307256
Test loss: 0.562423; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 14 0/3904 Training loss: 0.337409
Epoch: 14 800/3904 Training loss: 0.221959
Epoch: 14 1600/3904 Training loss: 0.067832
Epoch: 14 2400/3904 Training loss: 0.178777
Epoch: 14 3200/3904 Training loss: 0.475299
Training loss: 0.289064
Test loss: 0.587469; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 15 0/3904 Training loss: 0.292680
Epoch: 15 800/3904 Training loss: 0.300635
Epoch: 15 1600/3904 Training loss: 0.083797
Epoch: 15 2400/3904 Training loss: 0.391419
Epoch: 15 3200/3904 Training loss: 0.369679
Training loss: 0.285698
Test loss: 0.597689; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 16 0/3904 Training loss: 0.266237
Epoch: 16 800/3904 Training loss: 0.145668
Epoch: 16 1600/3904 Training loss: 0.060407
Epoch: 16 2400/3904 Training loss: 0.157948
Epoch: 16 3200/3904 Training loss: 0.300722
Training loss: 0.266018
Test loss: 0.603175; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 17 0/3904 Training loss: 0.367796
Epoch: 17 800/3904 Training loss: 0.172608
Epoch: 17 1600/3904 Training loss: 0.105805
Epoch: 17 2400/3904 Training loss: 0.183009
Epoch: 17 3200/3904 Training loss: 0.364217
Training loss: 0.268077
Test loss: 0.667469; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
starting trial 256
[I 2022-12-05 07:06:03,701] Trial 255 finished with value: 0.8287671232876712 and parameters: {'d_model': 64, 'nhead': 8, 'n_encoders': 1, 'learning_rate': 0.00011081173493964558, 'weight_decay': 4.2316130550061925e-06, 'dropout': 0.21073576948177108, 'max_pool_conv': 32, 'kernel_size': 18, 'd_mlp': 16, 'num_conv_layers': 5, 'encoder_dropout': 0.13822262147365066, 'd_feed_forward': 128, 'max_pool_dim': 8, 'n_mlp_layers': 3}. Best is trial 62 with value: 0.860445205479452.
Epoch: 0 0/3904 Training loss: 0.707223
Epoch: 0 800/3904 Training loss: 0.752118
Epoch: 0 1600/3904 Training loss: 0.434940
Epoch: 0 2400/3904 Training loss: 0.781394
Epoch: 0 3200/3904 Training loss: 0.525175
Training loss: 0.654602
Test loss: 0.762820; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 1 0/3904 Training loss: 0.676080
Epoch: 1 800/3904 Training loss: 0.705571
Epoch: 1 1600/3904 Training loss: 0.254935
Epoch: 1 2400/3904 Training loss: 0.802897
Epoch: 1 3200/3904 Training loss: 0.381612
Training loss: 0.579249
Test loss: 0.852398; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 2 0/3904 Training loss: 0.578481
Epoch: 2 800/3904 Training loss: 0.607896
Epoch: 2 1600/3904 Training loss: 0.229246
Epoch: 2 2400/3904 Training loss: 0.731956
Epoch: 2 3200/3904 Training loss: 0.366335
Training loss: 0.505410
Test loss: 0.858899; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 3 0/3904 Training loss: 0.540714
Epoch: 3 800/3904 Training loss: 0.591605
Epoch: 3 1600/3904 Training loss: 0.152335
Epoch: 3 2400/3904 Training loss: 0.544312
Epoch: 3 3200/3904 Training loss: 0.393656
Training loss: 0.451088
Test loss: 0.669159; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 4 0/3904 Training loss: 0.398677
Epoch: 4 800/3904 Training loss: 0.394074
Epoch: 4 1600/3904 Training loss: 0.165240
Epoch: 4 2400/3904 Training loss: 0.395482
Epoch: 4 3200/3904 Training loss: 0.331117
Training loss: 0.409351
Test loss: 0.637377; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 5 0/3904 Training loss: 0.420998
Epoch: 5 800/3904 Training loss: 0.283569
Epoch: 5 1600/3904 Training loss: 0.147099
Epoch: 5 2400/3904 Training loss: 0.362453
Epoch: 5 3200/3904 Training loss: 0.350283
Training loss: 0.393472
Test loss: 0.640463; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 6 0/3904 Training loss: 0.418728
Epoch: 6 800/3904 Training loss: 0.342506
Epoch: 6 1600/3904 Training loss: 0.151189
Epoch: 6 2400/3904 Training loss: 0.349235
Epoch: 6 3200/3904 Training loss: 0.289740
Training loss: 0.379213
Test loss: 0.643787; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 7 0/3904 Training loss: 0.364111
Epoch: 7 800/3904 Training loss: 0.242201
Epoch: 7 1600/3904 Training loss: 0.129778
Epoch: 7 2400/3904 Training loss: 0.300643
Epoch: 7 3200/3904 Training loss: 0.256711
Training loss: 0.366300
Test loss: 0.659512; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 8 0/3904 Training loss: 0.412980
Epoch: 8 800/3904 Training loss: 0.223800
Epoch: 8 1600/3904 Training loss: 0.125962
Epoch: 8 2400/3904 Training loss: 0.264335
Epoch: 8 3200/3904 Training loss: 0.320586
Training loss: 0.355840
Test loss: 0.651843; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 9 0/3904 Training loss: 0.353563
Epoch: 9 800/3904 Training loss: 0.206179
Epoch: 9 1600/3904 Training loss: 0.118157
Epoch: 9 2400/3904 Training loss: 0.258148
Epoch: 9 3200/3904 Training loss: 0.301563
Training loss: 0.359462
Test loss: 0.669994; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 10 0/3904 Training loss: 0.354718
Epoch: 10 800/3904 Training loss: 0.214926
Epoch: 10 1600/3904 Training loss: 0.139367
Epoch: 10 2400/3904 Training loss: 0.207006
Epoch: 10 3200/3904 Training loss: 0.273032
Training loss: 0.355965
Test loss: 0.686591; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 11 0/3904 Training loss: 0.305404
Epoch: 11 800/3904 Training loss: 0.253642
Epoch: 11 1600/3904 Training loss: 0.116603
Epoch: 11 2400/3904 Training loss: 0.223554
Epoch: 11 3200/3904 Training loss: 0.257371
Training loss: 0.341849
Test loss: 0.689326; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 12 0/3904 Training loss: 0.365125
Epoch: 12 800/3904 Training loss: 0.212287
Epoch: 12 1600/3904 Training loss: 0.125011
Epoch: 12 2400/3904 Training loss: 0.211287
Epoch: 12 3200/3904 Training loss: 0.236580
Training loss: 0.336021
Test loss: 0.694682; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 13 0/3904 Training loss: 0.347255
Epoch: 13 800/3904 Training loss: 0.130556
Epoch: 13 1600/3904 Training loss: 0.117856
Epoch: 13 2400/3904 Training loss: 0.206632
Epoch: 13 3200/3904 Training loss: 0.227167
Training loss: 0.327960
Test loss: 0.698555; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 14 0/3904 Training loss: 0.375600
Epoch: 14 800/3904 Training loss: 0.128113
Epoch: 14 1600/3904 Training loss: 0.107946
Epoch: 14 2400/3904 Training loss: 0.190853
Epoch: 14 3200/3904 Training loss: 0.235334
Training loss: 0.323130
Test loss: 0.696769; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
starting trial 257
[I 2022-12-05 07:08:59,221] Trial 256 finished with value: 0.8176369863013698 and parameters: {'d_model': 64, 'nhead': 8, 'n_encoders': 1, 'learning_rate': 0.00010746291096518983, 'weight_decay': 4.255269925576164e-06, 'dropout': 0.21119771845000765, 'max_pool_conv': 32, 'kernel_size': 19, 'd_mlp': 16, 'num_conv_layers': 5, 'encoder_dropout': 0.13871458228018446, 'd_feed_forward': 128, 'max_pool_dim': 4, 'n_mlp_layers': 3}. Best is trial 62 with value: 0.860445205479452.
Epoch: 0 0/3904 Training loss: 0.697220
Epoch: 0 800/3904 Training loss: 0.733357
Epoch: 0 1600/3904 Training loss: 0.449636
Epoch: 0 2400/3904 Training loss: 0.760962
Epoch: 0 3200/3904 Training loss: 0.542413
Training loss: 0.661422
Test loss: 0.803654; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 1 0/3904 Training loss: 0.705465
Epoch: 1 800/3904 Training loss: 0.706070
Epoch: 1 1600/3904 Training loss: 0.349553
Epoch: 1 2400/3904 Training loss: 1.014097
Epoch: 1 3200/3904 Training loss: 0.409118
Training loss: 0.594018
Test loss: 0.587542; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 2 0/3904 Training loss: 0.618417
Epoch: 2 800/3904 Training loss: 0.502237
Epoch: 2 1600/3904 Training loss: 0.250372
Epoch: 2 2400/3904 Training loss: 0.704333
Epoch: 2 3200/3904 Training loss: 0.396836
Training loss: 0.510366
Test loss: 0.574939; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 3 0/3904 Training loss: 0.563009
Epoch: 3 800/3904 Training loss: 0.456698
Epoch: 3 1600/3904 Training loss: 0.257361
Epoch: 3 2400/3904 Training loss: 0.573938
Epoch: 3 3200/3904 Training loss: 0.373594
Training loss: 0.462168
Test loss: 0.571043; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 4 0/3904 Training loss: 0.493651
Epoch: 4 800/3904 Training loss: 0.355777
Epoch: 4 1600/3904 Training loss: 0.220043
Epoch: 4 2400/3904 Training loss: 0.544058
Epoch: 4 3200/3904 Training loss: 0.432114
Training loss: 0.425939
Test loss: 0.563485; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 5 0/3904 Training loss: 0.408593
Epoch: 5 800/3904 Training loss: 0.367183
Epoch: 5 1600/3904 Training loss: 0.226641
Epoch: 5 2400/3904 Training loss: 0.408573
Epoch: 5 3200/3904 Training loss: 0.451334
Training loss: 0.395250
Test loss: 0.552567; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 6 0/3904 Training loss: 0.307182
Epoch: 6 800/3904 Training loss: 0.271137
Epoch: 6 1600/3904 Training loss: 0.207047
Epoch: 6 2400/3904 Training loss: 0.391134
Epoch: 6 3200/3904 Training loss: 0.378194
Training loss: 0.376613
Test loss: 0.566307; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 7 0/3904 Training loss: 0.388351
Epoch: 7 800/3904 Training loss: 0.321504
Epoch: 7 1600/3904 Training loss: 0.198273
Epoch: 7 2400/3904 Training loss: 0.324851
Epoch: 7 3200/3904 Training loss: 0.415020
Training loss: 0.356936
Test loss: 0.567077; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 8 0/3904 Training loss: 0.280931
Epoch: 8 800/3904 Training loss: 0.247318
Epoch: 8 1600/3904 Training loss: 0.207023
Epoch: 8 2400/3904 Training loss: 0.305564
Epoch: 8 3200/3904 Training loss: 0.402882
Training loss: 0.347445
Test loss: 0.575820; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 9 0/3904 Training loss: 0.344064
Epoch: 9 800/3904 Training loss: 0.206133
Epoch: 9 1600/3904 Training loss: 0.182294
Epoch: 9 2400/3904 Training loss: 0.250961
Epoch: 9 3200/3904 Training loss: 0.379401
Training loss: 0.328249
Test loss: 0.592325; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 10 0/3904 Training loss: 0.250763
Epoch: 10 800/3904 Training loss: 0.357323
Epoch: 10 1600/3904 Training loss: 0.177849
Epoch: 10 2400/3904 Training loss: 0.223747
Epoch: 10 3200/3904 Training loss: 0.362097
Training loss: 0.313748
Test loss: 0.602418; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 11 0/3904 Training loss: 0.317585
Epoch: 11 800/3904 Training loss: 0.135244
Epoch: 11 1600/3904 Training loss: 0.200319
Epoch: 11 2400/3904 Training loss: 0.221666
Epoch: 11 3200/3904 Training loss: 0.418375
Training loss: 0.300544
Test loss: 0.620502; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 12 0/3904 Training loss: 0.256540
Epoch: 12 800/3904 Training loss: 0.193904
Epoch: 12 1600/3904 Training loss: 0.141798
Epoch: 12 2400/3904 Training loss: 0.238637
Epoch: 12 3200/3904 Training loss: 0.274656
Training loss: 0.290628
Test loss: 0.647388; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 13 0/3904 Training loss: 0.222380
Epoch: 13 800/3904 Training loss: 0.139746
Epoch: 13 1600/3904 Training loss: 0.148812
Epoch: 13 2400/3904 Training loss: 0.176593
Epoch: 13 3200/3904 Training loss: 0.389211
Training loss: 0.272771
Test loss: 0.657237; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 14 0/3904 Training loss: 0.202881
Epoch: 14 800/3904 Training loss: 0.215669
Epoch: 14 1600/3904 Training loss: 0.151339
Epoch: 14 2400/3904 Training loss: 0.192790
Epoch: 14 3200/3904 Training loss: 0.361166
Training loss: 0.264137
Test loss: 0.685688; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 15 0/3904 Training loss: 0.168373
Epoch: 15 800/3904 Training loss: 0.107624
Epoch: 15 1600/3904 Training loss: 0.096767
Epoch: 15 2400/3904 Training loss: 0.262757
Epoch: 15 3200/3904 Training loss: 0.380913
Training loss: 0.245985
Test loss: 0.718134; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
starting trial 258
[I 2022-12-05 07:11:18,949] Trial 257 finished with value: 0.8176369863013698 and parameters: {'d_model': 64, 'nhead': 8, 'n_encoders': 1, 'learning_rate': 9.661966513915582e-05, 'weight_decay': 4.49110728095965e-06, 'dropout': 0.22227736890825517, 'max_pool_conv': 32, 'kernel_size': 17, 'd_mlp': 16, 'num_conv_layers': 4, 'encoder_dropout': 0.012116038013460905, 'd_feed_forward': 128, 'max_pool_dim': 4, 'n_mlp_layers': 3}. Best is trial 62 with value: 0.860445205479452.
Epoch: 0 0/3904 Training loss: 0.690511
Epoch: 0 800/3904 Training loss: 0.742485
Epoch: 0 1600/3904 Training loss: 0.435750
Epoch: 0 2400/3904 Training loss: 0.777644
Epoch: 0 3200/3904 Training loss: 0.566202
Training loss: 0.662968
Test loss: 0.809396; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 1 0/3904 Training loss: 0.712394
Epoch: 1 800/3904 Training loss: 0.732825
Epoch: 1 1600/3904 Training loss: 0.437170
Epoch: 1 2400/3904 Training loss: 0.808026
Epoch: 1 3200/3904 Training loss: 0.457049
Training loss: 0.643618
Test loss: 1.795030; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 2 0/3904 Training loss: 0.625203
Epoch: 2 800/3904 Training loss: 0.524815
Epoch: 2 1600/3904 Training loss: 0.226151
Epoch: 2 2400/3904 Training loss: 0.801911
Epoch: 2 3200/3904 Training loss: 0.367920
Training loss: 0.503789
Test loss: 2.437967; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 3 0/3904 Training loss: 0.490240
Epoch: 3 800/3904 Training loss: 0.387583
Epoch: 3 1600/3904 Training loss: 0.186573
Epoch: 3 2400/3904 Training loss: 0.457756
Epoch: 3 3200/3904 Training loss: 0.411209
Training loss: 0.427517
Test loss: 2.727882; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 4 0/3904 Training loss: 0.371903
Epoch: 4 800/3904 Training loss: 0.357649
Epoch: 4 1600/3904 Training loss: 0.161976
Epoch: 4 2400/3904 Training loss: 0.454169
Epoch: 4 3200/3904 Training loss: 0.401951
Training loss: 0.403197
Test loss: 2.756776; True positive: 0; True negative: 263, False Positive: 2, False negative: 903, accuracy: 0.22517123287671234, precision: 0.0, recall: 0.0
Epoch: 5 0/3904 Training loss: 0.333491
Epoch: 5 800/3904 Training loss: 0.406672
Epoch: 5 1600/3904 Training loss: 0.160292
Epoch: 5 2400/3904 Training loss: 0.408910
Epoch: 5 3200/3904 Training loss: 0.460357
Training loss: 0.393049
Test loss: 3.116410; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 6 0/3904 Training loss: 0.301646
Epoch: 6 800/3904 Training loss: 0.326759
Epoch: 6 1600/3904 Training loss: 0.139114
Epoch: 6 2400/3904 Training loss: 0.420459
Epoch: 6 3200/3904 Training loss: 0.329032
Training loss: 0.375451
Test loss: 3.142937; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 7 0/3904 Training loss: 0.251679
Epoch: 7 800/3904 Training loss: 0.291520
Epoch: 7 1600/3904 Training loss: 0.123267
Epoch: 7 2400/3904 Training loss: 0.382963
Epoch: 7 3200/3904 Training loss: 0.382524
Training loss: 0.365839
Test loss: 3.138144; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 8 0/3904 Training loss: 0.280534
Epoch: 8 800/3904 Training loss: 0.196887
Epoch: 8 1600/3904 Training loss: 0.100954
Epoch: 8 2400/3904 Training loss: 0.294092
Epoch: 8 3200/3904 Training loss: 0.393428
Training loss: 0.358903
Test loss: 3.070255; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 9 0/3904 Training loss: 0.244266
Epoch: 9 800/3904 Training loss: 0.284734
Epoch: 9 1600/3904 Training loss: 0.122406
Epoch: 9 2400/3904 Training loss: 0.271114
Epoch: 9 3200/3904 Training loss: 0.407872
Training loss: 0.351926
Test loss: 3.577529; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 10 0/3904 Training loss: 0.217023
Epoch: 10 800/3904 Training loss: 0.208961
Epoch: 10 1600/3904 Training loss: 0.124514
Epoch: 10 2400/3904 Training loss: 0.377602
Epoch: 10 3200/3904 Training loss: 0.367693
Training loss: 0.340300
Test loss: 3.643279; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
starting trial 259
[I 2022-12-05 07:13:17,576] Trial 258 finished with value: 0.2268835616438356 and parameters: {'d_model': 64, 'nhead': 8, 'n_encoders': 1, 'learning_rate': 0.0001176237934458526, 'weight_decay': 3.806606846838061e-06, 'dropout': 0.19898190090104362, 'max_pool_conv': 32, 'kernel_size': 17, 'd_mlp': 16, 'num_conv_layers': 5, 'encoder_dropout': 0.14118692560652332, 'd_feed_forward': 128, 'max_pool_dim': 4, 'n_mlp_layers': 3}. Best is trial 62 with value: 0.860445205479452.
Epoch: 0 0/3904 Training loss: 0.699774
Epoch: 0 800/3904 Training loss: 0.731492
Epoch: 0 1600/3904 Training loss: 0.489056
Epoch: 0 2400/3904 Training loss: 0.801510
Epoch: 0 3200/3904 Training loss: 0.554133
Training loss: 0.659394
Test loss: 0.857260; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 1 0/3904 Training loss: 0.713184
Epoch: 1 800/3904 Training loss: 0.735104
Epoch: 1 1600/3904 Training loss: 0.435099
Epoch: 1 2400/3904 Training loss: 0.694837
Epoch: 1 3200/3904 Training loss: 0.502532
Training loss: 0.622425
Test loss: 1.450118; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 2 0/3904 Training loss: 0.712018
Epoch: 2 800/3904 Training loss: 0.632350
Epoch: 2 1600/3904 Training loss: 0.281807
Epoch: 2 2400/3904 Training loss: 0.421994
Epoch: 2 3200/3904 Training loss: 0.413976
Training loss: 0.529308
Test loss: 2.121212; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 3 0/3904 Training loss: 0.618107
Epoch: 3 800/3904 Training loss: 0.595670
Epoch: 3 1600/3904 Training loss: 0.254523
Epoch: 3 2400/3904 Training loss: 0.524134
Epoch: 3 3200/3904 Training loss: 0.502276
Training loss: 0.467846
Test loss: 2.724538; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 4 0/3904 Training loss: 0.526262
Epoch: 4 800/3904 Training loss: 0.557784
Epoch: 4 1600/3904 Training loss: 0.201534
Epoch: 4 2400/3904 Training loss: 0.396490
Epoch: 4 3200/3904 Training loss: 0.600500
Training loss: 0.410734
Test loss: 3.190705; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 5 0/3904 Training loss: 0.454269
Epoch: 5 800/3904 Training loss: 0.513976
Epoch: 5 1600/3904 Training loss: 0.201130
Epoch: 5 2400/3904 Training loss: 0.457178
Epoch: 5 3200/3904 Training loss: 0.575649
Training loss: 0.380528
Test loss: 3.442226; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 6 0/3904 Training loss: 0.403981
Epoch: 6 800/3904 Training loss: 0.418168
Epoch: 6 1600/3904 Training loss: 0.176150
Epoch: 6 2400/3904 Training loss: 0.311339
Epoch: 6 3200/3904 Training loss: 0.563903
Training loss: 0.352993
Test loss: 3.649243; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 7 0/3904 Training loss: 0.361491
Epoch: 7 800/3904 Training loss: 0.230558
Epoch: 7 1600/3904 Training loss: 0.165094
Epoch: 7 2400/3904 Training loss: 0.360661
Epoch: 7 3200/3904 Training loss: 0.487713
Training loss: 0.336205
Test loss: 3.649606; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 8 0/3904 Training loss: 0.385343
Epoch: 8 800/3904 Training loss: 0.272719
Epoch: 8 1600/3904 Training loss: 0.209110
Epoch: 8 2400/3904 Training loss: 0.419549
Epoch: 8 3200/3904 Training loss: 0.469269
Training loss: 0.315954
Test loss: 3.809928; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 9 0/3904 Training loss: 0.412493
Epoch: 9 800/3904 Training loss: 0.191639
Epoch: 9 1600/3904 Training loss: 0.145135
Epoch: 9 2400/3904 Training loss: 0.411081
Epoch: 9 3200/3904 Training loss: 0.562468
Training loss: 0.305104
Test loss: 3.710784; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 10 0/3904 Training loss: 0.303882
Epoch: 10 800/3904 Training loss: 0.174394
Epoch: 10 1600/3904 Training loss: 0.188760
Epoch: 10 2400/3904 Training loss: 0.253141
Epoch: 10 3200/3904 Training loss: 0.500498
Training loss: 0.291322
Test loss: 3.818155; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
starting trial 260
[I 2022-12-05 07:15:26,877] Trial 259 finished with value: 0.2268835616438356 and parameters: {'d_model': 64, 'nhead': 8, 'n_encoders': 1, 'learning_rate': 0.0001124650490386225, 'weight_decay': 4.753962553360438e-06, 'dropout': 0.20891407882694574, 'max_pool_conv': 32, 'kernel_size': 18, 'd_mlp': 16, 'num_conv_layers': 5, 'encoder_dropout': 0.07410446377286138, 'd_feed_forward': 128, 'max_pool_dim': 4, 'n_mlp_layers': 4}. Best is trial 62 with value: 0.860445205479452.
Epoch: 0 0/3904 Training loss: 0.704085
Epoch: 0 800/3904 Training loss: 0.727184
Epoch: 0 1600/3904 Training loss: 0.428155
Epoch: 0 2400/3904 Training loss: 0.773890
Epoch: 0 3200/3904 Training loss: 0.544802
Training loss: 0.661856
Test loss: 0.805920; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 1 0/3904 Training loss: 0.702675
Epoch: 1 800/3904 Training loss: 0.716730
Epoch: 1 1600/3904 Training loss: 0.283794
Epoch: 1 2400/3904 Training loss: 0.803743
Epoch: 1 3200/3904 Training loss: 0.401505
Training loss: 0.594098
Test loss: 0.736841; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 2 0/3904 Training loss: 0.644042
Epoch: 2 800/3904 Training loss: 0.535764
Epoch: 2 1600/3904 Training loss: 0.198377
Epoch: 2 2400/3904 Training loss: 0.558461
Epoch: 2 3200/3904 Training loss: 0.389988
Training loss: 0.494614
Test loss: 0.573916; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 3 0/3904 Training loss: 0.484374
Epoch: 3 800/3904 Training loss: 0.357683
Epoch: 3 1600/3904 Training loss: 0.198580
Epoch: 3 2400/3904 Training loss: 0.410879
Epoch: 3 3200/3904 Training loss: 0.377665
Training loss: 0.428867
Test loss: 0.563358; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 4 0/3904 Training loss: 0.324124
Epoch: 4 800/3904 Training loss: 0.274262
Epoch: 4 1600/3904 Training loss: 0.179445
Epoch: 4 2400/3904 Training loss: 0.426632
Epoch: 4 3200/3904 Training loss: 0.359069
Training loss: 0.402926
Test loss: 0.561886; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 5 0/3904 Training loss: 0.347062
Epoch: 5 800/3904 Training loss: 0.283924
Epoch: 5 1600/3904 Training loss: 0.174191
Epoch: 5 2400/3904 Training loss: 0.356162
Epoch: 5 3200/3904 Training loss: 0.364909
Training loss: 0.382187
Test loss: 0.567133; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 6 0/3904 Training loss: 0.344192
Epoch: 6 800/3904 Training loss: 0.224529
Epoch: 6 1600/3904 Training loss: 0.167143
Epoch: 6 2400/3904 Training loss: 0.318418
Epoch: 6 3200/3904 Training loss: 0.309810
Training loss: 0.366667
Test loss: 0.579706; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 7 0/3904 Training loss: 0.385972
Epoch: 7 800/3904 Training loss: 0.180209
Epoch: 7 1600/3904 Training loss: 0.197309
Epoch: 7 2400/3904 Training loss: 0.263082
Epoch: 7 3200/3904 Training loss: 0.325749
Training loss: 0.350376
Test loss: 0.595066; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 8 0/3904 Training loss: 0.409071
Epoch: 8 800/3904 Training loss: 0.205481
Epoch: 8 1600/3904 Training loss: 0.200223
Epoch: 8 2400/3904 Training loss: 0.225156
Epoch: 8 3200/3904 Training loss: 0.326747
Training loss: 0.345772
Test loss: 0.581772; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 9 0/3904 Training loss: 0.288467
Epoch: 9 800/3904 Training loss: 0.155115
Epoch: 9 1600/3904 Training loss: 0.192852
Epoch: 9 2400/3904 Training loss: 0.192753
Epoch: 9 3200/3904 Training loss: 0.320574
Training loss: 0.328518
Test loss: 0.600296; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 10 0/3904 Training loss: 0.370074
Epoch: 10 800/3904 Training loss: 0.161739
Epoch: 10 1600/3904 Training loss: 0.178094
Epoch: 10 2400/3904 Training loss: 0.243279
Epoch: 10 3200/3904 Training loss: 0.361710
Training loss: 0.326105
Test loss: 0.594407; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 11 0/3904 Training loss: 0.440027
Epoch: 11 800/3904 Training loss: 0.171765
Epoch: 11 1600/3904 Training loss: 0.135725
Epoch: 11 2400/3904 Training loss: 0.209141
Epoch: 11 3200/3904 Training loss: 0.363062
Training loss: 0.308363
Test loss: 0.598895; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 12 0/3904 Training loss: 0.288070
Epoch: 12 800/3904 Training loss: 0.132246
Epoch: 12 1600/3904 Training loss: 0.130982
Epoch: 12 2400/3904 Training loss: 0.155656
Epoch: 12 3200/3904 Training loss: 0.323276
Training loss: 0.303358
Test loss: 0.600927; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 13 0/3904 Training loss: 0.461156
Epoch: 13 800/3904 Training loss: 0.206315
Epoch: 13 1600/3904 Training loss: 0.120475
Epoch: 13 2400/3904 Training loss: 0.161886
Epoch: 13 3200/3904 Training loss: 0.290476
Training loss: 0.282236
Test loss: 0.602772; True positive: 837; True negative: 117, False Positive: 148, False negative: 66, accuracy: 0.8167808219178082, precision: 0.849746192893401, recall: 0.9269102990033222
Epoch: 14 0/3904 Training loss: 0.448800
Epoch: 14 800/3904 Training loss: 0.110649
Epoch: 14 1600/3904 Training loss: 0.112120
Epoch: 14 2400/3904 Training loss: 0.234449
Epoch: 14 3200/3904 Training loss: 0.243173
Training loss: 0.279231
Test loss: 1.490860; True positive: 528; True negative: 220, False Positive: 45, False negative: 375, accuracy: 0.6404109589041096, precision: 0.9214659685863874, recall: 0.584717607973422
starting trial 261
[I 2022-12-05 07:18:21,324] Trial 260 finished with value: 0.8176369863013698 and parameters: {'d_model': 64, 'nhead': 8, 'n_encoders': 1, 'learning_rate': 0.00010048391377133477, 'weight_decay': 4.026897329070979e-06, 'dropout': 0.21693038541310788, 'max_pool_conv': 32, 'kernel_size': 18, 'd_mlp': 16, 'num_conv_layers': 5, 'encoder_dropout': 0.16173793319902607, 'd_feed_forward': 128, 'max_pool_dim': 4, 'n_mlp_layers': 3}. Best is trial 62 with value: 0.860445205479452.
Epoch: 0 0/3904 Training loss: 0.688413
Epoch: 0 800/3904 Training loss: 0.728039
Epoch: 0 1600/3904 Training loss: 0.444979
Epoch: 0 2400/3904 Training loss: 0.793836
Epoch: 0 3200/3904 Training loss: 0.503940
Training loss: 0.651389
Test loss: 0.737959; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 1 0/3904 Training loss: 0.673277
Epoch: 1 800/3904 Training loss: 0.630669
Epoch: 1 1600/3904 Training loss: 0.285829
Epoch: 1 2400/3904 Training loss: 0.919055
Epoch: 1 3200/3904 Training loss: 0.354628
Training loss: 0.555488
Test loss: 0.611103; True positive: 900; True negative: 5, False Positive: 260, False negative: 3, accuracy: 0.7748287671232876, precision: 0.7758620689655172, recall: 0.9966777408637874
Epoch: 2 0/3904 Training loss: 0.596761
Epoch: 2 800/3904 Training loss: 0.423009
Epoch: 2 1600/3904 Training loss: 0.234282
Epoch: 2 2400/3904 Training loss: 0.469375
Epoch: 2 3200/3904 Training loss: 0.421150
Training loss: 0.470916
Test loss: 0.477304; True positive: 889; True negative: 95, False Positive: 170, False negative: 14, accuracy: 0.8424657534246576, precision: 0.8394711992445704, recall: 0.9844961240310077
Epoch: 3 0/3904 Training loss: 0.482903
Epoch: 3 800/3904 Training loss: 0.366043
Epoch: 3 1600/3904 Training loss: 0.204494
Epoch: 3 2400/3904 Training loss: 0.387255
Epoch: 3 3200/3904 Training loss: 0.432791
Training loss: 0.438523
Test loss: 0.450782; True positive: 885; True negative: 104, False Positive: 161, False negative: 18, accuracy: 0.8467465753424658, precision: 0.8460803059273423, recall: 0.9800664451827242
Epoch: 4 0/3904 Training loss: 0.402014
Epoch: 4 800/3904 Training loss: 0.347851
Epoch: 4 1600/3904 Training loss: 0.237564
Epoch: 4 2400/3904 Training loss: 0.377919
Epoch: 4 3200/3904 Training loss: 0.359740
Training loss: 0.402803
Test loss: 2.459564; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 5 0/3904 Training loss: 0.362201
Epoch: 5 800/3904 Training loss: 0.355380
Epoch: 5 1600/3904 Training loss: 0.194389
Epoch: 5 2400/3904 Training loss: 0.407884
Epoch: 5 3200/3904 Training loss: 0.445453
Training loss: 0.396946
Test loss: 1.298876; True positive: 397; True negative: 226, False Positive: 39, False negative: 506, accuracy: 0.5333904109589042, precision: 0.9105504587155964, recall: 0.43964562569213733
Epoch: 6 0/3904 Training loss: 0.374208
Epoch: 6 800/3904 Training loss: 0.336685
Epoch: 6 1600/3904 Training loss: 0.179070
Epoch: 6 2400/3904 Training loss: 0.251664
Epoch: 6 3200/3904 Training loss: 0.452947
Training loss: 0.383940
Test loss: 0.513440; True positive: 837; True negative: 123, False Positive: 142, False negative: 66, accuracy: 0.821917808219178, precision: 0.8549540347293156, recall: 0.9269102990033222
Epoch: 7 0/3904 Training loss: 0.431044
Epoch: 7 800/3904 Training loss: 0.323272
Epoch: 7 1600/3904 Training loss: 0.209371
Epoch: 7 2400/3904 Training loss: 0.274555
Epoch: 7 3200/3904 Training loss: 0.449776
Training loss: 0.367404
Test loss: 0.515382; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 8 0/3904 Training loss: 0.465046
Epoch: 8 800/3904 Training loss: 0.324114
Epoch: 8 1600/3904 Training loss: 0.192603
Epoch: 8 2400/3904 Training loss: 0.230950
Epoch: 8 3200/3904 Training loss: 0.409056
Training loss: 0.348910
Test loss: 0.522348; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 9 0/3904 Training loss: 0.551283
Epoch: 9 800/3904 Training loss: 0.255715
Epoch: 9 1600/3904 Training loss: 0.173113
Epoch: 9 2400/3904 Training loss: 0.338386
Epoch: 9 3200/3904 Training loss: 0.448879
Training loss: 0.350921
Test loss: 0.515593; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 10 0/3904 Training loss: 0.457064
Epoch: 10 800/3904 Training loss: 0.226219
Epoch: 10 1600/3904 Training loss: 0.311580
Epoch: 10 2400/3904 Training loss: 0.179105
Epoch: 10 3200/3904 Training loss: 0.398163
Training loss: 0.340231
Test loss: 0.517571; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 11 0/3904 Training loss: 0.344298
Epoch: 11 800/3904 Training loss: 0.313475
Epoch: 11 1600/3904 Training loss: 0.211201
Epoch: 11 2400/3904 Training loss: 0.155490
Epoch: 11 3200/3904 Training loss: 0.350647
Training loss: 0.356104
Test loss: 0.514622; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 12 0/3904 Training loss: 0.446726
Epoch: 12 800/3904 Training loss: 0.293279
Epoch: 12 1600/3904 Training loss: 0.211513
Epoch: 12 2400/3904 Training loss: 0.153594
Epoch: 12 3200/3904 Training loss: 0.318242
Training loss: 0.338651
Test loss: 0.520952; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 13 0/3904 Training loss: 0.372801
Epoch: 13 800/3904 Training loss: 0.212850
Epoch: 13 1600/3904 Training loss: 0.177014
Epoch: 13 2400/3904 Training loss: 0.162716
Epoch: 13 3200/3904 Training loss: 0.358428
Training loss: 0.331741
Test loss: 0.527046; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
starting trial 262
[I 2022-12-05 07:22:41,142] Trial 261 finished with value: 0.8467465753424658 and parameters: {'d_model': 64, 'nhead': 8, 'n_encoders': 1, 'learning_rate': 8.170626281076582e-05, 'weight_decay': 3.585385782286939e-06, 'dropout': 0.18750445330423854, 'max_pool_conv': 32, 'kernel_size': 19, 'd_mlp': 16, 'num_conv_layers': 8, 'encoder_dropout': 0.15124008441226774, 'd_feed_forward': 128, 'max_pool_dim': 8, 'n_mlp_layers': 3}. Best is trial 62 with value: 0.860445205479452.
Epoch: 0 0/3904 Training loss: 0.693827
Epoch: 0 800/3904 Training loss: 0.715665
Epoch: 0 1600/3904 Training loss: 0.474571
Epoch: 0 2400/3904 Training loss: 0.780902
Epoch: 0 3200/3904 Training loss: 0.549284
Training loss: 0.661995
Test loss: 0.817492; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 1 0/3904 Training loss: 0.713196
Epoch: 1 800/3904 Training loss: 0.717445
Epoch: 1 1600/3904 Training loss: 0.354443
Epoch: 1 2400/3904 Training loss: 0.780919
Epoch: 1 3200/3904 Training loss: 0.432475
Training loss: 0.592949
Test loss: 0.748765; True positive: 721; True negative: 90, False Positive: 175, False negative: 182, accuracy: 0.6943493150684932, precision: 0.8046875, recall: 0.7984496124031008
Epoch: 2 0/3904 Training loss: 0.624587
Epoch: 2 800/3904 Training loss: 0.565119
Epoch: 2 1600/3904 Training loss: 0.239758
Epoch: 2 2400/3904 Training loss: 0.798397
Epoch: 2 3200/3904 Training loss: 0.404356
Training loss: 0.515607
Test loss: 0.631696; True positive: 902; True negative: 1, False Positive: 264, False negative: 1, accuracy: 0.7731164383561644, precision: 0.7735849056603774, recall: 0.9988925802879292
Epoch: 3 0/3904 Training loss: 0.596384
Epoch: 3 800/3904 Training loss: 0.564293
Epoch: 3 1600/3904 Training loss: 0.261532
Epoch: 3 2400/3904 Training loss: 0.636287
Epoch: 3 3200/3904 Training loss: 0.430693
Training loss: 0.456912
Test loss: 0.543863; True positive: 903; True negative: 0, False Positive: 265, False negative: 0, accuracy: 0.7731164383561644, precision: 0.7731164383561644, recall: 1.0
Epoch: 4 0/3904 Training loss: 0.544617
Epoch: 4 800/3904 Training loss: 0.529014
Epoch: 4 1600/3904 Training loss: 0.210191
Epoch: 4 2400/3904 Training loss: 0.491234
Epoch: 4 3200/3904 Training loss: 0.478637
Training loss: 0.424997
Test loss: 0.535855; True positive: 903; True negative: 0, False Positive: 265, False negative: 0, accuracy: 0.7731164383561644, precision: 0.7731164383561644, recall: 1.0
Epoch: 5 0/3904 Training loss: 0.389941
Epoch: 5 800/3904 Training loss: 0.400957
Epoch: 5 1600/3904 Training loss: 0.180709
Epoch: 5 2400/3904 Training loss: 0.461595
Epoch: 5 3200/3904 Training loss: 0.456195
Training loss: 0.401502
Test loss: 0.537512; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 6 0/3904 Training loss: 0.308785
Epoch: 6 800/3904 Training loss: 0.360456
Epoch: 6 1600/3904 Training loss: 0.161371
Epoch: 6 2400/3904 Training loss: 0.399995
Epoch: 6 3200/3904 Training loss: 0.370419
Training loss: 0.394365
Test loss: 0.537744; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 7 0/3904 Training loss: 0.310479
Epoch: 7 800/3904 Training loss: 0.298515
Epoch: 7 1600/3904 Training loss: 0.185332
Epoch: 7 2400/3904 Training loss: 0.367656
Epoch: 7 3200/3904 Training loss: 0.382550
Training loss: 0.377796
Test loss: 0.533221; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 8 0/3904 Training loss: 0.293673
Epoch: 8 800/3904 Training loss: 0.405397
Epoch: 8 1600/3904 Training loss: 0.163657
Epoch: 8 2400/3904 Training loss: 0.269351
Epoch: 8 3200/3904 Training loss: 0.368605
Training loss: 0.379338
Test loss: 0.535132; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 9 0/3904 Training loss: 0.342549
Epoch: 9 800/3904 Training loss: 0.354955
Epoch: 9 1600/3904 Training loss: 0.157699
Epoch: 9 2400/3904 Training loss: 0.404337
Epoch: 9 3200/3904 Training loss: 0.392275
Training loss: 0.370508
Test loss: 0.537323; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 10 0/3904 Training loss: 0.307680
Epoch: 10 800/3904 Training loss: 0.344408
Epoch: 10 1600/3904 Training loss: 0.146361
Epoch: 10 2400/3904 Training loss: 0.332495
Epoch: 10 3200/3904 Training loss: 0.307534
Training loss: 0.366410
Test loss: 0.544334; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 11 0/3904 Training loss: 0.323604
Epoch: 11 800/3904 Training loss: 0.286390
Epoch: 11 1600/3904 Training loss: 0.110426
Epoch: 11 2400/3904 Training loss: 0.317416
Epoch: 11 3200/3904 Training loss: 0.370031
Training loss: 0.367886
Test loss: 0.542722; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 12 0/3904 Training loss: 0.293441
Epoch: 12 800/3904 Training loss: 0.386248
Epoch: 12 1600/3904 Training loss: 0.135672
Epoch: 12 2400/3904 Training loss: 0.300519
Epoch: 12 3200/3904 Training loss: 0.413498
Training loss: 0.358749
Test loss: 0.546970; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 13 0/3904 Training loss: 0.366577
Epoch: 13 800/3904 Training loss: 0.321137
Epoch: 13 1600/3904 Training loss: 0.092248
Epoch: 13 2400/3904 Training loss: 0.385319
Epoch: 13 3200/3904 Training loss: 0.333134
Training loss: 0.354640
Test loss: 0.551373; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 14 0/3904 Training loss: 0.301977
Epoch: 14 800/3904 Training loss: 0.256815
Epoch: 14 1600/3904 Training loss: 0.124325
Epoch: 14 2400/3904 Training loss: 0.305162
Epoch: 14 3200/3904 Training loss: 0.338857
Training loss: 0.348000
Test loss: 0.551073; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 15 0/3904 Training loss: 0.301751
Epoch: 15 800/3904 Training loss: 0.392701
Epoch: 15 1600/3904 Training loss: 0.132726
Epoch: 15 2400/3904 Training loss: 0.280188
Epoch: 15 3200/3904 Training loss: 0.337117
Training loss: 0.347249
Test loss: 0.551049; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 16 0/3904 Training loss: 0.310565
Epoch: 16 800/3904 Training loss: 0.350424
Epoch: 16 1600/3904 Training loss: 0.119894
Epoch: 16 2400/3904 Training loss: 0.323014
Epoch: 16 3200/3904 Training loss: 0.352455
Training loss: 0.344901
Test loss: 0.554834; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 17 0/3904 Training loss: 0.305485
Epoch: 17 800/3904 Training loss: 0.287808
Epoch: 17 1600/3904 Training loss: 0.223598
Epoch: 17 2400/3904 Training loss: 0.252116
Epoch: 17 3200/3904 Training loss: 0.328049
Training loss: 0.342849
Test loss: 0.548911; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
starting trial 263
[I 2022-12-05 07:28:15,192] Trial 262 finished with value: 0.8176369863013698 and parameters: {'d_model': 64, 'nhead': 8, 'n_encoders': 1, 'learning_rate': 6.700219866023656e-05, 'weight_decay': 3.7027635183899375e-06, 'dropout': 0.18258801301498231, 'max_pool_conv': 32, 'kernel_size': 19, 'd_mlp': 16, 'num_conv_layers': 8, 'encoder_dropout': 0.14693983354815263, 'd_feed_forward': 128, 'max_pool_dim': 8, 'n_mlp_layers': 3}. Best is trial 62 with value: 0.860445205479452.
Epoch: 0 0/3904 Training loss: 0.692513
Epoch: 0 800/3904 Training loss: 0.710030
Epoch: 0 1600/3904 Training loss: 0.525324
Epoch: 0 2400/3904 Training loss: 0.780476
Epoch: 0 3200/3904 Training loss: 0.552655
Training loss: 0.660919
Test loss: 0.869930; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 1 0/3904 Training loss: 0.705962
Epoch: 1 800/3904 Training loss: 0.681175
Epoch: 1 1600/3904 Training loss: 0.347376
Epoch: 1 2400/3904 Training loss: 0.704700
Epoch: 1 3200/3904 Training loss: 0.432778
Training loss: 0.584771
Test loss: 1.126554; True positive: 65; True negative: 148, False Positive: 117, False negative: 838, accuracy: 0.18236301369863014, precision: 0.35714285714285715, recall: 0.07198228128460686
Epoch: 2 0/3904 Training loss: 0.607436
Epoch: 2 800/3904 Training loss: 0.466963
Epoch: 2 1600/3904 Training loss: 0.242114
Epoch: 2 2400/3904 Training loss: 0.450000
Epoch: 2 3200/3904 Training loss: 0.445717
Training loss: 0.489677
Test loss: 1.277796; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 3 0/3904 Training loss: 0.525116
Epoch: 3 800/3904 Training loss: 0.552375
Epoch: 3 1600/3904 Training loss: 0.229576
Epoch: 3 2400/3904 Training loss: 0.516935
Epoch: 3 3200/3904 Training loss: 0.428658
Training loss: 0.441758
Test loss: 1.493773; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 4 0/3904 Training loss: 0.496874
Epoch: 4 800/3904 Training loss: 0.282787
Epoch: 4 1600/3904 Training loss: 0.175942
Epoch: 4 2400/3904 Training loss: 0.385154
Epoch: 4 3200/3904 Training loss: 0.447688
Training loss: 0.407805
Test loss: 2.364239; True positive: 3; True negative: 264, False Positive: 1, False negative: 900, accuracy: 0.2285958904109589, precision: 0.75, recall: 0.0033222591362126247
Epoch: 5 0/3904 Training loss: 0.470686
Epoch: 5 800/3904 Training loss: 0.259611
Epoch: 5 1600/3904 Training loss: 0.156522
Epoch: 5 2400/3904 Training loss: 0.368456
Epoch: 5 3200/3904 Training loss: 0.425642
Training loss: 0.393617
Test loss: 1.740509; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 6 0/3904 Training loss: 0.545401
Epoch: 6 800/3904 Training loss: 0.298588
Epoch: 6 1600/3904 Training loss: 0.154434
Epoch: 6 2400/3904 Training loss: 0.313951
Epoch: 6 3200/3904 Training loss: 0.354772
Training loss: 0.387643
Test loss: 1.981130; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 7 0/3904 Training loss: 0.541762
Epoch: 7 800/3904 Training loss: 0.189702
Epoch: 7 1600/3904 Training loss: 0.167083
Epoch: 7 2400/3904 Training loss: 0.314106
Epoch: 7 3200/3904 Training loss: 0.418145
Training loss: 0.382757
Test loss: 2.531890; True positive: 1; True negative: 265, False Positive: 0, False negative: 902, accuracy: 0.22773972602739725, precision: 1.0, recall: 0.0011074197120708748
Epoch: 8 0/3904 Training loss: 0.482171
Epoch: 8 800/3904 Training loss: 0.179405
Epoch: 8 1600/3904 Training loss: 0.194854
Epoch: 8 2400/3904 Training loss: 0.347184
Epoch: 8 3200/3904 Training loss: 0.403422
Training loss: 0.370203
Test loss: 1.768915; True positive: 151; True negative: 256, False Positive: 9, False negative: 752, accuracy: 0.348458904109589, precision: 0.94375, recall: 0.1672203765227021
Epoch: 9 0/3904 Training loss: 0.370915
Epoch: 9 800/3904 Training loss: 0.195995
Epoch: 9 1600/3904 Training loss: 0.175600
Epoch: 9 2400/3904 Training loss: 0.226563
Epoch: 9 3200/3904 Training loss: 0.366729
Training loss: 0.378159
Test loss: 0.519418; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 10 0/3904 Training loss: 0.578348
Epoch: 10 800/3904 Training loss: 0.195403
Epoch: 10 1600/3904 Training loss: 0.186281
Epoch: 10 2400/3904 Training loss: 0.248380
Epoch: 10 3200/3904 Training loss: 0.423737
Training loss: 0.375837
Test loss: 0.519878; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 11 0/3904 Training loss: 0.425909
Epoch: 11 800/3904 Training loss: 0.254815
Epoch: 11 1600/3904 Training loss: 0.256327
Epoch: 11 2400/3904 Training loss: 0.239726
Epoch: 11 3200/3904 Training loss: 0.337067
Training loss: 0.372190
Test loss: 0.514658; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 12 0/3904 Training loss: 0.555996
Epoch: 12 800/3904 Training loss: 0.256741
Epoch: 12 1600/3904 Training loss: 0.127664
Epoch: 12 2400/3904 Training loss: 0.225962
Epoch: 12 3200/3904 Training loss: 0.380525
Training loss: 0.359647
Test loss: 0.509777; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 13 0/3904 Training loss: 0.473583
Epoch: 13 800/3904 Training loss: 0.216058
Epoch: 13 1600/3904 Training loss: 0.128981
Epoch: 13 2400/3904 Training loss: 0.209125
Epoch: 13 3200/3904 Training loss: 0.349810
Training loss: 0.353346
Test loss: 0.508156; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 14 0/3904 Training loss: 0.607554
Epoch: 14 800/3904 Training loss: 0.270139
Epoch: 14 1600/3904 Training loss: 0.185669
Epoch: 14 2400/3904 Training loss: 0.226165
Epoch: 14 3200/3904 Training loss: 0.339627
Training loss: 0.355975
Test loss: 0.506342; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 15 0/3904 Training loss: 0.429302
Epoch: 15 800/3904 Training loss: 0.176402
Epoch: 15 1600/3904 Training loss: 0.137062
Epoch: 15 2400/3904 Training loss: 0.184957
Epoch: 15 3200/3904 Training loss: 0.354811
Training loss: 0.353656
Test loss: 0.493319; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 16 0/3904 Training loss: 0.216301
Epoch: 16 800/3904 Training loss: 0.203113
Epoch: 16 1600/3904 Training loss: 0.163986
Epoch: 16 2400/3904 Training loss: 0.215794
Epoch: 16 3200/3904 Training loss: 0.354185
Training loss: 0.332784
Test loss: 0.483863; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 17 0/3904 Training loss: 0.223825
Epoch: 17 800/3904 Training loss: 0.221577
Epoch: 17 1600/3904 Training loss: 0.097785
Epoch: 17 2400/3904 Training loss: 0.222441
Epoch: 17 3200/3904 Training loss: 0.328788
Training loss: 0.332864
Test loss: 0.479710; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 18 0/3904 Training loss: 0.248695
Epoch: 18 800/3904 Training loss: 0.110090
Epoch: 18 1600/3904 Training loss: 0.104275
Epoch: 18 2400/3904 Training loss: 0.179707
Epoch: 18 3200/3904 Training loss: 0.334840
Training loss: 0.316887
Test loss: 0.483219; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 19 0/3904 Training loss: 0.554919
Epoch: 19 800/3904 Training loss: 0.119788
Epoch: 19 1600/3904 Training loss: 0.105967
Epoch: 19 2400/3904 Training loss: 0.171011
Epoch: 19 3200/3904 Training loss: 0.425813
Training loss: 0.316340
Test loss: 0.503182; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 20 0/3904 Training loss: 0.193999
Epoch: 20 800/3904 Training loss: 0.265111
Epoch: 20 1600/3904 Training loss: 0.114035
Epoch: 20 2400/3904 Training loss: 0.201741
Epoch: 20 3200/3904 Training loss: 0.311669
Training loss: 0.316333
Test loss: 0.500912; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 21 0/3904 Training loss: 0.239840
Epoch: 21 800/3904 Training loss: 0.440820
Epoch: 21 1600/3904 Training loss: 0.122698
Epoch: 21 2400/3904 Training loss: 0.218629
Epoch: 21 3200/3904 Training loss: 0.418724
Training loss: 0.304810
Test loss: 0.515062; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 22 0/3904 Training loss: 0.166475
Epoch: 22 800/3904 Training loss: 0.187270
Epoch: 22 1600/3904 Training loss: 0.153206
Epoch: 22 2400/3904 Training loss: 0.119354
Epoch: 22 3200/3904 Training loss: 0.373607
Training loss: 0.287033
Test loss: 0.507633; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 23 0/3904 Training loss: 0.294832
Epoch: 23 800/3904 Training loss: 0.324602
Epoch: 23 1600/3904 Training loss: 0.093993
Epoch: 23 2400/3904 Training loss: 0.207279
Epoch: 23 3200/3904 Training loss: 0.452486
Training loss: 0.296293
Test loss: 0.545921; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 24 0/3904 Training loss: 0.362040
Epoch: 24 800/3904 Training loss: 0.144042
Epoch: 24 1600/3904 Training loss: 0.094221
Epoch: 24 2400/3904 Training loss: 0.174196
Epoch: 24 3200/3904 Training loss: 0.444441
Training loss: 0.286203
Test loss: 0.710216; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 25 0/3904 Training loss: 0.289255
Epoch: 25 800/3904 Training loss: 0.174094
Epoch: 25 1600/3904 Training loss: 0.099234
Epoch: 25 2400/3904 Training loss: 0.165718
Epoch: 25 3200/3904 Training loss: 0.443717
Training loss: 0.279962
Test loss: 0.646657; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 26 0/3904 Training loss: 0.307746
Epoch: 26 800/3904 Training loss: 0.198407
Epoch: 26 1600/3904 Training loss: 0.079811
Epoch: 26 2400/3904 Training loss: 0.122263
Epoch: 26 3200/3904 Training loss: 0.411967
Training loss: 0.277449
Test loss: 0.699936; True positive: 146; True negative: 206, False Positive: 59, False negative: 757, accuracy: 0.3013698630136986, precision: 0.7121951219512195, recall: 0.16168327796234774
Epoch: 27 0/3904 Training loss: 0.208709
Epoch: 27 800/3904 Training loss: 0.183081
Epoch: 27 1600/3904 Training loss: 0.108738
Epoch: 27 2400/3904 Training loss: 0.112632
Epoch: 27 3200/3904 Training loss: 0.383746
Training loss: 0.295505
Test loss: 0.537594; True positive: 719; True negative: 143, False Positive: 122, False negative: 184, accuracy: 0.738013698630137, precision: 0.8549346016646849, recall: 0.7962347729789591
starting trial 264
[I 2022-12-05 07:37:35,024] Trial 263 finished with value: 0.8176369863013698 and parameters: {'d_model': 64, 'nhead': 8, 'n_encoders': 1, 'learning_rate': 8.062719493049614e-05, 'weight_decay': 4.189229409639741e-06, 'dropout': 0.19651749842380806, 'max_pool_conv': 32, 'kernel_size': 20, 'd_mlp': 16, 'num_conv_layers': 8, 'encoder_dropout': 0.13243442384146595, 'd_feed_forward': 128, 'max_pool_dim': 8, 'n_mlp_layers': 3}. Best is trial 62 with value: 0.860445205479452.
Epoch: 0 0/3904 Training loss: 0.695661
Epoch: 0 800/3904 Training loss: 0.716609
Epoch: 0 1600/3904 Training loss: 0.438434
Epoch: 0 2400/3904 Training loss: 0.790361
Epoch: 0 3200/3904 Training loss: 0.554676
Training loss: 0.662004
Test loss: 0.949797; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 1 0/3904 Training loss: 0.711675
Epoch: 1 800/3904 Training loss: 0.729881
Epoch: 1 1600/3904 Training loss: 0.408466
Epoch: 1 2400/3904 Training loss: 0.761040
Epoch: 1 3200/3904 Training loss: 0.450689
Training loss: 0.626406
Test loss: 0.993277; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 2 0/3904 Training loss: 0.669486
Epoch: 2 800/3904 Training loss: 0.587091
Epoch: 2 1600/3904 Training loss: 0.256772
Epoch: 2 2400/3904 Training loss: 0.757577
Epoch: 2 3200/3904 Training loss: 0.385338
Training loss: 0.528813
Test loss: 0.797674; True positive: 287; True negative: 216, False Positive: 49, False negative: 616, accuracy: 0.4306506849315068, precision: 0.8541666666666666, recall: 0.3178294573643411
Epoch: 3 0/3904 Training loss: 0.568721
Epoch: 3 800/3904 Training loss: 0.613837
Epoch: 3 1600/3904 Training loss: 0.227867
Epoch: 3 2400/3904 Training loss: 0.616859
Epoch: 3 3200/3904 Training loss: 0.394016
Training loss: 0.475613
Test loss: 0.993255; True positive: 444; True negative: 140, False Positive: 125, False negative: 459, accuracy: 0.5, precision: 0.7803163444639719, recall: 0.49169435215946844
Epoch: 4 0/3904 Training loss: 0.503112
Epoch: 4 800/3904 Training loss: 0.501926
Epoch: 4 1600/3904 Training loss: 0.208759
Epoch: 4 2400/3904 Training loss: 0.500288
Epoch: 4 3200/3904 Training loss: 0.340760
Training loss: 0.425392
Test loss: 0.630440; True positive: 802; True negative: 117, False Positive: 148, False negative: 101, accuracy: 0.7868150684931506, precision: 0.8442105263157895, recall: 0.8881506090808416
Epoch: 5 0/3904 Training loss: 0.428775
Epoch: 5 800/3904 Training loss: 0.451278
Epoch: 5 1600/3904 Training loss: 0.209184
Epoch: 5 2400/3904 Training loss: 0.408098
Epoch: 5 3200/3904 Training loss: 0.412668
Training loss: 0.397912
Test loss: 0.554080; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 6 0/3904 Training loss: 0.432583
Epoch: 6 800/3904 Training loss: 0.398407
Epoch: 6 1600/3904 Training loss: 0.173205
Epoch: 6 2400/3904 Training loss: 0.319339
Epoch: 6 3200/3904 Training loss: 0.413633
Training loss: 0.367533
Test loss: 0.561550; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 7 0/3904 Training loss: 0.339332
Epoch: 7 800/3904 Training loss: 0.410660
Epoch: 7 1600/3904 Training loss: 0.191210
Epoch: 7 2400/3904 Training loss: 0.265125
Epoch: 7 3200/3904 Training loss: 0.491455
Training loss: 0.344378
Test loss: 0.560457; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 8 0/3904 Training loss: 0.446279
Epoch: 8 800/3904 Training loss: 0.322804
Epoch: 8 1600/3904 Training loss: 0.168613
Epoch: 8 2400/3904 Training loss: 0.211579
Epoch: 8 3200/3904 Training loss: 0.347396
Training loss: 0.337338
Test loss: 0.561094; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 9 0/3904 Training loss: 0.518117
Epoch: 9 800/3904 Training loss: 0.283367
Epoch: 9 1600/3904 Training loss: 0.163257
Epoch: 9 2400/3904 Training loss: 0.187382
Epoch: 9 3200/3904 Training loss: 0.516933
Training loss: 0.323165
Test loss: 0.564529; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 10 0/3904 Training loss: 0.496878
Epoch: 10 800/3904 Training loss: 0.356027
Epoch: 10 1600/3904 Training loss: 0.153189
Epoch: 10 2400/3904 Training loss: 0.192941
Epoch: 10 3200/3904 Training loss: 0.336462
Training loss: 0.314941
Test loss: 0.578341; True positive: 837; True negative: 117, False Positive: 148, False negative: 66, accuracy: 0.8167808219178082, precision: 0.849746192893401, recall: 0.9269102990033222
Epoch: 11 0/3904 Training loss: 0.492452
Epoch: 11 800/3904 Training loss: 0.328686
Epoch: 11 1600/3904 Training loss: 0.185580
Epoch: 11 2400/3904 Training loss: 0.191989
Epoch: 11 3200/3904 Training loss: 0.407281
Training loss: 0.303325
Test loss: 0.582563; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 12 0/3904 Training loss: 0.447384
Epoch: 12 800/3904 Training loss: 0.302694
Epoch: 12 1600/3904 Training loss: 0.145408
Epoch: 12 2400/3904 Training loss: 0.148403
Epoch: 12 3200/3904 Training loss: 0.342251
Training loss: 0.294138
Test loss: 0.583124; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 13 0/3904 Training loss: 0.357924
Epoch: 13 800/3904 Training loss: 0.290369
Epoch: 13 1600/3904 Training loss: 0.175297
Epoch: 13 2400/3904 Training loss: 0.135775
Epoch: 13 3200/3904 Training loss: 0.332256
Training loss: 0.277120
Test loss: 0.591942; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 14 0/3904 Training loss: 0.252438
Epoch: 14 800/3904 Training loss: 0.350055
Epoch: 14 1600/3904 Training loss: 0.158628
Epoch: 14 2400/3904 Training loss: 0.129913
Epoch: 14 3200/3904 Training loss: 0.408260
Training loss: 0.265924
Test loss: 0.607148; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 15 0/3904 Training loss: 0.272884
Epoch: 15 800/3904 Training loss: 0.176258
Epoch: 15 1600/3904 Training loss: 0.125204
Epoch: 15 2400/3904 Training loss: 0.117962
Epoch: 15 3200/3904 Training loss: 0.352306
Training loss: 0.253307
Test loss: 0.609661; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
starting trial 265
[I 2022-12-05 07:40:42,551] Trial 264 finished with value: 0.8176369863013698 and parameters: {'d_model': 64, 'nhead': 8, 'n_encoders': 1, 'learning_rate': 5.6387965600329784e-05, 'weight_decay': 3.603789418472849e-06, 'dropout': 0.174602056268735, 'max_pool_conv': 32, 'kernel_size': 19, 'd_mlp': 16, 'num_conv_layers': 5, 'encoder_dropout': 0.15513085959243622, 'd_feed_forward': 128, 'max_pool_dim': 8, 'n_mlp_layers': 3}. Best is trial 62 with value: 0.860445205479452.
Epoch: 0 0/3904 Training loss: 0.702153
Epoch: 0 800/3904 Training loss: 0.707989
Epoch: 0 1600/3904 Training loss: 0.451983
Epoch: 0 2400/3904 Training loss: 0.790869
Epoch: 0 3200/3904 Training loss: 0.547661
Training loss: 0.659998
Test loss: 0.872290; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 1 0/3904 Training loss: 0.710582
Epoch: 1 800/3904 Training loss: 0.677984
Epoch: 1 1600/3904 Training loss: 0.333764
Epoch: 1 2400/3904 Training loss: 0.736633
Epoch: 1 3200/3904 Training loss: 0.380558
Training loss: 0.578076
Test loss: 1.275151; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 2 0/3904 Training loss: 0.580960
Epoch: 2 800/3904 Training loss: 0.422410
Epoch: 2 1600/3904 Training loss: 0.245804
Epoch: 2 2400/3904 Training loss: 0.531256
Epoch: 2 3200/3904 Training loss: 0.431945
Training loss: 0.482328
Test loss: 1.504424; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 3 0/3904 Training loss: 0.459829
Epoch: 3 800/3904 Training loss: 0.332465
Epoch: 3 1600/3904 Training loss: 0.245231
Epoch: 3 2400/3904 Training loss: 0.484432
Epoch: 3 3200/3904 Training loss: 0.415886
Training loss: 0.438605
Test loss: 1.678784; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 4 0/3904 Training loss: 0.453865
Epoch: 4 800/3904 Training loss: 0.262526
Epoch: 4 1600/3904 Training loss: 0.219902
Epoch: 4 2400/3904 Training loss: 0.412612
Epoch: 4 3200/3904 Training loss: 0.406600
Training loss: 0.409023
Test loss: 1.859883; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 5 0/3904 Training loss: 0.318921
Epoch: 5 800/3904 Training loss: 0.289277
Epoch: 5 1600/3904 Training loss: 0.204401
Epoch: 5 2400/3904 Training loss: 0.342601
Epoch: 5 3200/3904 Training loss: 0.412023
Training loss: 0.394772
Test loss: 2.014607; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 6 0/3904 Training loss: 0.315240
Epoch: 6 800/3904 Training loss: 0.191146
Epoch: 6 1600/3904 Training loss: 0.181652
Epoch: 6 2400/3904 Training loss: 0.379645
Epoch: 6 3200/3904 Training loss: 0.394388
Training loss: 0.384257
Test loss: 2.082188; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 7 0/3904 Training loss: 0.294567
Epoch: 7 800/3904 Training loss: 0.218620
Epoch: 7 1600/3904 Training loss: 0.182197
Epoch: 7 2400/3904 Training loss: 0.457063
Epoch: 7 3200/3904 Training loss: 0.422058
Training loss: 0.371384
Test loss: 2.486053; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 8 0/3904 Training loss: 0.246740
Epoch: 8 800/3904 Training loss: 0.173662
Epoch: 8 1600/3904 Training loss: 0.147256
Epoch: 8 2400/3904 Training loss: 0.224275
Epoch: 8 3200/3904 Training loss: 0.387196
Training loss: 0.366804
Test loss: 0.517268; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 9 0/3904 Training loss: 0.329573
Epoch: 9 800/3904 Training loss: 0.162785
Epoch: 9 1600/3904 Training loss: 0.183764
Epoch: 9 2400/3904 Training loss: 0.243086
Epoch: 9 3200/3904 Training loss: 0.346077
Training loss: 0.363980
Test loss: 0.514650; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 10 0/3904 Training loss: 0.263459
Epoch: 10 800/3904 Training loss: 0.184039
Epoch: 10 1600/3904 Training loss: 0.159479
Epoch: 10 2400/3904 Training loss: 0.227184
Epoch: 10 3200/3904 Training loss: 0.435740
Training loss: 0.348260
Test loss: 0.515981; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 11 0/3904 Training loss: 0.314471
Epoch: 11 800/3904 Training loss: 0.188637
Epoch: 11 1600/3904 Training loss: 0.174795
Epoch: 11 2400/3904 Training loss: 0.207052
Epoch: 11 3200/3904 Training loss: 0.351898
Training loss: 0.350800
Test loss: 0.525435; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 12 0/3904 Training loss: 0.239169
Epoch: 12 800/3904 Training loss: 0.157259
Epoch: 12 1600/3904 Training loss: 0.148652
Epoch: 12 2400/3904 Training loss: 0.204240
Epoch: 12 3200/3904 Training loss: 0.268996
Training loss: 0.342238
Test loss: 0.527957; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 13 0/3904 Training loss: 0.245928
Epoch: 13 800/3904 Training loss: 0.150794
Epoch: 13 1600/3904 Training loss: 0.145453
Epoch: 13 2400/3904 Training loss: 0.193867
Epoch: 13 3200/3904 Training loss: 0.392589
Training loss: 0.326021
Test loss: 0.525011; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 14 0/3904 Training loss: 0.226814
Epoch: 14 800/3904 Training loss: 0.246930
Epoch: 14 1600/3904 Training loss: 0.165866
Epoch: 14 2400/3904 Training loss: 0.222087
Epoch: 14 3200/3904 Training loss: 0.295845
Training loss: 0.345084
Test loss: 0.527477; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 15 0/3904 Training loss: 0.310475
Epoch: 15 800/3904 Training loss: 0.177382
Epoch: 15 1600/3904 Training loss: 0.125376
Epoch: 15 2400/3904 Training loss: 0.192209
Epoch: 15 3200/3904 Training loss: 0.339725
Training loss: 0.335745
Test loss: 0.528728; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 16 0/3904 Training loss: 0.233196
Epoch: 16 800/3904 Training loss: 0.157052
Epoch: 16 1600/3904 Training loss: 0.111525
Epoch: 16 2400/3904 Training loss: 0.207024
Epoch: 16 3200/3904 Training loss: 0.338851
Training loss: 0.324087
Test loss: 0.525279; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 17 0/3904 Training loss: 0.331195
Epoch: 17 800/3904 Training loss: 0.202325
Epoch: 17 1600/3904 Training loss: 0.116655
Epoch: 17 2400/3904 Training loss: 0.210310
Epoch: 17 3200/3904 Training loss: 0.286998
Training loss: 0.323995
Test loss: 0.530710; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 18 0/3904 Training loss: 0.278962
Epoch: 18 800/3904 Training loss: 0.144921
Epoch: 18 1600/3904 Training loss: 0.129583
Epoch: 18 2400/3904 Training loss: 0.210741
Epoch: 18 3200/3904 Training loss: 0.305686
Training loss: 0.315101
Test loss: 0.530299; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 19 0/3904 Training loss: 0.509506
Epoch: 19 800/3904 Training loss: 0.131608
Epoch: 19 1600/3904 Training loss: 0.125236
Epoch: 19 2400/3904 Training loss: 0.169152
Epoch: 19 3200/3904 Training loss: 0.342486
Training loss: 0.314745
Test loss: 0.526796; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
starting trial 266
[I 2022-12-05 07:47:29,277] Trial 265 finished with value: 0.8176369863013698 and parameters: {'d_model': 64, 'nhead': 8, 'n_encoders': 2, 'learning_rate': 6.537241099218611e-05, 'weight_decay': 3.012082692720591e-06, 'dropout': 0.1863815955369906, 'max_pool_conv': 32, 'kernel_size': 20, 'd_mlp': 16, 'num_conv_layers': 8, 'encoder_dropout': 0.10634958061624768, 'd_feed_forward': 128, 'max_pool_dim': 8, 'n_mlp_layers': 3}. Best is trial 62 with value: 0.860445205479452.
Epoch: 0 0/3904 Training loss: 0.695630
Epoch: 0 800/3904 Training loss: 0.727273
Epoch: 0 1600/3904 Training loss: 0.458658
Epoch: 0 2400/3904 Training loss: 0.813188
Epoch: 0 3200/3904 Training loss: 0.558310
Training loss: 0.662408
Test loss: 0.869586; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 1 0/3904 Training loss: 0.712605
Epoch: 1 800/3904 Training loss: 0.735067
Epoch: 1 1600/3904 Training loss: 0.396638
Epoch: 1 2400/3904 Training loss: 0.726130
Epoch: 1 3200/3904 Training loss: 0.457463
Training loss: 0.626119
Test loss: 0.744093; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 2 0/3904 Training loss: 0.662016
Epoch: 2 800/3904 Training loss: 0.544267
Epoch: 2 1600/3904 Training loss: 0.282755
Epoch: 2 2400/3904 Training loss: 0.715801
Epoch: 2 3200/3904 Training loss: 0.401634
Training loss: 0.519965
Test loss: 0.635976; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 3 0/3904 Training loss: 0.457539
Epoch: 3 800/3904 Training loss: 0.328823
Epoch: 3 1600/3904 Training loss: 0.267873
Epoch: 3 2400/3904 Training loss: 0.398972
Epoch: 3 3200/3904 Training loss: 0.430985
Training loss: 0.447743
Test loss: 0.612674; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 4 0/3904 Training loss: 0.365033
Epoch: 4 800/3904 Training loss: 0.383604
Epoch: 4 1600/3904 Training loss: 0.277397
Epoch: 4 2400/3904 Training loss: 0.378324
Epoch: 4 3200/3904 Training loss: 0.389153
Training loss: 0.414508
Test loss: 0.608249; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 5 0/3904 Training loss: 0.333253
Epoch: 5 800/3904 Training loss: 0.279146
Epoch: 5 1600/3904 Training loss: 0.164035
Epoch: 5 2400/3904 Training loss: 0.248578
Epoch: 5 3200/3904 Training loss: 0.358099
Training loss: 0.397198
Test loss: 0.605473; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 6 0/3904 Training loss: 0.387209
Epoch: 6 800/3904 Training loss: 0.254614
Epoch: 6 1600/3904 Training loss: 0.208127
Epoch: 6 2400/3904 Training loss: 0.253844
Epoch: 6 3200/3904 Training loss: 0.379813
Training loss: 0.383062
Test loss: 0.612509; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 7 0/3904 Training loss: 0.327210
Epoch: 7 800/3904 Training loss: 0.213311
Epoch: 7 1600/3904 Training loss: 0.206473
Epoch: 7 2400/3904 Training loss: 0.279181
Epoch: 7 3200/3904 Training loss: 0.384194
Training loss: 0.368816
Test loss: 0.619187; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 8 0/3904 Training loss: 0.317731
Epoch: 8 800/3904 Training loss: 0.172328
Epoch: 8 1600/3904 Training loss: 0.171577
Epoch: 8 2400/3904 Training loss: 0.230661
Epoch: 8 3200/3904 Training loss: 0.389268
Training loss: 0.360158
Test loss: 0.620079; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 9 0/3904 Training loss: 0.324419
Epoch: 9 800/3904 Training loss: 0.171246
Epoch: 9 1600/3904 Training loss: 0.157071
Epoch: 9 2400/3904 Training loss: 0.206341
Epoch: 9 3200/3904 Training loss: 0.336966
Training loss: 0.349828
Test loss: 0.629188; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 10 0/3904 Training loss: 0.317549
Epoch: 10 800/3904 Training loss: 0.180908
Epoch: 10 1600/3904 Training loss: 0.129430
Epoch: 10 2400/3904 Training loss: 0.177119
Epoch: 10 3200/3904 Training loss: 0.344022
Training loss: 0.329251
Test loss: 0.649016; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 11 0/3904 Training loss: 0.335159
Epoch: 11 800/3904 Training loss: 0.184062
Epoch: 11 1600/3904 Training loss: 0.090763
Epoch: 11 2400/3904 Training loss: 0.199680
Epoch: 11 3200/3904 Training loss: 0.329264
Training loss: 0.326129
Test loss: 0.657285; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 12 0/3904 Training loss: 0.289683
Epoch: 12 800/3904 Training loss: 0.128797
Epoch: 12 1600/3904 Training loss: 0.200134
Epoch: 12 2400/3904 Training loss: 0.165680
Epoch: 12 3200/3904 Training loss: 0.332483
Training loss: 0.300236
Test loss: 0.689816; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 13 0/3904 Training loss: 0.296309
Epoch: 13 800/3904 Training loss: 0.106103
Epoch: 13 1600/3904 Training loss: 0.154022
Epoch: 13 2400/3904 Training loss: 0.207605
Epoch: 13 3200/3904 Training loss: 0.324044
Training loss: 0.278133
Test loss: 0.735377; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 14 0/3904 Training loss: 0.376784
Epoch: 14 800/3904 Training loss: 0.135141
Epoch: 14 1600/3904 Training loss: 0.108328
Epoch: 14 2400/3904 Training loss: 0.162509
Epoch: 14 3200/3904 Training loss: 0.265040
Training loss: 0.279021
Test loss: 0.718068; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 15 0/3904 Training loss: 0.277668
Epoch: 15 800/3904 Training loss: 0.127214
Epoch: 15 1600/3904 Training loss: 0.123383
Epoch: 15 2400/3904 Training loss: 0.190988
Epoch: 15 3200/3904 Training loss: 0.407696
Training loss: 0.258175
Test loss: 0.720750; True positive: 836; True negative: 119, False Positive: 146, False negative: 67, accuracy: 0.8176369863013698, precision: 0.8513238289205702, recall: 0.9258028792912514
starting trial 267
[I 2022-12-05 07:48:42,940] Trial 266 finished with value: 0.8176369863013698 and parameters: {'d_model': 32, 'nhead': 8, 'n_encoders': 1, 'learning_rate': 0.00012082959165056385, 'weight_decay': 5.06125679668121e-06, 'dropout': 0.20544292606299125, 'max_pool_conv': 32, 'kernel_size': 19, 'd_mlp': 16, 'num_conv_layers': 4, 'encoder_dropout': 0.17267376901806636, 'd_feed_forward': 64, 'max_pool_dim': 4, 'n_mlp_layers': 3}. Best is trial 62 with value: 0.860445205479452.
Epoch: 0 0/3904 Training loss: 0.695280
Epoch: 0 800/3904 Training loss: 0.733421
Epoch: 0 1600/3904 Training loss: 0.437177
Epoch: 0 2400/3904 Training loss: 0.786263
Epoch: 0 3200/3904 Training loss: 0.557319
Training loss: 0.662838
Test loss: 0.753499; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 1 0/3904 Training loss: 0.710425
Epoch: 1 800/3904 Training loss: 0.732603
Epoch: 1 1600/3904 Training loss: 0.454480
Epoch: 1 2400/3904 Training loss: 0.820523
Epoch: 1 3200/3904 Training loss: 0.559730
Training loss: 0.659804
Test loss: 0.759173; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 2 0/3904 Training loss: 0.706507
Epoch: 2 800/3904 Training loss: 0.742477
Epoch: 2 1600/3904 Training loss: 0.473449
Epoch: 2 2400/3904 Training loss: 0.806867
Epoch: 2 3200/3904 Training loss: 0.554752
Training loss: 0.655880
Test loss: 0.708653; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 3 0/3904 Training loss: 0.717309
Epoch: 3 800/3904 Training loss: 0.726921
Epoch: 3 1600/3904 Training loss: 0.388216
Epoch: 3 2400/3904 Training loss: 0.782484
Epoch: 3 3200/3904 Training loss: 0.510737
Training loss: 0.638199
Test loss: 0.709154; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 4 0/3904 Training loss: 0.668571
Epoch: 4 800/3904 Training loss: 0.672857
Epoch: 4 1600/3904 Training loss: 0.325963
Epoch: 4 2400/3904 Training loss: 0.850863
Epoch: 4 3200/3904 Training loss: 0.451940
Training loss: 0.597652
Test loss: 0.984746; True positive: 57; True negative: 232, False Positive: 33, False negative: 846, accuracy: 0.24743150684931506, precision: 0.6333333333333333, recall: 0.06312292358803986
Epoch: 5 0/3904 Training loss: 0.563433
Epoch: 5 800/3904 Training loss: 0.606643
Epoch: 5 1600/3904 Training loss: 0.248646
Epoch: 5 2400/3904 Training loss: 0.968532
Epoch: 5 3200/3904 Training loss: 0.463538
Training loss: 0.536945
Test loss: 1.117279; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 6 0/3904 Training loss: 0.503537
Epoch: 6 800/3904 Training loss: 0.494691
Epoch: 6 1600/3904 Training loss: 0.223958
Epoch: 6 2400/3904 Training loss: 0.850536
Epoch: 6 3200/3904 Training loss: 0.403706
Training loss: 0.461135
Test loss: 1.275257; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 7 0/3904 Training loss: 0.449337
Epoch: 7 800/3904 Training loss: 0.443143
Epoch: 7 1600/3904 Training loss: 0.142307
Epoch: 7 2400/3904 Training loss: 0.989596
Epoch: 7 3200/3904 Training loss: 0.378821
Training loss: 0.425884
Test loss: 1.318470; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 8 0/3904 Training loss: 0.357960
Epoch: 8 800/3904 Training loss: 0.329122
Epoch: 8 1600/3904 Training loss: 0.172590
Epoch: 8 2400/3904 Training loss: 0.364462
Epoch: 8 3200/3904 Training loss: 0.516382
Training loss: 0.401018
Test loss: 1.234888; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 9 0/3904 Training loss: 0.506951
Epoch: 9 800/3904 Training loss: 0.458435
Epoch: 9 1600/3904 Training loss: 0.218229
Epoch: 9 2400/3904 Training loss: 0.564196
Epoch: 9 3200/3904 Training loss: 0.396138
Training loss: 0.366058
Test loss: 1.263647; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 10 0/3904 Training loss: 0.521010
Epoch: 10 800/3904 Training loss: 0.403017
Epoch: 10 1600/3904 Training loss: 0.231690
Epoch: 10 2400/3904 Training loss: 0.411782
Epoch: 10 3200/3904 Training loss: 0.427879
Training loss: 0.333172
Test loss: 2.097464; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 11 0/3904 Training loss: 0.337791
Epoch: 11 800/3904 Training loss: 0.381176
Epoch: 11 1600/3904 Training loss: 0.143442
Epoch: 11 2400/3904 Training loss: 0.426668
Epoch: 11 3200/3904 Training loss: 0.458846
Training loss: 0.314989
Test loss: 2.357112; True positive: 93; True negative: 124, False Positive: 141, False negative: 810, accuracy: 0.1857876712328767, precision: 0.3974358974358974, recall: 0.10299003322259136
Epoch: 12 0/3904 Training loss: 0.250120
Epoch: 12 800/3904 Training loss: 0.346026
Epoch: 12 1600/3904 Training loss: 0.157844
Epoch: 12 2400/3904 Training loss: 0.318170
Epoch: 12 3200/3904 Training loss: 0.535766
Training loss: 0.306036
Test loss: 1.257539; True positive: 515; True negative: 36, False Positive: 229, False negative: 388, accuracy: 0.4717465753424658, precision: 0.6922043010752689, recall: 0.5703211517165006
starting trial 268
[I 2022-12-05 07:53:09,345] Trial 267 finished with value: 0.4717465753424658 and parameters: {'d_model': 64, 'nhead': 8, 'n_encoders': 1, 'learning_rate': 8.307045277259608e-05, 'weight_decay': 3.0887737548581073e-06, 'dropout': 0.19034273040889316, 'max_pool_conv': 16, 'kernel_size': 20, 'd_mlp': 16, 'num_conv_layers': 8, 'encoder_dropout': 0.11459693600803078, 'd_feed_forward': 128, 'max_pool_dim': 8, 'n_mlp_layers': 3}. Best is trial 62 with value: 0.860445205479452.
Epoch: 0 0/3904 Training loss: 0.698574
Epoch: 0 800/3904 Training loss: 0.731834
Epoch: 0 1600/3904 Training loss: 0.456948
Epoch: 0 2400/3904 Training loss: 0.782195
Epoch: 0 3200/3904 Training loss: 0.539145
Training loss: 0.655511
Test loss: 0.767961; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 1 0/3904 Training loss: 0.711616
Epoch: 1 800/3904 Training loss: 0.655560
Epoch: 1 1600/3904 Training loss: 0.346255
Epoch: 1 2400/3904 Training loss: 0.529560
Epoch: 1 3200/3904 Training loss: 0.405432
Training loss: 0.551989
Test loss: 1.644621; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 2 0/3904 Training loss: 0.422736
Epoch: 2 800/3904 Training loss: 0.377705
Epoch: 2 1600/3904 Training loss: 0.254447
Epoch: 2 2400/3904 Training loss: 0.362519
Epoch: 2 3200/3904 Training loss: 0.395060
Training loss: 0.452361
Test loss: 1.857930; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 3 0/3904 Training loss: 0.406137
Epoch: 3 800/3904 Training loss: 0.306663
Epoch: 3 1600/3904 Training loss: 0.248472
Epoch: 3 2400/3904 Training loss: 0.341384
Epoch: 3 3200/3904 Training loss: 0.401176
Training loss: 0.413215
Test loss: 2.300931; True positive: 1; True negative: 265, False Positive: 0, False negative: 902, accuracy: 0.22773972602739725, precision: 1.0, recall: 0.0011074197120708748
Epoch: 4 0/3904 Training loss: 0.387880
Epoch: 4 800/3904 Training loss: 0.268848
Epoch: 4 1600/3904 Training loss: 0.236608
Epoch: 4 2400/3904 Training loss: 0.248465
Epoch: 4 3200/3904 Training loss: 0.350045
Training loss: 0.391040
Test loss: 1.540251; True positive: 315; True negative: 260, False Positive: 5, False negative: 588, accuracy: 0.4922945205479452, precision: 0.984375, recall: 0.3488372093023256
Epoch: 5 0/3904 Training loss: 0.329095
Epoch: 5 800/3904 Training loss: 0.228186
Epoch: 5 1600/3904 Training loss: 0.217581
Epoch: 5 2400/3904 Training loss: 0.243653
Epoch: 5 3200/3904 Training loss: 0.376066
Training loss: 0.380217
Test loss: 2.148685; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 6 0/3904 Training loss: 0.385263
Epoch: 6 800/3904 Training loss: 0.205560
Epoch: 6 1600/3904 Training loss: 0.235729
Epoch: 6 2400/3904 Training loss: 0.219273
Epoch: 6 3200/3904 Training loss: 0.364752
Training loss: 0.364276
Test loss: 2.391484; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 7 0/3904 Training loss: 0.410851
Epoch: 7 800/3904 Training loss: 0.176019
Epoch: 7 1600/3904 Training loss: 0.243443
Epoch: 7 2400/3904 Training loss: 0.262406
Epoch: 7 3200/3904 Training loss: 0.379788
Training loss: 0.356422
Test loss: 2.224944; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 8 0/3904 Training loss: 0.387206
Epoch: 8 800/3904 Training loss: 0.190372
Epoch: 8 1600/3904 Training loss: 0.189487
Epoch: 8 2400/3904 Training loss: 0.208405
Epoch: 8 3200/3904 Training loss: 0.422950
Training loss: 0.350783
Test loss: 2.248585; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 9 0/3904 Training loss: 0.502241
Epoch: 9 800/3904 Training loss: 0.141857
Epoch: 9 1600/3904 Training loss: 0.159039
Epoch: 9 2400/3904 Training loss: 0.261405
Epoch: 9 3200/3904 Training loss: 0.365062
Training loss: 0.341503
Test loss: 2.439600; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 10 0/3904 Training loss: 0.430052
Epoch: 10 800/3904 Training loss: 0.122466
Epoch: 10 1600/3904 Training loss: 0.205260
Epoch: 10 2400/3904 Training loss: 0.178849
Epoch: 10 3200/3904 Training loss: 0.434686
Training loss: 0.325261
Test loss: 2.495231; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
starting trial 269
[I 2022-12-05 07:55:17,203] Trial 268 finished with value: 0.4922945205479452 and parameters: {'d_model': 64, 'nhead': 8, 'n_encoders': 1, 'learning_rate': 0.00010903731089350188, 'weight_decay': 4.020671862877086e-06, 'dropout': 0.19759861198660414, 'max_pool_conv': 32, 'kernel_size': 18, 'd_mlp': 16, 'num_conv_layers': 5, 'encoder_dropout': 0.1291229847463005, 'd_feed_forward': 128, 'max_pool_dim': 8, 'n_mlp_layers': 3}. Best is trial 62 with value: 0.860445205479452.
Epoch: 0 0/3904 Training loss: 0.715207
Epoch: 0 800/3904 Training loss: 0.719329
Epoch: 0 1600/3904 Training loss: 0.443093
Epoch: 0 2400/3904 Training loss: 0.763089
Epoch: 0 3200/3904 Training loss: 0.538712
Training loss: 0.668418
Test loss: 0.793402; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 1 0/3904 Training loss: 0.702039
Epoch: 1 800/3904 Training loss: 0.701514
Epoch: 1 1600/3904 Training loss: 0.439482
Epoch: 1 2400/3904 Training loss: 0.780421
Epoch: 1 3200/3904 Training loss: 0.554429
Training loss: 0.663149
Test loss: 0.799749; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 2 0/3904 Training loss: 0.704734
Epoch: 2 800/3904 Training loss: 0.722353
Epoch: 2 1600/3904 Training loss: 0.291654
Epoch: 2 2400/3904 Training loss: 0.737858
Epoch: 2 3200/3904 Training loss: 0.527521
Training loss: 0.637576
Test loss: 0.680595; True positive: 903; True negative: 0, False Positive: 265, False negative: 0, accuracy: 0.7731164383561644, precision: 0.7731164383561644, recall: 1.0
Epoch: 3 0/3904 Training loss: 0.702662
Epoch: 3 800/3904 Training loss: 0.672224
Epoch: 3 1600/3904 Training loss: 0.228898
Epoch: 3 2400/3904 Training loss: 0.663259
Epoch: 3 3200/3904 Training loss: 0.447108
Training loss: 0.576529
Test loss: 0.591985; True positive: 903; True negative: 0, False Positive: 265, False negative: 0, accuracy: 0.7731164383561644, precision: 0.7731164383561644, recall: 1.0
Epoch: 4 0/3904 Training loss: 0.565072
Epoch: 4 800/3904 Training loss: 0.501931
Epoch: 4 1600/3904 Training loss: 0.212590
Epoch: 4 2400/3904 Training loss: 0.457877
Epoch: 4 3200/3904 Training loss: 0.431017
Training loss: 0.488265
Test loss: 0.559445; True positive: 903; True negative: 0, False Positive: 265, False negative: 0, accuracy: 0.7731164383561644, precision: 0.7731164383561644, recall: 1.0
Epoch: 5 0/3904 Training loss: 0.433864
Epoch: 5 800/3904 Training loss: 0.365716
Epoch: 5 1600/3904 Training loss: 0.208762
Epoch: 5 2400/3904 Training loss: 0.534100
Epoch: 5 3200/3904 Training loss: 0.373385
Training loss: 0.443401
Test loss: 0.539939; True positive: 903; True negative: 0, False Positive: 265, False negative: 0, accuracy: 0.7731164383561644, precision: 0.7731164383561644, recall: 1.0
Epoch: 6 0/3904 Training loss: 0.352783
Epoch: 6 800/3904 Training loss: 0.331673
Epoch: 6 1600/3904 Training loss: 0.252326
Epoch: 6 2400/3904 Training loss: 0.525369
Epoch: 6 3200/3904 Training loss: 0.378053
Training loss: 0.421895
Test loss: 0.539395; True positive: 903; True negative: 0, False Positive: 265, False negative: 0, accuracy: 0.7731164383561644, precision: 0.7731164383561644, recall: 1.0
Epoch: 7 0/3904 Training loss: 0.369389
Epoch: 7 800/3904 Training loss: 0.346852
Epoch: 7 1600/3904 Training loss: 0.174408
Epoch: 7 2400/3904 Training loss: 0.488491
Epoch: 7 3200/3904 Training loss: 0.468451
Training loss: 0.411168
Test loss: 0.537720; True positive: 903; True negative: 0, False Positive: 265, False negative: 0, accuracy: 0.7731164383561644, precision: 0.7731164383561644, recall: 1.0
Epoch: 8 0/3904 Training loss: 0.344190
Epoch: 8 800/3904 Training loss: 0.275575
Epoch: 8 1600/3904 Training loss: 0.153794
Epoch: 8 2400/3904 Training loss: 0.428832
Epoch: 8 3200/3904 Training loss: 0.324867
Training loss: 0.403619
Test loss: 0.536592; True positive: 903; True negative: 0, False Positive: 265, False negative: 0, accuracy: 0.7731164383561644, precision: 0.7731164383561644, recall: 1.0
Epoch: 9 0/3904 Training loss: 0.309060
Epoch: 9 800/3904 Training loss: 0.384789
Epoch: 9 1600/3904 Training loss: 0.159049
Epoch: 9 2400/3904 Training loss: 0.414834
Epoch: 9 3200/3904 Training loss: 0.368118
Training loss: 0.393463
Test loss: 0.535468; True positive: 903; True negative: 0, False Positive: 265, False negative: 0, accuracy: 0.7731164383561644, precision: 0.7731164383561644, recall: 1.0
Epoch: 10 0/3904 Training loss: 0.292944
Epoch: 10 800/3904 Training loss: 0.249132
Epoch: 10 1600/3904 Training loss: 0.159742
Epoch: 10 2400/3904 Training loss: 0.336167
Epoch: 10 3200/3904 Training loss: 0.305169
Training loss: 0.386029
Test loss: 0.535326; True positive: 903; True negative: 0, False Positive: 265, False negative: 0, accuracy: 0.7731164383561644, precision: 0.7731164383561644, recall: 1.0
Epoch: 11 0/3904 Training loss: 0.344862
Epoch: 11 800/3904 Training loss: 0.278145
Epoch: 11 1600/3904 Training loss: 0.161579
Epoch: 11 2400/3904 Training loss: 0.415038
Epoch: 11 3200/3904 Training loss: 0.367821
Training loss: 0.379812
Test loss: 0.535315; True positive: 903; True negative: 0, False Positive: 265, False negative: 0, accuracy: 0.7731164383561644, precision: 0.7731164383561644, recall: 1.0
Epoch: 12 0/3904 Training loss: 0.324050
Epoch: 12 800/3904 Training loss: 0.414236
Epoch: 12 1600/3904 Training loss: 0.171280
Epoch: 12 2400/3904 Training loss: 0.341873
Epoch: 12 3200/3904 Training loss: 0.373791
Training loss: 0.379759
Test loss: 0.535277; True positive: 903; True negative: 0, False Positive: 265, False negative: 0, accuracy: 0.7731164383561644, precision: 0.7731164383561644, recall: 1.0
Epoch: 13 0/3904 Training loss: 0.323063
Epoch: 13 800/3904 Training loss: 0.286738
Epoch: 13 1600/3904 Training loss: 0.173131
Epoch: 13 2400/3904 Training loss: 0.302726
Epoch: 13 3200/3904 Training loss: 0.412528
Training loss: 0.373668
Test loss: 0.535099; True positive: 903; True negative: 0, False Positive: 265, False negative: 0, accuracy: 0.7731164383561644, precision: 0.7731164383561644, recall: 1.0
Epoch: 14 0/3904 Training loss: 0.309818
Epoch: 14 800/3904 Training loss: 0.263533
Epoch: 14 1600/3904 Training loss: 0.154716
Epoch: 14 2400/3904 Training loss: 0.354783
Epoch: 14 3200/3904 Training loss: 0.327940
Training loss: 0.365756
Test loss: 0.535348; True positive: 903; True negative: 0, False Positive: 265, False negative: 0, accuracy: 0.7731164383561644, precision: 0.7731164383561644, recall: 1.0
Epoch: 15 0/3904 Training loss: 0.294552
Epoch: 15 800/3904 Training loss: 0.314261
Epoch: 15 1600/3904 Training loss: 0.157423
Epoch: 15 2400/3904 Training loss: 0.337176
Epoch: 15 3200/3904 Training loss: 0.281743
Training loss: 0.366734
Test loss: 0.536381; True positive: 903; True negative: 0, False Positive: 265, False negative: 0, accuracy: 0.7731164383561644, precision: 0.7731164383561644, recall: 1.0
Epoch: 16 0/3904 Training loss: 0.361165
Epoch: 16 800/3904 Training loss: 0.218460
Epoch: 16 1600/3904 Training loss: 0.186201
Epoch: 16 2400/3904 Training loss: 0.261208
Epoch: 16 3200/3904 Training loss: 0.292007
Training loss: 0.358338
Test loss: 0.535650; True positive: 903; True negative: 0, False Positive: 265, False negative: 0, accuracy: 0.7731164383561644, precision: 0.7731164383561644, recall: 1.0
Epoch: 17 0/3904 Training loss: 0.311807
Epoch: 17 800/3904 Training loss: 0.224472
Epoch: 17 1600/3904 Training loss: 0.155671
Epoch: 17 2400/3904 Training loss: 0.357999
Epoch: 17 3200/3904 Training loss: 0.354074
Training loss: 0.351180
Test loss: 0.538410; True positive: 903; True negative: 0, False Positive: 265, False negative: 0, accuracy: 0.7731164383561644, precision: 0.7731164383561644, recall: 1.0
Epoch: 18 0/3904 Training loss: 0.330708
Epoch: 18 800/3904 Training loss: 0.310302
Epoch: 18 1600/3904 Training loss: 0.171863
Epoch: 18 2400/3904 Training loss: 0.381563
Epoch: 18 3200/3904 Training loss: 0.325198
Training loss: 0.348616
Test loss: 0.460596; True positive: 900; True negative: 58, False Positive: 207, False negative: 3, accuracy: 0.8202054794520548, precision: 0.8130081300813008, recall: 0.9966777408637874
Epoch: 19 0/3904 Training loss: 0.304537
Epoch: 19 800/3904 Training loss: 0.247219
Epoch: 19 1600/3904 Training loss: 0.158585
Epoch: 19 2400/3904 Training loss: 0.268194
Epoch: 19 3200/3904 Training loss: 0.337884
Training loss: 0.345268
Test loss: 0.533561; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 20 0/3904 Training loss: 0.291085
Epoch: 20 800/3904 Training loss: 0.221002
Epoch: 20 1600/3904 Training loss: 0.133504
Epoch: 20 2400/3904 Training loss: 0.243876
Epoch: 20 3200/3904 Training loss: 0.370556
Training loss: 0.338354
Test loss: 0.422655; True positive: 884; True negative: 104, False Positive: 161, False negative: 19, accuracy: 0.8458904109589042, precision: 0.845933014354067, recall: 0.9789590254706534
Epoch: 21 0/3904 Training loss: 0.340777
Epoch: 21 800/3904 Training loss: 0.222409
Epoch: 21 1600/3904 Training loss: 0.143615
Epoch: 21 2400/3904 Training loss: 0.250691
Epoch: 21 3200/3904 Training loss: 0.338394
Training loss: 0.335038
Test loss: 0.440578; True positive: 880; True negative: 101, False Positive: 164, False negative: 23, accuracy: 0.8398972602739726, precision: 0.842911877394636, recall: 0.9745293466223699
Epoch: 22 0/3904 Training loss: 0.284453
Epoch: 22 800/3904 Training loss: 0.296302
Epoch: 22 1600/3904 Training loss: 0.144936
Epoch: 22 2400/3904 Training loss: 0.330969
Epoch: 22 3200/3904 Training loss: 0.328496
Training loss: 0.334061
Test loss: 0.680104; True positive: 838; True negative: 112, False Positive: 153, False negative: 65, accuracy: 0.8133561643835616, precision: 0.8456104944500504, recall: 0.9280177187153932
Epoch: 23 0/3904 Training loss: 0.358825
Epoch: 23 800/3904 Training loss: 0.263130
Epoch: 23 1600/3904 Training loss: 0.128541
Epoch: 23 2400/3904 Training loss: 0.343576
Epoch: 23 3200/3904 Training loss: 0.458078
Training loss: 0.328087
Test loss: 0.541855; True positive: 903; True negative: 0, False Positive: 265, False negative: 0, accuracy: 0.7731164383561644, precision: 0.7731164383561644, recall: 1.0
Epoch: 24 0/3904 Training loss: 0.341441
Epoch: 24 800/3904 Training loss: 0.336556
Epoch: 24 1600/3904 Training loss: 0.150733
Epoch: 24 2400/3904 Training loss: 0.329754
Epoch: 24 3200/3904 Training loss: 0.378011
Training loss: 0.332515
Test loss: 0.542096; True positive: 903; True negative: 0, False Positive: 265, False negative: 0, accuracy: 0.7731164383561644, precision: 0.7731164383561644, recall: 1.0
Epoch: 25 0/3904 Training loss: 0.276389
Epoch: 25 800/3904 Training loss: 0.315643
Epoch: 25 1600/3904 Training loss: 0.149694
Epoch: 25 2400/3904 Training loss: 0.223316
Epoch: 25 3200/3904 Training loss: 0.333777
Training loss: 0.323757
Test loss: 0.539428; True positive: 902; True negative: 3, False Positive: 262, False negative: 1, accuracy: 0.7748287671232876, precision: 0.7749140893470791, recall: 0.9988925802879292
Epoch: 26 0/3904 Training loss: 0.185744
Epoch: 26 800/3904 Training loss: 0.302865
Epoch: 26 1600/3904 Training loss: 0.176024
Epoch: 26 2400/3904 Training loss: 0.200939
Epoch: 26 3200/3904 Training loss: 0.363153
Training loss: 0.318724
Test loss: 0.544277; True positive: 903; True negative: 0, False Positive: 265, False negative: 0, accuracy: 0.7731164383561644, precision: 0.7731164383561644, recall: 1.0
Epoch: 27 0/3904 Training loss: 0.278355
Epoch: 27 800/3904 Training loss: 0.246791
Epoch: 27 1600/3904 Training loss: 0.132881
Epoch: 27 2400/3904 Training loss: 0.246266
Epoch: 27 3200/3904 Training loss: 0.242957
Training loss: 0.321945
Test loss: 0.544051; True positive: 903; True negative: 0, False Positive: 265, False negative: 0, accuracy: 0.7731164383561644, precision: 0.7731164383561644, recall: 1.0
Epoch: 28 0/3904 Training loss: 0.244863
Epoch: 28 800/3904 Training loss: 0.237002
Epoch: 28 1600/3904 Training loss: 0.117302
Epoch: 28 2400/3904 Training loss: 0.182368
Epoch: 28 3200/3904 Training loss: 0.345762
Training loss: 0.311806
Test loss: 0.545139; True positive: 902; True negative: 3, False Positive: 262, False negative: 1, accuracy: 0.7748287671232876, precision: 0.7749140893470791, recall: 0.9988925802879292
Epoch: 29 0/3904 Training loss: 0.271452
Epoch: 29 800/3904 Training loss: 0.303586
Epoch: 29 1600/3904 Training loss: 0.104878
Epoch: 29 2400/3904 Training loss: 0.184217
Epoch: 29 3200/3904 Training loss: 0.353943
Training loss: 0.309225
Test loss: 0.538603; True positive: 902; True negative: 5, False Positive: 260, False negative: 1, accuracy: 0.776541095890411, precision: 0.7762478485370051, recall: 0.9988925802879292
starting trial 270
[I 2022-12-05 07:58:13,889] Trial 269 finished with value: 0.8458904109589042 and parameters: {'d_model': 64, 'nhead': 8, 'n_encoders': 1, 'learning_rate': 0.000130793145854113, 'weight_decay': 4.698736221992153e-06, 'dropout': 0.22778647384737238, 'max_pool_conv': 32, 'kernel_size': 4, 'd_mlp': 32, 'num_conv_layers': 8, 'encoder_dropout': 0.010989924843841516, 'd_feed_forward': 128, 'max_pool_dim': 8, 'n_mlp_layers': 2}. Best is trial 62 with value: 0.860445205479452.
Epoch: 0 0/3904 Training loss: 0.682516
Epoch: 0 800/3904 Training loss: 0.721547
Epoch: 0 1600/3904 Training loss: 0.449189
Epoch: 0 2400/3904 Training loss: 0.764882
Epoch: 0 3200/3904 Training loss: 0.547475
Training loss: 0.668231
Test loss: 0.795788; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 1 0/3904 Training loss: 0.696492
Epoch: 1 800/3904 Training loss: 0.734417
Epoch: 1 1600/3904 Training loss: 0.437406
Epoch: 1 2400/3904 Training loss: 0.750659
Epoch: 1 3200/3904 Training loss: 0.550796
Training loss: 0.663281
Test loss: 0.820330; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 2 0/3904 Training loss: 0.711607
Epoch: 2 800/3904 Training loss: 0.727018
Epoch: 2 1600/3904 Training loss: 0.455861
Epoch: 2 2400/3904 Training loss: 0.819927
Epoch: 2 3200/3904 Training loss: 0.548860
Training loss: 0.663145
Test loss: 0.828403; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 3 0/3904 Training loss: 0.719189
Epoch: 3 800/3904 Training loss: 0.729112
Epoch: 3 1600/3904 Training loss: 0.390631
Epoch: 3 2400/3904 Training loss: 0.758077
Epoch: 3 3200/3904 Training loss: 0.479361
Training loss: 0.647542
Test loss: 0.705663; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 4 0/3904 Training loss: 0.646689
Epoch: 4 800/3904 Training loss: 0.692921
Epoch: 4 1600/3904 Training loss: 0.281134
Epoch: 4 2400/3904 Training loss: 0.699183
Epoch: 4 3200/3904 Training loss: 0.371988
Training loss: 0.570080
Test loss: 0.657726; True positive: 903; True negative: 0, False Positive: 265, False negative: 0, accuracy: 0.7731164383561644, precision: 0.7731164383561644, recall: 1.0
Epoch: 5 0/3904 Training loss: 0.525474
Epoch: 5 800/3904 Training loss: 0.581297
Epoch: 5 1600/3904 Training loss: 0.243877
Epoch: 5 2400/3904 Training loss: 0.679991
Epoch: 5 3200/3904 Training loss: 0.418316
Training loss: 0.512115
Test loss: 0.637428; True positive: 903; True negative: 0, False Positive: 265, False negative: 0, accuracy: 0.7731164383561644, precision: 0.7731164383561644, recall: 1.0
Epoch: 6 0/3904 Training loss: 0.491115
Epoch: 6 800/3904 Training loss: 0.493866
Epoch: 6 1600/3904 Training loss: 0.233067
Epoch: 6 2400/3904 Training loss: 0.549494
Epoch: 6 3200/3904 Training loss: 0.418614
Training loss: 0.479760
Test loss: 0.602278; True positive: 903; True negative: 0, False Positive: 265, False negative: 0, accuracy: 0.7731164383561644, precision: 0.7731164383561644, recall: 1.0
Epoch: 7 0/3904 Training loss: 0.452720
Epoch: 7 800/3904 Training loss: 0.510641
Epoch: 7 1600/3904 Training loss: 0.206906
Epoch: 7 2400/3904 Training loss: 0.558877
Epoch: 7 3200/3904 Training loss: 0.334569
Training loss: 0.456714
Test loss: 0.575452; True positive: 903; True negative: 0, False Positive: 265, False negative: 0, accuracy: 0.7731164383561644, precision: 0.7731164383561644, recall: 1.0
Epoch: 8 0/3904 Training loss: 0.368270
Epoch: 8 800/3904 Training loss: 0.442094
Epoch: 8 1600/3904 Training loss: 0.244873
Epoch: 8 2400/3904 Training loss: 0.735339
Epoch: 8 3200/3904 Training loss: 0.362816
Training loss: 0.440020
Test loss: 0.558011; True positive: 903; True negative: 2, False Positive: 263, False negative: 0, accuracy: 0.7748287671232876, precision: 0.774442538593482, recall: 1.0
Epoch: 9 0/3904 Training loss: 0.403353
Epoch: 9 800/3904 Training loss: 0.401485
Epoch: 9 1600/3904 Training loss: 0.163884
Epoch: 9 2400/3904 Training loss: 0.705076
Epoch: 9 3200/3904 Training loss: 0.337840
Training loss: 0.426595
Test loss: 0.544682; True positive: 903; True negative: 4, False Positive: 261, False negative: 0, accuracy: 0.776541095890411, precision: 0.7757731958762887, recall: 1.0
Epoch: 10 0/3904 Training loss: 0.377692
Epoch: 10 800/3904 Training loss: 0.510580
Epoch: 10 1600/3904 Training loss: 0.199930
Epoch: 10 2400/3904 Training loss: 0.499984
Epoch: 10 3200/3904 Training loss: 0.319878
Training loss: 0.421035
Test loss: 0.636098; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 11 0/3904 Training loss: 0.339301
Epoch: 11 800/3904 Training loss: 0.388181
Epoch: 11 1600/3904 Training loss: 0.154762
Epoch: 11 2400/3904 Training loss: 0.537583
Epoch: 11 3200/3904 Training loss: 0.278148
Training loss: 0.408682
Test loss: 0.651518; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 12 0/3904 Training loss: 0.328365
Epoch: 12 800/3904 Training loss: 0.359977
Epoch: 12 1600/3904 Training loss: 0.115148
Epoch: 12 2400/3904 Training loss: 0.502471
Epoch: 12 3200/3904 Training loss: 0.293125
Training loss: 0.405430
Test loss: 0.639318; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 13 0/3904 Training loss: 0.380244
Epoch: 13 800/3904 Training loss: 0.445070
Epoch: 13 1600/3904 Training loss: 0.140576
Epoch: 13 2400/3904 Training loss: 0.372324
Epoch: 13 3200/3904 Training loss: 0.331239
Training loss: 0.396192
Test loss: 0.654152; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 14 0/3904 Training loss: 0.306073
Epoch: 14 800/3904 Training loss: 0.452927
Epoch: 14 1600/3904 Training loss: 0.177192
Epoch: 14 2400/3904 Training loss: 0.351005
Epoch: 14 3200/3904 Training loss: 0.268935
Training loss: 0.395750
Test loss: 0.643878; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 15 0/3904 Training loss: 0.303742
Epoch: 15 800/3904 Training loss: 0.387241
Epoch: 15 1600/3904 Training loss: 0.171611
Epoch: 15 2400/3904 Training loss: 0.444150
Epoch: 15 3200/3904 Training loss: 0.321411
Training loss: 0.383714
Test loss: 0.646604; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 16 0/3904 Training loss: 0.331929
Epoch: 16 800/3904 Training loss: 0.350525
Epoch: 16 1600/3904 Training loss: 0.146421
Epoch: 16 2400/3904 Training loss: 0.289637
Epoch: 16 3200/3904 Training loss: 0.277192
Training loss: 0.385157
Test loss: 0.648730; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 17 0/3904 Training loss: 0.343841
Epoch: 17 800/3904 Training loss: 0.388657
Epoch: 17 1600/3904 Training loss: 0.172708
Epoch: 17 2400/3904 Training loss: 0.327776
Epoch: 17 3200/3904 Training loss: 0.336947
Training loss: 0.375876
Test loss: 0.701321; True positive: 801; True negative: 118, False Positive: 147, False negative: 102, accuracy: 0.7868150684931506, precision: 0.8449367088607594, recall: 0.8870431893687708
Epoch: 18 0/3904 Training loss: 0.333079
Epoch: 18 800/3904 Training loss: 0.327745
Epoch: 18 1600/3904 Training loss: 0.169163
Epoch: 18 2400/3904 Training loss: 0.315649
Epoch: 18 3200/3904 Training loss: 0.296522
Training loss: 0.380157
Test loss: 0.663144; True positive: 814; True negative: 118, False Positive: 147, False negative: 89, accuracy: 0.797945205479452, precision: 0.8470343392299687, recall: 0.9014396456256921
Epoch: 19 0/3904 Training loss: 0.326740
Epoch: 19 800/3904 Training loss: 0.386751
Epoch: 19 1600/3904 Training loss: 0.156138
Epoch: 19 2400/3904 Training loss: 0.299347
Epoch: 19 3200/3904 Training loss: 0.261638
Training loss: 0.373768
Test loss: 0.669876; True positive: 820; True negative: 118, False Positive: 147, False negative: 83, accuracy: 0.803082191780822, precision: 0.8479834539813857, recall: 0.9080841638981174
starting trial 271
[I 2022-12-05 08:00:11,976] Trial 270 finished with value: 0.8176369863013698 and parameters: {'d_model': 64, 'nhead': 8, 'n_encoders': 1, 'learning_rate': 7.326463310701103e-05, 'weight_decay': 2.099447722033847e-06, 'dropout': 0.22910189447242577, 'max_pool_conv': 32, 'kernel_size': 4, 'd_mlp': 32, 'num_conv_layers': 8, 'encoder_dropout': 0.010819785303268162, 'd_feed_forward': 128, 'max_pool_dim': 8, 'n_mlp_layers': 2}. Best is trial 62 with value: 0.860445205479452.
Epoch: 0 0/3904 Training loss: 0.712157
Epoch: 0 800/3904 Training loss: 0.696940
Epoch: 0 1600/3904 Training loss: 0.381186
Epoch: 0 2400/3904 Training loss: 0.742477
Epoch: 0 3200/3904 Training loss: 0.557277
Training loss: 0.672764
Test loss: 0.808073; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 1 0/3904 Training loss: 0.706078
Epoch: 1 800/3904 Training loss: 0.725903
Epoch: 1 1600/3904 Training loss: 0.447947
Epoch: 1 2400/3904 Training loss: 0.697122
Epoch: 1 3200/3904 Training loss: 0.554506
Training loss: 0.660605
Test loss: 0.782150; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 2 0/3904 Training loss: 0.683807
Epoch: 2 800/3904 Training loss: 0.719081
Epoch: 2 1600/3904 Training loss: 0.241150
Epoch: 2 2400/3904 Training loss: 0.585155
Epoch: 2 3200/3904 Training loss: 0.427690
Training loss: 0.583964
Test loss: 1.695404; True positive: 4; True negative: 265, False Positive: 0, False negative: 899, accuracy: 0.2303082191780822, precision: 1.0, recall: 0.004429678848283499
Epoch: 3 0/3904 Training loss: 0.535425
Epoch: 3 800/3904 Training loss: 0.528867
Epoch: 3 1600/3904 Training loss: 0.218674
Epoch: 3 2400/3904 Training loss: 0.522055
Epoch: 3 3200/3904 Training loss: 0.397702
Training loss: 0.535065
Test loss: 0.822147; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 4 0/3904 Training loss: 0.355392
Epoch: 4 800/3904 Training loss: 0.504304
Epoch: 4 1600/3904 Training loss: 0.257493
Epoch: 4 2400/3904 Training loss: 0.637464
Epoch: 4 3200/3904 Training loss: 0.338834
Training loss: 0.514830
Test loss: 0.607583; True positive: 903; True negative: 0, False Positive: 265, False negative: 0, accuracy: 0.7731164383561644, precision: 0.7731164383561644, recall: 1.0
Epoch: 5 0/3904 Training loss: 0.428541
Epoch: 5 800/3904 Training loss: 0.440104
Epoch: 5 1600/3904 Training loss: 0.187616
Epoch: 5 2400/3904 Training loss: 0.524998
Epoch: 5 3200/3904 Training loss: 0.381714
Training loss: 0.484087
Test loss: 0.691546; True positive: 848; True negative: 94, False Positive: 171, False negative: 55, accuracy: 0.8065068493150684, precision: 0.8321884200196271, recall: 0.9390919158361019
Epoch: 6 0/3904 Training loss: 0.502782
Epoch: 6 800/3904 Training loss: 0.423960
Epoch: 6 1600/3904 Training loss: 0.192326
Epoch: 6 2400/3904 Training loss: 0.591411
Epoch: 6 3200/3904 Training loss: 0.383853
Training loss: 0.473796
Test loss: 0.708969; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 7 0/3904 Training loss: 0.435266
Epoch: 7 800/3904 Training loss: 0.376519
Epoch: 7 1600/3904 Training loss: 0.192195
Epoch: 7 2400/3904 Training loss: 0.563296
Epoch: 7 3200/3904 Training loss: 0.319196
Training loss: 0.464029
Test loss: 0.785073; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 8 0/3904 Training loss: 0.363436
Epoch: 8 800/3904 Training loss: 0.430353
Epoch: 8 1600/3904 Training loss: 0.180763
Epoch: 8 2400/3904 Training loss: 0.690176
Epoch: 8 3200/3904 Training loss: 0.315600
Training loss: 0.463691
Test loss: 1.303993; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 9 0/3904 Training loss: 0.357746
Epoch: 9 800/3904 Training loss: 0.347543
Epoch: 9 1600/3904 Training loss: 0.188430
Epoch: 9 2400/3904 Training loss: 0.573987
Epoch: 9 3200/3904 Training loss: 0.332048
Training loss: 0.451966
Test loss: 0.710104; True positive: 31; True negative: 174, False Positive: 91, False negative: 872, accuracy: 0.175513698630137, precision: 0.2540983606557377, recall: 0.03433001107419712
Epoch: 10 0/3904 Training loss: 0.404343
Epoch: 10 800/3904 Training loss: 0.392568
Epoch: 10 1600/3904 Training loss: 0.129277
Epoch: 10 2400/3904 Training loss: 0.380758
Epoch: 10 3200/3904 Training loss: 0.300005
Training loss: 0.436490
Test loss: 0.708939; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 11 0/3904 Training loss: 0.441400
Epoch: 11 800/3904 Training loss: 0.319975
Epoch: 11 1600/3904 Training loss: 0.111827
Epoch: 11 2400/3904 Training loss: 0.448289
Epoch: 11 3200/3904 Training loss: 0.308726
Training loss: 0.430601
Test loss: 0.708107; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 12 0/3904 Training loss: 0.404462
Epoch: 12 800/3904 Training loss: 0.445831
Epoch: 12 1600/3904 Training loss: 0.206679
Epoch: 12 2400/3904 Training loss: 0.390103
Epoch: 12 3200/3904 Training loss: 0.346898
Training loss: 0.435722
Test loss: 0.687075; True positive: 903; True negative: 0, False Positive: 265, False negative: 0, accuracy: 0.7731164383561644, precision: 0.7731164383561644, recall: 1.0
Epoch: 13 0/3904 Training loss: 0.447429
Epoch: 13 800/3904 Training loss: 0.349035
Epoch: 13 1600/3904 Training loss: 0.158076
Epoch: 13 2400/3904 Training loss: 0.333378
Epoch: 13 3200/3904 Training loss: 0.304125
Training loss: 0.439404
Test loss: 0.699825; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 14 0/3904 Training loss: 0.388286
Epoch: 14 800/3904 Training loss: 0.463459
Epoch: 14 1600/3904 Training loss: 0.127283
Epoch: 14 2400/3904 Training loss: 0.411449
Epoch: 14 3200/3904 Training loss: 0.280662
Training loss: 0.428814
Test loss: 0.703958; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
starting trial 272
[I 2022-12-05 08:01:44,576] Trial 271 finished with value: 0.8065068493150684 and parameters: {'d_model': 64, 'nhead': 8, 'n_encoders': 2, 'learning_rate': 0.0007194973817759562, 'weight_decay': 4.603102823105017e-06, 'dropout': 0.22083741562085052, 'max_pool_conv': 32, 'kernel_size': 4, 'd_mlp': 32, 'num_conv_layers': 8, 'encoder_dropout': 0.0016017642312899571, 'd_feed_forward': 128, 'max_pool_dim': 8, 'n_mlp_layers': 2}. Best is trial 62 with value: 0.860445205479452.
Epoch: 0 0/3904 Training loss: 0.698765
Epoch: 0 800/3904 Training loss: 0.744532
Epoch: 0 1600/3904 Training loss: 0.445309
Epoch: 0 2400/3904 Training loss: 0.783635
Epoch: 0 3200/3904 Training loss: 0.549844
Training loss: 0.665758
Test loss: 0.814541; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 1 0/3904 Training loss: 0.713636
Epoch: 1 800/3904 Training loss: 0.713777
Epoch: 1 1600/3904 Training loss: 0.462650
Epoch: 1 2400/3904 Training loss: 0.800633
Epoch: 1 3200/3904 Training loss: 0.565534
Training loss: 0.663439
Test loss: 0.841887; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 2 0/3904 Training loss: 0.723065
Epoch: 2 800/3904 Training loss: 0.733729
Epoch: 2 1600/3904 Training loss: 0.364017
Epoch: 2 2400/3904 Training loss: 0.738405
Epoch: 2 3200/3904 Training loss: 0.438002
Training loss: 0.633561
Test loss: 0.729179; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 3 0/3904 Training loss: 0.628313
Epoch: 3 800/3904 Training loss: 0.694016
Epoch: 3 1600/3904 Training loss: 0.215760
Epoch: 3 2400/3904 Training loss: 0.798896
Epoch: 3 3200/3904 Training loss: 0.376387
Training loss: 0.544060
Test loss: 0.600949; True positive: 903; True negative: 0, False Positive: 265, False negative: 0, accuracy: 0.7731164383561644, precision: 0.7731164383561644, recall: 1.0
Epoch: 4 0/3904 Training loss: 0.446265
Epoch: 4 800/3904 Training loss: 0.508836
Epoch: 4 1600/3904 Training loss: 0.151616
Epoch: 4 2400/3904 Training loss: 0.735909
Epoch: 4 3200/3904 Training loss: 0.472518
Training loss: 0.481080
Test loss: 0.553173; True positive: 903; True negative: 0, False Positive: 265, False negative: 0, accuracy: 0.7731164383561644, precision: 0.7731164383561644, recall: 1.0
Epoch: 5 0/3904 Training loss: 0.348752
Epoch: 5 800/3904 Training loss: 0.497823
Epoch: 5 1600/3904 Training loss: 0.200131
Epoch: 5 2400/3904 Training loss: 0.347895
Epoch: 5 3200/3904 Training loss: 0.388647
Training loss: 0.452124
Test loss: 0.557135; True positive: 886; True negative: 2, False Positive: 263, False negative: 17, accuracy: 0.7602739726027398, precision: 0.7711053089643168, recall: 0.9811738648947951
Epoch: 6 0/3904 Training loss: 0.388676
Epoch: 6 800/3904 Training loss: 0.455145
Epoch: 6 1600/3904 Training loss: 0.156171
Epoch: 6 2400/3904 Training loss: 0.361530
Epoch: 6 3200/3904 Training loss: 0.380168
Training loss: 0.435563
Test loss: 1.318377; True positive: 552; True negative: 17, False Positive: 248, False negative: 351, accuracy: 0.4871575342465753, precision: 0.69, recall: 0.6112956810631229
Epoch: 7 0/3904 Training loss: 0.385952
Epoch: 7 800/3904 Training loss: 0.408653
Epoch: 7 1600/3904 Training loss: 0.193428
Epoch: 7 2400/3904 Training loss: 0.386786
Epoch: 7 3200/3904 Training loss: 0.448332
Training loss: 0.423447
Test loss: 2.188458; True positive: 286; True negative: 70, False Positive: 195, False negative: 617, accuracy: 0.3047945205479452, precision: 0.5945945945945946, recall: 0.3167220376522702
Epoch: 8 0/3904 Training loss: 0.376072
Epoch: 8 800/3904 Training loss: 0.314313
Epoch: 8 1600/3904 Training loss: 0.178181
Epoch: 8 2400/3904 Training loss: 0.349281
Epoch: 8 3200/3904 Training loss: 0.398415
Training loss: 0.413601
Test loss: 0.856447; True positive: 722; True negative: 6, False Positive: 259, False negative: 181, accuracy: 0.6232876712328768, precision: 0.7359836901121305, recall: 0.7995570321151716
Epoch: 9 0/3904 Training loss: 0.376142
Epoch: 9 800/3904 Training loss: 0.367244
Epoch: 9 1600/3904 Training loss: 0.188251
Epoch: 9 2400/3904 Training loss: 0.323840
Epoch: 9 3200/3904 Training loss: 0.403151
Training loss: 0.411002
Test loss: 0.988589; True positive: 651; True negative: 11, False Positive: 254, False negative: 252, accuracy: 0.5667808219178082, precision: 0.7193370165745856, recall: 0.7209302325581395
Epoch: 10 0/3904 Training loss: 0.298208
Epoch: 10 800/3904 Training loss: 0.271268
Epoch: 10 1600/3904 Training loss: 0.186813
Epoch: 10 2400/3904 Training loss: 0.339482
Epoch: 10 3200/3904 Training loss: 0.365248
Training loss: 0.401825
Test loss: 1.413693; True positive: 498; True negative: 25, False Positive: 240, False negative: 405, accuracy: 0.4477739726027397, precision: 0.6747967479674797, recall: 0.5514950166112956
Epoch: 11 0/3904 Training loss: 0.320082
Epoch: 11 800/3904 Training loss: 0.383270
Epoch: 11 1600/3904 Training loss: 0.190650
Epoch: 11 2400/3904 Training loss: 0.317829
Epoch: 11 3200/3904 Training loss: 0.429192
Training loss: 0.397751
Test loss: 1.213125; True positive: 517; True negative: 18, False Positive: 247, False negative: 386, accuracy: 0.4580479452054795, precision: 0.6767015706806283, recall: 0.5725359911406424
Epoch: 12 0/3904 Training loss: 0.322687
Epoch: 12 800/3904 Training loss: 0.265606
Epoch: 12 1600/3904 Training loss: 0.203444
Epoch: 12 2400/3904 Training loss: 0.343571
Epoch: 12 3200/3904 Training loss: 0.448855
Training loss: 0.393713
Test loss: 1.760790; True positive: 316; True negative: 101, False Positive: 164, False negative: 587, accuracy: 0.3570205479452055, precision: 0.6583333333333333, recall: 0.34994462901439644
Epoch: 13 0/3904 Training loss: 0.441726
Epoch: 13 800/3904 Training loss: 0.278492
Epoch: 13 1600/3904 Training loss: 0.173234
Epoch: 13 2400/3904 Training loss: 0.313649
Epoch: 13 3200/3904 Training loss: 0.467161
Training loss: 0.386709
Test loss: 0.625679; True positive: 833; True negative: 3, False Positive: 262, False negative: 70, accuracy: 0.7157534246575342, precision: 0.7607305936073059, recall: 0.9224806201550387
Epoch: 14 0/3904 Training loss: 0.337337
Epoch: 14 800/3904 Training loss: 0.345068
Epoch: 14 1600/3904 Training loss: 0.189069
Epoch: 14 2400/3904 Training loss: 0.291201
Epoch: 14 3200/3904 Training loss: 0.413931
Training loss: 0.386429
Test loss: 0.550543; True positive: 884; True negative: 2, False Positive: 263, False negative: 19, accuracy: 0.7585616438356164, precision: 0.7707061900610288, recall: 0.9789590254706534
Epoch: 15 0/3904 Training loss: 0.319627
Epoch: 15 800/3904 Training loss: 0.298731
Epoch: 15 1600/3904 Training loss: 0.221807
Epoch: 15 2400/3904 Training loss: 0.261759
Epoch: 15 3200/3904 Training loss: 0.440898
Training loss: 0.375036
Test loss: 0.520855; True positive: 903; True negative: 0, False Positive: 265, False negative: 0, accuracy: 0.7731164383561644, precision: 0.7731164383561644, recall: 1.0
Epoch: 16 0/3904 Training loss: 0.321811
Epoch: 16 800/3904 Training loss: 0.282633
Epoch: 16 1600/3904 Training loss: 0.190554
Epoch: 16 2400/3904 Training loss: 0.281346
Epoch: 16 3200/3904 Training loss: 0.409151
Training loss: 0.380094
Test loss: 0.531641; True positive: 892; True negative: 2, False Positive: 263, False negative: 11, accuracy: 0.7654109589041096, precision: 0.7722943722943723, recall: 0.9878183831672204
Epoch: 17 0/3904 Training loss: 0.312291
Epoch: 17 800/3904 Training loss: 0.219961
Epoch: 17 1600/3904 Training loss: 0.190151
Epoch: 17 2400/3904 Training loss: 0.271814
Epoch: 17 3200/3904 Training loss: 0.459549
Training loss: 0.374032
Test loss: 0.528614; True positive: 894; True negative: 1, False Positive: 264, False negative: 9, accuracy: 0.7662671232876712, precision: 0.772020725388601, recall: 0.9900332225913622
Epoch: 18 0/3904 Training loss: 0.291716
Epoch: 18 800/3904 Training loss: 0.237696
Epoch: 18 1600/3904 Training loss: 0.189384
Epoch: 18 2400/3904 Training loss: 0.253406
Epoch: 18 3200/3904 Training loss: 0.398081
Training loss: 0.367360
Test loss: 0.584732; True positive: 856; True negative: 3, False Positive: 262, False negative: 47, accuracy: 0.735445205479452, precision: 0.7656529516994633, recall: 0.9479512735326688
Epoch: 19 0/3904 Training loss: 0.330809
Epoch: 19 800/3904 Training loss: 0.213090
Epoch: 19 1600/3904 Training loss: 0.179397
Epoch: 19 2400/3904 Training loss: 0.230728
Epoch: 19 3200/3904 Training loss: 0.394498
Training loss: 0.364104
Test loss: 1.741638; True positive: 280; True negative: 108, False Positive: 157, False negative: 623, accuracy: 0.3321917808219178, precision: 0.6407322654462243, recall: 0.31007751937984496
Epoch: 20 0/3904 Training loss: 0.278239
Epoch: 20 800/3904 Training loss: 0.232676
Epoch: 20 1600/3904 Training loss: 0.205262
Epoch: 20 2400/3904 Training loss: 0.249173
Epoch: 20 3200/3904 Training loss: 0.417933
Training loss: 0.359303
Test loss: 1.876487; True positive: 260; True negative: 109, False Positive: 156, False negative: 643, accuracy: 0.3159246575342466, precision: 0.625, recall: 0.28792912513842744
Epoch: 21 0/3904 Training loss: 0.311066
Epoch: 21 800/3904 Training loss: 0.266386
Epoch: 21 1600/3904 Training loss: 0.240752
Epoch: 21 2400/3904 Training loss: 0.280048
Epoch: 21 3200/3904 Training loss: 0.406554
Training loss: 0.366235
Test loss: 3.913530; True positive: 65; True negative: 147, False Positive: 118, False negative: 838, accuracy: 0.1815068493150685, precision: 0.3551912568306011, recall: 0.07198228128460686
Epoch: 22 0/3904 Training loss: 0.281917
Epoch: 22 800/3904 Training loss: 0.270906
Epoch: 22 1600/3904 Training loss: 0.220214
Epoch: 22 2400/3904 Training loss: 0.295034
Epoch: 22 3200/3904 Training loss: 0.445904
Training loss: 0.352939
Test loss: 2.759001; True positive: 142; True negative: 134, False Positive: 131, False negative: 761, accuracy: 0.2363013698630137, precision: 0.5201465201465202, recall: 0.15725359911406422
Epoch: 23 0/3904 Training loss: 0.312207
Epoch: 23 800/3904 Training loss: 0.191655
Epoch: 23 1600/3904 Training loss: 0.240234
Epoch: 23 2400/3904 Training loss: 0.247018
Epoch: 23 3200/3904 Training loss: 0.432449
Training loss: 0.347816
Test loss: 4.022079; True positive: 92; True negative: 140, False Positive: 125, False negative: 811, accuracy: 0.19863013698630136, precision: 0.423963133640553, recall: 0.10188261351052048
Epoch: 24 0/3904 Training loss: 0.261781
Epoch: 24 800/3904 Training loss: 0.237718
Epoch: 24 1600/3904 Training loss: 0.205529
Epoch: 24 2400/3904 Training loss: 0.271120
Epoch: 24 3200/3904 Training loss: 0.436309
Training loss: 0.348488
Test loss: 4.465253; True positive: 78; True negative: 141, False Positive: 124, False negative: 825, accuracy: 0.1875, precision: 0.38613861386138615, recall: 0.08637873754152824
Epoch: 25 0/3904 Training loss: 0.260696
Epoch: 25 800/3904 Training loss: 0.162502
Epoch: 25 1600/3904 Training loss: 0.200400
Epoch: 25 2400/3904 Training loss: 0.224571
Epoch: 25 3200/3904 Training loss: 0.391952
Training loss: 0.350272
Test loss: 1.933956; True positive: 257; True negative: 92, False Positive: 173, False negative: 646, accuracy: 0.2988013698630137, precision: 0.5976744186046512, recall: 0.28460686600221485
starting trial 273
[I 2022-12-05 08:04:17,847] Trial 272 finished with value: 0.7731164383561644 and parameters: {'d_model': 64, 'nhead': 8, 'n_encoders': 1, 'learning_rate': 0.00013022327013620844, 'weight_decay': 5.185241450610798e-06, 'dropout': 0.24235457003112, 'max_pool_conv': 32, 'kernel_size': 4, 'd_mlp': 32, 'num_conv_layers': 8, 'encoder_dropout': 0.015275051503579159, 'd_feed_forward': 128, 'max_pool_dim': 8, 'n_mlp_layers': 2}. Best is trial 62 with value: 0.860445205479452.
Epoch: 0 0/3904 Training loss: 0.699181
Epoch: 0 800/3904 Training loss: 0.737026
Epoch: 0 1600/3904 Training loss: 0.462364
Epoch: 0 2400/3904 Training loss: 0.810138
Epoch: 0 3200/3904 Training loss: 0.563797
Training loss: 0.663769
Test loss: 0.828080; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 1 0/3904 Training loss: 0.716391
Epoch: 1 800/3904 Training loss: 0.731850
Epoch: 1 1600/3904 Training loss: 0.481761
Epoch: 1 2400/3904 Training loss: 0.823330
Epoch: 1 3200/3904 Training loss: 0.558303
Training loss: 0.661413
Test loss: 0.882190; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 2 0/3904 Training loss: 0.727880
Epoch: 2 800/3904 Training loss: 0.731076
Epoch: 2 1600/3904 Training loss: 0.412051
Epoch: 2 2400/3904 Training loss: 0.784893
Epoch: 2 3200/3904 Training loss: 0.463785
Training loss: 0.638687
Test loss: 0.686974; True positive: 903; True negative: 0, False Positive: 265, False negative: 0, accuracy: 0.7731164383561644, precision: 0.7731164383561644, recall: 1.0
Epoch: 3 0/3904 Training loss: 0.664841
Epoch: 3 800/3904 Training loss: 0.596513
Epoch: 3 1600/3904 Training loss: 0.242699
Epoch: 3 2400/3904 Training loss: 0.613154
Epoch: 3 3200/3904 Training loss: 0.397250
Training loss: 0.520871
Test loss: 0.562491; True positive: 903; True negative: 0, False Positive: 265, False negative: 0, accuracy: 0.7731164383561644, precision: 0.7731164383561644, recall: 1.0
Epoch: 4 0/3904 Training loss: 0.475922
Epoch: 4 800/3904 Training loss: 0.487142
Epoch: 4 1600/3904 Training loss: 0.193960
Epoch: 4 2400/3904 Training loss: 0.395309
Epoch: 4 3200/3904 Training loss: 0.464296
Training loss: 0.459613
Test loss: 0.533154; True positive: 903; True negative: 0, False Positive: 265, False negative: 0, accuracy: 0.7731164383561644, precision: 0.7731164383561644, recall: 1.0
Epoch: 5 0/3904 Training loss: 0.393515
Epoch: 5 800/3904 Training loss: 0.419756
Epoch: 5 1600/3904 Training loss: 0.215518
Epoch: 5 2400/3904 Training loss: 0.383042
Epoch: 5 3200/3904 Training loss: 0.501117
Training loss: 0.428948
Test loss: 0.533328; True positive: 903; True negative: 0, False Positive: 265, False negative: 0, accuracy: 0.7731164383561644, precision: 0.7731164383561644, recall: 1.0
Epoch: 6 0/3904 Training loss: 0.367041
Epoch: 6 800/3904 Training loss: 0.442845
Epoch: 6 1600/3904 Training loss: 0.215166
Epoch: 6 2400/3904 Training loss: 0.366826
Epoch: 6 3200/3904 Training loss: 0.466888
Training loss: 0.412720
Test loss: 0.533464; True positive: 903; True negative: 0, False Positive: 265, False negative: 0, accuracy: 0.7731164383561644, precision: 0.7731164383561644, recall: 1.0
Epoch: 7 0/3904 Training loss: 0.357313
Epoch: 7 800/3904 Training loss: 0.472583
Epoch: 7 1600/3904 Training loss: 0.170599
Epoch: 7 2400/3904 Training loss: 0.335731
Epoch: 7 3200/3904 Training loss: 0.465004
Training loss: 0.400942
Test loss: 0.528914; True positive: 903; True negative: 0, False Positive: 265, False negative: 0, accuracy: 0.7731164383561644, precision: 0.7731164383561644, recall: 1.0
Epoch: 8 0/3904 Training loss: 0.318384
Epoch: 8 800/3904 Training loss: 0.402956
Epoch: 8 1600/3904 Training loss: 0.166834
Epoch: 8 2400/3904 Training loss: 0.312528
Epoch: 8 3200/3904 Training loss: 0.523465
Training loss: 0.393019
Test loss: 0.525518; True positive: 903; True negative: 0, False Positive: 265, False negative: 0, accuracy: 0.7731164383561644, precision: 0.7731164383561644, recall: 1.0
Epoch: 9 0/3904 Training loss: 0.349164
Epoch: 9 800/3904 Training loss: 0.465534
Epoch: 9 1600/3904 Training loss: 0.155452
Epoch: 9 2400/3904 Training loss: 0.336653
Epoch: 9 3200/3904 Training loss: 0.438629
Training loss: 0.384762
Test loss: 0.535245; True positive: 903; True negative: 0, False Positive: 265, False negative: 0, accuracy: 0.7731164383561644, precision: 0.7731164383561644, recall: 1.0
Epoch: 10 0/3904 Training loss: 0.339448
Epoch: 10 800/3904 Training loss: 0.420903
Epoch: 10 1600/3904 Training loss: 0.199293
Epoch: 10 2400/3904 Training loss: 0.286582
Epoch: 10 3200/3904 Training loss: 0.445557
Training loss: 0.382013
Test loss: 0.536543; True positive: 903; True negative: 4, False Positive: 261, False negative: 0, accuracy: 0.776541095890411, precision: 0.7757731958762887, recall: 1.0
Epoch: 11 0/3904 Training loss: 0.306995
Epoch: 11 800/3904 Training loss: 0.426204
Epoch: 11 1600/3904 Training loss: 0.126139
Epoch: 11 2400/3904 Training loss: 0.247807
Epoch: 11 3200/3904 Training loss: 0.407782
Training loss: 0.379717
Test loss: 0.536920; True positive: 903; True negative: 4, False Positive: 261, False negative: 0, accuracy: 0.776541095890411, precision: 0.7757731958762887, recall: 1.0
Epoch: 12 0/3904 Training loss: 0.311676
Epoch: 12 800/3904 Training loss: 0.497309
Epoch: 12 1600/3904 Training loss: 0.147691
Epoch: 12 2400/3904 Training loss: 0.261419
Epoch: 12 3200/3904 Training loss: 0.391768
Training loss: 0.374373
Test loss: 0.634955; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 13 0/3904 Training loss: 0.362455
Epoch: 13 800/3904 Training loss: 0.444506
Epoch: 13 1600/3904 Training loss: 0.158466
Epoch: 13 2400/3904 Training loss: 0.255494
Epoch: 13 3200/3904 Training loss: 0.402660
Training loss: 0.372433
Test loss: 0.627277; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 14 0/3904 Training loss: 0.328723
Epoch: 14 800/3904 Training loss: 0.459942
Epoch: 14 1600/3904 Training loss: 0.133383
Epoch: 14 2400/3904 Training loss: 0.224252
Epoch: 14 3200/3904 Training loss: 0.459265
Training loss: 0.364800
Test loss: 0.630837; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 15 0/3904 Training loss: 0.303182
Epoch: 15 800/3904 Training loss: 0.395404
Epoch: 15 1600/3904 Training loss: 0.185123
Epoch: 15 2400/3904 Training loss: 0.229151
Epoch: 15 3200/3904 Training loss: 0.393664
Training loss: 0.358576
Test loss: 0.629307; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 16 0/3904 Training loss: 0.282508
Epoch: 16 800/3904 Training loss: 0.341000
Epoch: 16 1600/3904 Training loss: 0.179802
Epoch: 16 2400/3904 Training loss: 0.245597
Epoch: 16 3200/3904 Training loss: 0.496373
Training loss: 0.361721
Test loss: 0.634684; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 17 0/3904 Training loss: 0.297914
Epoch: 17 800/3904 Training loss: 0.577314
Epoch: 17 1600/3904 Training loss: 0.228449
Epoch: 17 2400/3904 Training loss: 0.267467
Epoch: 17 3200/3904 Training loss: 0.469159
Training loss: 0.359417
Test loss: 0.632590; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 18 0/3904 Training loss: 0.279454
Epoch: 18 800/3904 Training loss: 0.318318
Epoch: 18 1600/3904 Training loss: 0.171559
Epoch: 18 2400/3904 Training loss: 0.267494
Epoch: 18 3200/3904 Training loss: 0.435221
Training loss: 0.347680
Test loss: 0.635397; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
starting trial 274
[I 2022-12-05 08:08:08,917] Trial 273 finished with value: 0.8176369863013698 and parameters: {'d_model': 64, 'nhead': 8, 'n_encoders': 1, 'learning_rate': 5.1445007162640564e-05, 'weight_decay': 4.417490928360998e-06, 'dropout': 0.2117464714000419, 'max_pool_conv': 32, 'kernel_size': 11, 'd_mlp': 32, 'num_conv_layers': 8, 'encoder_dropout': 0.02941402359708411, 'd_feed_forward': 128, 'max_pool_dim': 8, 'n_mlp_layers': 2}. Best is trial 62 with value: 0.860445205479452.
Epoch: 0 0/3904 Training loss: 0.681456
Epoch: 0 800/3904 Training loss: 0.714550
Epoch: 0 1600/3904 Training loss: 0.415934
Epoch: 0 2400/3904 Training loss: 0.770799
Epoch: 0 3200/3904 Training loss: 0.543955
Training loss: 0.664462
Test loss: 0.828414; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 1 0/3904 Training loss: 0.725217
Epoch: 1 800/3904 Training loss: 0.731979
Epoch: 1 1600/3904 Training loss: 0.472329
Epoch: 1 2400/3904 Training loss: 0.808269
Epoch: 1 3200/3904 Training loss: 0.563848
Training loss: 0.662299
Test loss: 0.846327; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 2 0/3904 Training loss: 0.720452
Epoch: 2 800/3904 Training loss: 0.723942
Epoch: 2 1600/3904 Training loss: 0.451977
Epoch: 2 2400/3904 Training loss: 0.800220
Epoch: 2 3200/3904 Training loss: 0.541540
Training loss: 0.660344
Test loss: 0.821689; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 3 0/3904 Training loss: 0.716092
Epoch: 3 800/3904 Training loss: 0.731932
Epoch: 3 1600/3904 Training loss: 0.264382
Epoch: 3 2400/3904 Training loss: 0.926847
Epoch: 3 3200/3904 Training loss: 0.362969
Training loss: 0.590626
Test loss: 0.700006; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 4 0/3904 Training loss: 0.544917
Epoch: 4 800/3904 Training loss: 0.591758
Epoch: 4 1600/3904 Training loss: 0.237437
Epoch: 4 2400/3904 Training loss: 0.560404
Epoch: 4 3200/3904 Training loss: 0.340115
Training loss: 0.498328
Test loss: 0.560359; True positive: 903; True negative: 0, False Positive: 265, False negative: 0, accuracy: 0.7731164383561644, precision: 0.7731164383561644, recall: 1.0
Epoch: 5 0/3904 Training loss: 0.430367
Epoch: 5 800/3904 Training loss: 0.555152
Epoch: 5 1600/3904 Training loss: 0.168643
Epoch: 5 2400/3904 Training loss: 0.551681
Epoch: 5 3200/3904 Training loss: 0.355688
Training loss: 0.454498
Test loss: 0.542197; True positive: 903; True negative: 0, False Positive: 265, False negative: 0, accuracy: 0.7731164383561644, precision: 0.7731164383561644, recall: 1.0
Epoch: 6 0/3904 Training loss: 0.338249
Epoch: 6 800/3904 Training loss: 0.493569
Epoch: 6 1600/3904 Training loss: 0.138236
Epoch: 6 2400/3904 Training loss: 0.544176
Epoch: 6 3200/3904 Training loss: 0.329970
Training loss: 0.425277
Test loss: 0.643968; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 7 0/3904 Training loss: 0.338742
Epoch: 7 800/3904 Training loss: 0.553661
Epoch: 7 1600/3904 Training loss: 0.160853
Epoch: 7 2400/3904 Training loss: 0.449240
Epoch: 7 3200/3904 Training loss: 0.365046
Training loss: 0.410965
Test loss: 0.635062; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 8 0/3904 Training loss: 0.341487
Epoch: 8 800/3904 Training loss: 0.480404
Epoch: 8 1600/3904 Training loss: 0.166974
Epoch: 8 2400/3904 Training loss: 0.462072
Epoch: 8 3200/3904 Training loss: 0.349997
Training loss: 0.403364
Test loss: 0.638153; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 9 0/3904 Training loss: 0.287327
Epoch: 9 800/3904 Training loss: 0.328423
Epoch: 9 1600/3904 Training loss: 0.124647
Epoch: 9 2400/3904 Training loss: 0.368859
Epoch: 9 3200/3904 Training loss: 0.289479
Training loss: 0.393425
Test loss: 0.645890; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 10 0/3904 Training loss: 0.301704
Epoch: 10 800/3904 Training loss: 0.322997
Epoch: 10 1600/3904 Training loss: 0.111037
Epoch: 10 2400/3904 Training loss: 0.384815
Epoch: 10 3200/3904 Training loss: 0.246812
Training loss: 0.384399
Test loss: 0.640149; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 11 0/3904 Training loss: 0.287924
Epoch: 11 800/3904 Training loss: 0.394539
Epoch: 11 1600/3904 Training loss: 0.151033
Epoch: 11 2400/3904 Training loss: 0.406962
Epoch: 11 3200/3904 Training loss: 0.312316
Training loss: 0.382671
Test loss: 0.637607; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 12 0/3904 Training loss: 0.334957
Epoch: 12 800/3904 Training loss: 0.324598
Epoch: 12 1600/3904 Training loss: 0.097236
Epoch: 12 2400/3904 Training loss: 0.367994
Epoch: 12 3200/3904 Training loss: 0.303265
Training loss: 0.364293
Test loss: 0.625294; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 13 0/3904 Training loss: 0.356068
Epoch: 13 800/3904 Training loss: 0.315822
Epoch: 13 1600/3904 Training loss: 0.187526
Epoch: 13 2400/3904 Training loss: 0.302208
Epoch: 13 3200/3904 Training loss: 0.349297
Training loss: 0.365159
Test loss: 0.631020; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 14 0/3904 Training loss: 0.281341
Epoch: 14 800/3904 Training loss: 0.423939
Epoch: 14 1600/3904 Training loss: 0.132301
Epoch: 14 2400/3904 Training loss: 0.273092
Epoch: 14 3200/3904 Training loss: 0.347467
Training loss: 0.364381
Test loss: 0.626674; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 15 0/3904 Training loss: 0.292957
Epoch: 15 800/3904 Training loss: 0.271391
Epoch: 15 1600/3904 Training loss: 0.197994
Epoch: 15 2400/3904 Training loss: 0.257549
Epoch: 15 3200/3904 Training loss: 0.263258
Training loss: 0.364375
Test loss: 0.612221; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
starting trial 275
[I 2022-12-05 08:10:03,300] Trial 274 finished with value: 0.8176369863013698 and parameters: {'d_model': 64, 'nhead': 8, 'n_encoders': 1, 'learning_rate': 0.00012479295857443113, 'weight_decay': 3.403763247465247e-06, 'dropout': 0.2281190431051557, 'max_pool_conv': 32, 'kernel_size': 5, 'd_mlp': 32, 'num_conv_layers': 8, 'encoder_dropout': 0.016442168195159035, 'd_feed_forward': 128, 'max_pool_dim': 8, 'n_mlp_layers': 2}. Best is trial 62 with value: 0.860445205479452.
Epoch: 0 0/3904 Training loss: 0.694448
Epoch: 0 800/3904 Training loss: 0.730799
Epoch: 0 1600/3904 Training loss: 0.442713
Epoch: 0 2400/3904 Training loss: 0.801078
Epoch: 0 3200/3904 Training loss: 0.554887
Training loss: 0.664479
Test loss: 0.826471; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 1 0/3904 Training loss: 0.713689
Epoch: 1 800/3904 Training loss: 0.730866
Epoch: 1 1600/3904 Training loss: 0.461489
Epoch: 1 2400/3904 Training loss: 0.800655
Epoch: 1 3200/3904 Training loss: 0.557774
Training loss: 0.662021
Test loss: 0.837815; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 2 0/3904 Training loss: 0.715705
Epoch: 2 800/3904 Training loss: 0.737179
Epoch: 2 1600/3904 Training loss: 0.469422
Epoch: 2 2400/3904 Training loss: 0.811376
Epoch: 2 3200/3904 Training loss: 0.559577
Training loss: 0.661419
Test loss: 0.843438; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 3 0/3904 Training loss: 0.717280
Epoch: 3 800/3904 Training loss: 0.736799
Epoch: 3 1600/3904 Training loss: 0.470425
Epoch: 3 2400/3904 Training loss: 0.815691
Epoch: 3 3200/3904 Training loss: 0.560095
Training loss: 0.661141
Test loss: 0.845627; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 4 0/3904 Training loss: 0.715805
Epoch: 4 800/3904 Training loss: 0.736334
Epoch: 4 1600/3904 Training loss: 0.471515
Epoch: 4 2400/3904 Training loss: 0.813563
Epoch: 4 3200/3904 Training loss: 0.557678
Training loss: 0.661217
Test loss: 0.847609; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 5 0/3904 Training loss: 0.722355
Epoch: 5 800/3904 Training loss: 0.739836
Epoch: 5 1600/3904 Training loss: 0.442533
Epoch: 5 2400/3904 Training loss: 0.792267
Epoch: 5 3200/3904 Training loss: 0.530259
Training loss: 0.655428
Test loss: 0.761364; True positive: 65; True negative: 148, False Positive: 117, False negative: 838, accuracy: 0.18236301369863014, precision: 0.35714285714285715, recall: 0.07198228128460686
Epoch: 6 0/3904 Training loss: 0.702066
Epoch: 6 800/3904 Training loss: 0.639474
Epoch: 6 1600/3904 Training loss: 0.249377
Epoch: 6 2400/3904 Training loss: 0.729584
Epoch: 6 3200/3904 Training loss: 0.348997
Training loss: 0.542075
Test loss: 0.573603; True positive: 903; True negative: 0, False Positive: 265, False negative: 0, accuracy: 0.7731164383561644, precision: 0.7731164383561644, recall: 1.0
Epoch: 7 0/3904 Training loss: 0.508774
Epoch: 7 800/3904 Training loss: 0.599136
Epoch: 7 1600/3904 Training loss: 0.279947
Epoch: 7 2400/3904 Training loss: 0.336108
Epoch: 7 3200/3904 Training loss: 0.355680
Training loss: 0.449740
Test loss: 0.542733; True positive: 903; True negative: 0, False Positive: 265, False negative: 0, accuracy: 0.7731164383561644, precision: 0.7731164383561644, recall: 1.0
Epoch: 8 0/3904 Training loss: 0.376703
Epoch: 8 800/3904 Training loss: 0.450107
Epoch: 8 1600/3904 Training loss: 0.185363
Epoch: 8 2400/3904 Training loss: 0.397976
Epoch: 8 3200/3904 Training loss: 0.405122
Training loss: 0.431384
Test loss: 0.541326; True positive: 903; True negative: 0, False Positive: 265, False negative: 0, accuracy: 0.7731164383561644, precision: 0.7731164383561644, recall: 1.0
Epoch: 9 0/3904 Training loss: 0.432985
Epoch: 9 800/3904 Training loss: 0.448577
Epoch: 9 1600/3904 Training loss: 0.176012
Epoch: 9 2400/3904 Training loss: 0.341252
Epoch: 9 3200/3904 Training loss: 0.296265
Training loss: 0.418353
Test loss: 0.564559; True positive: 903; True negative: 0, False Positive: 265, False negative: 0, accuracy: 0.7731164383561644, precision: 0.7731164383561644, recall: 1.0
Epoch: 10 0/3904 Training loss: 0.435252
Epoch: 10 800/3904 Training loss: 0.411145
Epoch: 10 1600/3904 Training loss: 0.180243
Epoch: 10 2400/3904 Training loss: 0.371962
Epoch: 10 3200/3904 Training loss: 0.330045
Training loss: 0.407228
Test loss: 0.528761; True positive: 903; True negative: 0, False Positive: 265, False negative: 0, accuracy: 0.7731164383561644, precision: 0.7731164383561644, recall: 1.0
Epoch: 11 0/3904 Training loss: 0.431938
Epoch: 11 800/3904 Training loss: 0.702337
Epoch: 11 1600/3904 Training loss: 0.202472
Epoch: 11 2400/3904 Training loss: 0.248850
Epoch: 11 3200/3904 Training loss: 0.335217
Training loss: 0.407677
Test loss: 0.531847; True positive: 903; True negative: 0, False Positive: 265, False negative: 0, accuracy: 0.7731164383561644, precision: 0.7731164383561644, recall: 1.0
Epoch: 12 0/3904 Training loss: 0.352201
Epoch: 12 800/3904 Training loss: 0.542081
Epoch: 12 1600/3904 Training loss: 0.217346
Epoch: 12 2400/3904 Training loss: 0.244890
Epoch: 12 3200/3904 Training loss: 0.374152
Training loss: 0.395411
Test loss: 0.530295; True positive: 903; True negative: 0, False Positive: 265, False negative: 0, accuracy: 0.7731164383561644, precision: 0.7731164383561644, recall: 1.0
Epoch: 13 0/3904 Training loss: 0.467101
Epoch: 13 800/3904 Training loss: 0.378221
Epoch: 13 1600/3904 Training loss: 0.185593
Epoch: 13 2400/3904 Training loss: 0.241360
Epoch: 13 3200/3904 Training loss: 0.436292
Training loss: 0.390988
Test loss: 0.535167; True positive: 903; True negative: 0, False Positive: 265, False negative: 0, accuracy: 0.7731164383561644, precision: 0.7731164383561644, recall: 1.0
Epoch: 14 0/3904 Training loss: 0.393684
Epoch: 14 800/3904 Training loss: 0.438505
Epoch: 14 1600/3904 Training loss: 0.155418
Epoch: 14 2400/3904 Training loss: 0.292050
Epoch: 14 3200/3904 Training loss: 0.333699
Training loss: 0.395844
Test loss: 0.532949; True positive: 903; True negative: 0, False Positive: 265, False negative: 0, accuracy: 0.7731164383561644, precision: 0.7731164383561644, recall: 1.0
Epoch: 15 0/3904 Training loss: 0.371217
Epoch: 15 800/3904 Training loss: 0.581154
Epoch: 15 1600/3904 Training loss: 0.192020
Epoch: 15 2400/3904 Training loss: 0.232765
Epoch: 15 3200/3904 Training loss: 0.342490
Training loss: 0.387265
Test loss: 0.535939; True positive: 903; True negative: 0, False Positive: 265, False negative: 0, accuracy: 0.7731164383561644, precision: 0.7731164383561644, recall: 1.0
Epoch: 16 0/3904 Training loss: 0.335425
Epoch: 16 800/3904 Training loss: 0.314999
Epoch: 16 1600/3904 Training loss: 0.123669
Epoch: 16 2400/3904 Training loss: 0.256172
Epoch: 16 3200/3904 Training loss: 0.405917
Training loss: 0.380590
Test loss: 0.535900; True positive: 903; True negative: 0, False Positive: 265, False negative: 0, accuracy: 0.7731164383561644, precision: 0.7731164383561644, recall: 1.0
Epoch: 17 0/3904 Training loss: 0.335403
Epoch: 17 800/3904 Training loss: 0.577052
Epoch: 17 1600/3904 Training loss: 0.228323
Epoch: 17 2400/3904 Training loss: 0.335902
Epoch: 17 3200/3904 Training loss: 0.392827
Training loss: 0.407661
Test loss: 0.552829; True positive: 903; True negative: 0, False Positive: 265, False negative: 0, accuracy: 0.7731164383561644, precision: 0.7731164383561644, recall: 1.0
Epoch: 18 0/3904 Training loss: 0.465963
Epoch: 18 800/3904 Training loss: 0.707520
Epoch: 18 1600/3904 Training loss: 0.114133
Epoch: 18 2400/3904 Training loss: 0.415590
Epoch: 18 3200/3904 Training loss: 0.559316
Training loss: 0.410344
Test loss: 0.542656; True positive: 903; True negative: 0, False Positive: 265, False negative: 0, accuracy: 0.7731164383561644, precision: 0.7731164383561644, recall: 1.0
Epoch: 19 0/3904 Training loss: 0.318997
Epoch: 19 800/3904 Training loss: 0.382345
Epoch: 19 1600/3904 Training loss: 0.359172
Epoch: 19 2400/3904 Training loss: 0.360791
Epoch: 19 3200/3904 Training loss: 0.387088
Training loss: 0.401012
Test loss: 0.550598; True positive: 903; True negative: 0, False Positive: 265, False negative: 0, accuracy: 0.7731164383561644, precision: 0.7731164383561644, recall: 1.0
Epoch: 20 0/3904 Training loss: 0.306702
Epoch: 20 800/3904 Training loss: 0.362271
Epoch: 20 1600/3904 Training loss: 0.185610
Epoch: 20 2400/3904 Training loss: 0.245274
Epoch: 20 3200/3904 Training loss: 0.453610
Training loss: 0.414743
Test loss: 0.572896; True positive: 903; True negative: 0, False Positive: 265, False negative: 0, accuracy: 0.7731164383561644, precision: 0.7731164383561644, recall: 1.0
starting trial 276
[I 2022-12-05 08:16:32,651] Trial 275 finished with value: 0.7731164383561644 and parameters: {'d_model': 64, 'nhead': 8, 'n_encoders': 1, 'learning_rate': 0.00014503023928511262, 'weight_decay': 3.5866739220948655e-06, 'dropout': 0.20395648408055755, 'max_pool_conv': 32, 'kernel_size': 19, 'd_mlp': 32, 'num_conv_layers': 8, 'encoder_dropout': 0.006048820635762818, 'd_feed_forward': 128, 'max_pool_dim': 8, 'n_mlp_layers': 4}. Best is trial 62 with value: 0.860445205479452.
Epoch: 0 0/3904 Training loss: 0.695279
Epoch: 0 800/3904 Training loss: 0.721837
Epoch: 0 1600/3904 Training loss: 0.491875
Epoch: 0 2400/3904 Training loss: 0.785094
Epoch: 0 3200/3904 Training loss: 0.549896
Training loss: 0.660763
Test loss: 0.764932; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 1 0/3904 Training loss: 0.703598
Epoch: 1 800/3904 Training loss: 0.729828
Epoch: 1 1600/3904 Training loss: 0.356884
Epoch: 1 2400/3904 Training loss: 0.792732
Epoch: 1 3200/3904 Training loss: 0.423166
Training loss: 0.604367
Test loss: 1.643493; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 2 0/3904 Training loss: 0.625209
Epoch: 2 800/3904 Training loss: 0.578364
Epoch: 2 1600/3904 Training loss: 0.232445
Epoch: 2 2400/3904 Training loss: 0.507981
Epoch: 2 3200/3904 Training loss: 0.409145
Training loss: 0.486998
Test loss: 2.020262; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 3 0/3904 Training loss: 0.404955
Epoch: 3 800/3904 Training loss: 0.493943
Epoch: 3 1600/3904 Training loss: 0.238387
Epoch: 3 2400/3904 Training loss: 0.476158
Epoch: 3 3200/3904 Training loss: 0.423665
Training loss: 0.422217
Test loss: 2.656296; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 4 0/3904 Training loss: 0.381146
Epoch: 4 800/3904 Training loss: 0.270363
Epoch: 4 1600/3904 Training loss: 0.206427
Epoch: 4 2400/3904 Training loss: 0.400420
Epoch: 4 3200/3904 Training loss: 0.440996
Training loss: 0.390485
Test loss: 2.885879; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 5 0/3904 Training loss: 0.418626
Epoch: 5 800/3904 Training loss: 0.271457
Epoch: 5 1600/3904 Training loss: 0.217196
Epoch: 5 2400/3904 Training loss: 0.304268
Epoch: 5 3200/3904 Training loss: 0.315337
Training loss: 0.368357
Test loss: 0.557737; True positive: 838; True negative: 118, False Positive: 147, False negative: 65, accuracy: 0.8184931506849316, precision: 0.8507614213197969, recall: 0.9280177187153932
Epoch: 6 0/3904 Training loss: 0.374436
Epoch: 6 800/3904 Training loss: 0.185012
Epoch: 6 1600/3904 Training loss: 0.132425
Epoch: 6 2400/3904 Training loss: 0.194475
Epoch: 6 3200/3904 Training loss: 0.381368
Training loss: 0.348703
Test loss: 0.559256; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 7 0/3904 Training loss: 0.306396
Epoch: 7 800/3904 Training loss: 0.253338
Epoch: 7 1600/3904 Training loss: 0.116542
Epoch: 7 2400/3904 Training loss: 0.199101
Epoch: 7 3200/3904 Training loss: 0.406860
Training loss: 0.327521
Test loss: 1.397206; True positive: 333; True negative: 200, False Positive: 65, False negative: 570, accuracy: 0.4563356164383562, precision: 0.8366834170854272, recall: 0.3687707641196013
Epoch: 8 0/3904 Training loss: 0.194769
Epoch: 8 800/3904 Training loss: 0.133181
Epoch: 8 1600/3904 Training loss: 0.111246
Epoch: 8 2400/3904 Training loss: 0.215299
Epoch: 8 3200/3904 Training loss: 0.301048
Training loss: 0.310505
Test loss: 0.584894; True positive: 827; True negative: 117, False Positive: 148, False negative: 76, accuracy: 0.8082191780821918, precision: 0.8482051282051282, recall: 0.9158361018826136
Epoch: 9 0/3904 Training loss: 0.229635
Epoch: 9 800/3904 Training loss: 0.173047
Epoch: 9 1600/3904 Training loss: 0.102264
Epoch: 9 2400/3904 Training loss: 0.189422
Epoch: 9 3200/3904 Training loss: 0.376206
Training loss: 0.296545
Test loss: 0.572049; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 10 0/3904 Training loss: 0.174398
Epoch: 10 800/3904 Training loss: 0.117025
Epoch: 10 1600/3904 Training loss: 0.104836
Epoch: 10 2400/3904 Training loss: 0.193564
Epoch: 10 3200/3904 Training loss: 0.473204
Training loss: 0.273558
Test loss: 0.584473; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 11 0/3904 Training loss: 0.136644
Epoch: 11 800/3904 Training loss: 0.069238
Epoch: 11 1600/3904 Training loss: 0.137686
Epoch: 11 2400/3904 Training loss: 0.216697
Epoch: 11 3200/3904 Training loss: 0.292283
Training loss: 0.260290
Test loss: 0.576683; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 12 0/3904 Training loss: 0.242998
Epoch: 12 800/3904 Training loss: 0.072421
Epoch: 12 1600/3904 Training loss: 0.144353
Epoch: 12 2400/3904 Training loss: 0.182329
Epoch: 12 3200/3904 Training loss: 0.371054
Training loss: 0.235752
Test loss: 0.600967; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 13 0/3904 Training loss: 0.142178
Epoch: 13 800/3904 Training loss: 0.037990
Epoch: 13 1600/3904 Training loss: 0.083501
Epoch: 13 2400/3904 Training loss: 0.133405
Epoch: 13 3200/3904 Training loss: 0.334685
Training loss: 0.233044
Test loss: 0.819201; True positive: 603; True negative: 138, False Positive: 127, False negative: 300, accuracy: 0.634417808219178, precision: 0.826027397260274, recall: 0.6677740863787376
Epoch: 14 0/3904 Training loss: 0.205950
Epoch: 14 800/3904 Training loss: 0.053548
Epoch: 14 1600/3904 Training loss: 0.120469
Epoch: 14 2400/3904 Training loss: 0.198630
Epoch: 14 3200/3904 Training loss: 0.278932
Training loss: 0.211045
Test loss: 0.638502; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 15 0/3904 Training loss: 0.314588
Epoch: 15 800/3904 Training loss: 0.052887
Epoch: 15 1600/3904 Training loss: 0.049460
Epoch: 15 2400/3904 Training loss: 0.077593
Epoch: 15 3200/3904 Training loss: 0.263446
Training loss: 0.195166
Test loss: 0.686559; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
starting trial 277
[I 2022-12-05 08:18:05,511] Trial 276 finished with value: 0.8184931506849316 and parameters: {'d_model': 64, 'nhead': 4, 'n_encoders': 2, 'learning_rate': 0.00013175097556623313, 'weight_decay': 4.895828375261151e-06, 'dropout': 0.19135963311212756, 'max_pool_conv': 32, 'kernel_size': 12, 'd_mlp': 32, 'num_conv_layers': 3, 'encoder_dropout': 0.03855071117886332, 'd_feed_forward': 128, 'max_pool_dim': 8, 'n_mlp_layers': 4}. Best is trial 62 with value: 0.860445205479452.
Epoch: 0 0/3904 Training loss: 0.696525
Epoch: 0 800/3904 Training loss: 0.693390
Epoch: 0 1600/3904 Training loss: 0.585902
Epoch: 0 2400/3904 Training loss: 0.773732
Epoch: 0 3200/3904 Training loss: 0.575715
Training loss: 0.673460
Test loss: 0.777559; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 1 0/3904 Training loss: 0.715397
Epoch: 1 800/3904 Training loss: 0.739052
Epoch: 1 1600/3904 Training loss: 0.479480
Epoch: 1 2400/3904 Training loss: 0.787942
Epoch: 1 3200/3904 Training loss: 0.543824
Training loss: 0.655303
Test loss: 0.821232; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 2 0/3904 Training loss: 0.714977
Epoch: 2 800/3904 Training loss: 0.723108
Epoch: 2 1600/3904 Training loss: 0.416250
Epoch: 2 2400/3904 Training loss: 0.711379
Epoch: 2 3200/3904 Training loss: 0.460075
Training loss: 0.623286
Test loss: 0.691885; True positive: 596; True negative: 105, False Positive: 160, False negative: 307, accuracy: 0.6001712328767124, precision: 0.7883597883597884, recall: 0.6600221483942414
Epoch: 3 0/3904 Training loss: 0.628758
Epoch: 3 800/3904 Training loss: 0.620697
Epoch: 3 1600/3904 Training loss: 0.286520
Epoch: 3 2400/3904 Training loss: 0.638287
Epoch: 3 3200/3904 Training loss: 0.332211
Training loss: 0.528023
Test loss: 1.404393; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 4 0/3904 Training loss: 0.472997
Epoch: 4 800/3904 Training loss: 0.578354
Epoch: 4 1600/3904 Training loss: 0.190899
Epoch: 4 2400/3904 Training loss: 0.436881
Epoch: 4 3200/3904 Training loss: 0.342871
Training loss: 0.472030
Test loss: 1.665343; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 5 0/3904 Training loss: 0.427756
Epoch: 5 800/3904 Training loss: 0.477911
Epoch: 5 1600/3904 Training loss: 0.206190
Epoch: 5 2400/3904 Training loss: 0.428320
Epoch: 5 3200/3904 Training loss: 0.307754
Training loss: 0.439352
Test loss: 1.734288; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 6 0/3904 Training loss: 0.349084
Epoch: 6 800/3904 Training loss: 0.368719
Epoch: 6 1600/3904 Training loss: 0.221503
Epoch: 6 2400/3904 Training loss: 0.408695
Epoch: 6 3200/3904 Training loss: 0.219321
Training loss: 0.414257
Test loss: 1.844234; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 7 0/3904 Training loss: 0.375695
Epoch: 7 800/3904 Training loss: 0.387850
Epoch: 7 1600/3904 Training loss: 0.142909
Epoch: 7 2400/3904 Training loss: 0.481740
Epoch: 7 3200/3904 Training loss: 0.350863
Training loss: 0.396787
Test loss: 1.901876; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 8 0/3904 Training loss: 0.266299
Epoch: 8 800/3904 Training loss: 0.409212
Epoch: 8 1600/3904 Training loss: 0.228889
Epoch: 8 2400/3904 Training loss: 0.456802
Epoch: 8 3200/3904 Training loss: 0.354974
Training loss: 0.371965
Test loss: 1.966325; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 9 0/3904 Training loss: 0.254774
Epoch: 9 800/3904 Training loss: 0.319266
Epoch: 9 1600/3904 Training loss: 0.145638
Epoch: 9 2400/3904 Training loss: 0.503712
Epoch: 9 3200/3904 Training loss: 0.265365
Training loss: 0.357164
Test loss: 2.036965; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 10 0/3904 Training loss: 0.262968
Epoch: 10 800/3904 Training loss: 0.323661
Epoch: 10 1600/3904 Training loss: 0.203096
Epoch: 10 2400/3904 Training loss: 0.571986
Epoch: 10 3200/3904 Training loss: 0.312481
Training loss: 0.336439
Test loss: 2.186548; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 11 0/3904 Training loss: 0.214048
Epoch: 11 800/3904 Training loss: 0.216368
Epoch: 11 1600/3904 Training loss: 0.124804
Epoch: 11 2400/3904 Training loss: 0.480186
Epoch: 11 3200/3904 Training loss: 0.292509
Training loss: 0.314525
Test loss: 2.343403; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 12 0/3904 Training loss: 0.271299
Epoch: 12 800/3904 Training loss: 0.228264
Epoch: 12 1600/3904 Training loss: 0.180690
Epoch: 12 2400/3904 Training loss: 0.473049
Epoch: 12 3200/3904 Training loss: 0.291469
Training loss: 0.306540
Test loss: 2.411549; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
starting trial 278
[I 2022-12-05 08:18:48,836] Trial 277 finished with value: 0.6001712328767124 and parameters: {'d_model': 64, 'nhead': 8, 'n_encoders': 1, 'learning_rate': 9.687110749089414e-05, 'weight_decay': 2.705111535788206e-06, 'dropout': 0.1777559682832292, 'max_pool_conv': 32, 'kernel_size': 5, 'd_mlp': 32, 'num_conv_layers': 3, 'encoder_dropout': 0.1809525663866787, 'd_feed_forward': 128, 'max_pool_dim': 16, 'n_mlp_layers': 4}. Best is trial 62 with value: 0.860445205479452.
Epoch: 0 0/3904 Training loss: 0.696110
Epoch: 0 800/3904 Training loss: 0.697137
Epoch: 0 1600/3904 Training loss: 0.626500
Epoch: 0 2400/3904 Training loss: 0.749583
Epoch: 0 3200/3904 Training loss: 0.600735
Training loss: 0.675862
Test loss: 0.806706; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 1 0/3904 Training loss: 0.703373
Epoch: 1 800/3904 Training loss: 0.731597
Epoch: 1 1600/3904 Training loss: 0.522315
Epoch: 1 2400/3904 Training loss: 0.773925
Epoch: 1 3200/3904 Training loss: 0.557826
Training loss: 0.656531
Test loss: 0.876492; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 2 0/3904 Training loss: 0.708962
Epoch: 2 800/3904 Training loss: 0.727946
Epoch: 2 1600/3904 Training loss: 0.459833
Epoch: 2 2400/3904 Training loss: 0.735132
Epoch: 2 3200/3904 Training loss: 0.526717
Training loss: 0.634005
Test loss: 0.756764; True positive: 65; True negative: 148, False Positive: 117, False negative: 838, accuracy: 0.18236301369863014, precision: 0.35714285714285715, recall: 0.07198228128460686
Epoch: 3 0/3904 Training loss: 0.657251
Epoch: 3 800/3904 Training loss: 0.616405
Epoch: 3 1600/3904 Training loss: 0.380742
Epoch: 3 2400/3904 Training loss: 0.635349
Epoch: 3 3200/3904 Training loss: 0.480390
Training loss: 0.569847
Test loss: 0.675307; True positive: 760; True negative: 27, False Positive: 238, False negative: 143, accuracy: 0.6738013698630136, precision: 0.7615230460921844, recall: 0.8416389811738649
Epoch: 4 0/3904 Training loss: 0.567474
Epoch: 4 800/3904 Training loss: 0.560895
Epoch: 4 1600/3904 Training loss: 0.312672
Epoch: 4 2400/3904 Training loss: 0.525303
Epoch: 4 3200/3904 Training loss: 0.445558
Training loss: 0.510947
Test loss: 1.465017; True positive: 44; True negative: 263, False Positive: 2, False negative: 859, accuracy: 0.2628424657534247, precision: 0.9565217391304348, recall: 0.048726467331118496
Epoch: 5 0/3904 Training loss: 0.506911
Epoch: 5 800/3904 Training loss: 0.459373
Epoch: 5 1600/3904 Training loss: 0.252530
Epoch: 5 2400/3904 Training loss: 0.424944
Epoch: 5 3200/3904 Training loss: 0.442661
Training loss: 0.474685
Test loss: 1.409438; True positive: 163; True negative: 250, False Positive: 15, False negative: 740, accuracy: 0.3535958904109589, precision: 0.9157303370786517, recall: 0.1805094130675526
Epoch: 6 0/3904 Training loss: 0.489058
Epoch: 6 800/3904 Training loss: 0.451571
Epoch: 6 1600/3904 Training loss: 0.252127
Epoch: 6 2400/3904 Training loss: 0.376347
Epoch: 6 3200/3904 Training loss: 0.461993
Training loss: 0.447059
Test loss: 1.361471; True positive: 270; True negative: 231, False Positive: 34, False negative: 633, accuracy: 0.4289383561643836, precision: 0.8881578947368421, recall: 0.29900332225913623
Epoch: 7 0/3904 Training loss: 0.464504
Epoch: 7 800/3904 Training loss: 0.366329
Epoch: 7 1600/3904 Training loss: 0.218803
Epoch: 7 2400/3904 Training loss: 0.373654
Epoch: 7 3200/3904 Training loss: 0.447084
Training loss: 0.426302
Test loss: 2.043563; True positive: 1; True negative: 265, False Positive: 0, False negative: 902, accuracy: 0.22773972602739725, precision: 1.0, recall: 0.0011074197120708748
Epoch: 8 0/3904 Training loss: 0.459914
Epoch: 8 800/3904 Training loss: 0.314032
Epoch: 8 1600/3904 Training loss: 0.248627
Epoch: 8 2400/3904 Training loss: 0.315015
Epoch: 8 3200/3904 Training loss: 0.442307
Training loss: 0.408136
Test loss: 2.188079; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 9 0/3904 Training loss: 0.444694
Epoch: 9 800/3904 Training loss: 0.318745
Epoch: 9 1600/3904 Training loss: 0.201231
Epoch: 9 2400/3904 Training loss: 0.280257
Epoch: 9 3200/3904 Training loss: 0.413720
Training loss: 0.395433
Test loss: 2.295076; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 10 0/3904 Training loss: 0.400455
Epoch: 10 800/3904 Training loss: 0.290494
Epoch: 10 1600/3904 Training loss: 0.231214
Epoch: 10 2400/3904 Training loss: 0.300896
Epoch: 10 3200/3904 Training loss: 0.428210
Training loss: 0.379850
Test loss: 2.222175; True positive: 31; True negative: 261, False Positive: 4, False negative: 872, accuracy: 0.25, precision: 0.8857142857142857, recall: 0.03433001107419712
Epoch: 11 0/3904 Training loss: 0.456891
Epoch: 11 800/3904 Training loss: 0.254162
Epoch: 11 1600/3904 Training loss: 0.217294
Epoch: 11 2400/3904 Training loss: 0.273147
Epoch: 11 3200/3904 Training loss: 0.424071
Training loss: 0.371957
Test loss: 2.403823; True positive: 3; True negative: 264, False Positive: 1, False negative: 900, accuracy: 0.2285958904109589, precision: 0.75, recall: 0.0033222591362126247
Epoch: 12 0/3904 Training loss: 0.404607
Epoch: 12 800/3904 Training loss: 0.255652
Epoch: 12 1600/3904 Training loss: 0.174665
Epoch: 12 2400/3904 Training loss: 0.253329
Epoch: 12 3200/3904 Training loss: 0.406948
Training loss: 0.365054
Test loss: 0.941692; True positive: 613; True negative: 156, False Positive: 109, False negative: 290, accuracy: 0.6583904109589042, precision: 0.8490304709141274, recall: 0.6788482834994463
Epoch: 13 0/3904 Training loss: 0.431651
Epoch: 13 800/3904 Training loss: 0.337017
Epoch: 13 1600/3904 Training loss: 0.145634
Epoch: 13 2400/3904 Training loss: 0.232116
Epoch: 13 3200/3904 Training loss: 0.378898
Training loss: 0.357537
Test loss: 1.225626; True positive: 446; True negative: 224, False Positive: 41, False negative: 457, accuracy: 0.5736301369863014, precision: 0.9158110882956879, recall: 0.4939091915836102
starting trial 279
[I 2022-12-05 08:23:32,963] Trial 278 finished with value: 0.6738013698630136 and parameters: {'d_model': 64, 'nhead': 8, 'n_encoders': 1, 'learning_rate': 2.3805025910565526e-05, 'weight_decay': 4.237503459463588e-06, 'dropout': 0.23650322868880275, 'max_pool_conv': 32, 'kernel_size': 21, 'd_mlp': 32, 'num_conv_layers': 8, 'encoder_dropout': 0.024509103344140894, 'd_feed_forward': 128, 'max_pool_dim': 8, 'n_mlp_layers': 4}. Best is trial 62 with value: 0.860445205479452.
Epoch: 0 0/3904 Training loss: 0.706396
Epoch: 0 800/3904 Training loss: 0.690364
Epoch: 0 1600/3904 Training loss: 0.545700
Epoch: 0 2400/3904 Training loss: 0.777575
Epoch: 0 3200/3904 Training loss: 0.569201
Training loss: 0.675398
Test loss: 0.864601; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 1 0/3904 Training loss: 0.724680
Epoch: 1 800/3904 Training loss: 0.742701
Epoch: 1 1600/3904 Training loss: 0.479504
Epoch: 1 2400/3904 Training loss: 0.795482
Epoch: 1 3200/3904 Training loss: 0.541921
Training loss: 0.655734
Test loss: 0.810648; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 2 0/3904 Training loss: 0.700033
Epoch: 2 800/3904 Training loss: 0.719664
Epoch: 2 1600/3904 Training loss: 0.395098
Epoch: 2 2400/3904 Training loss: 0.736669
Epoch: 2 3200/3904 Training loss: 0.448415
Training loss: 0.616974
Test loss: 0.603212; True positive: 903; True negative: 0, False Positive: 265, False negative: 0, accuracy: 0.7731164383561644, precision: 0.7731164383561644, recall: 1.0
Epoch: 3 0/3904 Training loss: 0.622766
Epoch: 3 800/3904 Training loss: 0.490503
Epoch: 3 1600/3904 Training loss: 0.252103
Epoch: 3 2400/3904 Training loss: 0.700121
Epoch: 3 3200/3904 Training loss: 0.389807
Training loss: 0.511729
Test loss: 0.571844; True positive: 903; True negative: 0, False Positive: 265, False negative: 0, accuracy: 0.7731164383561644, precision: 0.7731164383561644, recall: 1.0
Epoch: 4 0/3904 Training loss: 0.492277
Epoch: 4 800/3904 Training loss: 0.458307
Epoch: 4 1600/3904 Training loss: 0.250754
Epoch: 4 2400/3904 Training loss: 0.561584
Epoch: 4 3200/3904 Training loss: 0.323315
Training loss: 0.462219
Test loss: 0.534274; True positive: 903; True negative: 0, False Positive: 265, False negative: 0, accuracy: 0.7731164383561644, precision: 0.7731164383561644, recall: 1.0
Epoch: 5 0/3904 Training loss: 0.421903
Epoch: 5 800/3904 Training loss: 0.409007
Epoch: 5 1600/3904 Training loss: 0.266583
Epoch: 5 2400/3904 Training loss: 0.471785
Epoch: 5 3200/3904 Training loss: 0.331385
Training loss: 0.422620
Test loss: 0.527848; True positive: 903; True negative: 0, False Positive: 265, False negative: 0, accuracy: 0.7731164383561644, precision: 0.7731164383561644, recall: 1.0
Epoch: 6 0/3904 Training loss: 0.368106
Epoch: 6 800/3904 Training loss: 0.383508
Epoch: 6 1600/3904 Training loss: 0.211760
Epoch: 6 2400/3904 Training loss: 0.445940
Epoch: 6 3200/3904 Training loss: 0.352709
Training loss: 0.402930
Test loss: 0.521913; True positive: 903; True negative: 0, False Positive: 265, False negative: 0, accuracy: 0.7731164383561644, precision: 0.7731164383561644, recall: 1.0
Epoch: 7 0/3904 Training loss: 0.309946
Epoch: 7 800/3904 Training loss: 0.289343
Epoch: 7 1600/3904 Training loss: 0.215879
Epoch: 7 2400/3904 Training loss: 0.353484
Epoch: 7 3200/3904 Training loss: 0.299289
Training loss: 0.373357
Test loss: 0.521973; True positive: 903; True negative: 0, False Positive: 265, False negative: 0, accuracy: 0.7731164383561644, precision: 0.7731164383561644, recall: 1.0
Epoch: 8 0/3904 Training loss: 0.300354
Epoch: 8 800/3904 Training loss: 0.250346
Epoch: 8 1600/3904 Training loss: 0.200319
Epoch: 8 2400/3904 Training loss: 0.402721
Epoch: 8 3200/3904 Training loss: 0.370600
Training loss: 0.356049
Test loss: 0.528662; True positive: 903; True negative: 0, False Positive: 265, False negative: 0, accuracy: 0.7731164383561644, precision: 0.7731164383561644, recall: 1.0
Epoch: 9 0/3904 Training loss: 0.345017
Epoch: 9 800/3904 Training loss: 0.309904
Epoch: 9 1600/3904 Training loss: 0.158481
Epoch: 9 2400/3904 Training loss: 0.406689
Epoch: 9 3200/3904 Training loss: 0.318996
Training loss: 0.335143
Test loss: 0.450896; True positive: 839; True negative: 117, False Positive: 148, False negative: 64, accuracy: 0.8184931506849316, precision: 0.8500506585612969, recall: 0.929125138427464
Epoch: 10 0/3904 Training loss: 0.323576
Epoch: 10 800/3904 Training loss: 0.312969
Epoch: 10 1600/3904 Training loss: 0.098249
Epoch: 10 2400/3904 Training loss: 0.365900
Epoch: 10 3200/3904 Training loss: 0.409219
Training loss: 0.304320
Test loss: 0.552627; True positive: 903; True negative: 0, False Positive: 265, False negative: 0, accuracy: 0.7731164383561644, precision: 0.7731164383561644, recall: 1.0
Epoch: 11 0/3904 Training loss: 0.239024
Epoch: 11 800/3904 Training loss: 0.140912
Epoch: 11 1600/3904 Training loss: 0.097350
Epoch: 11 2400/3904 Training loss: 0.285880
Epoch: 11 3200/3904 Training loss: 0.467531
Training loss: 0.296293
Test loss: 0.584154; True positive: 903; True negative: 0, False Positive: 265, False negative: 0, accuracy: 0.7731164383561644, precision: 0.7731164383561644, recall: 1.0
Epoch: 12 0/3904 Training loss: 0.334464
Epoch: 12 800/3904 Training loss: 0.349613
Epoch: 12 1600/3904 Training loss: 0.120840
Epoch: 12 2400/3904 Training loss: 0.281107
Epoch: 12 3200/3904 Training loss: 0.445426
Training loss: 0.285026
Test loss: 0.625530; True positive: 903; True negative: 0, False Positive: 265, False negative: 0, accuracy: 0.7731164383561644, precision: 0.7731164383561644, recall: 1.0
Epoch: 13 0/3904 Training loss: 0.539097
Epoch: 13 800/3904 Training loss: 0.245358
Epoch: 13 1600/3904 Training loss: 0.130208
Epoch: 13 2400/3904 Training loss: 0.264946
Epoch: 13 3200/3904 Training loss: 0.452355
Training loss: 0.276625
Test loss: 0.626525; True positive: 903; True negative: 1, False Positive: 264, False negative: 0, accuracy: 0.773972602739726, precision: 0.7737789203084833, recall: 1.0
Epoch: 14 0/3904 Training loss: 0.359684
Epoch: 14 800/3904 Training loss: 0.258722
Epoch: 14 1600/3904 Training loss: 0.092983
Epoch: 14 2400/3904 Training loss: 0.301686
Epoch: 14 3200/3904 Training loss: 0.366071
Training loss: 0.249480
Test loss: 0.680659; True positive: 903; True negative: 0, False Positive: 265, False negative: 0, accuracy: 0.7731164383561644, precision: 0.7731164383561644, recall: 1.0
Epoch: 15 0/3904 Training loss: 0.412364
Epoch: 15 800/3904 Training loss: 0.192665
Epoch: 15 1600/3904 Training loss: 0.078113
Epoch: 15 2400/3904 Training loss: 0.197958
Epoch: 15 3200/3904 Training loss: 0.342774
Training loss: 0.242725
Test loss: 0.701517; True positive: 903; True negative: 0, False Positive: 265, False negative: 0, accuracy: 0.7731164383561644, precision: 0.7731164383561644, recall: 1.0
Epoch: 16 0/3904 Training loss: 0.392423
Epoch: 16 800/3904 Training loss: 0.141502
Epoch: 16 1600/3904 Training loss: 0.113788
Epoch: 16 2400/3904 Training loss: 0.234572
Epoch: 16 3200/3904 Training loss: 0.385264
Training loss: 0.233056
Test loss: 0.636333; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 17 0/3904 Training loss: 0.356101
Epoch: 17 800/3904 Training loss: 0.222647
Epoch: 17 1600/3904 Training loss: 0.064183
Epoch: 17 2400/3904 Training loss: 0.240324
Epoch: 17 3200/3904 Training loss: 0.517316
Training loss: 0.225246
Test loss: 0.588109; True positive: 805; True negative: 138, False Positive: 127, False negative: 98, accuracy: 0.8073630136986302, precision: 0.8637339055793991, recall: 0.8914728682170543
Epoch: 18 0/3904 Training loss: 0.261203
Epoch: 18 800/3904 Training loss: 0.120159
Epoch: 18 1600/3904 Training loss: 0.090391
Epoch: 18 2400/3904 Training loss: 0.239419
Epoch: 18 3200/3904 Training loss: 0.438983
Training loss: 0.221917
Test loss: 0.646471; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 19 0/3904 Training loss: 0.371975
Epoch: 19 800/3904 Training loss: 0.381799
Epoch: 19 1600/3904 Training loss: 0.099248
Epoch: 19 2400/3904 Training loss: 0.150117
Epoch: 19 3200/3904 Training loss: 0.435256
Training loss: 0.217281
Test loss: 1.558652; True positive: 440; True negative: 226, False Positive: 39, False negative: 463, accuracy: 0.5702054794520548, precision: 0.918580375782881, recall: 0.48726467331118495
starting trial 280
[I 2022-12-05 08:25:52,020] Trial 279 finished with value: 0.8184931506849316 and parameters: {'d_model': 64, 'nhead': 8, 'n_encoders': 1, 'learning_rate': 7.279123724716258e-05, 'weight_decay': 2.3817333042916704e-06, 'dropout': 0.21441870278184177, 'max_pool_conv': 64, 'kernel_size': 12, 'd_mlp': 16, 'num_conv_layers': 4, 'encoder_dropout': 0.20188072597772586, 'd_feed_forward': 128, 'max_pool_dim': 4, 'n_mlp_layers': 3}. Best is trial 62 with value: 0.860445205479452.
Epoch: 0 0/3904 Training loss: 0.699194
Epoch: 0 800/3904 Training loss: 0.702888
Epoch: 0 1600/3904 Training loss: 0.534366
Epoch: 0 2400/3904 Training loss: 0.785230
Epoch: 0 3200/3904 Training loss: 0.566628
Training loss: 0.664530
Test loss: 0.848315; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 1 0/3904 Training loss: 0.725934
Epoch: 1 800/3904 Training loss: 0.764674
Epoch: 1 1600/3904 Training loss: 0.467288
Epoch: 1 2400/3904 Training loss: 0.816755
Epoch: 1 3200/3904 Training loss: 0.538868
Training loss: 0.655423
Test loss: 0.908967; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 2 0/3904 Training loss: 0.715908
Epoch: 2 800/3904 Training loss: 0.723449
Epoch: 2 1600/3904 Training loss: 0.441488
Epoch: 2 2400/3904 Training loss: 0.760095
Epoch: 2 3200/3904 Training loss: 0.515833
Training loss: 0.644178
Test loss: 1.009710; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 3 0/3904 Training loss: 0.693857
Epoch: 3 800/3904 Training loss: 0.687471
Epoch: 3 1600/3904 Training loss: 0.365497
Epoch: 3 2400/3904 Training loss: 0.646656
Epoch: 3 3200/3904 Training loss: 0.421108
Training loss: 0.608241
Test loss: 1.214535; True positive: 42; True negative: 198, False Positive: 67, False negative: 861, accuracy: 0.2054794520547945, precision: 0.3853211009174312, recall: 0.046511627906976744
Epoch: 4 0/3904 Training loss: 0.603370
Epoch: 4 800/3904 Training loss: 0.627317
Epoch: 4 1600/3904 Training loss: 0.302120
Epoch: 4 2400/3904 Training loss: 0.709826
Epoch: 4 3200/3904 Training loss: 0.384353
Training loss: 0.555298
Test loss: 1.509598; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 5 0/3904 Training loss: 0.557463
Epoch: 5 800/3904 Training loss: 0.561250
Epoch: 5 1600/3904 Training loss: 0.264995
Epoch: 5 2400/3904 Training loss: 0.761190
Epoch: 5 3200/3904 Training loss: 0.368483
Training loss: 0.509210
Test loss: 1.605377; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 6 0/3904 Training loss: 0.498460
Epoch: 6 800/3904 Training loss: 0.514056
Epoch: 6 1600/3904 Training loss: 0.280588
Epoch: 6 2400/3904 Training loss: 0.788323
Epoch: 6 3200/3904 Training loss: 0.344022
Training loss: 0.484187
Test loss: 1.819897; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 7 0/3904 Training loss: 0.446349
Epoch: 7 800/3904 Training loss: 0.460475
Epoch: 7 1600/3904 Training loss: 0.273770
Epoch: 7 2400/3904 Training loss: 0.681176
Epoch: 7 3200/3904 Training loss: 0.308297
Training loss: 0.452993
Test loss: 1.986520; True positive: 0; True negative: 264, False Positive: 1, False negative: 903, accuracy: 0.22602739726027396, precision: 0.0, recall: 0.0
Epoch: 8 0/3904 Training loss: 0.402758
Epoch: 8 800/3904 Training loss: 0.494806
Epoch: 8 1600/3904 Training loss: 0.203805
Epoch: 8 2400/3904 Training loss: 0.758920
Epoch: 8 3200/3904 Training loss: 0.363353
Training loss: 0.433173
Test loss: 1.552761; True positive: 5; True negative: 262, False Positive: 3, False negative: 898, accuracy: 0.2285958904109589, precision: 0.625, recall: 0.005537098560354375
Epoch: 9 0/3904 Training loss: 0.406430
Epoch: 9 800/3904 Training loss: 0.490329
Epoch: 9 1600/3904 Training loss: 0.283299
Epoch: 9 2400/3904 Training loss: 0.621499
Epoch: 9 3200/3904 Training loss: 0.389354
Training loss: 0.413838
Test loss: 0.914108; True positive: 124; True negative: 256, False Positive: 9, False negative: 779, accuracy: 0.3253424657534247, precision: 0.9323308270676691, recall: 0.13732004429678848
Epoch: 10 0/3904 Training loss: 0.318407
Epoch: 10 800/3904 Training loss: 0.357252
Epoch: 10 1600/3904 Training loss: 0.265243
Epoch: 10 2400/3904 Training loss: 0.704237
Epoch: 10 3200/3904 Training loss: 0.399098
Training loss: 0.394649
Test loss: 0.696210; True positive: 543; True negative: 207, False Positive: 58, False negative: 360, accuracy: 0.6421232876712328, precision: 0.9034941763727121, recall: 0.6013289036544851
Epoch: 11 0/3904 Training loss: 0.256196
Epoch: 11 800/3904 Training loss: 0.444468
Epoch: 11 1600/3904 Training loss: 0.264570
Epoch: 11 2400/3904 Training loss: 0.485355
Epoch: 11 3200/3904 Training loss: 0.372773
Training loss: 0.378582
Test loss: 0.565114; True positive: 834; True negative: 117, False Positive: 148, False negative: 69, accuracy: 0.8142123287671232, precision: 0.8492871690427699, recall: 0.9235880398671097
Epoch: 12 0/3904 Training loss: 0.294343
Epoch: 12 800/3904 Training loss: 0.395954
Epoch: 12 1600/3904 Training loss: 0.183873
Epoch: 12 2400/3904 Training loss: 0.561466
Epoch: 12 3200/3904 Training loss: 0.338908
Training loss: 0.361761
Test loss: 0.507099; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 13 0/3904 Training loss: 0.341242
Epoch: 13 800/3904 Training loss: 0.304649
Epoch: 13 1600/3904 Training loss: 0.115646
Epoch: 13 2400/3904 Training loss: 0.655170
Epoch: 13 3200/3904 Training loss: 0.334355
Training loss: 0.344710
Test loss: 0.507330; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 14 0/3904 Training loss: 0.303157
Epoch: 14 800/3904 Training loss: 0.342817
Epoch: 14 1600/3904 Training loss: 0.135857
Epoch: 14 2400/3904 Training loss: 0.482096
Epoch: 14 3200/3904 Training loss: 0.426983
Training loss: 0.325088
Test loss: 0.517609; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 15 0/3904 Training loss: 0.214466
Epoch: 15 800/3904 Training loss: 0.350990
Epoch: 15 1600/3904 Training loss: 0.281065
Epoch: 15 2400/3904 Training loss: 0.517604
Epoch: 15 3200/3904 Training loss: 0.465533
Training loss: 0.324646
Test loss: 0.524101; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 16 0/3904 Training loss: 0.237554
Epoch: 16 800/3904 Training loss: 0.343415
Epoch: 16 1600/3904 Training loss: 0.178881
Epoch: 16 2400/3904 Training loss: 0.524308
Epoch: 16 3200/3904 Training loss: 0.348972
Training loss: 0.320077
Test loss: 0.530085; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 17 0/3904 Training loss: 0.277856
Epoch: 17 800/3904 Training loss: 0.290070
Epoch: 17 1600/3904 Training loss: 0.186475
Epoch: 17 2400/3904 Training loss: 0.449653
Epoch: 17 3200/3904 Training loss: 0.352353
Training loss: 0.299723
Test loss: 0.544832; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 18 0/3904 Training loss: 0.325475
Epoch: 18 800/3904 Training loss: 0.479738
Epoch: 18 1600/3904 Training loss: 0.121894
Epoch: 18 2400/3904 Training loss: 0.355979
Epoch: 18 3200/3904 Training loss: 0.369023
Training loss: 0.296646
Test loss: 0.549430; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 19 0/3904 Training loss: 0.182395
Epoch: 19 800/3904 Training loss: 0.227977
Epoch: 19 1600/3904 Training loss: 0.138705
Epoch: 19 2400/3904 Training loss: 0.435187
Epoch: 19 3200/3904 Training loss: 0.323356
Training loss: 0.277462
Test loss: 0.563883; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 20 0/3904 Training loss: 0.193744
Epoch: 20 800/3904 Training loss: 0.302978
Epoch: 20 1600/3904 Training loss: 0.168207
Epoch: 20 2400/3904 Training loss: 0.304363
Epoch: 20 3200/3904 Training loss: 0.382429
Training loss: 0.278536
Test loss: 0.570917; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 21 0/3904 Training loss: 0.181373
Epoch: 21 800/3904 Training loss: 0.293583
Epoch: 21 1600/3904 Training loss: 0.125672
Epoch: 21 2400/3904 Training loss: 0.233697
Epoch: 21 3200/3904 Training loss: 0.487753
Training loss: 0.266420
Test loss: 0.570438; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 22 0/3904 Training loss: 0.326286
Epoch: 22 800/3904 Training loss: 0.307819
Epoch: 22 1600/3904 Training loss: 0.096136
Epoch: 22 2400/3904 Training loss: 0.328528
Epoch: 22 3200/3904 Training loss: 0.475696
Training loss: 0.268697
Test loss: 0.580972; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
starting trial 281
[I 2022-12-05 08:27:43,354] Trial 280 finished with value: 0.8176369863013698 and parameters: {'d_model': 64, 'nhead': 8, 'n_encoders': 1, 'learning_rate': 4.0235974237196155e-05, 'weight_decay': 3.795594933120882e-06, 'dropout': 0.22348349610804535, 'max_pool_conv': 64, 'kernel_size': 10, 'd_mlp': 32, 'num_conv_layers': 3, 'encoder_dropout': 0.2538622851535571, 'd_feed_forward': 128, 'max_pool_dim': 8, 'n_mlp_layers': 3}. Best is trial 62 with value: 0.860445205479452.
Epoch: 0 0/3904 Training loss: 0.690139
Epoch: 0 800/3904 Training loss: 0.712989
Epoch: 0 1600/3904 Training loss: 0.577016
Epoch: 0 2400/3904 Training loss: 0.761264
Epoch: 0 3200/3904 Training loss: 0.600421
Training loss: 0.668069
Test loss: 0.780989; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 1 0/3904 Training loss: 0.705192
Epoch: 1 800/3904 Training loss: 0.728801
Epoch: 1 1600/3904 Training loss: 0.523196
Epoch: 1 2400/3904 Training loss: 0.794818
Epoch: 1 3200/3904 Training loss: 0.565315
Training loss: 0.659914
Test loss: 0.829400; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 2 0/3904 Training loss: 0.717723
Epoch: 2 800/3904 Training loss: 0.745971
Epoch: 2 1600/3904 Training loss: 0.475224
Epoch: 2 2400/3904 Training loss: 0.796214
Epoch: 2 3200/3904 Training loss: 0.528486
Training loss: 0.652096
Test loss: 0.790134; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 3 0/3904 Training loss: 0.708741
Epoch: 3 800/3904 Training loss: 0.722848
Epoch: 3 1600/3904 Training loss: 0.369098
Epoch: 3 2400/3904 Training loss: 0.794806
Epoch: 3 3200/3904 Training loss: 0.432388
Training loss: 0.605582
Test loss: 0.617592; True positive: 902; True negative: 3, False Positive: 262, False negative: 1, accuracy: 0.7748287671232876, precision: 0.7749140893470791, recall: 0.9988925802879292
Epoch: 4 0/3904 Training loss: 0.620144
Epoch: 4 800/3904 Training loss: 0.564484
Epoch: 4 1600/3904 Training loss: 0.230155
Epoch: 4 2400/3904 Training loss: 0.630173
Epoch: 4 3200/3904 Training loss: 0.346727
Training loss: 0.501638
Test loss: 0.573261; True positive: 876; True negative: 21, False Positive: 244, False negative: 27, accuracy: 0.7679794520547946, precision: 0.7821428571428571, recall: 0.9700996677740864
Epoch: 5 0/3904 Training loss: 0.460137
Epoch: 5 800/3904 Training loss: 0.438214
Epoch: 5 1600/3904 Training loss: 0.221764
Epoch: 5 2400/3904 Training loss: 0.396541
Epoch: 5 3200/3904 Training loss: 0.418467
Training loss: 0.440479
Test loss: 0.573163; True positive: 851; True negative: 35, False Positive: 230, False negative: 52, accuracy: 0.7585616438356164, precision: 0.7872340425531915, recall: 0.9424141749723145
Epoch: 6 0/3904 Training loss: 0.383566
Epoch: 6 800/3904 Training loss: 0.428242
Epoch: 6 1600/3904 Training loss: 0.225835
Epoch: 6 2400/3904 Training loss: 0.368745
Epoch: 6 3200/3904 Training loss: 0.413956
Training loss: 0.410957
Test loss: 0.829539; True positive: 434; True negative: 231, False Positive: 34, False negative: 469, accuracy: 0.5693493150684932, precision: 0.9273504273504274, recall: 0.4806201550387597
Epoch: 7 0/3904 Training loss: 0.313911
Epoch: 7 800/3904 Training loss: 0.426167
Epoch: 7 1600/3904 Training loss: 0.171927
Epoch: 7 2400/3904 Training loss: 0.311179
Epoch: 7 3200/3904 Training loss: 0.472975
Training loss: 0.391935
Test loss: 0.560446; True positive: 802; True negative: 58, False Positive: 207, False negative: 101, accuracy: 0.7363013698630136, precision: 0.7948463825569871, recall: 0.8881506090808416
Epoch: 8 0/3904 Training loss: 0.297633
Epoch: 8 800/3904 Training loss: 0.332474
Epoch: 8 1600/3904 Training loss: 0.175527
Epoch: 8 2400/3904 Training loss: 0.280045
Epoch: 8 3200/3904 Training loss: 0.443999
Training loss: 0.382483
Test loss: 0.695548; True positive: 629; True negative: 193, False Positive: 72, False negative: 274, accuracy: 0.7037671232876712, precision: 0.8972895863052782, recall: 0.6965669988925803
Epoch: 9 0/3904 Training loss: 0.292380
Epoch: 9 800/3904 Training loss: 0.365388
Epoch: 9 1600/3904 Training loss: 0.124150
Epoch: 9 2400/3904 Training loss: 0.304797
Epoch: 9 3200/3904 Training loss: 0.499998
Training loss: 0.365183
Test loss: 0.557025; True positive: 828; True negative: 35, False Positive: 230, False negative: 75, accuracy: 0.7388698630136986, precision: 0.782608695652174, recall: 0.9169435215946844
Epoch: 10 0/3904 Training loss: 0.332951
Epoch: 10 800/3904 Training loss: 0.318127
Epoch: 10 1600/3904 Training loss: 0.171560
Epoch: 10 2400/3904 Training loss: 0.277313
Epoch: 10 3200/3904 Training loss: 0.558089
Training loss: 0.354566
Test loss: 0.538554; True positive: 855; True negative: 20, False Positive: 245, False negative: 48, accuracy: 0.7491438356164384, precision: 0.7772727272727272, recall: 0.946843853820598
Epoch: 11 0/3904 Training loss: 0.289053
Epoch: 11 800/3904 Training loss: 0.311534
Epoch: 11 1600/3904 Training loss: 0.181292
Epoch: 11 2400/3904 Training loss: 0.218615
Epoch: 11 3200/3904 Training loss: 0.513651
Training loss: 0.344315
Test loss: 0.640806; True positive: 726; True negative: 75, False Positive: 190, False negative: 177, accuracy: 0.6857876712328768, precision: 0.7925764192139738, recall: 0.8039867109634552
Epoch: 12 0/3904 Training loss: 0.274288
Epoch: 12 800/3904 Training loss: 0.278644
Epoch: 12 1600/3904 Training loss: 0.118710
Epoch: 12 2400/3904 Training loss: 0.238382
Epoch: 12 3200/3904 Training loss: 0.507711
Training loss: 0.334720
Test loss: 0.655804; True positive: 696; True negative: 88, False Positive: 177, False negative: 207, accuracy: 0.6712328767123288, precision: 0.7972508591065293, recall: 0.770764119601329
Epoch: 13 0/3904 Training loss: 0.306067
Epoch: 13 800/3904 Training loss: 0.233754
Epoch: 13 1600/3904 Training loss: 0.131528
Epoch: 13 2400/3904 Training loss: 0.195175
Epoch: 13 3200/3904 Training loss: 0.521283
Training loss: 0.326104
Test loss: 0.574027; True positive: 762; True negative: 63, False Positive: 202, False negative: 141, accuracy: 0.7063356164383562, precision: 0.7904564315352697, recall: 0.8438538205980066
Epoch: 14 0/3904 Training loss: 0.281357
Epoch: 14 800/3904 Training loss: 0.233886
Epoch: 14 1600/3904 Training loss: 0.070271
Epoch: 14 2400/3904 Training loss: 0.187205
Epoch: 14 3200/3904 Training loss: 0.520202
Training loss: 0.308988
Test loss: 0.531334; True positive: 835; True negative: 32, False Positive: 233, False negative: 68, accuracy: 0.7422945205479452, precision: 0.7818352059925093, recall: 0.9246954595791805
Epoch: 15 0/3904 Training loss: 0.341770
Epoch: 15 800/3904 Training loss: 0.238050
Epoch: 15 1600/3904 Training loss: 0.131594
Epoch: 15 2400/3904 Training loss: 0.185141
Epoch: 15 3200/3904 Training loss: 0.394821
Training loss: 0.299478
Test loss: 0.505890; True positive: 889; True negative: 3, False Positive: 262, False negative: 14, accuracy: 0.7636986301369864, precision: 0.7723718505647263, recall: 0.9844961240310077
Epoch: 16 0/3904 Training loss: 0.212885
Epoch: 16 800/3904 Training loss: 0.224578
Epoch: 16 1600/3904 Training loss: 0.108773
Epoch: 16 2400/3904 Training loss: 0.177919
Epoch: 16 3200/3904 Training loss: 0.417786
Training loss: 0.292181
Test loss: 0.504570; True positive: 902; True negative: 1, False Positive: 264, False negative: 1, accuracy: 0.7731164383561644, precision: 0.7735849056603774, recall: 0.9988925802879292
Epoch: 17 0/3904 Training loss: 0.313516
Epoch: 17 800/3904 Training loss: 0.176103
Epoch: 17 1600/3904 Training loss: 0.052005
Epoch: 17 2400/3904 Training loss: 0.180780
Epoch: 17 3200/3904 Training loss: 0.525031
Training loss: 0.280591
Test loss: 0.521957; True positive: 903; True negative: 0, False Positive: 265, False negative: 0, accuracy: 0.7731164383561644, precision: 0.7731164383561644, recall: 1.0
Epoch: 18 0/3904 Training loss: 0.299056
Epoch: 18 800/3904 Training loss: 0.271002
Epoch: 18 1600/3904 Training loss: 0.050536
Epoch: 18 2400/3904 Training loss: 0.127606
Epoch: 18 3200/3904 Training loss: 0.573317
Training loss: 0.274756
Test loss: 0.523711; True positive: 903; True negative: 0, False Positive: 265, False negative: 0, accuracy: 0.7731164383561644, precision: 0.7731164383561644, recall: 1.0
Epoch: 19 0/3904 Training loss: 0.227946
Epoch: 19 800/3904 Training loss: 0.262446
Epoch: 19 1600/3904 Training loss: 0.052664
Epoch: 19 2400/3904 Training loss: 0.182635
Epoch: 19 3200/3904 Training loss: 0.495368
Training loss: 0.258599
Test loss: 0.512541; True positive: 902; True negative: 1, False Positive: 264, False negative: 1, accuracy: 0.7731164383561644, precision: 0.7735849056603774, recall: 0.9988925802879292
Epoch: 20 0/3904 Training loss: 0.248497
Epoch: 20 800/3904 Training loss: 0.213685
Epoch: 20 1600/3904 Training loss: 0.070646
Epoch: 20 2400/3904 Training loss: 0.124826
Epoch: 20 3200/3904 Training loss: 0.619553
Training loss: 0.248691
Test loss: 0.499356; True positive: 903; True negative: 0, False Positive: 265, False negative: 0, accuracy: 0.7731164383561644, precision: 0.7731164383561644, recall: 1.0
Epoch: 21 0/3904 Training loss: 0.252288
Epoch: 21 800/3904 Training loss: 0.129777
Epoch: 21 1600/3904 Training loss: 0.053339
Epoch: 21 2400/3904 Training loss: 0.139379
Epoch: 21 3200/3904 Training loss: 0.477332
Training loss: 0.237492
Test loss: 0.511971; True positive: 903; True negative: 0, False Positive: 265, False negative: 0, accuracy: 0.7731164383561644, precision: 0.7731164383561644, recall: 1.0
Epoch: 22 0/3904 Training loss: 0.225861
Epoch: 22 800/3904 Training loss: 0.214193
Epoch: 22 1600/3904 Training loss: 0.082465
Epoch: 22 2400/3904 Training loss: 0.152013
Epoch: 22 3200/3904 Training loss: 0.564444
Training loss: 0.225470
Test loss: 0.483365; True positive: 884; True negative: 63, False Positive: 202, False negative: 19, accuracy: 0.8107876712328768, precision: 0.8139963167587477, recall: 0.9789590254706534
Epoch: 23 0/3904 Training loss: 0.275367
Epoch: 23 800/3904 Training loss: 0.141409
Epoch: 23 1600/3904 Training loss: 0.033857
Epoch: 23 2400/3904 Training loss: 0.114788
Epoch: 23 3200/3904 Training loss: 0.486025
Training loss: 0.220201
Test loss: 0.526301; True positive: 903; True negative: 0, False Positive: 265, False negative: 0, accuracy: 0.7731164383561644, precision: 0.7731164383561644, recall: 1.0
Epoch: 24 0/3904 Training loss: 0.240621
Epoch: 24 800/3904 Training loss: 0.263552
Epoch: 24 1600/3904 Training loss: 0.052129
Epoch: 24 2400/3904 Training loss: 0.090050
Epoch: 24 3200/3904 Training loss: 0.309776
Training loss: 0.218033
Test loss: 0.507710; True positive: 887; True negative: 54, False Positive: 211, False negative: 16, accuracy: 0.8056506849315068, precision: 0.807832422586521, recall: 0.982281284606866
Epoch: 25 0/3904 Training loss: 0.206200
Epoch: 25 800/3904 Training loss: 0.147402
Epoch: 25 1600/3904 Training loss: 0.030832
Epoch: 25 2400/3904 Training loss: 0.094609
Epoch: 25 3200/3904 Training loss: 0.383300
Training loss: 0.209042
Test loss: 0.593162; True positive: 897; True negative: 4, False Positive: 261, False negative: 6, accuracy: 0.771404109589041, precision: 0.7746113989637305, recall: 0.9933554817275747
Epoch: 26 0/3904 Training loss: 0.224755
Epoch: 26 800/3904 Training loss: 0.096117
Epoch: 26 1600/3904 Training loss: 0.026559
Epoch: 26 2400/3904 Training loss: 0.096770
Epoch: 26 3200/3904 Training loss: 0.663190
Training loss: 0.195867
Test loss: 0.599794; True positive: 893; True negative: 3, False Positive: 262, False negative: 10, accuracy: 0.7671232876712328, precision: 0.7731601731601732, recall: 0.9889258028792912
Epoch: 27 0/3904 Training loss: 0.221805
Epoch: 27 800/3904 Training loss: 0.066773
Epoch: 27 1600/3904 Training loss: 0.024315
Epoch: 27 2400/3904 Training loss: 0.096911
Epoch: 27 3200/3904 Training loss: 0.567565
Training loss: 0.195927
Test loss: 0.638336; True positive: 855; True negative: 5, False Positive: 260, False negative: 48, accuracy: 0.7363013698630136, precision: 0.7668161434977578, recall: 0.946843853820598
Epoch: 28 0/3904 Training loss: 0.230943
Epoch: 28 800/3904 Training loss: 0.061427
Epoch: 28 1600/3904 Training loss: 0.031173
Epoch: 28 2400/3904 Training loss: 0.061456
Epoch: 28 3200/3904 Training loss: 0.615741
Training loss: 0.185490
Test loss: 0.692609; True positive: 605; True negative: 19, False Positive: 246, False negative: 298, accuracy: 0.5342465753424658, precision: 0.7109283196239718, recall: 0.6699889258028793
Epoch: 29 0/3904 Training loss: 0.225120
Epoch: 29 800/3904 Training loss: 0.093189
Epoch: 29 1600/3904 Training loss: 0.013115
Epoch: 29 2400/3904 Training loss: 0.094942
Epoch: 29 3200/3904 Training loss: 0.433189
Training loss: 0.177770
Test loss: 0.752578; True positive: 330; True negative: 115, False Positive: 150, False negative: 573, accuracy: 0.3809931506849315, precision: 0.6875, recall: 0.3654485049833887
starting trial 282
[I 2022-12-05 08:29:11,701] Trial 281 finished with value: 0.8107876712328768 and parameters: {'d_model': 64, 'nhead': 4, 'n_encoders': 1, 'learning_rate': 0.0001565379064881765, 'weight_decay': 3.338165328697401e-06, 'dropout': 0.20305447031684806, 'max_pool_conv': 32, 'kernel_size': 4, 'd_mlp': 16, 'num_conv_layers': 3, 'encoder_dropout': 0.15000388046565025, 'd_feed_forward': 128, 'max_pool_dim': 16, 'n_mlp_layers': 3}. Best is trial 62 with value: 0.860445205479452.
Epoch: 0 0/3904 Training loss: 0.699066
Epoch: 0 800/3904 Training loss: 0.713184
Epoch: 0 1600/3904 Training loss: 0.500833
Epoch: 0 2400/3904 Training loss: 0.808569
Epoch: 0 3200/3904 Training loss: 0.551763
Training loss: 0.664570
Test loss: 0.848215; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 1 0/3904 Training loss: 0.720626
Epoch: 1 800/3904 Training loss: 0.722080
Epoch: 1 1600/3904 Training loss: 0.434354
Epoch: 1 2400/3904 Training loss: 0.734022
Epoch: 1 3200/3904 Training loss: 0.507955
Training loss: 0.637648
Test loss: 0.849754; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 2 0/3904 Training loss: 0.678154
Epoch: 2 800/3904 Training loss: 0.643082
Epoch: 2 1600/3904 Training loss: 0.346868
Epoch: 2 2400/3904 Training loss: 0.684422
Epoch: 2 3200/3904 Training loss: 0.459667
Training loss: 0.575333
Test loss: 1.115222; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 3 0/3904 Training loss: 0.549853
Epoch: 3 800/3904 Training loss: 0.521624
Epoch: 3 1600/3904 Training loss: 0.260848
Epoch: 3 2400/3904 Training loss: 0.599078
Epoch: 3 3200/3904 Training loss: 0.398042
Training loss: 0.496457
Test loss: 1.431292; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 4 0/3904 Training loss: 0.437234
Epoch: 4 800/3904 Training loss: 0.417603
Epoch: 4 1600/3904 Training loss: 0.233682
Epoch: 4 2400/3904 Training loss: 0.646096
Epoch: 4 3200/3904 Training loss: 0.440406
Training loss: 0.445304
Test loss: 1.520903; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 5 0/3904 Training loss: 0.382810
Epoch: 5 800/3904 Training loss: 0.369837
Epoch: 5 1600/3904 Training loss: 0.266690
Epoch: 5 2400/3904 Training loss: 0.674342
Epoch: 5 3200/3904 Training loss: 0.309314
Training loss: 0.411818
Test loss: 1.246773; True positive: 76; True negative: 265, False Positive: 0, False negative: 827, accuracy: 0.2919520547945205, precision: 1.0, recall: 0.08416389811738649
Epoch: 6 0/3904 Training loss: 0.362086
Epoch: 6 800/3904 Training loss: 0.318547
Epoch: 6 1600/3904 Training loss: 0.190283
Epoch: 6 2400/3904 Training loss: 0.506190
Epoch: 6 3200/3904 Training loss: 0.339633
Training loss: 0.378187
Test loss: 0.485086; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 7 0/3904 Training loss: 0.265009
Epoch: 7 800/3904 Training loss: 0.291206
Epoch: 7 1600/3904 Training loss: 0.211287
Epoch: 7 2400/3904 Training loss: 0.463639
Epoch: 7 3200/3904 Training loss: 0.261706
Training loss: 0.354095
Test loss: 0.498720; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 8 0/3904 Training loss: 0.293826
Epoch: 8 800/3904 Training loss: 0.346856
Epoch: 8 1600/3904 Training loss: 0.161705
Epoch: 8 2400/3904 Training loss: 0.381946
Epoch: 8 3200/3904 Training loss: 0.425276
Training loss: 0.327493
Test loss: 0.507486; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 9 0/3904 Training loss: 0.235667
Epoch: 9 800/3904 Training loss: 0.211183
Epoch: 9 1600/3904 Training loss: 0.173612
Epoch: 9 2400/3904 Training loss: 0.601032
Epoch: 9 3200/3904 Training loss: 0.389470
Training loss: 0.316933
Test loss: 0.518385; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 10 0/3904 Training loss: 0.302623
Epoch: 10 800/3904 Training loss: 0.175031
Epoch: 10 1600/3904 Training loss: 0.165331
Epoch: 10 2400/3904 Training loss: 0.689474
Epoch: 10 3200/3904 Training loss: 0.383170
Training loss: 0.301159
Test loss: 0.529899; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 11 0/3904 Training loss: 0.338781
Epoch: 11 800/3904 Training loss: 0.228522
Epoch: 11 1600/3904 Training loss: 0.156172
Epoch: 11 2400/3904 Training loss: 0.426678
Epoch: 11 3200/3904 Training loss: 0.365189
Training loss: 0.289569
Test loss: 0.543707; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 12 0/3904 Training loss: 0.425850
Epoch: 12 800/3904 Training loss: 0.198367
Epoch: 12 1600/3904 Training loss: 0.178562
Epoch: 12 2400/3904 Training loss: 0.285240
Epoch: 12 3200/3904 Training loss: 0.323165
Training loss: 0.285298
Test loss: 0.545819; True positive: 838; True negative: 118, False Positive: 147, False negative: 65, accuracy: 0.8184931506849316, precision: 0.8507614213197969, recall: 0.9280177187153932
Epoch: 13 0/3904 Training loss: 0.362487
Epoch: 13 800/3904 Training loss: 0.192494
Epoch: 13 1600/3904 Training loss: 0.114862
Epoch: 13 2400/3904 Training loss: 0.301157
Epoch: 13 3200/3904 Training loss: 0.320859
Training loss: 0.267184
Test loss: 0.538437; True positive: 838; True negative: 120, False Positive: 145, False negative: 65, accuracy: 0.8202054794520548, precision: 0.8524923702950152, recall: 0.9280177187153932
Epoch: 14 0/3904 Training loss: 0.232328
Epoch: 14 800/3904 Training loss: 0.137485
Epoch: 14 1600/3904 Training loss: 0.206693
Epoch: 14 2400/3904 Training loss: 0.315479
Epoch: 14 3200/3904 Training loss: 0.410359
Training loss: 0.258073
Test loss: 0.560041; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 15 0/3904 Training loss: 0.310081
Epoch: 15 800/3904 Training loss: 0.214015
Epoch: 15 1600/3904 Training loss: 0.124298
Epoch: 15 2400/3904 Training loss: 0.286891
Epoch: 15 3200/3904 Training loss: 0.401435
Training loss: 0.257915
Test loss: 0.527016; True positive: 836; True negative: 120, False Positive: 145, False negative: 67, accuracy: 0.8184931506849316, precision: 0.8521916411824668, recall: 0.9258028792912514
Epoch: 16 0/3904 Training loss: 0.284439
Epoch: 16 800/3904 Training loss: 0.162857
Epoch: 16 1600/3904 Training loss: 0.150443
Epoch: 16 2400/3904 Training loss: 0.207937
Epoch: 16 3200/3904 Training loss: 0.334973
Training loss: 0.245474
Test loss: 0.572478; True positive: 738; True negative: 166, False Positive: 99, False negative: 165, accuracy: 0.773972602739726, precision: 0.8817204301075269, recall: 0.8172757475083057
starting trial 283
[I 2022-12-05 08:30:02,016] Trial 282 finished with value: 0.8202054794520548 and parameters: {'d_model': 32, 'nhead': 8, 'n_encoders': 1, 'learning_rate': 0.00011761159416865115, 'weight_decay': 5.653285556343838e-06, 'dropout': 0.18584806641008236, 'max_pool_conv': 64, 'kernel_size': 11, 'd_mlp': 16, 'num_conv_layers': 3, 'encoder_dropout': 0.09938997690672507, 'd_feed_forward': 128, 'max_pool_dim': 8, 'n_mlp_layers': 3}. Best is trial 62 with value: 0.860445205479452.
Epoch: 0 0/3904 Training loss: 0.696603
Epoch: 0 800/3904 Training loss: 0.707150
Epoch: 0 1600/3904 Training loss: 0.413625
Epoch: 0 2400/3904 Training loss: 0.754389
Epoch: 0 3200/3904 Training loss: 0.542316
Training loss: 0.667514
Test loss: 0.732889; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 1 0/3904 Training loss: 0.683439
Epoch: 1 800/3904 Training loss: 0.706602
Epoch: 1 1600/3904 Training loss: 0.398815
Epoch: 1 2400/3904 Training loss: 0.748224
Epoch: 1 3200/3904 Training loss: 0.524167
Training loss: 0.656371
Test loss: 0.670013; True positive: 903; True negative: 0, False Positive: 265, False negative: 0, accuracy: 0.7731164383561644, precision: 0.7731164383561644, recall: 1.0
Epoch: 2 0/3904 Training loss: 0.654231
Epoch: 2 800/3904 Training loss: 0.719705
Epoch: 2 1600/3904 Training loss: 0.308418
Epoch: 2 2400/3904 Training loss: 0.776317
Epoch: 2 3200/3904 Training loss: 0.544663
Training loss: 0.660840
Test loss: 0.723297; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 3 0/3904 Training loss: 0.692054
Epoch: 3 800/3904 Training loss: 0.702386
Epoch: 3 1600/3904 Training loss: 0.351778
Epoch: 3 2400/3904 Training loss: 0.789621
Epoch: 3 3200/3904 Training loss: 0.492996
Training loss: 0.645122
Test loss: 0.674766; True positive: 903; True negative: 0, False Positive: 265, False negative: 0, accuracy: 0.7731164383561644, precision: 0.7731164383561644, recall: 1.0
Epoch: 4 0/3904 Training loss: 0.676956
Epoch: 4 800/3904 Training loss: 0.552598
Epoch: 4 1600/3904 Training loss: 0.291414
Epoch: 4 2400/3904 Training loss: 0.795624
Epoch: 4 3200/3904 Training loss: 0.462997
Training loss: 0.587396
Test loss: 0.616863; True positive: 903; True negative: 0, False Positive: 265, False negative: 0, accuracy: 0.7731164383561644, precision: 0.7731164383561644, recall: 1.0
Epoch: 5 0/3904 Training loss: 0.449118
Epoch: 5 800/3904 Training loss: 0.444968
Epoch: 5 1600/3904 Training loss: 0.203045
Epoch: 5 2400/3904 Training loss: 0.721539
Epoch: 5 3200/3904 Training loss: 0.527009
Training loss: 0.499603
Test loss: 1.044322; True positive: 397; True negative: 49, False Positive: 216, False negative: 506, accuracy: 0.3818493150684932, precision: 0.6476345840130505, recall: 0.43964562569213733
Epoch: 6 0/3904 Training loss: 0.283763
Epoch: 6 800/3904 Training loss: 0.332956
Epoch: 6 1600/3904 Training loss: 0.178094
Epoch: 6 2400/3904 Training loss: 0.686181
Epoch: 6 3200/3904 Training loss: 0.477830
Training loss: 0.450550
Test loss: 0.541364; True positive: 878; True negative: 17, False Positive: 248, False negative: 25, accuracy: 0.7662671232876712, precision: 0.7797513321492007, recall: 0.9723145071982281
Epoch: 7 0/3904 Training loss: 0.331752
Epoch: 7 800/3904 Training loss: 0.298483
Epoch: 7 1600/3904 Training loss: 0.190943
Epoch: 7 2400/3904 Training loss: 0.581136
Epoch: 7 3200/3904 Training loss: 0.562626
Training loss: 0.462910
Test loss: 1.061813; True positive: 365; True negative: 52, False Positive: 213, False negative: 538, accuracy: 0.3570205479452055, precision: 0.6314878892733564, recall: 0.40420819490586934
Epoch: 8 0/3904 Training loss: 0.282634
Epoch: 8 800/3904 Training loss: 0.503071
Epoch: 8 1600/3904 Training loss: 0.267286
Epoch: 8 2400/3904 Training loss: 0.328847
Epoch: 8 3200/3904 Training loss: 0.501546
Training loss: 0.447024
Test loss: 0.820175; True positive: 613; True negative: 32, False Positive: 233, False negative: 290, accuracy: 0.5522260273972602, precision: 0.7245862884160756, recall: 0.6788482834994463
Epoch: 9 0/3904 Training loss: 0.288180
Epoch: 9 800/3904 Training loss: 0.363606
Epoch: 9 1600/3904 Training loss: 0.201892
Epoch: 9 2400/3904 Training loss: 0.480920
Epoch: 9 3200/3904 Training loss: 0.512072
Training loss: 0.434949
Test loss: 0.775707; True positive: 705; True negative: 8, False Positive: 257, False negative: 198, accuracy: 0.610445205479452, precision: 0.7328482328482329, recall: 0.7807308970099668
Epoch: 10 0/3904 Training loss: 0.304214
Epoch: 10 800/3904 Training loss: 0.380857
Epoch: 10 1600/3904 Training loss: 0.141181
Epoch: 10 2400/3904 Training loss: 0.570635
Epoch: 10 3200/3904 Training loss: 0.482895
Training loss: 0.417571
Test loss: 1.735246; True positive: 189; True negative: 123, False Positive: 142, False negative: 714, accuracy: 0.2671232876712329, precision: 0.5709969788519638, recall: 0.20930232558139536
Epoch: 11 0/3904 Training loss: 0.324481
Epoch: 11 800/3904 Training loss: 0.321272
Epoch: 11 1600/3904 Training loss: 0.200651
Epoch: 11 2400/3904 Training loss: 0.508479
Epoch: 11 3200/3904 Training loss: 0.573152
Training loss: 0.421921
Test loss: 0.968396; True positive: 457; True negative: 127, False Positive: 138, False negative: 446, accuracy: 0.5, precision: 0.7680672268907563, recall: 0.5060908084163898
Epoch: 12 0/3904 Training loss: 0.359921
Epoch: 12 800/3904 Training loss: 0.333677
Epoch: 12 1600/3904 Training loss: 0.131714
Epoch: 12 2400/3904 Training loss: 0.499299
Epoch: 12 3200/3904 Training loss: 0.547060
Training loss: 0.419075
Test loss: 1.717220; True positive: 285; True negative: 143, False Positive: 122, False negative: 618, accuracy: 0.3664383561643836, precision: 0.7002457002457002, recall: 0.31561461794019935
Epoch: 13 0/3904 Training loss: 0.346892
Epoch: 13 800/3904 Training loss: 0.337777
Epoch: 13 1600/3904 Training loss: 0.103302
Epoch: 13 2400/3904 Training loss: 0.617406
Epoch: 13 3200/3904 Training loss: 0.482836
Training loss: 0.408069
Test loss: 1.526724; True positive: 206; True negative: 202, False Positive: 63, False negative: 697, accuracy: 0.3493150684931507, precision: 0.7657992565055762, recall: 0.22812846068660023
Epoch: 14 0/3904 Training loss: 0.376155
Epoch: 14 800/3904 Training loss: 0.278977
Epoch: 14 1600/3904 Training loss: 0.100254
Epoch: 14 2400/3904 Training loss: 0.514666
Epoch: 14 3200/3904 Training loss: 0.468388
Training loss: 0.431372
Test loss: 1.844966; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 15 0/3904 Training loss: 0.326052
Epoch: 15 800/3904 Training loss: 0.363621
Epoch: 15 1600/3904 Training loss: 0.138517
Epoch: 15 2400/3904 Training loss: 0.575535
Epoch: 15 3200/3904 Training loss: 0.523766
Training loss: 0.411365
Test loss: 1.415709; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 16 0/3904 Training loss: 0.297262
Epoch: 16 800/3904 Training loss: 0.302370
Epoch: 16 1600/3904 Training loss: 0.127243
Epoch: 16 2400/3904 Training loss: 0.450304
Epoch: 16 3200/3904 Training loss: 0.414388
Training loss: 0.419555
Test loss: 0.807316; True positive: 455; True negative: 135, False Positive: 130, False negative: 448, accuracy: 0.5051369863013698, precision: 0.7777777777777778, recall: 0.5038759689922481
starting trial 284
[I 2022-12-05 08:34:01,400] Trial 283 finished with value: 0.7731164383561644 and parameters: {'d_model': 64, 'nhead': 8, 'n_encoders': 2, 'learning_rate': 0.0006068490117847084, 'weight_decay': 4.579399510214366e-06, 'dropout': 0.16877286185802248, 'max_pool_conv': 32, 'kernel_size': 13, 'd_mlp': 32, 'num_conv_layers': 8, 'encoder_dropout': 0.013972449467853875, 'd_feed_forward': 128, 'max_pool_dim': 8, 'n_mlp_layers': 3}. Best is trial 62 with value: 0.860445205479452.
Epoch: 0 0/3904 Training loss: 0.687753
Epoch: 0 800/3904 Training loss: 0.698587
Epoch: 0 1600/3904 Training loss: 0.527930
Epoch: 0 2400/3904 Training loss: 0.796578
Epoch: 0 3200/3904 Training loss: 0.564854
Training loss: 0.665146
Test loss: 0.893113; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 1 0/3904 Training loss: 0.721416
Epoch: 1 800/3904 Training loss: 0.743562
Epoch: 1 1600/3904 Training loss: 0.435340
Epoch: 1 2400/3904 Training loss: 0.754771
Epoch: 1 3200/3904 Training loss: 0.523756
Training loss: 0.642504
Test loss: 0.718990; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 2 0/3904 Training loss: 0.660284
Epoch: 2 800/3904 Training loss: 0.694654
Epoch: 2 1600/3904 Training loss: 0.403024
Epoch: 2 2400/3904 Training loss: 0.666254
Epoch: 2 3200/3904 Training loss: 0.487477
Training loss: 0.596435
Test loss: 0.665944; True positive: 903; True negative: 0, False Positive: 265, False negative: 0, accuracy: 0.7731164383561644, precision: 0.7731164383561644, recall: 1.0
Epoch: 3 0/3904 Training loss: 0.577324
Epoch: 3 800/3904 Training loss: 0.541862
Epoch: 3 1600/3904 Training loss: 0.278438
Epoch: 3 2400/3904 Training loss: 0.646329
Epoch: 3 3200/3904 Training loss: 0.397208
Training loss: 0.514376
Test loss: 0.913376; True positive: 0; True negative: 264, False Positive: 1, False negative: 903, accuracy: 0.22602739726027396, precision: 0.0, recall: 0.0
Epoch: 4 0/3904 Training loss: 0.520896
Epoch: 4 800/3904 Training loss: 0.483749
Epoch: 4 1600/3904 Training loss: 0.270606
Epoch: 4 2400/3904 Training loss: 0.587502
Epoch: 4 3200/3904 Training loss: 0.412748
Training loss: 0.459456
Test loss: 1.216824; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 5 0/3904 Training loss: 0.422032
Epoch: 5 800/3904 Training loss: 0.373249
Epoch: 5 1600/3904 Training loss: 0.236111
Epoch: 5 2400/3904 Training loss: 0.410879
Epoch: 5 3200/3904 Training loss: 0.385077
Training loss: 0.417138
Test loss: 1.242604; True positive: 1; True negative: 264, False Positive: 1, False negative: 902, accuracy: 0.2268835616438356, precision: 0.5, recall: 0.0011074197120708748
Epoch: 6 0/3904 Training loss: 0.358554
Epoch: 6 800/3904 Training loss: 0.321529
Epoch: 6 1600/3904 Training loss: 0.202214
Epoch: 6 2400/3904 Training loss: 0.471294
Epoch: 6 3200/3904 Training loss: 0.495136
Training loss: 0.389404
Test loss: 1.664427; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 7 0/3904 Training loss: 0.326501
Epoch: 7 800/3904 Training loss: 0.276897
Epoch: 7 1600/3904 Training loss: 0.207194
Epoch: 7 2400/3904 Training loss: 0.364426
Epoch: 7 3200/3904 Training loss: 0.372705
Training loss: 0.363444
Test loss: 1.534966; True positive: 1; True negative: 264, False Positive: 1, False negative: 902, accuracy: 0.2268835616438356, precision: 0.5, recall: 0.0011074197120708748
Epoch: 8 0/3904 Training loss: 0.342779
Epoch: 8 800/3904 Training loss: 0.269333
Epoch: 8 1600/3904 Training loss: 0.160565
Epoch: 8 2400/3904 Training loss: 0.390128
Epoch: 8 3200/3904 Training loss: 0.487010
Training loss: 0.332937
Test loss: 1.867202; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 9 0/3904 Training loss: 0.305858
Epoch: 9 800/3904 Training loss: 0.216225
Epoch: 9 1600/3904 Training loss: 0.145110
Epoch: 9 2400/3904 Training loss: 0.312328
Epoch: 9 3200/3904 Training loss: 0.462770
Training loss: 0.308327
Test loss: 1.972542; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 10 0/3904 Training loss: 0.417137
Epoch: 10 800/3904 Training loss: 0.194882
Epoch: 10 1600/3904 Training loss: 0.153721
Epoch: 10 2400/3904 Training loss: 0.281919
Epoch: 10 3200/3904 Training loss: 0.378530
Training loss: 0.291364
Test loss: 2.043533; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 11 0/3904 Training loss: 0.342116
Epoch: 11 800/3904 Training loss: 0.121524
Epoch: 11 1600/3904 Training loss: 0.199709
Epoch: 11 2400/3904 Training loss: 0.210386
Epoch: 11 3200/3904 Training loss: 0.368033
Training loss: 0.280287
Test loss: 2.100725; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 12 0/3904 Training loss: 0.343496
Epoch: 12 800/3904 Training loss: 0.169043
Epoch: 12 1600/3904 Training loss: 0.170554
Epoch: 12 2400/3904 Training loss: 0.240006
Epoch: 12 3200/3904 Training loss: 0.423825
Training loss: 0.265384
Test loss: 2.083807; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
starting trial 285
[I 2022-12-05 08:35:26,836] Trial 284 finished with value: 0.7731164383561644 and parameters: {'d_model': 64, 'nhead': 8, 'n_encoders': 1, 'learning_rate': 6.270061704169085e-05, 'weight_decay': 2.8971186284008185e-06, 'dropout': 0.24677052643701963, 'max_pool_conv': 64, 'kernel_size': 17, 'd_mlp': 16, 'num_conv_layers': 3, 'encoder_dropout': 0.045873086491531094, 'd_feed_forward': 128, 'max_pool_dim': 8, 'n_mlp_layers': 3}. Best is trial 62 with value: 0.860445205479452.
Epoch: 0 0/3904 Training loss: 0.710699
Epoch: 0 800/3904 Training loss: 0.722064
Epoch: 0 1600/3904 Training loss: 0.441150
Epoch: 0 2400/3904 Training loss: 0.767073
Epoch: 0 3200/3904 Training loss: 0.533448
Training loss: 0.659209
Test loss: 0.750048; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 1 0/3904 Training loss: 0.697049
Epoch: 1 800/3904 Training loss: 0.673264
Epoch: 1 1600/3904 Training loss: 0.284651
Epoch: 1 2400/3904 Training loss: 0.518093
Epoch: 1 3200/3904 Training loss: 0.470965
Training loss: 0.569827
Test loss: 0.574971; True positive: 903; True negative: 0, False Positive: 265, False negative: 0, accuracy: 0.7731164383561644, precision: 0.7731164383561644, recall: 1.0
Epoch: 2 0/3904 Training loss: 0.523076
Epoch: 2 800/3904 Training loss: 0.420518
Epoch: 2 1600/3904 Training loss: 0.292266
Epoch: 2 2400/3904 Training loss: 0.534768
Epoch: 2 3200/3904 Training loss: 0.352447
Training loss: 0.483391
Test loss: 0.544815; True positive: 903; True negative: 0, False Positive: 265, False negative: 0, accuracy: 0.7731164383561644, precision: 0.7731164383561644, recall: 1.0
Epoch: 3 0/3904 Training loss: 0.429356
Epoch: 3 800/3904 Training loss: 0.386964
Epoch: 3 1600/3904 Training loss: 0.282000
Epoch: 3 2400/3904 Training loss: 0.420307
Epoch: 3 3200/3904 Training loss: 0.492614
Training loss: 0.460054
Test loss: 0.533908; True positive: 903; True negative: 0, False Positive: 265, False negative: 0, accuracy: 0.7731164383561644, precision: 0.7731164383561644, recall: 1.0
Epoch: 4 0/3904 Training loss: 0.439572
Epoch: 4 800/3904 Training loss: 0.607715
Epoch: 4 1600/3904 Training loss: 0.309150
Epoch: 4 2400/3904 Training loss: 0.390727
Epoch: 4 3200/3904 Training loss: 0.388936
Training loss: 0.443212
Test loss: 0.526204; True positive: 903; True negative: 0, False Positive: 265, False negative: 0, accuracy: 0.7731164383561644, precision: 0.7731164383561644, recall: 1.0
Epoch: 5 0/3904 Training loss: 0.359890
Epoch: 5 800/3904 Training loss: 0.457417
Epoch: 5 1600/3904 Training loss: 0.274630
Epoch: 5 2400/3904 Training loss: 0.344124
Epoch: 5 3200/3904 Training loss: 0.462244
Training loss: 0.419628
Test loss: 0.530250; True positive: 902; True negative: 1, False Positive: 264, False negative: 1, accuracy: 0.7731164383561644, precision: 0.7735849056603774, recall: 0.9988925802879292
Epoch: 6 0/3904 Training loss: 0.410259
Epoch: 6 800/3904 Training loss: 0.437626
Epoch: 6 1600/3904 Training loss: 0.244818
Epoch: 6 2400/3904 Training loss: 0.274646
Epoch: 6 3200/3904 Training loss: 0.546885
Training loss: 0.415223
Test loss: 2.391009; True positive: 2; True negative: 262, False Positive: 3, False negative: 901, accuracy: 0.22602739726027396, precision: 0.4, recall: 0.0022148394241417496
Epoch: 7 0/3904 Training loss: 0.339865
Epoch: 7 800/3904 Training loss: 0.445029
Epoch: 7 1600/3904 Training loss: 0.335463
Epoch: 7 2400/3904 Training loss: 0.251718
Epoch: 7 3200/3904 Training loss: 0.570512
Training loss: 0.403186
Test loss: 2.457296; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 8 0/3904 Training loss: 0.319216
Epoch: 8 800/3904 Training loss: 0.476930
Epoch: 8 1600/3904 Training loss: 0.326242
Epoch: 8 2400/3904 Training loss: 0.234783
Epoch: 8 3200/3904 Training loss: 0.507894
Training loss: 0.397637
Test loss: 2.489462; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 9 0/3904 Training loss: 0.360693
Epoch: 9 800/3904 Training loss: 0.416891
Epoch: 9 1600/3904 Training loss: 0.203957
Epoch: 9 2400/3904 Training loss: 0.329425
Epoch: 9 3200/3904 Training loss: 0.451028
Training loss: 0.389442
Test loss: 2.684368; True positive: 46; True negative: 252, False Positive: 13, False negative: 857, accuracy: 0.2551369863013699, precision: 0.7796610169491526, recall: 0.05094130675526024
Epoch: 10 0/3904 Training loss: 0.337880
Epoch: 10 800/3904 Training loss: 0.379790
Epoch: 10 1600/3904 Training loss: 0.217530
Epoch: 10 2400/3904 Training loss: 0.425541
Epoch: 10 3200/3904 Training loss: 0.495512
Training loss: 0.388104
Test loss: 2.961171; True positive: 65; True negative: 148, False Positive: 117, False negative: 838, accuracy: 0.18236301369863014, precision: 0.35714285714285715, recall: 0.07198228128460686
Epoch: 11 0/3904 Training loss: 0.411137
Epoch: 11 800/3904 Training loss: 0.460908
Epoch: 11 1600/3904 Training loss: 0.329731
Epoch: 11 2400/3904 Training loss: 0.371402
Epoch: 11 3200/3904 Training loss: 0.553703
Training loss: 0.380965
Test loss: 1.039186; True positive: 537; True negative: 108, False Positive: 157, False negative: 366, accuracy: 0.5522260273972602, precision: 0.7737752161383286, recall: 0.5946843853820598
Epoch: 12 0/3904 Training loss: 0.397397
Epoch: 12 800/3904 Training loss: 0.450515
Epoch: 12 1600/3904 Training loss: 0.178698
Epoch: 12 2400/3904 Training loss: 0.289667
Epoch: 12 3200/3904 Training loss: 0.556731
Training loss: 0.390429
Test loss: 0.689379; True positive: 673; True negative: 116, False Positive: 149, False negative: 230, accuracy: 0.675513698630137, precision: 0.818734793187348, recall: 0.7452934662236987
Epoch: 13 0/3904 Training loss: 0.396434
Epoch: 13 800/3904 Training loss: 0.397146
Epoch: 13 1600/3904 Training loss: 0.320644
Epoch: 13 2400/3904 Training loss: 0.355662
Epoch: 13 3200/3904 Training loss: 0.558301
Training loss: 0.381984
Test loss: 2.792445; True positive: 65; True negative: 148, False Positive: 117, False negative: 838, accuracy: 0.18236301369863014, precision: 0.35714285714285715, recall: 0.07198228128460686
Epoch: 14 0/3904 Training loss: 0.294913
Epoch: 14 800/3904 Training loss: 0.384016
Epoch: 14 1600/3904 Training loss: 0.176832
Epoch: 14 2400/3904 Training loss: 0.396638
Epoch: 14 3200/3904 Training loss: 0.620750
Training loss: 0.380366
Test loss: 2.293791; True positive: 65; True negative: 148, False Positive: 117, False negative: 838, accuracy: 0.18236301369863014, precision: 0.35714285714285715, recall: 0.07198228128460686
starting trial 286
[I 2022-12-05 08:38:46,378] Trial 285 finished with value: 0.7731164383561644 and parameters: {'d_model': 64, 'nhead': 4, 'n_encoders': 1, 'learning_rate': 0.00013885022398393062, 'weight_decay': 1.727785646462317e-06, 'dropout': 0.2117161052490777, 'max_pool_conv': 64, 'kernel_size': 12, 'd_mlp': 32, 'num_conv_layers': 8, 'encoder_dropout': 0.0006237961140719268, 'd_feed_forward': 128, 'max_pool_dim': 16, 'n_mlp_layers': 3}. Best is trial 62 with value: 0.860445205479452.
Epoch: 0 0/3904 Training loss: 0.692266
Epoch: 0 800/3904 Training loss: 0.721738
Epoch: 0 1600/3904 Training loss: 0.474806
Epoch: 0 2400/3904 Training loss: 0.751630
Epoch: 0 3200/3904 Training loss: 0.530000
Training loss: 0.655885
Test loss: 0.745102; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 1 0/3904 Training loss: 0.682853
Epoch: 1 800/3904 Training loss: 0.593169
Epoch: 1 1600/3904 Training loss: 0.259854
Epoch: 1 2400/3904 Training loss: 0.659391
Epoch: 1 3200/3904 Training loss: 0.371681
Training loss: 0.538382
Test loss: 1.491327; True positive: 29; True negative: 262, False Positive: 3, False negative: 874, accuracy: 0.24914383561643835, precision: 0.90625, recall: 0.03211517165005537
Epoch: 2 0/3904 Training loss: 0.476898
Epoch: 2 800/3904 Training loss: 0.433564
Epoch: 2 1600/3904 Training loss: 0.243360
Epoch: 2 2400/3904 Training loss: 0.542951
Epoch: 2 3200/3904 Training loss: 0.390245
Training loss: 0.446182
Test loss: 0.534613; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 3 0/3904 Training loss: 0.392661
Epoch: 3 800/3904 Training loss: 0.428744
Epoch: 3 1600/3904 Training loss: 0.181299
Epoch: 3 2400/3904 Training loss: 0.512033
Epoch: 3 3200/3904 Training loss: 0.408645
Training loss: 0.411785
Test loss: 0.553560; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 4 0/3904 Training loss: 0.395515
Epoch: 4 800/3904 Training loss: 0.454192
Epoch: 4 1600/3904 Training loss: 0.171772
Epoch: 4 2400/3904 Training loss: 0.453277
Epoch: 4 3200/3904 Training loss: 0.426930
Training loss: 0.393765
Test loss: 0.564644; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 5 0/3904 Training loss: 0.383911
Epoch: 5 800/3904 Training loss: 0.324919
Epoch: 5 1600/3904 Training loss: 0.136887
Epoch: 5 2400/3904 Training loss: 0.426464
Epoch: 5 3200/3904 Training loss: 0.350234
Training loss: 0.374618
Test loss: 0.563981; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 6 0/3904 Training loss: 0.374755
Epoch: 6 800/3904 Training loss: 0.344898
Epoch: 6 1600/3904 Training loss: 0.145611
Epoch: 6 2400/3904 Training loss: 0.359941
Epoch: 6 3200/3904 Training loss: 0.417471
Training loss: 0.362027
Test loss: 0.601540; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 7 0/3904 Training loss: 0.304787
Epoch: 7 800/3904 Training loss: 0.303614
Epoch: 7 1600/3904 Training loss: 0.187062
Epoch: 7 2400/3904 Training loss: 0.338504
Epoch: 7 3200/3904 Training loss: 0.362804
Training loss: 0.353331
Test loss: 0.576337; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 8 0/3904 Training loss: 0.268651
Epoch: 8 800/3904 Training loss: 0.207711
Epoch: 8 1600/3904 Training loss: 0.166419
Epoch: 8 2400/3904 Training loss: 0.257519
Epoch: 8 3200/3904 Training loss: 0.403802
Training loss: 0.326005
Test loss: 0.599296; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 9 0/3904 Training loss: 0.218938
Epoch: 9 800/3904 Training loss: 0.241088
Epoch: 9 1600/3904 Training loss: 0.214925
Epoch: 9 2400/3904 Training loss: 0.231046
Epoch: 9 3200/3904 Training loss: 0.365452
Training loss: 0.318211
Test loss: 0.595065; True positive: 838; True negative: 121, False Positive: 144, False negative: 65, accuracy: 0.8210616438356164, precision: 0.8533604887983707, recall: 0.9280177187153932
Epoch: 10 0/3904 Training loss: 0.309110
Epoch: 10 800/3904 Training loss: 0.211993
Epoch: 10 1600/3904 Training loss: 0.146042
Epoch: 10 2400/3904 Training loss: 0.311573
Epoch: 10 3200/3904 Training loss: 0.359287
Training loss: 0.293691
Test loss: 0.612192; True positive: 812; True negative: 142, False Positive: 123, False negative: 91, accuracy: 0.8167808219178082, precision: 0.8684491978609625, recall: 0.8992248062015504
Epoch: 11 0/3904 Training loss: 0.210881
Epoch: 11 800/3904 Training loss: 0.234991
Epoch: 11 1600/3904 Training loss: 0.176305
Epoch: 11 2400/3904 Training loss: 0.280894
Epoch: 11 3200/3904 Training loss: 0.303833
Training loss: 0.272986
Test loss: 0.627386; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 12 0/3904 Training loss: 0.284869
Epoch: 12 800/3904 Training loss: 0.171998
Epoch: 12 1600/3904 Training loss: 0.102839
Epoch: 12 2400/3904 Training loss: 0.241879
Epoch: 12 3200/3904 Training loss: 0.326359
Training loss: 0.268364
Test loss: 3.583087; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
starting trial 287
[I 2022-12-05 08:40:49,119] Trial 286 finished with value: 0.8210616438356164 and parameters: {'d_model': 64, 'nhead': 8, 'n_encoders': 1, 'learning_rate': 0.00010376710870254646, 'weight_decay': 4.227928166996072e-06, 'dropout': 0.22898675879602692, 'max_pool_conv': 32, 'kernel_size': 19, 'd_mlp': 16, 'num_conv_layers': 4, 'encoder_dropout': 0.059456925169534526, 'd_feed_forward': 64, 'max_pool_dim': 8, 'n_mlp_layers': 3}. Best is trial 62 with value: 0.860445205479452.
Epoch: 0 0/3904 Training loss: 0.695582
Epoch: 0 800/3904 Training loss: 0.699869
Epoch: 0 1600/3904 Training loss: 0.607328
Epoch: 0 2400/3904 Training loss: 0.749095
Epoch: 0 3200/3904 Training loss: 0.594546
Training loss: 0.672256
Test loss: 0.815529; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 1 0/3904 Training loss: 0.706849
Epoch: 1 800/3904 Training loss: 0.732526
Epoch: 1 1600/3904 Training loss: 0.506831
Epoch: 1 2400/3904 Training loss: 0.803318
Epoch: 1 3200/3904 Training loss: 0.561423
Training loss: 0.656828
Test loss: 0.867851; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 2 0/3904 Training loss: 0.720322
Epoch: 2 800/3904 Training loss: 0.747168
Epoch: 2 1600/3904 Training loss: 0.460854
Epoch: 2 2400/3904 Training loss: 0.775467
Epoch: 2 3200/3904 Training loss: 0.536999
Training loss: 0.647169
Test loss: 0.872940; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 3 0/3904 Training loss: 0.726666
Epoch: 3 800/3904 Training loss: 0.716804
Epoch: 3 1600/3904 Training loss: 0.434150
Epoch: 3 2400/3904 Training loss: 0.716085
Epoch: 3 3200/3904 Training loss: 0.520631
Training loss: 0.628516
Test loss: 0.724634; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 4 0/3904 Training loss: 0.676891
Epoch: 4 800/3904 Training loss: 0.668921
Epoch: 4 1600/3904 Training loss: 0.366469
Epoch: 4 2400/3904 Training loss: 0.683055
Epoch: 4 3200/3904 Training loss: 0.443599
Training loss: 0.589671
Test loss: 0.738288; True positive: 58; True negative: 263, False Positive: 2, False negative: 845, accuracy: 0.2748287671232877, precision: 0.9666666666666667, recall: 0.06423034330011074
Epoch: 5 0/3904 Training loss: 0.629871
Epoch: 5 800/3904 Training loss: 0.631761
Epoch: 5 1600/3904 Training loss: 0.312998
Epoch: 5 2400/3904 Training loss: 0.651899
Epoch: 5 3200/3904 Training loss: 0.424451
Training loss: 0.539255
Test loss: 0.860846; True positive: 4; True negative: 265, False Positive: 0, False negative: 899, accuracy: 0.2303082191780822, precision: 1.0, recall: 0.004429678848283499
Epoch: 6 0/3904 Training loss: 0.578875
Epoch: 6 800/3904 Training loss: 0.553585
Epoch: 6 1600/3904 Training loss: 0.273151
Epoch: 6 2400/3904 Training loss: 0.599755
Epoch: 6 3200/3904 Training loss: 0.459648
Training loss: 0.497452
Test loss: 1.335052; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 7 0/3904 Training loss: 0.513991
Epoch: 7 800/3904 Training loss: 0.472478
Epoch: 7 1600/3904 Training loss: 0.213826
Epoch: 7 2400/3904 Training loss: 0.542348
Epoch: 7 3200/3904 Training loss: 0.397912
Training loss: 0.465491
Test loss: 1.628839; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 8 0/3904 Training loss: 0.416994
Epoch: 8 800/3904 Training loss: 0.436990
Epoch: 8 1600/3904 Training loss: 0.219479
Epoch: 8 2400/3904 Training loss: 0.506900
Epoch: 8 3200/3904 Training loss: 0.419878
Training loss: 0.437549
Test loss: 1.735642; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 9 0/3904 Training loss: 0.385964
Epoch: 9 800/3904 Training loss: 0.409011
Epoch: 9 1600/3904 Training loss: 0.242393
Epoch: 9 2400/3904 Training loss: 0.422952
Epoch: 9 3200/3904 Training loss: 0.373931
Training loss: 0.416085
Test loss: 1.842189; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 10 0/3904 Training loss: 0.382723
Epoch: 10 800/3904 Training loss: 0.383565
Epoch: 10 1600/3904 Training loss: 0.183414
Epoch: 10 2400/3904 Training loss: 0.393792
Epoch: 10 3200/3904 Training loss: 0.501100
Training loss: 0.399994
Test loss: 1.879924; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 11 0/3904 Training loss: 0.371456
Epoch: 11 800/3904 Training loss: 0.361772
Epoch: 11 1600/3904 Training loss: 0.153937
Epoch: 11 2400/3904 Training loss: 0.380241
Epoch: 11 3200/3904 Training loss: 0.434051
Training loss: 0.378459
Test loss: 1.945481; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 12 0/3904 Training loss: 0.344870
Epoch: 12 800/3904 Training loss: 0.433200
Epoch: 12 1600/3904 Training loss: 0.163091
Epoch: 12 2400/3904 Training loss: 0.339322
Epoch: 12 3200/3904 Training loss: 0.435790
Training loss: 0.363871
Test loss: 2.072287; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 13 0/3904 Training loss: 0.342854
Epoch: 13 800/3904 Training loss: 0.346488
Epoch: 13 1600/3904 Training loss: 0.143170
Epoch: 13 2400/3904 Training loss: 0.284035
Epoch: 13 3200/3904 Training loss: 0.543894
Training loss: 0.350453
Test loss: 1.091793; True positive: 152; True negative: 242, False Positive: 23, False negative: 751, accuracy: 0.3373287671232877, precision: 0.8685714285714285, recall: 0.16832779623477298
starting trial 288
[I 2022-12-05 08:41:58,163] Trial 287 finished with value: 0.3373287671232877 and parameters: {'d_model': 64, 'nhead': 8, 'n_encoders': 1, 'learning_rate': 3.122636600329666e-05, 'weight_decay': 3.7991955587847076e-06, 'dropout': 0.1565291910950838, 'max_pool_conv': 64, 'kernel_size': 11, 'd_mlp': 32, 'num_conv_layers': 3, 'encoder_dropout': 0.03618082043355262, 'd_feed_forward': 128, 'max_pool_dim': 8, 'n_mlp_layers': 4}. Best is trial 62 with value: 0.860445205479452.
Epoch: 0 0/3904 Training loss: 0.695390
Epoch: 0 800/3904 Training loss: 0.733140
Epoch: 0 1600/3904 Training loss: 0.498060
Epoch: 0 2400/3904 Training loss: 0.813822
Epoch: 0 3200/3904 Training loss: 0.564983
Training loss: 0.659805
Test loss: 0.920800; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 1 0/3904 Training loss: 0.730190
Epoch: 1 800/3904 Training loss: 0.738704
Epoch: 1 1600/3904 Training loss: 0.453662
Epoch: 1 2400/3904 Training loss: 0.780127
Epoch: 1 3200/3904 Training loss: 0.538967
Training loss: 0.651110
Test loss: 0.897884; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 2 0/3904 Training loss: 0.710746
Epoch: 2 800/3904 Training loss: 0.704630
Epoch: 2 1600/3904 Training loss: 0.382954
Epoch: 2 2400/3904 Training loss: 0.720004
Epoch: 2 3200/3904 Training loss: 0.448336
Training loss: 0.620396
Test loss: 0.751940; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 3 0/3904 Training loss: 0.636813
Epoch: 3 800/3904 Training loss: 0.646911
Epoch: 3 1600/3904 Training loss: 0.333845
Epoch: 3 2400/3904 Training loss: 0.754664
Epoch: 3 3200/3904 Training loss: 0.410589
Training loss: 0.560417
Test loss: 0.713859; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 4 0/3904 Training loss: 0.555181
Epoch: 4 800/3904 Training loss: 0.630638
Epoch: 4 1600/3904 Training loss: 0.193946
Epoch: 4 2400/3904 Training loss: 0.694749
Epoch: 4 3200/3904 Training loss: 0.359020
Training loss: 0.507920
Test loss: 0.677873; True positive: 832; True negative: 119, False Positive: 146, False negative: 71, accuracy: 0.8142123287671232, precision: 0.8507157464212679, recall: 0.9213732004429679
Epoch: 5 0/3904 Training loss: 0.521240
Epoch: 5 800/3904 Training loss: 0.519783
Epoch: 5 1600/3904 Training loss: 0.232587
Epoch: 5 2400/3904 Training loss: 0.558015
Epoch: 5 3200/3904 Training loss: 0.344551
Training loss: 0.476997
Test loss: 0.630476; True positive: 833; True negative: 119, False Positive: 146, False negative: 70, accuracy: 0.815068493150685, precision: 0.8508682328907048, recall: 0.9224806201550387
Epoch: 6 0/3904 Training loss: 0.432659
Epoch: 6 800/3904 Training loss: 0.551039
Epoch: 6 1600/3904 Training loss: 0.192169
Epoch: 6 2400/3904 Training loss: 0.566103
Epoch: 6 3200/3904 Training loss: 0.421997
Training loss: 0.438815
Test loss: 0.564417; True positive: 833; True negative: 117, False Positive: 148, False negative: 70, accuracy: 0.8133561643835616, precision: 0.8491335372069317, recall: 0.9224806201550387
Epoch: 7 0/3904 Training loss: 0.387350
Epoch: 7 800/3904 Training loss: 0.403968
Epoch: 7 1600/3904 Training loss: 0.169862
Epoch: 7 2400/3904 Training loss: 0.498952
Epoch: 7 3200/3904 Training loss: 0.488199
Training loss: 0.417470
Test loss: 0.527943; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 8 0/3904 Training loss: 0.398171
Epoch: 8 800/3904 Training loss: 0.401090
Epoch: 8 1600/3904 Training loss: 0.163869
Epoch: 8 2400/3904 Training loss: 0.378390
Epoch: 8 3200/3904 Training loss: 0.431406
Training loss: 0.398481
Test loss: 0.516905; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 9 0/3904 Training loss: 0.327175
Epoch: 9 800/3904 Training loss: 0.334177
Epoch: 9 1600/3904 Training loss: 0.129042
Epoch: 9 2400/3904 Training loss: 0.422896
Epoch: 9 3200/3904 Training loss: 0.484553
Training loss: 0.385344
Test loss: 0.508828; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 10 0/3904 Training loss: 0.320601
Epoch: 10 800/3904 Training loss: 0.311288
Epoch: 10 1600/3904 Training loss: 0.141727
Epoch: 10 2400/3904 Training loss: 0.408614
Epoch: 10 3200/3904 Training loss: 0.451779
Training loss: 0.372208
Test loss: 0.516007; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 11 0/3904 Training loss: 0.356481
Epoch: 11 800/3904 Training loss: 0.404738
Epoch: 11 1600/3904 Training loss: 0.155579
Epoch: 11 2400/3904 Training loss: 0.515102
Epoch: 11 3200/3904 Training loss: 0.496583
Training loss: 0.359712
Test loss: 0.499436; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 12 0/3904 Training loss: 0.330321
Epoch: 12 800/3904 Training loss: 0.270622
Epoch: 12 1600/3904 Training loss: 0.155633
Epoch: 12 2400/3904 Training loss: 0.457547
Epoch: 12 3200/3904 Training loss: 0.480407
Training loss: 0.345170
Test loss: 0.513846; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 13 0/3904 Training loss: 0.285424
Epoch: 13 800/3904 Training loss: 0.326716
Epoch: 13 1600/3904 Training loss: 0.123800
Epoch: 13 2400/3904 Training loss: 0.460461
Epoch: 13 3200/3904 Training loss: 0.449304
Training loss: 0.327968
Test loss: 0.519108; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 14 0/3904 Training loss: 0.337580
Epoch: 14 800/3904 Training loss: 0.171513
Epoch: 14 1600/3904 Training loss: 0.104271
Epoch: 14 2400/3904 Training loss: 0.540976
Epoch: 14 3200/3904 Training loss: 0.428786
Training loss: 0.309893
Test loss: 0.516175; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 15 0/3904 Training loss: 0.311358
Epoch: 15 800/3904 Training loss: 0.224479
Epoch: 15 1600/3904 Training loss: 0.151542
Epoch: 15 2400/3904 Training loss: 0.448559
Epoch: 15 3200/3904 Training loss: 0.544010
Training loss: 0.303930
Test loss: 0.518310; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 16 0/3904 Training loss: 0.323049
Epoch: 16 800/3904 Training loss: 0.298900
Epoch: 16 1600/3904 Training loss: 0.110618
Epoch: 16 2400/3904 Training loss: 0.422430
Epoch: 16 3200/3904 Training loss: 0.499492
Training loss: 0.290323
Test loss: 0.518520; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 17 0/3904 Training loss: 0.295220
Epoch: 17 800/3904 Training loss: 0.303198
Epoch: 17 1600/3904 Training loss: 0.093384
Epoch: 17 2400/3904 Training loss: 0.279984
Epoch: 17 3200/3904 Training loss: 0.578731
Training loss: 0.283742
Test loss: 0.519802; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 18 0/3904 Training loss: 0.372745
Epoch: 18 800/3904 Training loss: 0.357336
Epoch: 18 1600/3904 Training loss: 0.133046
Epoch: 18 2400/3904 Training loss: 0.296278
Epoch: 18 3200/3904 Training loss: 0.664485
Training loss: 0.274549
Test loss: 0.521619; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 19 0/3904 Training loss: 0.210795
Epoch: 19 800/3904 Training loss: 0.354247
Epoch: 19 1600/3904 Training loss: 0.107703
Epoch: 19 2400/3904 Training loss: 0.271906
Epoch: 19 3200/3904 Training loss: 0.632202
Training loss: 0.263947
Test loss: 0.525367; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 20 0/3904 Training loss: 0.259751
Epoch: 20 800/3904 Training loss: 0.298777
Epoch: 20 1600/3904 Training loss: 0.093888
Epoch: 20 2400/3904 Training loss: 0.271757
Epoch: 20 3200/3904 Training loss: 0.432908
Training loss: 0.263142
Test loss: 0.528732; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 21 0/3904 Training loss: 0.226206
Epoch: 21 800/3904 Training loss: 0.313415
Epoch: 21 1600/3904 Training loss: 0.105396
Epoch: 21 2400/3904 Training loss: 0.269944
Epoch: 21 3200/3904 Training loss: 0.423823
Training loss: 0.248201
Test loss: 0.530009; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
starting trial 289
[I 2022-12-05 08:43:14,509] Trial 288 finished with value: 0.8176369863013698 and parameters: {'d_model': 64, 'nhead': 8, 'n_encoders': 1, 'learning_rate': 8.695542561778376e-05, 'weight_decay': 3.303414362895336e-06, 'dropout': 0.20048185241871017, 'max_pool_conv': 64, 'kernel_size': 6, 'd_mlp': 16, 'num_conv_layers': 3, 'encoder_dropout': 0.09154597192964088, 'd_feed_forward': 128, 'max_pool_dim': 16, 'n_mlp_layers': 3}. Best is trial 62 with value: 0.860445205479452.
Epoch: 0 0/3904 Training loss: 0.690024
Epoch: 0 800/3904 Training loss: 0.729830
Epoch: 0 1600/3904 Training loss: 0.449591
Epoch: 0 2400/3904 Training loss: 0.798916
Epoch: 0 3200/3904 Training loss: 0.534230
Training loss: 0.660441
Test loss: 0.808662; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 1 0/3904 Training loss: 0.707296
Epoch: 1 800/3904 Training loss: 0.686652
Epoch: 1 1600/3904 Training loss: 0.343566
Epoch: 1 2400/3904 Training loss: 0.627193
Epoch: 1 3200/3904 Training loss: 0.394579
Training loss: 0.592265
Test loss: 0.659700; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 2 0/3904 Training loss: 0.588712
Epoch: 2 800/3904 Training loss: 0.590892
Epoch: 2 1600/3904 Training loss: 0.227548
Epoch: 2 2400/3904 Training loss: 0.637289
Epoch: 2 3200/3904 Training loss: 0.409654
Training loss: 0.498193
Test loss: 0.571623; True positive: 811; True negative: 130, False Positive: 135, False negative: 92, accuracy: 0.8056506849315068, precision: 0.857293868921776, recall: 0.8981173864894795
Epoch: 3 0/3904 Training loss: 0.526665
Epoch: 3 800/3904 Training loss: 0.462164
Epoch: 3 1600/3904 Training loss: 0.210588
Epoch: 3 2400/3904 Training loss: 0.386269
Epoch: 3 3200/3904 Training loss: 0.353039
Training loss: 0.448499
Test loss: 0.556719; True positive: 810; True negative: 127, False Positive: 138, False negative: 93, accuracy: 0.8022260273972602, precision: 0.8544303797468354, recall: 0.8970099667774086
Epoch: 4 0/3904 Training loss: 0.414035
Epoch: 4 800/3904 Training loss: 0.375588
Epoch: 4 1600/3904 Training loss: 0.197735
Epoch: 4 2400/3904 Training loss: 0.435843
Epoch: 4 3200/3904 Training loss: 0.452436
Training loss: 0.421793
Test loss: 0.536533; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 5 0/3904 Training loss: 0.429700
Epoch: 5 800/3904 Training loss: 0.361724
Epoch: 5 1600/3904 Training loss: 0.180257
Epoch: 5 2400/3904 Training loss: 0.441281
Epoch: 5 3200/3904 Training loss: 0.350836
Training loss: 0.408477
Test loss: 1.095673; True positive: 392; True negative: 171, False Positive: 94, False negative: 511, accuracy: 0.4820205479452055, precision: 0.8065843621399177, recall: 0.43410852713178294
Epoch: 6 0/3904 Training loss: 0.338970
Epoch: 6 800/3904 Training loss: 0.248404
Epoch: 6 1600/3904 Training loss: 0.140988
Epoch: 6 2400/3904 Training loss: 0.376898
Epoch: 6 3200/3904 Training loss: 0.335969
Training loss: 0.410130
Test loss: 0.704626; True positive: 673; True negative: 135, False Positive: 130, False negative: 230, accuracy: 0.6917808219178082, precision: 0.838107098381071, recall: 0.7452934662236987
Epoch: 7 0/3904 Training loss: 0.361929
Epoch: 7 800/3904 Training loss: 0.475884
Epoch: 7 1600/3904 Training loss: 0.137303
Epoch: 7 2400/3904 Training loss: 0.424859
Epoch: 7 3200/3904 Training loss: 0.429749
Training loss: 0.399549
Test loss: 0.553053; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 8 0/3904 Training loss: 0.381237
Epoch: 8 800/3904 Training loss: 0.402047
Epoch: 8 1600/3904 Training loss: 0.190772
Epoch: 8 2400/3904 Training loss: 0.455446
Epoch: 8 3200/3904 Training loss: 0.321966
Training loss: 0.393749
Test loss: 0.565575; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 9 0/3904 Training loss: 0.365427
Epoch: 9 800/3904 Training loss: 0.338515
Epoch: 9 1600/3904 Training loss: 0.161331
Epoch: 9 2400/3904 Training loss: 0.495995
Epoch: 9 3200/3904 Training loss: 0.328316
Training loss: 0.393417
Test loss: 0.653638; True positive: 745; True negative: 129, False Positive: 136, False negative: 158, accuracy: 0.7482876712328768, precision: 0.8456299659477866, recall: 0.8250276854928018
Epoch: 10 0/3904 Training loss: 0.326119
Epoch: 10 800/3904 Training loss: 0.321447
Epoch: 10 1600/3904 Training loss: 0.137632
Epoch: 10 2400/3904 Training loss: 0.333630
Epoch: 10 3200/3904 Training loss: 0.423372
Training loss: 0.387368
Test loss: 0.730708; True positive: 685; True negative: 134, False Positive: 131, False negative: 218, accuracy: 0.7011986301369864, precision: 0.8394607843137255, recall: 0.7585825027685493
Epoch: 11 0/3904 Training loss: 0.317990
Epoch: 11 800/3904 Training loss: 0.347988
Epoch: 11 1600/3904 Training loss: 0.187103
Epoch: 11 2400/3904 Training loss: 0.377292
Epoch: 11 3200/3904 Training loss: 0.220779
Training loss: 0.377760
Test loss: 0.854605; True positive: 600; True negative: 144, False Positive: 121, False negative: 303, accuracy: 0.636986301369863, precision: 0.8321775312066574, recall: 0.6644518272425249
Epoch: 12 0/3904 Training loss: 0.293094
Epoch: 12 800/3904 Training loss: 0.329141
Epoch: 12 1600/3904 Training loss: 0.145975
Epoch: 12 2400/3904 Training loss: 0.393106
Epoch: 12 3200/3904 Training loss: 0.329677
Training loss: 0.376046
Test loss: 0.674262; True positive: 737; True negative: 130, False Positive: 135, False negative: 166, accuracy: 0.7422945205479452, precision: 0.8451834862385321, recall: 0.8161683277962348
Epoch: 13 0/3904 Training loss: 0.405720
Epoch: 13 800/3904 Training loss: 0.362341
Epoch: 13 1600/3904 Training loss: 0.206016
Epoch: 13 2400/3904 Training loss: 0.392031
Epoch: 13 3200/3904 Training loss: 0.327980
Training loss: 0.373713
Test loss: 1.845371; True positive: 132; True negative: 234, False Positive: 31, False negative: 771, accuracy: 0.3133561643835616, precision: 0.8098159509202454, recall: 0.1461794019933555
Epoch: 14 0/3904 Training loss: 0.354106
Epoch: 14 800/3904 Training loss: 0.356808
Epoch: 14 1600/3904 Training loss: 0.262682
Epoch: 14 2400/3904 Training loss: 0.340552
Epoch: 14 3200/3904 Training loss: 0.376916
Training loss: 0.375047
Test loss: 1.366454; True positive: 290; True negative: 185, False Positive: 80, False negative: 613, accuracy: 0.4066780821917808, precision: 0.7837837837837838, recall: 0.3211517165005537
starting trial 290
[I 2022-12-05 08:45:53,327] Trial 289 finished with value: 0.8176369863013698 and parameters: {'d_model': 64, 'nhead': 4, 'n_encoders': 1, 'learning_rate': 0.00012481566002735714, 'weight_decay': 2.5416918618663955e-06, 'dropout': 0.22000258387498545, 'max_pool_conv': 32, 'kernel_size': 9, 'd_mlp': 16, 'num_conv_layers': 8, 'encoder_dropout': 0.1376420242854016, 'd_feed_forward': 128, 'max_pool_dim': 8, 'n_mlp_layers': 3}. Best is trial 62 with value: 0.860445205479452.
Epoch: 0 0/3904 Training loss: 0.694737
Epoch: 0 800/3904 Training loss: 0.732921
Epoch: 0 1600/3904 Training loss: 0.458738
Epoch: 0 2400/3904 Training loss: 0.794981
Epoch: 0 3200/3904 Training loss: 0.536095
Training loss: 0.659437
Test loss: 0.862675; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 1 0/3904 Training loss: 0.696843
Epoch: 1 800/3904 Training loss: 0.744855
Epoch: 1 1600/3904 Training loss: 0.396925
Epoch: 1 2400/3904 Training loss: 0.673163
Epoch: 1 3200/3904 Training loss: 0.434658
Training loss: 0.609061
Test loss: 0.712291; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 2 0/3904 Training loss: 0.540811
Epoch: 2 800/3904 Training loss: 0.553161
Epoch: 2 1600/3904 Training loss: 0.242666
Epoch: 2 2400/3904 Training loss: 0.423388
Epoch: 2 3200/3904 Training loss: 0.420513
Training loss: 0.488224
Test loss: 0.596978; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 3 0/3904 Training loss: 0.447547
Epoch: 3 800/3904 Training loss: 0.416754
Epoch: 3 1600/3904 Training loss: 0.282918
Epoch: 3 2400/3904 Training loss: 0.343466
Epoch: 3 3200/3904 Training loss: 0.394690
Training loss: 0.429119
Test loss: 0.595654; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 4 0/3904 Training loss: 0.427030
Epoch: 4 800/3904 Training loss: 0.374304
Epoch: 4 1600/3904 Training loss: 0.312003
Epoch: 4 2400/3904 Training loss: 0.373974
Epoch: 4 3200/3904 Training loss: 0.364013
Training loss: 0.400856
Test loss: 0.563824; True positive: 903; True negative: 0, False Positive: 265, False negative: 0, accuracy: 0.7731164383561644, precision: 0.7731164383561644, recall: 1.0
Epoch: 5 0/3904 Training loss: 0.387020
Epoch: 5 800/3904 Training loss: 0.395700
Epoch: 5 1600/3904 Training loss: 0.221538
Epoch: 5 2400/3904 Training loss: 0.284767
Epoch: 5 3200/3904 Training loss: 0.372727
Training loss: 0.384940
Test loss: 0.542784; True positive: 903; True negative: 0, False Positive: 265, False negative: 0, accuracy: 0.7731164383561644, precision: 0.7731164383561644, recall: 1.0
Epoch: 6 0/3904 Training loss: 0.386469
Epoch: 6 800/3904 Training loss: 0.386692
Epoch: 6 1600/3904 Training loss: 0.227782
Epoch: 6 2400/3904 Training loss: 0.286512
Epoch: 6 3200/3904 Training loss: 0.448749
Training loss: 0.360733
Test loss: 0.491029; True positive: 903; True negative: 0, False Positive: 265, False negative: 0, accuracy: 0.7731164383561644, precision: 0.7731164383561644, recall: 1.0
Epoch: 7 0/3904 Training loss: 0.344802
Epoch: 7 800/3904 Training loss: 0.223202
Epoch: 7 1600/3904 Training loss: 0.240720
Epoch: 7 2400/3904 Training loss: 0.323610
Epoch: 7 3200/3904 Training loss: 0.279481
Training loss: 0.332631
Test loss: 0.481768; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 8 0/3904 Training loss: 0.267945
Epoch: 8 800/3904 Training loss: 0.265501
Epoch: 8 1600/3904 Training loss: 0.122442
Epoch: 8 2400/3904 Training loss: 0.366316
Epoch: 8 3200/3904 Training loss: 0.353318
Training loss: 0.300001
Test loss: 0.491374; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 9 0/3904 Training loss: 0.253614
Epoch: 9 800/3904 Training loss: 0.451566
Epoch: 9 1600/3904 Training loss: 0.159327
Epoch: 9 2400/3904 Training loss: 0.330777
Epoch: 9 3200/3904 Training loss: 0.360353
Training loss: 0.282254
Test loss: 0.465605; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 10 0/3904 Training loss: 0.265342
Epoch: 10 800/3904 Training loss: 0.293769
Epoch: 10 1600/3904 Training loss: 0.099697
Epoch: 10 2400/3904 Training loss: 0.241149
Epoch: 10 3200/3904 Training loss: 0.400370
Training loss: 0.259558
Test loss: 0.531141; True positive: 761; True negative: 162, False Positive: 103, False negative: 142, accuracy: 0.7902397260273972, precision: 0.8807870370370371, recall: 0.8427464008859358
Epoch: 11 0/3904 Training loss: 0.274937
Epoch: 11 800/3904 Training loss: 0.224097
Epoch: 11 1600/3904 Training loss: 0.110088
Epoch: 11 2400/3904 Training loss: 0.232681
Epoch: 11 3200/3904 Training loss: 0.309552
Training loss: 0.249109
Test loss: 1.502192; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 12 0/3904 Training loss: 0.554911
Epoch: 12 800/3904 Training loss: 0.239522
Epoch: 12 1600/3904 Training loss: 0.103475
Epoch: 12 2400/3904 Training loss: 0.117312
Epoch: 12 3200/3904 Training loss: 0.343535
Training loss: 0.243968
Test loss: 1.160849; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 13 0/3904 Training loss: 0.262870
Epoch: 13 800/3904 Training loss: 0.293062
Epoch: 13 1600/3904 Training loss: 0.124591
Epoch: 13 2400/3904 Training loss: 0.126556
Epoch: 13 3200/3904 Training loss: 0.258056
Training loss: 0.221628
Test loss: 1.620457; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 14 0/3904 Training loss: 0.652514
Epoch: 14 800/3904 Training loss: 0.126885
Epoch: 14 1600/3904 Training loss: 0.167152
Epoch: 14 2400/3904 Training loss: 0.062472
Epoch: 14 3200/3904 Training loss: 0.274464
Training loss: 0.224810
Test loss: 1.225200; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 15 0/3904 Training loss: 0.375700
Epoch: 15 800/3904 Training loss: 0.217865
Epoch: 15 1600/3904 Training loss: 0.174116
Epoch: 15 2400/3904 Training loss: 0.092558
Epoch: 15 3200/3904 Training loss: 0.345371
Training loss: 0.212773
Test loss: 1.512862; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 16 0/3904 Training loss: 0.210880
Epoch: 16 800/3904 Training loss: 0.093166
Epoch: 16 1600/3904 Training loss: 0.077141
Epoch: 16 2400/3904 Training loss: 0.052086
Epoch: 16 3200/3904 Training loss: 0.293032
Training loss: 0.205857
Test loss: 1.749177; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 17 0/3904 Training loss: 0.276353
Epoch: 17 800/3904 Training loss: 0.261574
Epoch: 17 1600/3904 Training loss: 0.131288
Epoch: 17 2400/3904 Training loss: 0.048030
Epoch: 17 3200/3904 Training loss: 0.370083
Training loss: 0.200809
Test loss: 1.913911; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 18 0/3904 Training loss: 0.873274
Epoch: 18 800/3904 Training loss: 0.113046
Epoch: 18 1600/3904 Training loss: 0.095761
Epoch: 18 2400/3904 Training loss: 0.081354
Epoch: 18 3200/3904 Training loss: 0.285495
Training loss: 0.202625
Test loss: 1.829252; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 19 0/3904 Training loss: 0.728717
Epoch: 19 800/3904 Training loss: 0.150727
Epoch: 19 1600/3904 Training loss: 0.067091
Epoch: 19 2400/3904 Training loss: 0.039241
Epoch: 19 3200/3904 Training loss: 0.294115
Training loss: 0.183660
Test loss: 2.078420; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
starting trial 291
[I 2022-12-05 08:48:07,834] Trial 290 finished with value: 0.8176369863013698 and parameters: {'d_model': 64, 'nhead': 8, 'n_encoders': 2, 'learning_rate': 0.00011369174151317556, 'weight_decay': 5.0430243263625786e-06, 'dropout': 0.23596686412589435, 'max_pool_conv': 64, 'kernel_size': 16, 'd_mlp': 32, 'num_conv_layers': 3, 'encoder_dropout': 0.10626142733024452, 'd_feed_forward': 128, 'max_pool_dim': 8, 'n_mlp_layers': 3}. Best is trial 62 with value: 0.860445205479452.
Epoch: 0 0/3904 Training loss: 0.693139
Epoch: 0 800/3904 Training loss: 0.695239
Epoch: 0 1600/3904 Training loss: 0.562002
Epoch: 0 2400/3904 Training loss: 0.775351
Epoch: 0 3200/3904 Training loss: 0.554095
Training loss: 0.671612
Test loss: 0.897134; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 1 0/3904 Training loss: 0.743744
Epoch: 1 800/3904 Training loss: 0.750153
Epoch: 1 1600/3904 Training loss: 0.503119
Epoch: 1 2400/3904 Training loss: 0.808432
Epoch: 1 3200/3904 Training loss: 0.545023
Training loss: 0.657773
Test loss: 0.936603; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 2 0/3904 Training loss: 0.724835
Epoch: 2 800/3904 Training loss: 0.748622
Epoch: 2 1600/3904 Training loss: 0.481814
Epoch: 2 2400/3904 Training loss: 0.788787
Epoch: 2 3200/3904 Training loss: 0.529363
Training loss: 0.654674
Test loss: 0.973344; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 3 0/3904 Training loss: 0.742596
Epoch: 3 800/3904 Training loss: 0.739481
Epoch: 3 1600/3904 Training loss: 0.468276
Epoch: 3 2400/3904 Training loss: 0.795620
Epoch: 3 3200/3904 Training loss: 0.536782
Training loss: 0.649512
Test loss: 1.035539; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 4 0/3904 Training loss: 0.695970
Epoch: 4 800/3904 Training loss: 0.685003
Epoch: 4 1600/3904 Training loss: 0.456819
Epoch: 4 2400/3904 Training loss: 0.780358
Epoch: 4 3200/3904 Training loss: 0.519366
Training loss: 0.643124
Test loss: 1.135076; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 5 0/3904 Training loss: 0.682467
Epoch: 5 800/3904 Training loss: 0.696134
Epoch: 5 1600/3904 Training loss: 0.456537
Epoch: 5 2400/3904 Training loss: 0.739147
Epoch: 5 3200/3904 Training loss: 0.484897
Training loss: 0.630348
Test loss: 1.280295; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 6 0/3904 Training loss: 0.622765
Epoch: 6 800/3904 Training loss: 0.640230
Epoch: 6 1600/3904 Training loss: 0.411324
Epoch: 6 2400/3904 Training loss: 0.694621
Epoch: 6 3200/3904 Training loss: 0.490030
Training loss: 0.610803
Test loss: 1.481467; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 7 0/3904 Training loss: 0.608621
Epoch: 7 800/3904 Training loss: 0.594009
Epoch: 7 1600/3904 Training loss: 0.371027
Epoch: 7 2400/3904 Training loss: 0.689006
Epoch: 7 3200/3904 Training loss: 0.462972
Training loss: 0.583898
Test loss: 1.717769; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 8 0/3904 Training loss: 0.544864
Epoch: 8 800/3904 Training loss: 0.612540
Epoch: 8 1600/3904 Training loss: 0.342040
Epoch: 8 2400/3904 Training loss: 0.732725
Epoch: 8 3200/3904 Training loss: 0.383061
Training loss: 0.551051
Test loss: 1.970358; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 9 0/3904 Training loss: 0.422022
Epoch: 9 800/3904 Training loss: 0.578203
Epoch: 9 1600/3904 Training loss: 0.308410
Epoch: 9 2400/3904 Training loss: 0.701383
Epoch: 9 3200/3904 Training loss: 0.459214
Training loss: 0.516099
Test loss: 2.193440; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 10 0/3904 Training loss: 0.416852
Epoch: 10 800/3904 Training loss: 0.494182
Epoch: 10 1600/3904 Training loss: 0.248452
Epoch: 10 2400/3904 Training loss: 0.687986
Epoch: 10 3200/3904 Training loss: 0.335669
Training loss: 0.500768
Test loss: 2.374626; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
starting trial 292
[I 2022-12-05 08:48:34,207] Trial 291 finished with value: 0.2268835616438356 and parameters: {'d_model': 16, 'nhead': 8, 'n_encoders': 1, 'learning_rate': 4.633765769719643e-05, 'weight_decay': 4.56259019963396e-06, 'dropout': 0.17963067446699563, 'max_pool_conv': 32, 'kernel_size': 14, 'd_mlp': 16, 'num_conv_layers': 2, 'encoder_dropout': 0.02594103990735877, 'd_feed_forward': 128, 'max_pool_dim': 8, 'n_mlp_layers': 2}. Best is trial 62 with value: 0.860445205479452.
Epoch: 0 0/3904 Training loss: 0.712206
Epoch: 0 800/3904 Training loss: 0.737086
Epoch: 0 1600/3904 Training loss: 0.426427
Epoch: 0 2400/3904 Training loss: 0.763946
Epoch: 0 3200/3904 Training loss: 0.541213
Training loss: 0.663127
Test loss: 0.760700; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 1 0/3904 Training loss: 0.706825
Epoch: 1 800/3904 Training loss: 0.735140
Epoch: 1 1600/3904 Training loss: 0.360606
Epoch: 1 2400/3904 Training loss: 0.636422
Epoch: 1 3200/3904 Training loss: 0.485934
Training loss: 0.622415
Test loss: 0.667786; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 2 0/3904 Training loss: 0.664746
Epoch: 2 800/3904 Training loss: 0.618583
Epoch: 2 1600/3904 Training loss: 0.240509
Epoch: 2 2400/3904 Training loss: 0.447789
Epoch: 2 3200/3904 Training loss: 0.353669
Training loss: 0.529717
Test loss: 0.530423; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 3 0/3904 Training loss: 0.473486
Epoch: 3 800/3904 Training loss: 0.553689
Epoch: 3 1600/3904 Training loss: 0.253275
Epoch: 3 2400/3904 Training loss: 0.324869
Epoch: 3 3200/3904 Training loss: 0.310201
Training loss: 0.472294
Test loss: 0.740644; True positive: 672; True negative: 135, False Positive: 130, False negative: 231, accuracy: 0.6909246575342466, precision: 0.8379052369077307, recall: 0.7441860465116279
Epoch: 4 0/3904 Training loss: 0.430352
Epoch: 4 800/3904 Training loss: 0.471304
Epoch: 4 1600/3904 Training loss: 0.159929
Epoch: 4 2400/3904 Training loss: 0.252541
Epoch: 4 3200/3904 Training loss: 0.507787
Training loss: 0.446103
Test loss: 0.520337; True positive: 837; True negative: 117, False Positive: 148, False negative: 66, accuracy: 0.8167808219178082, precision: 0.849746192893401, recall: 0.9269102990033222
Epoch: 5 0/3904 Training loss: 0.445778
Epoch: 5 800/3904 Training loss: 0.389151
Epoch: 5 1600/3904 Training loss: 0.175406
Epoch: 5 2400/3904 Training loss: 0.327718
Epoch: 5 3200/3904 Training loss: 0.333417
Training loss: 0.432980
Test loss: 0.795649; True positive: 627; True negative: 160, False Positive: 105, False negative: 276, accuracy: 0.6738013698630136, precision: 0.8565573770491803, recall: 0.6943521594684385
Epoch: 6 0/3904 Training loss: 0.355912
Epoch: 6 800/3904 Training loss: 0.445947
Epoch: 6 1600/3904 Training loss: 0.153344
Epoch: 6 2400/3904 Training loss: 0.359279
Epoch: 6 3200/3904 Training loss: 0.417786
Training loss: 0.414082
Test loss: 0.508264; True positive: 834; True negative: 123, False Positive: 142, False negative: 69, accuracy: 0.8193493150684932, precision: 0.8545081967213115, recall: 0.9235880398671097
Epoch: 7 0/3904 Training loss: 0.367372
Epoch: 7 800/3904 Training loss: 0.395041
Epoch: 7 1600/3904 Training loss: 0.143444
Epoch: 7 2400/3904 Training loss: 0.236708
Epoch: 7 3200/3904 Training loss: 0.415881
Training loss: 0.390212
Test loss: 0.582528; True positive: 836; True negative: 117, False Positive: 148, False negative: 67, accuracy: 0.8159246575342466, precision: 0.8495934959349594, recall: 0.9258028792912514
Epoch: 8 0/3904 Training loss: 0.476604
Epoch: 8 800/3904 Training loss: 0.294071
Epoch: 8 1600/3904 Training loss: 0.232725
Epoch: 8 2400/3904 Training loss: 0.292725
Epoch: 8 3200/3904 Training loss: 0.423391
Training loss: 0.385428
Test loss: 0.601172; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 9 0/3904 Training loss: 0.478786
Epoch: 9 800/3904 Training loss: 0.214088
Epoch: 9 1600/3904 Training loss: 0.157245
Epoch: 9 2400/3904 Training loss: 0.417736
Epoch: 9 3200/3904 Training loss: 0.356572
Training loss: 0.368193
Test loss: 0.599254; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 10 0/3904 Training loss: 0.480605
Epoch: 10 800/3904 Training loss: 0.155532
Epoch: 10 1600/3904 Training loss: 0.152350
Epoch: 10 2400/3904 Training loss: 0.210035
Epoch: 10 3200/3904 Training loss: 0.422980
Training loss: 0.354071
Test loss: 0.631144; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 11 0/3904 Training loss: 0.422185
Epoch: 11 800/3904 Training loss: 0.315271
Epoch: 11 1600/3904 Training loss: 0.186478
Epoch: 11 2400/3904 Training loss: 0.244884
Epoch: 11 3200/3904 Training loss: 0.408594
Training loss: 0.357108
Test loss: 0.649823; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 12 0/3904 Training loss: 0.267447
Epoch: 12 800/3904 Training loss: 0.336052
Epoch: 12 1600/3904 Training loss: 0.213519
Epoch: 12 2400/3904 Training loss: 0.187803
Epoch: 12 3200/3904 Training loss: 0.401488
Training loss: 0.332222
Test loss: 0.622144; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 13 0/3904 Training loss: 0.404403
Epoch: 13 800/3904 Training loss: 0.390854
Epoch: 13 1600/3904 Training loss: 0.158490
Epoch: 13 2400/3904 Training loss: 0.297985
Epoch: 13 3200/3904 Training loss: 0.485750
Training loss: 0.316973
Test loss: 0.682597; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 14 0/3904 Training loss: 0.450705
Epoch: 14 800/3904 Training loss: 0.184546
Epoch: 14 1600/3904 Training loss: 0.191454
Epoch: 14 2400/3904 Training loss: 0.186529
Epoch: 14 3200/3904 Training loss: 0.391655
Training loss: 0.312898
Test loss: 0.684523; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 15 0/3904 Training loss: 0.270719
Epoch: 15 800/3904 Training loss: 0.334556
Epoch: 15 1600/3904 Training loss: 0.105173
Epoch: 15 2400/3904 Training loss: 0.156963
Epoch: 15 3200/3904 Training loss: 0.338919
Training loss: 0.298513
Test loss: 0.747500; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 16 0/3904 Training loss: 0.481343
Epoch: 16 800/3904 Training loss: 0.314284
Epoch: 16 1600/3904 Training loss: 0.110939
Epoch: 16 2400/3904 Training loss: 0.310819
Epoch: 16 3200/3904 Training loss: 0.410419
Training loss: 0.288777
Test loss: 0.779189; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
starting trial 293
[I 2022-12-05 08:49:32,799] Trial 292 finished with value: 0.8193493150684932 and parameters: {'d_model': 64, 'nhead': 8, 'n_encoders': 1, 'learning_rate': 0.00040603005455359383, 'weight_decay': 3.6154244811642087e-06, 'dropout': 0.4815529359079475, 'max_pool_conv': 64, 'kernel_size': 6, 'd_mlp': 32, 'num_conv_layers': 3, 'encoder_dropout': 0.12342988445437901, 'd_feed_forward': 128, 'max_pool_dim': 16, 'n_mlp_layers': 3}. Best is trial 62 with value: 0.860445205479452.
Epoch: 0 0/3904 Training loss: 0.703097
Epoch: 0 800/3904 Training loss: 0.737799
Epoch: 0 1600/3904 Training loss: 0.456406
Epoch: 0 2400/3904 Training loss: 0.796457
Epoch: 0 3200/3904 Training loss: 0.549099
Training loss: 0.663010
Test loss: 0.847849; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 1 0/3904 Training loss: 0.718379
Epoch: 1 800/3904 Training loss: 0.739020
Epoch: 1 1600/3904 Training loss: 0.466238
Epoch: 1 2400/3904 Training loss: 0.818302
Epoch: 1 3200/3904 Training loss: 0.554157
Training loss: 0.659680
Test loss: 0.883992; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 2 0/3904 Training loss: 0.707046
Epoch: 2 800/3904 Training loss: 0.742465
Epoch: 2 1600/3904 Training loss: 0.448614
Epoch: 2 2400/3904 Training loss: 0.798391
Epoch: 2 3200/3904 Training loss: 0.537420
Training loss: 0.655151
Test loss: 0.947776; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 3 0/3904 Training loss: 0.705299
Epoch: 3 800/3904 Training loss: 0.721360
Epoch: 3 1600/3904 Training loss: 0.406354
Epoch: 3 2400/3904 Training loss: 0.730497
Epoch: 3 3200/3904 Training loss: 0.487338
Training loss: 0.635754
Test loss: 1.111040; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 4 0/3904 Training loss: 0.648649
Epoch: 4 800/3904 Training loss: 0.658442
Epoch: 4 1600/3904 Training loss: 0.283576
Epoch: 4 2400/3904 Training loss: 0.761367
Epoch: 4 3200/3904 Training loss: 0.377237
Training loss: 0.584459
Test loss: 1.726403; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 5 0/3904 Training loss: 0.575857
Epoch: 5 800/3904 Training loss: 0.557271
Epoch: 5 1600/3904 Training loss: 0.301809
Epoch: 5 2400/3904 Training loss: 0.835262
Epoch: 5 3200/3904 Training loss: 0.353568
Training loss: 0.535572
Test loss: 2.159141; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 6 0/3904 Training loss: 0.533457
Epoch: 6 800/3904 Training loss: 0.458852
Epoch: 6 1600/3904 Training loss: 0.239835
Epoch: 6 2400/3904 Training loss: 0.537326
Epoch: 6 3200/3904 Training loss: 0.280365
Training loss: 0.474346
Test loss: 2.262023; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 7 0/3904 Training loss: 0.371512
Epoch: 7 800/3904 Training loss: 0.444507
Epoch: 7 1600/3904 Training loss: 0.109571
Epoch: 7 2400/3904 Training loss: 0.726831
Epoch: 7 3200/3904 Training loss: 0.331532
Training loss: 0.429085
Test loss: 2.212138; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 8 0/3904 Training loss: 0.306720
Epoch: 8 800/3904 Training loss: 0.377611
Epoch: 8 1600/3904 Training loss: 0.102003
Epoch: 8 2400/3904 Training loss: 0.713016
Epoch: 8 3200/3904 Training loss: 0.342596
Training loss: 0.397186
Test loss: 2.371752; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 9 0/3904 Training loss: 0.264320
Epoch: 9 800/3904 Training loss: 0.313341
Epoch: 9 1600/3904 Training loss: 0.115207
Epoch: 9 2400/3904 Training loss: 0.945893
Epoch: 9 3200/3904 Training loss: 0.338044
Training loss: 0.375187
Test loss: 2.409533; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 10 0/3904 Training loss: 0.288758
Epoch: 10 800/3904 Training loss: 0.273672
Epoch: 10 1600/3904 Training loss: 0.160328
Epoch: 10 2400/3904 Training loss: 0.912196
Epoch: 10 3200/3904 Training loss: 0.349762
Training loss: 0.343905
Test loss: 2.227970; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
starting trial 294
[I 2022-12-05 08:50:10,689] Trial 293 finished with value: 0.2268835616438356 and parameters: {'d_model': 64, 'nhead': 4, 'n_encoders': 1, 'learning_rate': 7.811152591409713e-05, 'weight_decay': 4.056831962019164e-06, 'dropout': 0.19540721459539023, 'max_pool_conv': 16, 'kernel_size': 5, 'd_mlp': 16, 'num_conv_layers': 3, 'encoder_dropout': 0.0108962776925832, 'd_feed_forward': 128, 'max_pool_dim': 8, 'n_mlp_layers': 3}. Best is trial 62 with value: 0.860445205479452.
Epoch: 0 0/3904 Training loss: 0.687254
Epoch: 0 800/3904 Training loss: 0.704727
Epoch: 0 1600/3904 Training loss: 0.619815
Epoch: 0 2400/3904 Training loss: 0.740276
Epoch: 0 3200/3904 Training loss: 0.626306
Training loss: 0.672484
Test loss: 0.772972; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 1 0/3904 Training loss: 0.697012
Epoch: 1 800/3904 Training loss: 0.719303
Epoch: 1 1600/3904 Training loss: 0.572341
Epoch: 1 2400/3904 Training loss: 0.760903
Epoch: 1 3200/3904 Training loss: 0.595392
Training loss: 0.665513
Test loss: 0.812352; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 2 0/3904 Training loss: 0.704527
Epoch: 2 800/3904 Training loss: 0.726125
Epoch: 2 1600/3904 Training loss: 0.529945
Epoch: 2 2400/3904 Training loss: 0.795188
Epoch: 2 3200/3904 Training loss: 0.584601
Training loss: 0.661624
Test loss: 0.837983; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 3 0/3904 Training loss: 0.729030
Epoch: 3 800/3904 Training loss: 0.742457
Epoch: 3 1600/3904 Training loss: 0.516846
Epoch: 3 2400/3904 Training loss: 0.805524
Epoch: 3 3200/3904 Training loss: 0.571937
Training loss: 0.659606
Test loss: 0.854163; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 4 0/3904 Training loss: 0.716772
Epoch: 4 800/3904 Training loss: 0.745445
Epoch: 4 1600/3904 Training loss: 0.499433
Epoch: 4 2400/3904 Training loss: 0.817031
Epoch: 4 3200/3904 Training loss: 0.567533
Training loss: 0.658216
Test loss: 0.863152; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 5 0/3904 Training loss: 0.730081
Epoch: 5 800/3904 Training loss: 0.753007
Epoch: 5 1600/3904 Training loss: 0.502201
Epoch: 5 2400/3904 Training loss: 0.829778
Epoch: 5 3200/3904 Training loss: 0.547333
Training loss: 0.658507
Test loss: 0.869794; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 6 0/3904 Training loss: 0.728796
Epoch: 6 800/3904 Training loss: 0.759704
Epoch: 6 1600/3904 Training loss: 0.500764
Epoch: 6 2400/3904 Training loss: 0.817476
Epoch: 6 3200/3904 Training loss: 0.572565
Training loss: 0.658645
Test loss: 0.872897; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 7 0/3904 Training loss: 0.727946
Epoch: 7 800/3904 Training loss: 0.755391
Epoch: 7 1600/3904 Training loss: 0.492978
Epoch: 7 2400/3904 Training loss: 0.819655
Epoch: 7 3200/3904 Training loss: 0.545411
Training loss: 0.658754
Test loss: 0.875275; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 8 0/3904 Training loss: 0.707345
Epoch: 8 800/3904 Training loss: 0.768271
Epoch: 8 1600/3904 Training loss: 0.501224
Epoch: 8 2400/3904 Training loss: 0.818586
Epoch: 8 3200/3904 Training loss: 0.549660
Training loss: 0.659081
Test loss: 0.876480; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 9 0/3904 Training loss: 0.738365
Epoch: 9 800/3904 Training loss: 0.751114
Epoch: 9 1600/3904 Training loss: 0.482713
Epoch: 9 2400/3904 Training loss: 0.831036
Epoch: 9 3200/3904 Training loss: 0.575312
Training loss: 0.657077
Test loss: 0.878662; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 10 0/3904 Training loss: 0.759150
Epoch: 10 800/3904 Training loss: 0.747591
Epoch: 10 1600/3904 Training loss: 0.491250
Epoch: 10 2400/3904 Training loss: 0.814938
Epoch: 10 3200/3904 Training loss: 0.565005
Training loss: 0.658688
Test loss: 0.879125; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
starting trial 295
[I 2022-12-05 08:50:51,880] Trial 294 finished with value: 0.2268835616438356 and parameters: {'d_model': 16, 'nhead': 8, 'n_encoders': 1, 'learning_rate': 1.4993924228710738e-05, 'weight_decay': 2.933328987186046e-06, 'dropout': 0.2720664565088581, 'max_pool_conv': 64, 'kernel_size': 11, 'd_mlp': 32, 'num_conv_layers': 8, 'encoder_dropout': 0.08591798617144702, 'd_feed_forward': 128, 'max_pool_dim': 4, 'n_mlp_layers': 3}. Best is trial 62 with value: 0.860445205479452.
Epoch: 0 0/3904 Training loss: 0.690915
Epoch: 0 800/3904 Training loss: 0.734422
Epoch: 0 1600/3904 Training loss: 0.472331
Epoch: 0 2400/3904 Training loss: 0.800171
Epoch: 0 3200/3904 Training loss: 0.550423
Training loss: 0.661186
Test loss: 0.841873; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 1 0/3904 Training loss: 0.712787
Epoch: 1 800/3904 Training loss: 0.733773
Epoch: 1 1600/3904 Training loss: 0.345164
Epoch: 1 2400/3904 Training loss: 0.731793
Epoch: 1 3200/3904 Training loss: 0.430292
Training loss: 0.587793
Test loss: 0.563183; True positive: 903; True negative: 0, False Positive: 265, False negative: 0, accuracy: 0.7731164383561644, precision: 0.7731164383561644, recall: 1.0
Epoch: 2 0/3904 Training loss: 0.530002
Epoch: 2 800/3904 Training loss: 0.432497
Epoch: 2 1600/3904 Training loss: 0.238828
Epoch: 2 2400/3904 Training loss: 0.614875
Epoch: 2 3200/3904 Training loss: 0.375228
Training loss: 0.477145
Test loss: 0.532595; True positive: 822; True negative: 122, False Positive: 143, False negative: 81, accuracy: 0.8082191780821918, precision: 0.8518134715025907, recall: 0.9102990033222591
Epoch: 3 0/3904 Training loss: 0.406958
Epoch: 3 800/3904 Training loss: 0.395128
Epoch: 3 1600/3904 Training loss: 0.214751
Epoch: 3 2400/3904 Training loss: 0.501102
Epoch: 3 3200/3904 Training loss: 0.406407
Training loss: 0.432756
Test loss: 0.529887; True positive: 792; True negative: 152, False Positive: 113, False negative: 111, accuracy: 0.8082191780821918, precision: 0.8751381215469614, recall: 0.8770764119601329
Epoch: 4 0/3904 Training loss: 0.444289
Epoch: 4 800/3904 Training loss: 0.346625
Epoch: 4 1600/3904 Training loss: 0.237104
Epoch: 4 2400/3904 Training loss: 0.443971
Epoch: 4 3200/3904 Training loss: 0.433182
Training loss: 0.415455
Test loss: 0.536800; True positive: 800; True negative: 144, False Positive: 121, False negative: 103, accuracy: 0.8082191780821918, precision: 0.8686210640608035, recall: 0.8859357696566998
Epoch: 5 0/3904 Training loss: 0.358277
Epoch: 5 800/3904 Training loss: 0.407108
Epoch: 5 1600/3904 Training loss: 0.160623
Epoch: 5 2400/3904 Training loss: 0.365244
Epoch: 5 3200/3904 Training loss: 0.502346
Training loss: 0.396698
Test loss: 0.540111; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 6 0/3904 Training loss: 0.310753
Epoch: 6 800/3904 Training loss: 0.327299
Epoch: 6 1600/3904 Training loss: 0.158546
Epoch: 6 2400/3904 Training loss: 0.402561
Epoch: 6 3200/3904 Training loss: 0.476427
Training loss: 0.383849
Test loss: 0.543372; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 7 0/3904 Training loss: 0.376988
Epoch: 7 800/3904 Training loss: 0.375162
Epoch: 7 1600/3904 Training loss: 0.187957
Epoch: 7 2400/3904 Training loss: 0.320173
Epoch: 7 3200/3904 Training loss: 0.401308
Training loss: 0.385137
Test loss: 0.561076; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 8 0/3904 Training loss: 0.340459
Epoch: 8 800/3904 Training loss: 0.403498
Epoch: 8 1600/3904 Training loss: 0.178671
Epoch: 8 2400/3904 Training loss: 0.346617
Epoch: 8 3200/3904 Training loss: 0.303231
Training loss: 0.376218
Test loss: 0.573393; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 9 0/3904 Training loss: 0.331129
Epoch: 9 800/3904 Training loss: 0.272374
Epoch: 9 1600/3904 Training loss: 0.126429
Epoch: 9 2400/3904 Training loss: 0.268044
Epoch: 9 3200/3904 Training loss: 0.364489
Training loss: 0.369463
Test loss: 0.557665; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 10 0/3904 Training loss: 0.287878
Epoch: 10 800/3904 Training loss: 0.313972
Epoch: 10 1600/3904 Training loss: 0.135308
Epoch: 10 2400/3904 Training loss: 0.302003
Epoch: 10 3200/3904 Training loss: 0.458117
Training loss: 0.367618
Test loss: 0.603818; True positive: 785; True negative: 132, False Positive: 133, False negative: 118, accuracy: 0.7851027397260274, precision: 0.855119825708061, recall: 0.8693244739756367
Epoch: 11 0/3904 Training loss: 0.337882
Epoch: 11 800/3904 Training loss: 0.346429
Epoch: 11 1600/3904 Training loss: 0.151569
Epoch: 11 2400/3904 Training loss: 0.292408
Epoch: 11 3200/3904 Training loss: 0.381660
Training loss: 0.366426
Test loss: 0.646374; True positive: 731; True negative: 168, False Positive: 97, False negative: 172, accuracy: 0.7696917808219178, precision: 0.8828502415458938, recall: 0.8095238095238095
Epoch: 12 0/3904 Training loss: 0.330615
Epoch: 12 800/3904 Training loss: 0.396828
Epoch: 12 1600/3904 Training loss: 0.158252
Epoch: 12 2400/3904 Training loss: 0.211732
Epoch: 12 3200/3904 Training loss: 0.318411
Training loss: 0.355871
Test loss: 0.562021; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 13 0/3904 Training loss: 0.332939
Epoch: 13 800/3904 Training loss: 0.326467
Epoch: 13 1600/3904 Training loss: 0.143173
Epoch: 13 2400/3904 Training loss: 0.213189
Epoch: 13 3200/3904 Training loss: 0.372316
Training loss: 0.347064
Test loss: 0.575859; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
starting trial 296
[I 2022-12-05 08:53:33,408] Trial 295 finished with value: 0.8176369863013698 and parameters: {'d_model': 64, 'nhead': 8, 'n_encoders': 1, 'learning_rate': 9.374023057232532e-05, 'weight_decay': 2.1697125943877284e-06, 'dropout': 0.22213092134366463, 'max_pool_conv': 32, 'kernel_size': 14, 'd_mlp': 16, 'num_conv_layers': 6, 'encoder_dropout': 0.06994839964770945, 'd_feed_forward': 128, 'max_pool_dim': 8, 'n_mlp_layers': 3}. Best is trial 62 with value: 0.860445205479452.
Epoch: 0 0/3904 Training loss: 0.712182
Epoch: 0 800/3904 Training loss: 0.731006
Epoch: 0 1600/3904 Training loss: 0.420255
Epoch: 0 2400/3904 Training loss: 0.782242
Epoch: 0 3200/3904 Training loss: 0.567066
Training loss: 0.662585
Test loss: 0.808586; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 1 0/3904 Training loss: 0.707425
Epoch: 1 800/3904 Training loss: 0.736942
Epoch: 1 1600/3904 Training loss: 0.449385
Epoch: 1 2400/3904 Training loss: 0.786552
Epoch: 1 3200/3904 Training loss: 0.560176
Training loss: 0.660868
Test loss: 0.805144; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 2 0/3904 Training loss: 0.719270
Epoch: 2 800/3904 Training loss: 0.729747
Epoch: 2 1600/3904 Training loss: 0.473211
Epoch: 2 2400/3904 Training loss: 0.809802
Epoch: 2 3200/3904 Training loss: 0.559029
Training loss: 0.660549
Test loss: 0.804807; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 3 0/3904 Training loss: 0.719247
Epoch: 3 800/3904 Training loss: 0.738132
Epoch: 3 1600/3904 Training loss: 0.469915
Epoch: 3 2400/3904 Training loss: 0.812797
Epoch: 3 3200/3904 Training loss: 0.551725
Training loss: 0.659291
Test loss: 0.793352; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 4 0/3904 Training loss: 0.721952
Epoch: 4 800/3904 Training loss: 0.732233
Epoch: 4 1600/3904 Training loss: 0.463389
Epoch: 4 2400/3904 Training loss: 0.821293
Epoch: 4 3200/3904 Training loss: 0.550953
Training loss: 0.659020
Test loss: 0.798160; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 5 0/3904 Training loss: 0.719670
Epoch: 5 800/3904 Training loss: 0.737391
Epoch: 5 1600/3904 Training loss: 0.480003
Epoch: 5 2400/3904 Training loss: 0.817486
Epoch: 5 3200/3904 Training loss: 0.550993
Training loss: 0.659140
Test loss: 0.803625; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 6 0/3904 Training loss: 0.720521
Epoch: 6 800/3904 Training loss: 0.738514
Epoch: 6 1600/3904 Training loss: 0.485077
Epoch: 6 2400/3904 Training loss: 0.825832
Epoch: 6 3200/3904 Training loss: 0.553455
Training loss: 0.658592
Test loss: 0.799146; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 7 0/3904 Training loss: 0.729697
Epoch: 7 800/3904 Training loss: 0.746407
Epoch: 7 1600/3904 Training loss: 0.465665
Epoch: 7 2400/3904 Training loss: 0.826874
Epoch: 7 3200/3904 Training loss: 0.556314
Training loss: 0.658236
Test loss: 0.790550; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 8 0/3904 Training loss: 0.723588
Epoch: 8 800/3904 Training loss: 0.742971
Epoch: 8 1600/3904 Training loss: 0.474831
Epoch: 8 2400/3904 Training loss: 0.814263
Epoch: 8 3200/3904 Training loss: 0.540749
Training loss: 0.657999
Test loss: 0.786741; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 9 0/3904 Training loss: 0.726685
Epoch: 9 800/3904 Training loss: 0.734048
Epoch: 9 1600/3904 Training loss: 0.463483
Epoch: 9 2400/3904 Training loss: 0.801233
Epoch: 9 3200/3904 Training loss: 0.552166
Training loss: 0.657886
Test loss: 0.770089; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 10 0/3904 Training loss: 0.706779
Epoch: 10 800/3904 Training loss: 0.730306
Epoch: 10 1600/3904 Training loss: 0.462476
Epoch: 10 2400/3904 Training loss: 0.802217
Epoch: 10 3200/3904 Training loss: 0.550910
Training loss: 0.657055
Test loss: 0.768662; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 11 0/3904 Training loss: 0.706418
Epoch: 11 800/3904 Training loss: 0.739370
Epoch: 11 1600/3904 Training loss: 0.479562
Epoch: 11 2400/3904 Training loss: 0.795183
Epoch: 11 3200/3904 Training loss: 0.558157
Training loss: 0.656006
Test loss: 0.773211; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 12 0/3904 Training loss: 0.706402
Epoch: 12 800/3904 Training loss: 0.735817
Epoch: 12 1600/3904 Training loss: 0.439845
Epoch: 12 2400/3904 Training loss: 0.798985
Epoch: 12 3200/3904 Training loss: 0.568788
Training loss: 0.658282
Test loss: 0.764677; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 13 0/3904 Training loss: 0.713485
Epoch: 13 800/3904 Training loss: 0.723222
Epoch: 13 1600/3904 Training loss: 0.429129
Epoch: 13 2400/3904 Training loss: 0.789794
Epoch: 13 3200/3904 Training loss: 0.556385
Training loss: 0.655400
Test loss: 0.766261; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 14 0/3904 Training loss: 0.684436
Epoch: 14 800/3904 Training loss: 0.726268
Epoch: 14 1600/3904 Training loss: 0.419301
Epoch: 14 2400/3904 Training loss: 0.760020
Epoch: 14 3200/3904 Training loss: 0.533889
Training loss: 0.651098
Test loss: 0.773184; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 15 0/3904 Training loss: 0.677727
Epoch: 15 800/3904 Training loss: 0.725858
Epoch: 15 1600/3904 Training loss: 0.361517
Epoch: 15 2400/3904 Training loss: 0.737875
Epoch: 15 3200/3904 Training loss: 0.491484
Training loss: 0.637842
Test loss: 0.760655; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 16 0/3904 Training loss: 0.666611
Epoch: 16 800/3904 Training loss: 0.774985
Epoch: 16 1600/3904 Training loss: 0.292873
Epoch: 16 2400/3904 Training loss: 0.666606
Epoch: 16 3200/3904 Training loss: 0.521098
Training loss: 0.614308
Test loss: 0.722332; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 17 0/3904 Training loss: 0.564259
Epoch: 17 800/3904 Training loss: 0.749489
Epoch: 17 1600/3904 Training loss: 0.330667
Epoch: 17 2400/3904 Training loss: 0.612819
Epoch: 17 3200/3904 Training loss: 0.422908
Training loss: 0.603372
Test loss: 0.701917; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 18 0/3904 Training loss: 0.589902
Epoch: 18 800/3904 Training loss: 0.691002
Epoch: 18 1600/3904 Training loss: 0.320225
Epoch: 18 2400/3904 Training loss: 0.734574
Epoch: 18 3200/3904 Training loss: 0.409799
Training loss: 0.580955
Test loss: 0.732605; True positive: 786; True negative: 19, False Positive: 246, False negative: 117, accuracy: 0.6892123287671232, precision: 0.7616279069767442, recall: 0.8704318936877077
Epoch: 19 0/3904 Training loss: 0.626910
Epoch: 19 800/3904 Training loss: 0.695804
Epoch: 19 1600/3904 Training loss: 0.251398
Epoch: 19 2400/3904 Training loss: 0.820895
Epoch: 19 3200/3904 Training loss: 0.387310
Training loss: 0.564820
Test loss: 0.939370; True positive: 572; True negative: 58, False Positive: 207, False negative: 331, accuracy: 0.5393835616438356, precision: 0.7342747111681643, recall: 0.6334440753045404
Epoch: 20 0/3904 Training loss: 0.583198
Epoch: 20 800/3904 Training loss: 0.680126
Epoch: 20 1600/3904 Training loss: 0.249857
Epoch: 20 2400/3904 Training loss: 0.612255
Epoch: 20 3200/3904 Training loss: 0.407344
Training loss: 0.551307
Test loss: 0.785202; True positive: 748; True negative: 27, False Positive: 238, False negative: 155, accuracy: 0.663527397260274, precision: 0.7586206896551724, recall: 0.8283499446290143
Epoch: 21 0/3904 Training loss: 0.513683
Epoch: 21 800/3904 Training loss: 0.735343
Epoch: 21 1600/3904 Training loss: 0.280893
Epoch: 21 2400/3904 Training loss: 0.677068
Epoch: 21 3200/3904 Training loss: 0.462672
Training loss: 0.542485
Test loss: 0.643918; True positive: 871; True negative: 44, False Positive: 221, False negative: 32, accuracy: 0.7833904109589042, precision: 0.7976190476190477, recall: 0.964562569213732
Epoch: 22 0/3904 Training loss: 0.555668
Epoch: 22 800/3904 Training loss: 0.635313
Epoch: 22 1600/3904 Training loss: 0.253222
Epoch: 22 2400/3904 Training loss: 0.827511
Epoch: 22 3200/3904 Training loss: 0.439252
Training loss: 0.534053
Test loss: 1.711096; True positive: 89; True negative: 148, False Positive: 117, False negative: 814, accuracy: 0.2029109589041096, precision: 0.4320388349514563, recall: 0.09856035437430787
Epoch: 23 0/3904 Training loss: 0.467223
Epoch: 23 800/3904 Training loss: 0.601612
Epoch: 23 1600/3904 Training loss: 0.201656
Epoch: 23 2400/3904 Training loss: 0.750476
Epoch: 23 3200/3904 Training loss: 0.392545
Training loss: 0.520848
Test loss: 1.477469; True positive: 75; True negative: 140, False Positive: 125, False negative: 828, accuracy: 0.1840753424657534, precision: 0.375, recall: 0.08305647840531562
Epoch: 24 0/3904 Training loss: 0.468930
Epoch: 24 800/3904 Training loss: 0.506492
Epoch: 24 1600/3904 Training loss: 0.196059
Epoch: 24 2400/3904 Training loss: 0.655460
Epoch: 24 3200/3904 Training loss: 0.420625
Training loss: 0.500766
Test loss: 0.773078; True positive: 272; True negative: 90, False Positive: 175, False negative: 631, accuracy: 0.3099315068493151, precision: 0.6085011185682326, recall: 0.301218161683278
Epoch: 25 0/3904 Training loss: 0.487884
Epoch: 25 800/3904 Training loss: 0.648614
Epoch: 25 1600/3904 Training loss: 0.263516
Epoch: 25 2400/3904 Training loss: 0.720849
Epoch: 25 3200/3904 Training loss: 0.410312
Training loss: 0.491492
Test loss: 0.560211; True positive: 894; True negative: 2, False Positive: 263, False negative: 9, accuracy: 0.7671232876712328, precision: 0.7726879861711322, recall: 0.9900332225913622
Epoch: 26 0/3904 Training loss: 0.561880
Epoch: 26 800/3904 Training loss: 0.511217
Epoch: 26 1600/3904 Training loss: 0.242382
Epoch: 26 2400/3904 Training loss: 0.525324
Epoch: 26 3200/3904 Training loss: 0.375147
Training loss: 0.528415
Test loss: 0.590655; True positive: 903; True negative: 2, False Positive: 263, False negative: 0, accuracy: 0.7748287671232876, precision: 0.774442538593482, recall: 1.0
Epoch: 27 0/3904 Training loss: 0.662289
Epoch: 27 800/3904 Training loss: 0.480544
Epoch: 27 1600/3904 Training loss: 0.308128
Epoch: 27 2400/3904 Training loss: 0.552062
Epoch: 27 3200/3904 Training loss: 0.406093
Training loss: 0.529116
Test loss: 0.635846; True positive: 834; True negative: 43, False Positive: 222, False negative: 69, accuracy: 0.7508561643835616, precision: 0.7897727272727273, recall: 0.9235880398671097
Epoch: 28 0/3904 Training loss: 0.504414
Epoch: 28 800/3904 Training loss: 0.559350
Epoch: 28 1600/3904 Training loss: 0.180414
Epoch: 28 2400/3904 Training loss: 0.565991
Epoch: 28 3200/3904 Training loss: 0.485009
Training loss: 0.498852
Test loss: 1.567251; True positive: 117; True negative: 146, False Positive: 119, False negative: 786, accuracy: 0.22517123287671234, precision: 0.4957627118644068, recall: 0.12956810631229235
Epoch: 29 0/3904 Training loss: 0.461827
Epoch: 29 800/3904 Training loss: 0.474418
Epoch: 29 1600/3904 Training loss: 0.228642
Epoch: 29 2400/3904 Training loss: 0.515145
Epoch: 29 3200/3904 Training loss: 0.456063
Training loss: 0.479895
Test loss: 1.355294; True positive: 163; True negative: 146, False Positive: 119, False negative: 740, accuracy: 0.2645547945205479, precision: 0.5780141843971631, recall: 0.1805094130675526
starting trial 297
[I 2022-12-05 09:00:05,521] Trial 296 finished with value: 0.7833904109589042 and parameters: {'d_model': 64, 'nhead': 8, 'n_encoders': 1, 'learning_rate': 0.0006606246421001598, 'weight_decay': 3.2379494985880667e-06, 'dropout': 0.20990287149883266, 'max_pool_conv': 64, 'kernel_size': 28, 'd_mlp': 16, 'num_conv_layers': 4, 'encoder_dropout': 0.11207004564470986, 'd_feed_forward': 128, 'max_pool_dim': 16, 'n_mlp_layers': 3}. Best is trial 62 with value: 0.860445205479452.
Epoch: 0 0/3904 Training loss: 0.698434
Epoch: 0 800/3904 Training loss: 0.733302
Epoch: 0 1600/3904 Training loss: 0.422983
Epoch: 0 2400/3904 Training loss: 0.754538
Epoch: 0 3200/3904 Training loss: 0.523569
Training loss: 0.657645
Test loss: 0.717337; True positive: 65; True negative: 148, False Positive: 117, False negative: 838, accuracy: 0.18236301369863014, precision: 0.35714285714285715, recall: 0.07198228128460686
Epoch: 1 0/3904 Training loss: 0.693311
Epoch: 1 800/3904 Training loss: 0.688950
Epoch: 1 1600/3904 Training loss: 0.271153
Epoch: 1 2400/3904 Training loss: 0.724792
Epoch: 1 3200/3904 Training loss: 0.391986
Training loss: 0.582165
Test loss: 0.662141; True positive: 903; True negative: 0, False Positive: 265, False negative: 0, accuracy: 0.7731164383561644, precision: 0.7731164383561644, recall: 1.0
Epoch: 2 0/3904 Training loss: 0.494367
Epoch: 2 800/3904 Training loss: 0.494011
Epoch: 2 1600/3904 Training loss: 0.218926
Epoch: 2 2400/3904 Training loss: 0.560510
Epoch: 2 3200/3904 Training loss: 0.338550
Training loss: 0.466083
Test loss: 0.612851; True positive: 903; True negative: 0, False Positive: 265, False negative: 0, accuracy: 0.7731164383561644, precision: 0.7731164383561644, recall: 1.0
Epoch: 3 0/3904 Training loss: 0.390684
Epoch: 3 800/3904 Training loss: 0.335769
Epoch: 3 1600/3904 Training loss: 0.182539
Epoch: 3 2400/3904 Training loss: 0.537661
Epoch: 3 3200/3904 Training loss: 0.300021
Training loss: 0.410498
Test loss: 0.598683; True positive: 903; True negative: 0, False Positive: 265, False negative: 0, accuracy: 0.7731164383561644, precision: 0.7731164383561644, recall: 1.0
Epoch: 4 0/3904 Training loss: 0.337517
Epoch: 4 800/3904 Training loss: 0.391909
Epoch: 4 1600/3904 Training loss: 0.145039
Epoch: 4 2400/3904 Training loss: 0.400334
Epoch: 4 3200/3904 Training loss: 0.331121
Training loss: 0.372716
Test loss: 0.629908; True positive: 887; True negative: 6, False Positive: 259, False negative: 16, accuracy: 0.764554794520548, precision: 0.7739965095986039, recall: 0.982281284606866
Epoch: 5 0/3904 Training loss: 0.250978
Epoch: 5 800/3904 Training loss: 0.146849
Epoch: 5 1600/3904 Training loss: 0.152284
Epoch: 5 2400/3904 Training loss: 0.485105
Epoch: 5 3200/3904 Training loss: 0.308026
Training loss: 0.331871
Test loss: 0.586223; True positive: 895; True negative: 3, False Positive: 262, False negative: 8, accuracy: 0.7688356164383562, precision: 0.773552290406223, recall: 0.991140642303433
Epoch: 6 0/3904 Training loss: 0.298807
Epoch: 6 800/3904 Training loss: 0.227256
Epoch: 6 1600/3904 Training loss: 0.174861
Epoch: 6 2400/3904 Training loss: 0.499883
Epoch: 6 3200/3904 Training loss: 0.359564
Training loss: 0.294915
Test loss: 0.543305; True positive: 903; True negative: 0, False Positive: 265, False negative: 0, accuracy: 0.7731164383561644, precision: 0.7731164383561644, recall: 1.0
Epoch: 7 0/3904 Training loss: 0.392763
Epoch: 7 800/3904 Training loss: 0.088724
Epoch: 7 1600/3904 Training loss: 0.143280
Epoch: 7 2400/3904 Training loss: 0.241604
Epoch: 7 3200/3904 Training loss: 0.253279
Training loss: 0.263977
Test loss: 0.867918; True positive: 115; True negative: 248, False Positive: 17, False negative: 788, accuracy: 0.3107876712328767, precision: 0.8712121212121212, recall: 0.1273532668881506
Epoch: 8 0/3904 Training loss: 0.237336
Epoch: 8 800/3904 Training loss: 0.150399
Epoch: 8 1600/3904 Training loss: 0.072740
Epoch: 8 2400/3904 Training loss: 0.209772
Epoch: 8 3200/3904 Training loss: 0.250689
Training loss: 0.247218
Test loss: 0.936381; True positive: 102; True negative: 142, False Positive: 123, False negative: 801, accuracy: 0.2089041095890411, precision: 0.4533333333333333, recall: 0.11295681063122924
Epoch: 9 0/3904 Training loss: 0.183688
Epoch: 9 800/3904 Training loss: 0.108906
Epoch: 9 1600/3904 Training loss: 0.100056
Epoch: 9 2400/3904 Training loss: 0.252651
Epoch: 9 3200/3904 Training loss: 0.192640
Training loss: 0.226918
Test loss: 1.045920; True positive: 0; True negative: 263, False Positive: 2, False negative: 903, accuracy: 0.22517123287671234, precision: 0.0, recall: 0.0
Epoch: 10 0/3904 Training loss: 0.175512
Epoch: 10 800/3904 Training loss: 0.051261
Epoch: 10 1600/3904 Training loss: 0.131159
Epoch: 10 2400/3904 Training loss: 0.180390
Epoch: 10 3200/3904 Training loss: 0.237955
Training loss: 0.213262
Test loss: 0.969040; True positive: 9; True negative: 253, False Positive: 12, False negative: 894, accuracy: 0.2243150684931507, precision: 0.42857142857142855, recall: 0.009966777408637873
Epoch: 11 0/3904 Training loss: 0.177132
Epoch: 11 800/3904 Training loss: 0.069948
Epoch: 11 1600/3904 Training loss: 0.083550
Epoch: 11 2400/3904 Training loss: 0.109948
Epoch: 11 3200/3904 Training loss: 0.140221
Training loss: 0.199812
Test loss: 0.891980; True positive: 47; True negative: 256, False Positive: 9, False negative: 856, accuracy: 0.2594178082191781, precision: 0.8392857142857143, recall: 0.05204872646733112
Epoch: 12 0/3904 Training loss: 0.155565
Epoch: 12 800/3904 Training loss: 0.058283
Epoch: 12 1600/3904 Training loss: 0.067550
Epoch: 12 2400/3904 Training loss: 0.193638
Epoch: 12 3200/3904 Training loss: 0.244285
Training loss: 0.190493
Test loss: 0.979734; True positive: 22; True negative: 260, False Positive: 5, False negative: 881, accuracy: 0.24143835616438356, precision: 0.8148148148148148, recall: 0.024363233665559248
Epoch: 13 0/3904 Training loss: 0.155888
Epoch: 13 800/3904 Training loss: 0.050374
Epoch: 13 1600/3904 Training loss: 0.064642
Epoch: 13 2400/3904 Training loss: 0.096276
Epoch: 13 3200/3904 Training loss: 0.149016
Training loss: 0.175922
Test loss: 0.586043; True positive: 793; True negative: 32, False Positive: 233, False negative: 110, accuracy: 0.7063356164383562, precision: 0.7729044834307992, recall: 0.8781838316722038
Epoch: 14 0/3904 Training loss: 0.059851
Epoch: 14 800/3904 Training loss: 0.033530
Epoch: 14 1600/3904 Training loss: 0.037375
Epoch: 14 2400/3904 Training loss: 0.109683
Epoch: 14 3200/3904 Training loss: 0.104353
Training loss: 0.164272
Test loss: 1.259952; True positive: 2; True negative: 264, False Positive: 1, False negative: 901, accuracy: 0.22773972602739725, precision: 0.6666666666666666, recall: 0.0022148394241417496
Epoch: 15 0/3904 Training loss: 0.237540
Epoch: 15 800/3904 Training loss: 0.049982
Epoch: 15 1600/3904 Training loss: 0.053708
Epoch: 15 2400/3904 Training loss: 0.087638
Epoch: 15 3200/3904 Training loss: 0.141863
Training loss: 0.149260
Test loss: 1.195757; True positive: 40; True negative: 228, False Positive: 37, False negative: 863, accuracy: 0.22945205479452055, precision: 0.5194805194805194, recall: 0.044296788482835
Epoch: 16 0/3904 Training loss: 0.127726
Epoch: 16 800/3904 Training loss: 0.036791
Epoch: 16 1600/3904 Training loss: 0.049571
Epoch: 16 2400/3904 Training loss: 0.090010
Epoch: 16 3200/3904 Training loss: 0.175379
Training loss: 0.139723
Test loss: 1.482132; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
starting trial 298
[I 2022-12-05 09:01:11,605] Trial 297 finished with value: 0.7731164383561644 and parameters: {'d_model': 64, 'nhead': 4, 'n_encoders': 1, 'learning_rate': 0.00016113117846509322, 'weight_decay': 4.254478585793674e-06, 'dropout': 0.16985866557869755, 'max_pool_conv': 32, 'kernel_size': 12, 'd_mlp': 62, 'num_conv_layers': 2, 'encoder_dropout': 0.10313783723747584, 'd_feed_forward': 128, 'max_pool_dim': 8, 'n_mlp_layers': 4}. Best is trial 62 with value: 0.860445205479452.
Epoch: 0 0/3904 Training loss: 0.702669
Epoch: 0 800/3904 Training loss: 0.720312
Epoch: 0 1600/3904 Training loss: 0.517566
Epoch: 0 2400/3904 Training loss: 0.812401
Epoch: 0 3200/3904 Training loss: 0.560107
Training loss: 0.664553
Test loss: 0.844806; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 1 0/3904 Training loss: 0.721929
Epoch: 1 800/3904 Training loss: 0.750482
Epoch: 1 1600/3904 Training loss: 0.467213
Epoch: 1 2400/3904 Training loss: 0.816478
Epoch: 1 3200/3904 Training loss: 0.524062
Training loss: 0.652541
Test loss: 0.768302; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 2 0/3904 Training loss: 0.700136
Epoch: 2 800/3904 Training loss: 0.705744
Epoch: 2 1600/3904 Training loss: 0.392307
Epoch: 2 2400/3904 Training loss: 0.780144
Epoch: 2 3200/3904 Training loss: 0.467106
Training loss: 0.618534
Test loss: 0.694767; True positive: 568; True negative: 92, False Positive: 173, False negative: 335, accuracy: 0.565068493150685, precision: 0.766531713900135, recall: 0.6290143964562569
Epoch: 3 0/3904 Training loss: 0.630812
Epoch: 3 800/3904 Training loss: 0.644141
Epoch: 3 1600/3904 Training loss: 0.364082
Epoch: 3 2400/3904 Training loss: 1.057567
Epoch: 3 3200/3904 Training loss: 0.397691
Training loss: 0.563290
Test loss: 0.816997; True positive: 65; True negative: 148, False Positive: 117, False negative: 838, accuracy: 0.18236301369863014, precision: 0.35714285714285715, recall: 0.07198228128460686
Epoch: 4 0/3904 Training loss: 0.612093
Epoch: 4 800/3904 Training loss: 0.679660
Epoch: 4 1600/3904 Training loss: 0.278532
Epoch: 4 2400/3904 Training loss: 0.965956
Epoch: 4 3200/3904 Training loss: 0.445909
Training loss: 0.518257
Test loss: 0.986920; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 5 0/3904 Training loss: 0.446583
Epoch: 5 800/3904 Training loss: 0.554888
Epoch: 5 1600/3904 Training loss: 0.235608
Epoch: 5 2400/3904 Training loss: 0.793242
Epoch: 5 3200/3904 Training loss: 0.359115
Training loss: 0.479483
Test loss: 1.037990; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 6 0/3904 Training loss: 0.475029
Epoch: 6 800/3904 Training loss: 0.586432
Epoch: 6 1600/3904 Training loss: 0.190419
Epoch: 6 2400/3904 Training loss: 0.896051
Epoch: 6 3200/3904 Training loss: 0.290305
Training loss: 0.454847
Test loss: 1.025564; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 7 0/3904 Training loss: 0.418690
Epoch: 7 800/3904 Training loss: 0.421258
Epoch: 7 1600/3904 Training loss: 0.231032
Epoch: 7 2400/3904 Training loss: 0.799176
Epoch: 7 3200/3904 Training loss: 0.401239
Training loss: 0.442699
Test loss: 0.994077; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 8 0/3904 Training loss: 0.357176
Epoch: 8 800/3904 Training loss: 0.459669
Epoch: 8 1600/3904 Training loss: 0.194469
Epoch: 8 2400/3904 Training loss: 0.577022
Epoch: 8 3200/3904 Training loss: 0.420266
Training loss: 0.411321
Test loss: 0.923327; True positive: 6; True negative: 265, False Positive: 0, False negative: 897, accuracy: 0.2320205479452055, precision: 1.0, recall: 0.006644518272425249
Epoch: 9 0/3904 Training loss: 0.328284
Epoch: 9 800/3904 Training loss: 0.532191
Epoch: 9 1600/3904 Training loss: 0.177658
Epoch: 9 2400/3904 Training loss: 0.615271
Epoch: 9 3200/3904 Training loss: 0.333112
Training loss: 0.396629
Test loss: 1.009261; True positive: 1; True negative: 265, False Positive: 0, False negative: 902, accuracy: 0.22773972602739725, precision: 1.0, recall: 0.0011074197120708748
Epoch: 10 0/3904 Training loss: 0.400636
Epoch: 10 800/3904 Training loss: 0.372813
Epoch: 10 1600/3904 Training loss: 0.247371
Epoch: 10 2400/3904 Training loss: 0.483295
Epoch: 10 3200/3904 Training loss: 0.410050
Training loss: 0.387025
Test loss: 1.003678; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 11 0/3904 Training loss: 0.387526
Epoch: 11 800/3904 Training loss: 0.408381
Epoch: 11 1600/3904 Training loss: 0.244422
Epoch: 11 2400/3904 Training loss: 0.681788
Epoch: 11 3200/3904 Training loss: 0.391961
Training loss: 0.374995
Test loss: 1.048521; True positive: 1; True negative: 265, False Positive: 0, False negative: 902, accuracy: 0.22773972602739725, precision: 1.0, recall: 0.0011074197120708748
Epoch: 12 0/3904 Training loss: 0.263147
Epoch: 12 800/3904 Training loss: 0.570234
Epoch: 12 1600/3904 Training loss: 0.244537
Epoch: 12 2400/3904 Training loss: 0.535622
Epoch: 12 3200/3904 Training loss: 0.316523
Training loss: 0.362885
Test loss: 0.692739; True positive: 438; True negative: 250, False Positive: 15, False negative: 465, accuracy: 0.589041095890411, precision: 0.9668874172185431, recall: 0.4850498338870432
Epoch: 13 0/3904 Training loss: 0.371971
Epoch: 13 800/3904 Training loss: 0.520829
Epoch: 13 1600/3904 Training loss: 0.204013
Epoch: 13 2400/3904 Training loss: 0.532239
Epoch: 13 3200/3904 Training loss: 0.426193
Training loss: 0.351058
Test loss: 0.893865; True positive: 3; True negative: 265, False Positive: 0, False negative: 900, accuracy: 0.22945205479452055, precision: 1.0, recall: 0.0033222591362126247
Epoch: 14 0/3904 Training loss: 0.413096
Epoch: 14 800/3904 Training loss: 0.353402
Epoch: 14 1600/3904 Training loss: 0.141224
Epoch: 14 2400/3904 Training loss: 0.447016
Epoch: 14 3200/3904 Training loss: 0.436519
Training loss: 0.344586
Test loss: 0.998708; True positive: 2; True negative: 265, False Positive: 0, False negative: 901, accuracy: 0.2285958904109589, precision: 1.0, recall: 0.0022148394241417496
Epoch: 15 0/3904 Training loss: 0.291746
Epoch: 15 800/3904 Training loss: 0.583978
Epoch: 15 1600/3904 Training loss: 0.123175
Epoch: 15 2400/3904 Training loss: 0.425609
Epoch: 15 3200/3904 Training loss: 0.411458
Training loss: 0.334388
Test loss: 1.034292; True positive: 1; True negative: 265, False Positive: 0, False negative: 902, accuracy: 0.22773972602739725, precision: 1.0, recall: 0.0011074197120708748
Epoch: 16 0/3904 Training loss: 0.344532
Epoch: 16 800/3904 Training loss: 0.192582
Epoch: 16 1600/3904 Training loss: 0.292019
Epoch: 16 2400/3904 Training loss: 0.459566
Epoch: 16 3200/3904 Training loss: 0.282053
Training loss: 0.329905
Test loss: 0.957771; True positive: 2; True negative: 265, False Positive: 0, False negative: 901, accuracy: 0.2285958904109589, precision: 1.0, recall: 0.0022148394241417496
Epoch: 17 0/3904 Training loss: 0.434550
Epoch: 17 800/3904 Training loss: 0.249072
Epoch: 17 1600/3904 Training loss: 0.197132
Epoch: 17 2400/3904 Training loss: 0.464386
Epoch: 17 3200/3904 Training loss: 0.448223
Training loss: 0.337270
Test loss: 1.126700; True positive: 1; True negative: 265, False Positive: 0, False negative: 902, accuracy: 0.22773972602739725, precision: 1.0, recall: 0.0011074197120708748
Epoch: 18 0/3904 Training loss: 0.267897
Epoch: 18 800/3904 Training loss: 0.225429
Epoch: 18 1600/3904 Training loss: 0.088742
Epoch: 18 2400/3904 Training loss: 0.380804
Epoch: 18 3200/3904 Training loss: 0.318451
Training loss: 0.304358
Test loss: 1.347336; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 19 0/3904 Training loss: 0.264392
Epoch: 19 800/3904 Training loss: 0.432892
Epoch: 19 1600/3904 Training loss: 0.152693
Epoch: 19 2400/3904 Training loss: 0.371948
Epoch: 19 3200/3904 Training loss: 0.464676
Training loss: 0.312028
Test loss: 1.374148; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 20 0/3904 Training loss: 0.279838
Epoch: 20 800/3904 Training loss: 0.197662
Epoch: 20 1600/3904 Training loss: 0.099968
Epoch: 20 2400/3904 Training loss: 0.553664
Epoch: 20 3200/3904 Training loss: 0.524310
Training loss: 0.307244
Test loss: 1.423011; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 21 0/3904 Training loss: 0.283469
Epoch: 21 800/3904 Training loss: 0.288420
Epoch: 21 1600/3904 Training loss: 0.122555
Epoch: 21 2400/3904 Training loss: 0.365617
Epoch: 21 3200/3904 Training loss: 0.403204
Training loss: 0.302356
Test loss: 1.488309; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 22 0/3904 Training loss: 0.329031
Epoch: 22 800/3904 Training loss: 0.264792
Epoch: 22 1600/3904 Training loss: 0.119696
Epoch: 22 2400/3904 Training loss: 0.461012
Epoch: 22 3200/3904 Training loss: 0.443653
Training loss: 0.286369
Test loss: 1.546430; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
starting trial 299
[I 2022-12-05 09:02:28,505] Trial 298 finished with value: 0.589041095890411 and parameters: {'d_model': 16, 'nhead': 8, 'n_encoders': 2, 'learning_rate': 0.00014004037763932863, 'weight_decay': 1.8691906339975431e-06, 'dropout': 0.21311761524481532, 'max_pool_conv': 128, 'kernel_size': 10, 'd_mlp': 32, 'num_conv_layers': 3, 'encoder_dropout': 0.016993110767631738, 'd_feed_forward': 256, 'max_pool_dim': 8, 'n_mlp_layers': 3}. Best is trial 62 with value: 0.860445205479452.
Epoch: 0 0/3904 Training loss: 0.705112
Epoch: 0 800/3904 Training loss: 0.689592
Epoch: 0 1600/3904 Training loss: 0.522122
Epoch: 0 2400/3904 Training loss: 0.758621
Epoch: 0 3200/3904 Training loss: 0.559195
Training loss: 0.672174
Test loss: 0.729532; True positive: 0; True negative: 265, False Positive: 0, False negative: 903, accuracy: 0.2268835616438356, precision: 0, recall: 0.0
Epoch: 1 0/3904 Training loss: 0.686283
Epoch: 1 800/3904 Training loss: 0.687377
Epoch: 1 1600/3904 Training loss: 0.429252
Epoch: 1 2400/3904 Training loss: 0.669168
Epoch: 1 3200/3904 Training loss: 0.481580
Training loss: 0.602318
Test loss: 0.547096; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 2 0/3904 Training loss: 0.522237
Epoch: 2 800/3904 Training loss: 0.495526
Epoch: 2 1600/3904 Training loss: 0.262746
Epoch: 2 2400/3904 Training loss: 0.704630
Epoch: 2 3200/3904 Training loss: 0.386829
Training loss: 0.469288
Test loss: 0.536859; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 3 0/3904 Training loss: 0.315295
Epoch: 3 800/3904 Training loss: 0.315185
Epoch: 3 1600/3904 Training loss: 0.253220
Epoch: 3 2400/3904 Training loss: 0.725600
Epoch: 3 3200/3904 Training loss: 0.367187
Training loss: 0.389304
Test loss: 0.514557; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 4 0/3904 Training loss: 0.340704
Epoch: 4 800/3904 Training loss: 0.281554
Epoch: 4 1600/3904 Training loss: 0.260274
Epoch: 4 2400/3904 Training loss: 0.577508
Epoch: 4 3200/3904 Training loss: 0.365248
Training loss: 0.344686
Test loss: 0.492010; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 5 0/3904 Training loss: 0.240626
Epoch: 5 800/3904 Training loss: 0.334547
Epoch: 5 1600/3904 Training loss: 0.124404
Epoch: 5 2400/3904 Training loss: 0.451165
Epoch: 5 3200/3904 Training loss: 0.502197
Training loss: 0.305298
Test loss: 0.510658; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 6 0/3904 Training loss: 0.185365
Epoch: 6 800/3904 Training loss: 0.215311
Epoch: 6 1600/3904 Training loss: 0.167175
Epoch: 6 2400/3904 Training loss: 0.533768
Epoch: 6 3200/3904 Training loss: 0.360248
Training loss: 0.285345
Test loss: 0.504456; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 7 0/3904 Training loss: 0.364502
Epoch: 7 800/3904 Training loss: 0.163712
Epoch: 7 1600/3904 Training loss: 0.130135
Epoch: 7 2400/3904 Training loss: 0.401812
Epoch: 7 3200/3904 Training loss: 0.396814
Training loss: 0.261604
Test loss: 0.495793; True positive: 838; True negative: 117, False Positive: 148, False negative: 65, accuracy: 0.8176369863013698, precision: 0.8498985801217038, recall: 0.9280177187153932
Epoch: 8 0/3904 Training loss: 0.270250
Epoch: 8 800/3904 Training loss: 0.216925
Epoch: 8 1600/3904 Training loss: 0.105692
Epoch: 8 2400/3904 Training loss: 0.446298
Epoch: 8 3200/3904 Training loss: 0.427486
Training loss: 0.248864
Test loss: 0.943158; True positive: 11; True negative: 260, False Positive: 5, False negative: 892, accuracy: 0.2320205479452055, precision: 0.6875, recall: 0.012181616832779624
Epoch: 9 0/3904 Training loss: 0.247416
Epoch: 9 800/3904 Training loss: 0.239354
Epoch: 9 1600/3904 Training loss: 0.190451
Epoch: 9 2400/3904 Training loss: 0.460087
Epoch: 9 3200/3904 Training loss: 0.282165
Training loss: 0.241247
Test loss: 0.767412; True positive: 129; True negative: 238, False Positive: 27, False negative: 774, accuracy: 0.3142123287671233, precision: 0.8269230769230769, recall: 0.14285714285714285
Epoch: 10 0/3904 Training loss: 0.423559
Epoch: 10 800/3904 Training loss: 0.150637
Epoch: 10 1600/3904 Training loss: 0.082945
Epoch: 10 2400/3904 Training loss: 0.294102
Epoch: 10 3200/3904 Training loss: 0.297066
Training loss: 0.223286
Test loss: 0.709300; True positive: 428; True negative: 185, False Positive: 80, False negative: 475, accuracy: 0.5248287671232876, precision: 0.84251968503937, recall: 0.4739756367663344
Epoch: 11 0/3904 Training loss: 0.237472
Epoch: 11 800/3904 Training loss: 0.125837
Epoch: 11 1600/3904 Training loss: 0.127734
Epoch: 11 2400/3904 Training loss: 0.118239
Epoch: 11 3200/3904 Training loss: 0.390669
Training loss: 0.215915
Test loss: 0.614338; True positive: 790; True negative: 132, False Positive: 133, False negative: 113, accuracy: 0.7893835616438356, precision: 0.8559046587215602, recall: 0.8748615725359912
Epoch: 12 0/3904 Training loss: 0.108340
Epoch: 12 800/3904 Training loss: 0.136881
Epoch: 12 1600/3904 Training loss: 0.082222
Epoch: 12 2400/3904 Training loss: 0.154240
Epoch: 12 3200/3904 Training loss: 0.381398
Training loss: 0.203002
Test loss: 0.631043; True positive: 730; True negative: 161, False Positive: 104, False negative: 173, accuracy: 0.7628424657534246, precision: 0.8752997601918465, recall: 0.8084163898117387
Epoch: 13 0/3904 Training loss: 0.364184
Epoch: 13 800/3904 Training loss: 0.332162
Epoch: 13 1600/3904 Training loss: 0.171165
Epoch: 13 2400/3904 Training loss: 0.181353
Epoch: 13 3200/3904 Training loss: 0.236883
Training loss: 0.196762
Test loss: 0.651435; True positive: 750; True negative: 144, False Positive: 121, False negative: 153, accuracy: 0.7654109589041096, precision: 0.8610792192881745, recall: 0.8305647840531561
Epoch: 14 0/3904 Training loss: 0.326281
Epoch: 14 800/3904 Training loss: 0.062605
Epoch: 14 1600/3904 Training loss: 0.089563
Epoch: 14 2400/3904 Training loss: 0.230482
Epoch: 14 3200/3904 Training loss: 0.338732
Training loss: 0.190467
Test loss: 0.688685; True positive: 573; True negative: 167, False Positive: 98, False negative: 330, accuracy: 0.6335616438356164, precision: 0.8539493293591655, recall: 0.6345514950166113
Study statistics: 
[I 2022-12-05 09:03:40,235] Trial 299 finished with value: 0.8176369863013698 and parameters: {'d_model': 64, 'nhead': 8, 'n_encoders': 1, 'learning_rate': 0.00012349258683740216, 'weight_decay': 3.631032577140749e-06, 'dropout': 0.3163110785598671, 'max_pool_conv': 64, 'kernel_size': 18, 'd_mlp': 16, 'num_conv_layers': 2, 'encoder_dropout': 0.05100931911943837, 'd_feed_forward': 128, 'max_pool_dim': 8, 'n_mlp_layers': 3}. Best is trial 62 with value: 0.860445205479452.
  Number of finished trials:  300
  Number of pruned trials:  0
  Number of complete trials:  300
Best trial:
  Value:  0.860445205479452
  Params: 
    d_model: 16
    nhead: 8
    n_encoders: 1
    learning_rate: 0.00029211988558292576
    weight_decay: 4.3438033182491795e-06
    dropout: 0.16768967022680045
    max_pool_conv: 64
    kernel_size: 6
    d_mlp: 16
    num_conv_layers: 2
    encoder_dropout: 0.03501255714864188
    d_feed_forward: 128
    max_pool_dim: 8
    n_mlp_layers: 3
kernel_size, 24.828577685584545
learning_rate, 15.177184438491825
dropout, 15.173936368476323
encoder_dropout, 8.46692807250212
max_pool_conv, 8.14415470389487
max_pool_dim, 7.088344771043609
nhead, 4.501752529989207
num_conv_layers, 4.332022725700451
d_model, 3.6645109668424305
weight_decay, 3.310939923849951
d_feed_forward, 1.7450011401349614
d_mlp, 1.6036015163918251
n_encoders, 1.4233729559262902
n_mlp_layers, 0.5396722011715832
