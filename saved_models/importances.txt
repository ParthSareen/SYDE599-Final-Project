kernel_size, 0.24828577685584546learning_rate, 0.15177184438491825dropout, 0.15173936368476323encoder_dropout, 0.0846692807250212max_pool_conv, 0.0814415470389487max_pool_dim, 0.07088344771043609nhead, 0.045017525299892065num_conv_layers, 0.04332022725700451d_model, 0.036645109668424304weight_decay, 0.03310939923849951d_feed_forward, 0.017450011401349615d_mlp, 0.01603601516391825n_encoders, 0.014233729559262902n_mlp_layers, 0.005396722011715832